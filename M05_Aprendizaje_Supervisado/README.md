# MÃ³dulo 05: Aprendizaje Supervisado

> **Semanas:** 9-11 | **Fase:** ML Core â­ | **Curso Alineado:** CSCA 5622

---

## ğŸ“ Estructura

```
M05_Aprendizaje_Supervisado/
â”œâ”€â”€ Teoria/
â”‚   â”œâ”€â”€ 01_regresion_lineal.md
â”‚   â”œâ”€â”€ 02_regresion_logistica.md
â”‚   â”œâ”€â”€ 03_regularizacion_l1_l2.md
â”‚   â”œâ”€â”€ 04_arboles_ensembles.md
â”‚   â””â”€â”€ 05_etica_xai.md                    # NUEVO: Ã‰tica e Interpretabilidad
â”œâ”€â”€ Notebooks/
â”‚   â”œâ”€â”€ 01_regresion_lineal_scratch.ipynb
â”‚   â”œâ”€â”€ 01b_regresion_lineal_sklearn.ipynb # NUEVO: Paridad Scikit-Learn
â”‚   â”œâ”€â”€ 02_regresion_logistica_scratch.ipynb
â”‚   â”œâ”€â”€ 02b_regresion_logistica_sklearn.ipynb
â”‚   â”œâ”€â”€ 03_regularizacion.ipynb
â”‚   â”œâ”€â”€ 04_arboles_decision_scratch.ipynb
â”‚   â”œâ”€â”€ 04b_arboles_ensembles_sklearn.ipynb
â”‚   â””â”€â”€ 05_shap_lime_interpretabilidad.ipynb # NUEVO: XAI
â”œâ”€â”€ Laboratorios_Interactivos/
â”‚   â”œâ”€â”€ overfitting_bias_variance_app.py
â”‚   â”œâ”€â”€ visualizacion_regresion.py
â”‚   â””â”€â”€ shap_explainer_app.py              # NUEVO
â””â”€â”€ assets/
```

---

## ğŸ¯ Objetivos de Aprendizaje

### Semana 9-10: Modelos Lineales (From Scratch â†’ Production Ready)

| Objetivo | Criterio de Ã‰xito |
|----------|-------------------|
| Implementar regresiÃ³n lineal desde cero | Normal Equation + Gradient Descent funcionando |
| Implementar regresiÃ³n logÃ­stica desde cero | Cross-Entropy loss convergiendo |
| **Replicar resultados con Scikit-Learn** | Coeficientes coinciden Â±0.01 con `sklearn.linear_model` |
| Dominar regularizaciÃ³n L1/L2 | Explicar trade-off bias-variance con ejemplos |

### Semana 10: Ãrboles y Ensembles

| Objetivo | Criterio de Ã‰xito |
|----------|-------------------|
| Implementar Ã¡rbol de decisiÃ³n desde cero | Information Gain / Gini funcionando |
| **Usar `sklearn.tree` y `sklearn.ensemble`** | Random Forest con GridSearchCV |
| Entender bagging vs boosting | Comparar RF vs XGBoost en dataset real |

### Semana 11: Ã‰tica en IA e Interpretabilidad (XAI) ğŸ†•

| Objetivo | Criterio de Ã‰xito |
|----------|-------------------|
| Comprender sesgo algorÃ­tmico (Bias/Fairness) | Identificar bias en dataset COMPAS o similar |
| Implementar SHAP values | Explicar predicciones de modelo de caja negra |
| Implementar LIME | Generar explicaciones locales interpretables |
| Documentar consideraciones Ã©ticas | Checklist de fairness para modelos ML |

---

## ğŸ“š Lecturas Obligatorias (Semana 11 - Ã‰tica)

1. **"Machine Bias" (ProPublica)** - Caso COMPAS y sesgo racial
2. **DocumentaciÃ³n SHAP** - https://shap.readthedocs.io/
3. **"Fairness and Machine Learning" (Barocas & Hardt)** - CapÃ­tulos 1-2

---

## âš¡ Inicio RÃ¡pido

```bash
# Semana 9: RegresiÃ³n Lineal
jupyter notebook Notebooks/01_regresion_lineal_scratch.ipynb
jupyter notebook Notebooks/01b_regresion_lineal_sklearn.ipynb  # Validar paridad

# Semana 10: Ãrboles
jupyter notebook Notebooks/04_arboles_decision_scratch.ipynb
jupyter notebook Notebooks/04b_arboles_ensembles_sklearn.ipynb

# Semana 11: Ã‰tica y XAI
jupyter notebook Notebooks/05_shap_lime_interpretabilidad.ipynb
streamlit run Laboratorios_Interactivos/shap_explainer_app.py
```

---

## âœ… Entregables del MÃ³dulo

- [ ] `linear_regression.py` con tests (from scratch)
- [ ] `logistic_regression.py` con tests (from scratch)
- [ ] Notebook de paridad: resultados manuales == sklearn
- [ ] `decision_tree.py` con tests (from scratch)
- [ ] AnÃ¡lisis SHAP de un modelo Random Forest
- [ ] Documento de reflexiÃ³n Ã©tica (500 palabras)

---

## ğŸ”— NavegaciÃ³n

| Anterior | Ãndice | Siguiente |
|----------|--------|-----------|
| [M04 Probabilidad](../M04_Probabilidad_Estadistica/) | [README](../README.md) | [M06 No Supervisado â†’](../M06_Aprendizaje_No_Supervisado/) |
