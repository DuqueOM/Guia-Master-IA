# MÃ³dulo 03 - CÃ¡lculo Multivariante para Deep Learning

> **ğŸ¯ Objetivo:** Dominar derivadas, gradientes y la Chain Rule para entender Backpropagation
> **Fase:** 1 - Fundamentos MatemÃ¡ticos | **Semanas 6-8**
> **Prerrequisitos:** MÃ³dulo 02 (Ãlgebra Lineal para ML)

---

<a id="m03-0"></a>

## ğŸ§­ CÃ³mo usar este mÃ³dulo (modo 0â†’100)

**PropÃ³sito:** que puedas hacer 3 cosas sin depender de â€œfeâ€:

- derivar gradientes de pÃ©rdidas comunes (MSE, BCE)
- implementar y depurar optimizaciÃ³n (gradient descent)
- entender por quÃ© backprop es chain rule aplicada a un grafo

### Objetivos de aprendizaje (medibles)

Al terminar este mÃ³dulo podrÃ¡s:

- **Calcular** derivadas y derivadas parciales (a mano y con verificaciÃ³n numÃ©rica).
- **Aplicar** gradiente y direcciÃ³n de mÃ¡ximo descenso para optimizar funciones.
- **Implementar** gradient descent con criterios de convergencia razonables.
- **Explicar** la Chain Rule y usarla para derivar gradientes compuestos.
- **Validar** derivadas con gradient checking (error relativo pequeÃ±o).

### Prerrequisitos

- `MÃ³dulo 02` (producto matricial, normas, intuiciÃ³n geomÃ©trica).

Enlaces rÃ¡pidos:

- [GLOSARIO: Derivative](GLOSARIO.md#derivative)
- [GLOSARIO: Gradient](GLOSARIO.md#gradient)
- [GLOSARIO: Gradient Descent](GLOSARIO.md#gradient-descent)
- [GLOSARIO: Chain Rule](GLOSARIO.md#chain-rule)
- [RECURSOS.md](RECURSOS.md)

### IntegraciÃ³n con Plan v4/v5

- VisualizaciÃ³n de optimizaciÃ³n: `study_tools/VISUALIZACION_GRADIENT_DESCENT.md`
- Simulacros: `study_tools/SIMULACRO_EXAMEN_TEORICO.md`
- EvaluaciÃ³n (rÃºbrica): [study_tools/RUBRICA_v1.md](../study_tools/RUBRICA_v1.md) (scope `M03` en `rubrica.csv`)
- Protocolo completo:
  - [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md)
  - [PLAN_V5_ESTRATEGICO.md](PLAN_V5_ESTRATEGICO.md)

### Recursos (cuÃ¡ndo usarlos)

| Prioridad | Recurso | CuÃ¡ndo usarlo en este mÃ³dulo | Para quÃ© |
|----------|---------|------------------------------|----------|
| **Obligatorio** | `study_tools/VISUALIZACION_GRADIENT_DESCENT.md` | Al implementar Gradient Descent (cuando ajustes `learning_rate` y criterios de parada) | Ver si â€œbajaâ€ o diverge y por quÃ© |
| **Complementario** | [`visualizations/viz_gradient_3d.py`](../visualizations/viz_gradient_3d.py) | Semana 7, cuando ya entiendas `âˆ‡J` pero el `learning_rate` se sienta â€œmÃ¡gicoâ€ | Generar un HTML interactivo con superficie 3D + trayectoria (convergencia/overshooting) |
| **Complementario** | [3Blue1Brown: Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr) | Antes de Chain Rule (o si derivar se siente mecÃ¡nico) | IntuiciÃ³n visual de derivadas y composiciÃ³n |
| **Complementario** | [Mathematics for ML: Multivariate Calculus](https://www.coursera.org/learn/multivariate-calculus-machine-learning) | Cuando pases de derivadas 1D a gradiente/derivadas parciales | PrÃ¡ctica estructurada con ejercicios |
| **Obligatorio** | `study_tools/SIMULACRO_EXAMEN_TEORICO.md` | Tras terminar Chain Rule (antes de saltar a M05/M07) | Verificar que puedes derivar sin mirar apuntes |
| **Opcional** | [RECURSOS.md](RECURSOS.md) | Al cerrar el mÃ³dulo (para refuerzo) | Elegir material extra sin perder foco |

### Criterio de salida (cuÃ¡ndo puedes avanzar)

- Puedes derivar y verificar (numÃ©rico vs analÃ­tico) gradientes de MSE y BCE.
- Puedes explicar chain rule en 5 lÃ­neas y aplicarla a una composiciÃ³n.
- Puedes ejecutar gradient checking y entender quÃ© significa el error relativo.

### Ritmo semanal recomendado (aplicado a Semanas 6â€“8)

- **Lunes y Martes (Concepto):** prioriza Chain Rule. Si solo dominas 1 cosa de cÃ¡lculo para DL, es esta.
- **MiÃ©rcoles y Jueves (ImplementaciÃ³n):** implementa y valida: gradientes analÃ­ticos + diferencias finitas.
- **Viernes (Romper cosas):** fuerza fallos tÃ­picos y explÃ­cales con teorÃ­a:
  - sube `learning_rate` hasta divergir y describe la seÃ±al en `history_f`
  - prueba entradas grandes en sigmoide (`z` muy positivo/negativo) y explica saturaciÃ³n (gradiente ~ 0)
  - cambia `epsilon` en diferencias finitas y observa cuÃ¡ndo se rompe (ruido numÃ©rico)

## ğŸ§  Â¿Por QuÃ© CÃ¡lculo para ML?

### âš ï¸ CRÃTICO: Sin Chain Rule No Hay Deep Learning

```
El algoritmo de Backpropagation ES la Regla de la Cadena aplicada
a funciones compuestas de redes neuronales.

Si no entiendes:
  âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚Å· Â· âˆ‚Å·/âˆ‚z Â· âˆ‚z/âˆ‚w

NO entenderÃ¡s por quÃ© funciona una red neuronal y
probablemente REPROBARÃS el curso de Deep Learning.
```

### ConexiÃ³n con el Pathway

| Concepto | Uso en ML | Curso del Pathway |
|----------|-----------|-------------------|
| **Derivada** | Tasa de cambio, pendiente | Todos |
| **Gradiente** | DirecciÃ³n de mÃ¡ximo ascenso | Supervised Learning |
| **Gradient Descent** | OptimizaciÃ³n de parÃ¡metros | Supervised + Deep Learning |
| **Chain Rule** | Backpropagation | Deep Learning |

---

## ğŸ§­ IntuiciÃ³n geomÃ©trica (para que no sea mecÃ¡nico)

### 1) El gradiente como brÃºjula en una montaÃ±a

Piensa en la funciÃ³n de pÃ©rdida `J(Î¸)` como un terreno (montaÃ±a/valle) y tÃº como alguien parado en un punto.

- `J` te dice la altura.
- El **gradiente** `âˆ‡J` apunta hacia donde el terreno sube mÃ¡s rÃ¡pido.
- Si quieres bajar (minimizar), te mueves en la direcciÃ³n opuesta:

`Î¸_{t+1} = Î¸_t - Î± âˆ‡J(Î¸_t)`

VisualizaciÃ³n sugerida (hazlo en papel):

- curvas de nivel (contornos) alrededor de un valle
- un vector `âˆ‡J` perpendicular a las curvas de nivel

### 2) La regla de la cadena como engranajes (ratios de cambio)

Imagina tres engranajes conectados:

`x  â†’  g(x)  â†’  f(g(x))`

Si giras un poquito el primer engranaje (`x`), el Ãºltimo (`f`) gira segÃºn dos â€œratiosâ€:

- cuÃ¡nto cambia `f` si cambia `g` (`df/dg`)
- cuÃ¡nto cambia `g` si cambia `x` (`dg/dx`)

Y la regla es:

`df/dx = (df/dg) Â· (dg/dx)`

Backprop es esto mismo, pero aplicado a un grafo con muchas piezas: multiplicas ratios locales y propagas desde el final al inicio.

Diagrama sugerido (dibÃºjalo): un grafo pequeÃ±o con nodos `z = Wx + b`, `a = Ï†(z)`, `L(a)` y flechas con gradientes â€œrÃ­o arribaâ€.

## ğŸ“š Contenido del MÃ³dulo

### Semana 6: Derivadas y Derivadas Parciales
### Semana 7: Gradiente y Gradient Descent
### Semana 8: Chain Rule y PreparaciÃ³n para Backprop

---

## ğŸ’» Parte 1: Derivadas

### 1.1 Concepto de Derivada

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica
import matplotlib.pyplot as plt  # Importar librerÃ­a para visualizaciÃ³n

"""
DERIVADA: Tasa de cambio instantÃ¡nea de una funciÃ³n.

DefiniciÃ³n formal:
    f'(x) = lim[hâ†’0] (f(x+h) - f(x)) / h

InterpretaciÃ³n geomÃ©trica: pendiente de la recta tangente.

Notaciones equivalentes:
    f'(x) = df/dx = d/dx f(x) = Df(x)
"""

def numerical_derivative(f, x: float, h: float = 1e-7) -> float:  # Definir funciÃ³n de derivada numÃ©rica
    """
    Calcula la derivada numÃ©rica usando diferencias finitas.

    MÃ©todo: diferencia central (mÃ¡s preciso)
    f'(x) â‰ˆ (f(x+h) - f(x-h)) / (2h)
    """
    return (f(x + h) - f(x - h)) / (2 * h)  # Calcular diferencia central


# Ejemplo: f(x) = xÂ²
def f(x):  # Definir funciÃ³n de ejemplo
    return x ** 2  # Calcular x al cuadrado

# Derivada analÃ­tica: f'(x) = 2x
def f_prime_analytical(x):  # Definir derivada analÃ­tica
    return 2 * x  # Calcular 2x

# Comparar
x = 3.0  # Punto de evaluaciÃ³n
numerical = numerical_derivative(f, x)  # Calcular derivada numÃ©rica
analytical = f_prime_analytical(x)  # Calcular derivada analÃ­tica

print(f"f(x) = xÂ² en x={x}")  # Mostrar funciÃ³n y punto
print(f"Derivada numÃ©rica:  {numerical:.6f}")  # Mostrar derivada numÃ©rica
print(f"Derivada analÃ­tica: {analytical:.6f}")  # Mostrar derivada analÃ­tica
print(f"Error: {abs(numerical - analytical):.2e}")  # Mostrar error
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 1.1: Concepto de Derivada</strong></summary>

#### 1) Metadatos (1â€“2 lÃ­neas)
- **TÃ­tulo:** Derivada como pendiente local + verificaciÃ³n numÃ©rica
- **ID (opcional):** `M03-T01_1`
- **DuraciÃ³n estimada:** 60â€“90 min
- **Nivel:** Fundamentos
- **Dependencias:** Ãlgebra bÃ¡sica, intuiciÃ³n de funciÃ³n

#### 2) Objetivo(s) de aprendizaje (medibles)
- Calcular una derivada analÃ­tica simple (ej. `xÂ²`) y **validarla** con diferencias finitas.
- Explicar quÃ© representa `h` y cÃ³mo afecta el error numÃ©rico.

#### 3) Relevancia y contexto
- En ML, el gradiente es â€œla derivadaâ€ que guÃ­a la optimizaciÃ³n; si no controlas el concepto, backprop se vuelve magia.

#### 4) Mapa conceptual / conceptos clave
- derivada = tasa de cambio local
- recta tangente
- diferencias finitas (central)

#### 5) Definiciones y fÃ³rmulas esenciales
- `f'(x) = lim[hâ†’0] (f(x+h) - f(x-h)) / (2h)` (central).

#### 6) ExplicaciÃ³n didÃ¡ctica (2 niveles)
- **IntuiciÃ³n:** â€œquÃ© tan inclinada estÃ¡ la curva en ese puntoâ€.
- **Operativa:** compara derivada analÃ­tica vs numÃ©rica y mira el error.

#### 7) Ejemplo modelado
- `f(x)=xÂ²` â†’ `f'(x)=2x`; valida en `x=3`.

#### 8) PrÃ¡ctica guiada
- Cambia `x` (ej. `-2`, `0.5`, `10`) y observa el error.

#### 9) PrÃ¡ctica independiente / transferencia
- Repite con `f(x)=xÂ³` y `f(x)=sin(x)` (deriva y verifica).

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© la diferencia central suele ser mÃ¡s precisa que la forward difference?

#### 11) Errores comunes
- Elegir `h` demasiado pequeÃ±o (ruido numÃ©rico) o demasiado grande (sesgo).

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe el esquema â€œanalÃ­tica vs numÃ©rica â†’ errorâ€ y explica quÃ© valida.

#### 13) DiferenciaciÃ³n
- Avanzado: prueba funciones con cambios bruscos (ej. `abs`) y discute no-diferenciabilidad.

#### 14) Recursos
- GLOSARIO: Derivative.

#### 15) Nota docente
- Exigir siempre â€œderivada + validaciÃ³n numÃ©ricaâ€ al introducir un nuevo gradiente.
</details>

### 1.2 Derivadas Comunes en ML

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica

"""
DERIVADAS QUE NECESITAS MEMORIZAR PARA ML:

1. Constante:     d/dx(c) = 0  # Derivada de constante es cero
2. Lineal:        d/dx(x) = 1  # Derivada de identidad es uno
3. Potencia:      d/dx(xâ¿) = nÂ·x^(n-1)  # Regla de la potencia
4. Exponencial:   d/dx(eË£) = eË£  # Exponencial es su propia derivada
5. Logaritmo:     d/dx(ln x) = 1/x  # Derivada del logaritmo natural
6. Suma:          d/dx(f+g) = f' + g'  # Derivada de suma
7. Producto:      d/dx(fÂ·g) = f'g + fg'  # Regla del producto
8. Cociente:      d/dx(f/g) = (f'g - fg')/gÂ²  # Regla del cociente
9. Cadena:        d/dx(f(g(x))) = f'(g(x))Â·g'(x)  # Regla de la cadena
"""

# Funciones de activaciÃ³n y sus derivadas

def sigmoid(x: np.ndarray) -> np.ndarray:  # Definir funciÃ³n sigmoide
    """Ïƒ(x) = 1 / (1 + e^(-x))"""
    return 1 / (1 + np.exp(-x))  # Calcular sigmoide

def sigmoid_derivative(x: np.ndarray) -> np.ndarray:  # Definir derivada de sigmoide
    """
    d/dx Ïƒ(x) = Ïƒ(x) Â· (1 - Ïƒ(x))

    DerivaciÃ³n:
    Ïƒ(x) = (1 + e^(-x))^(-1)
    Ïƒ'(x) = -1Â·(1 + e^(-x))^(-2) Â· (-e^(-x))
          = e^(-x) / (1 + e^(-x))Â²
          = Ïƒ(x) Â· (1 - Ïƒ(x))
    """
    s = sigmoid(x)  # Calcular sigmoide una vez
    return s * (1 - s)  # Aplicar fÃ³rmula Ïƒ(1-Ïƒ)


def relu(x: np.ndarray) -> np.ndarray:  # Definir funciÃ³n ReLU
    """ReLU(x) = max(0, x)"""
    return np.maximum(0, x)  # Calcular mÃ¡ximo entre 0 y x

def relu_derivative(x: np.ndarray) -> np.ndarray:  # Definir derivada de ReLU
    """
    d/dx ReLU(x) = { 1 si x > 0
                  { 0 si x < 0
                  { indefinido si x = 0 (usamos 0)  # En x=0 definimos como 0
    """
    return (x > 0).astype(float)  # Convertir boolean a float (1 si True, 0 si False)


def tanh_derivative(x: np.ndarray) -> np.ndarray:  # Definir derivada de tanh
    """
    d/dx tanh(x) = 1 - tanhÂ²(x)
    """
    return 1 - np.tanh(x) ** 2  # Aplicar fÃ³rmula 1 - tanhÂ²(x)


# Verificar con derivada numÃ©rica
def verify_derivative(f, f_prime, x, name):  # Definir funciÃ³n de verificaciÃ³n
    numerical = (f(x + 1e-7) - f(x - 1e-7)) / (2e-7)  # Calcular derivada numÃ©rica
    analytical = f_prime(x)  # Calcular derivada analÃ­tica
    error = np.abs(numerical - analytical).max()  # Calcular error mÃ¡ximo
    print(f"{name}: error mÃ¡ximo = {error:.2e}")  # Mostrar error

x = np.array([-2, -1, 0.5, 1, 2])  # Puntos de prueba
verify_derivative(sigmoid, sigmoid_derivative, x, "Sigmoid")  # Verificar sigmoide
verify_derivative(np.tanh, tanh_derivative, x, "Tanh")  # Verificar tanh
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 1.2: Derivadas Comunes en ML</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** â€œderivadas que debes memorizarâ€ + verificaciÃ³n automÃ¡tica
- **ID (opcional):** `M03-T01_2`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Fundamentos
- **Dependencias:** 1.1

#### 2) Objetivos
- Memorizar y aplicar derivadas de `exp`, `log`, potencias y activaciones (sigmoid/tanh/ReLU).
- Implementar un verificador numÃ©rico y usar el error para detectar bugs.

#### 3) Relevancia
- Estas derivadas aparecen en backprop: activaciÃ³n + loss + capa lineal.

#### 4) Conceptos clave
- `Ïƒ'(x) = Ïƒ(x)(1-Ïƒ(x))`
- `tanh'(x) = 1-tanh(x)^2`
- ReLU derivada por tramos

#### 5) FÃ³rmulas esenciales
- Regla de la cadena (adelanto): derivadas se multiplican en composiciones.

#### 6) ExplicaciÃ³n didÃ¡ctica
- **PatrÃ³n ML:** implementa `f`, implementa `f'`, valida con diferencias finitas.

#### 7) Ejemplo modelado
- VerificaciÃ³n de `sigmoid` y `tanh` con error mÃ¡ximo.

#### 8) PrÃ¡ctica guiada
- AÃ±ade `relu` al verificador y discute el punto `x=0`.

#### 9) PrÃ¡ctica independiente
- Implementa `softplus(x)=log(1+exp(x))` y su derivada; verifica numÃ©ricamente.

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© en `sigmoid_derivative` conviene reutilizar `Ïƒ(x)` en lugar de re-computar `exp`?

#### 11) Errores comunes
- Overflow en `exp` para `x` grande (necesidad de estabilidad numÃ©rica).

#### 12) RetenciÃ³n
- (dÃ­a 7) recita 5 derivadas clave sin mirar (potencia, exp, log, sigmoid, tanh).

#### 13) DiferenciaciÃ³n
- Avanzado: explica por quÃ© ReLU â€œfuncionaâ€ pese a no ser derivable en 0.

#### 14) Recursos
- GLOSARIO: Gradient, Chain Rule.

#### 15) Nota docente
- Requerir â€œtabla personalâ€ de derivadas + mini test de verificaciÃ³n.
</details>

### 1.3 Derivadas Parciales

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica

"""
DERIVADA PARCIAL: Derivada respecto a UNA variable,
manteniendo las otras constantes.  # Mantener otras variables fijas

Para f(x, y):
    âˆ‚f/âˆ‚x = derivada respecto a x, tratando y como constante
    âˆ‚f/âˆ‚y = derivada respecto a y, tratando x como constante

NotaciÃ³n: âˆ‚ (partial) en lugar de d
"""

def f(x: float, y: float) -> float:  # Definir funciÃ³n de dos variables
    """f(x, y) = xÂ² + 3xy + yÂ²"""
    return x**2 + 3*x*y + y**2  # Evaluar funciÃ³n

# Derivadas parciales analÃ­ticas:
# âˆ‚f/âˆ‚x = 2x + 3y  # Derivada parcial respecto a x
# âˆ‚f/âˆ‚y = 3x + 2y  # Derivada parcial respecto a y

def df_dx(x: float, y: float) -> float:  # Definir derivada parcial respecto a x
    """âˆ‚f/âˆ‚x = 2x + 3y"""
    return 2*x + 3*y  # Calcular derivada parcial

def df_dy(x: float, y: float) -> float:  # Definir derivada parcial respecto a y
    """âˆ‚f/âˆ‚y = 3x + 2y"""
    return 3*x + 2*y  # Calcular derivada parcial


# Derivada parcial numÃ©rica
def partial_derivative(f, var_idx: int, point: list, h: float = 1e-7) -> float:  # Definir funciÃ³n de derivada parcial numÃ©rica
    """
    Calcula âˆ‚f/âˆ‚xáµ¢ en un punto dado.

    Args:
        f: funciÃ³n  # FunciÃ³n a derivar
        var_idx: Ã­ndice de la variable (0 para x, 1 para y, etc.)  # Ãndice de variable a derivar
        point: punto donde evaluar [x, y, ...]  # Punto de evaluaciÃ³n
        h: paso pequeÃ±o  # Paso para diferencias finitas
    """
    point_plus = point.copy()  # Copiar punto original
    point_minus = point.copy()  # Copiar punto original
    point_plus[var_idx] += h  # Perturbar variable hacia arriba
    point_minus[var_idx] -= h  # Perturbar variable hacia abajo
    return (f(*point_plus) - f(*point_minus)) / (2 * h)  # Calcular derivada central


# Verificar
point = [2.0, 3.0]  # Punto de evaluaciÃ³n
print(f"Punto: x={point[0]}, y={point[1]}")  # Mostrar punto
print(f"f(x,y) = {f(*point)}")  # Mostrar valor de funciÃ³n
print(f"\nâˆ‚f/âˆ‚x:")  # Mostrar tÃ­tulo
print(f"  AnalÃ­tica: {df_dx(*point)}")  # Mostrar derivada analÃ­tica
print(f"  NumÃ©rica:  {partial_derivative(f, 0, point):.6f}")  # Mostrar derivada numÃ©rica
print(f"\nâˆ‚f/âˆ‚y:")  # Mostrar etiqueta para derivada parcial respecto a y
print(f"  AnalÃ­tica: {df_dy(*point)}")  # Mostrar derivada analÃ­tica
print(f"  NumÃ©rica:  {partial_derivative(f, 1, point):.6f}")  # Mostrar derivada numÃ©rica
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 1.3: Derivadas Parciales</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Parciales como â€œcongelar variablesâ€ + check numÃ©rico
- **ID (opcional):** `M03-T01_3`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Fundamentos
- **Dependencias:** 1.1

#### 2) Objetivos
- Calcular `âˆ‚f/âˆ‚x` y `âˆ‚f/âˆ‚y` y verificarlas numÃ©ricamente en un punto.
- Interpretar â€œmantener constanteâ€ y su conexiÃ³n con gradiente.

#### 3) Relevancia
- Backprop calcula parciales â€œlocalesâ€ en cada nodo del grafo.

#### 4) Conceptos clave
- parcial vs total
- punto de evaluaciÃ³n
- diferencias finitas por coordenada

#### 5) FÃ³rmulas
- `âˆ‚f/âˆ‚x â‰ˆ (f(x+h,y)-f(x-h,y)) / (2h)`.

#### 6) ExplicaciÃ³n didÃ¡ctica
- Cada parcial es â€œcÃ³mo cambia la salida si muevo solo una coordenadaâ€.

#### 7) Ejemplo modelado
- `f(x,y)=xÂ²+3xy+yÂ²` con parciales analÃ­ticas y check.

#### 8) PrÃ¡ctica guiada
- Cambia el punto (ej. `[0,0]`, `[1,-2]`) y compara parciales.

#### 9) PrÃ¡ctica independiente
- Define `g(x,y)=sin(xy)+x` y deriva parciales; valida.

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© el gradiente junta todas las parciales en un vector?

#### 11) Errores comunes
- Confundir `df/dx` (1D) con `âˆ‚f/âˆ‚x` (multivariable).

#### 12) RetenciÃ³n
- (dÃ­a 2) explica la idea de â€œcongelar variablesâ€ con un ejemplo propio.

#### 13) DiferenciaciÃ³n
- Avanzado: relacionar parciales con derivada direccional (preview del gradiente).

#### 14) Recursos
- GLOSARIO: Gradient.

#### 15) Nota docente
- Repetir: â€œprimero analÃ­tica, luego numÃ©rica, luego interpretaciÃ³nâ€.
</details>

---

## ğŸ’» Parte 2: Gradiente

### 2.1 DefiniciÃ³n del Gradiente

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica

"""
GRADIENTE: Vector de todas las derivadas parciales.

Para f: Râ¿ â†’ R (funciÃ³n de n variables que retorna un escalar):

âˆ‡f = [âˆ‚f/âˆ‚xâ‚, âˆ‚f/âˆ‚xâ‚‚, ..., âˆ‚f/âˆ‚xâ‚™]

Propiedades importantes:
1. El gradiente apunta en la direcciÃ³n de MÃXIMO ASCENSO
2. La magnitud indica quÃ© tan rÃ¡pido aumenta f en esa direcciÃ³n
3. -âˆ‡f apunta en la direcciÃ³n de MÃXIMO DESCENSO (usado en optimizaciÃ³n)
"""

def compute_gradient(f, point: np.ndarray, h: float = 1e-7) -> np.ndarray:  # Definir funciÃ³n de gradiente numÃ©rico
    """
    Calcula el gradiente de f en un punto usando diferencias finitas.

    Args:
        f: funciÃ³n f(x) donde x es un array  # FunciÃ³n a derivar
        point: punto donde calcular el gradiente  # Punto de evaluaciÃ³n
        h: paso para diferencias finitas  # Paso para diferencias

    Returns:
        gradiente como array  # Vector gradiente resultante
    """
    n = len(point)  # NÃºmero de dimensiones
    gradient = np.zeros(n)  # Inicializar gradiente con ceros

    for i in range(n):  # Iterar sobre cada dimensiÃ³n
        point_plus = point.copy()  # Copiar punto original
        point_minus = point.copy()  # Copiar punto original
        point_plus[i] += h  # Perturbar dimensiÃ³n i hacia arriba
        point_minus[i] -= h  # Perturbar dimensiÃ³n i hacia abajo
        gradient[i] = (f(point_plus) - f(point_minus)) / (2 * h)  # Calcular derivada parcial

    return gradient  # Devolver vector gradiente


# Ejemplo: f(x, y) = xÂ² + yÂ²
def paraboloid(p: np.ndarray) -> float:  # Definir funciÃ³n paraboloide
    """Paraboloide: f(x,y) = xÂ² + yÂ²"""
    return p[0]**2 + p[1]**2  # Evaluar paraboloide

# Gradiente analÃ­tico: âˆ‡f = [2x, 2y]
def paraboloid_gradient_analytical(p: np.ndarray) -> np.ndarray:  # Definir gradiente analÃ­tico
    return np.array([2*p[0], 2*p[1]])  # Calcular gradiente [2x, 2y]


# Verificar
point = np.array([3.0, 4.0])  # Punto de evaluaciÃ³n
grad_numerical = compute_gradient(paraboloid, point)  # Calcular gradiente numÃ©rico
grad_analytical = paraboloid_gradient_analytical(point)  # Calcular gradiente analÃ­tico

print(f"Punto: {point}")  # Mostrar punto
print(f"f(punto) = {paraboloid(point)}")  # Mostrar valor de funciÃ³n
print(f"Gradiente numÃ©rico:  {grad_numerical}")  # Mostrar gradiente numÃ©rico
print(f"Gradiente analÃ­tico: {grad_analytical}")  # Mostrar gradiente analÃ­tico
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 2.1: DefiniciÃ³n del Gradiente</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Gradiente como vector de derivadas parciales + verificaciÃ³n numÃ©rica
- **ID (opcional):** `M03-T02_1`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Fundamentos
- **Dependencias:** 1.3 (parciales)

#### 2) Objetivos
- Calcular un gradiente analÃ­tico simple (paraboloide) y **validarlo** con diferencias finitas.
- Interpretar `âˆ‡f` como direcciÃ³n de mÃ¡ximo ascenso y `-âˆ‡f` como direcciÃ³n de descenso.

#### 3) Relevancia
- El gradiente es la seÃ±al que guÃ­a el entrenamiento en ML; si el gradiente estÃ¡ mal, el modelo no aprende.

#### 4) Conceptos clave
- `âˆ‡f` (vector)
- norma del gradiente
- diferencia central por coordenada

#### 5) FÃ³rmulas esenciales
- `âˆ‡f = [âˆ‚f/âˆ‚xâ‚, â€¦, âˆ‚f/âˆ‚xâ‚™]`.

#### 6) ExplicaciÃ³n didÃ¡ctica
- **Mentalidad de debugging:** primero deriva, luego valida numÃ©ricamente, luego interpreta.

#### 7) Ejemplo modelado
- `f(x,y)=xÂ²+yÂ²` â†’ `âˆ‡f=[2x,2y]`.

#### 8) PrÃ¡ctica guiada
- Cambia el punto (ej. `[1,1]`, `[-3,0]`) y compara gradiente analÃ­tico vs numÃ©rico.

#### 9) PrÃ¡ctica independiente
- Define `f(x,y)=xÂ²+10yÂ²` y deriva `âˆ‡f`; valida numÃ©ricamente.

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© `âˆ‡f` es perpendicular a las curvas de nivel?

#### 11) Errores comunes
- Confundir gradiente (vector) con â€œderivadaâ€ (escalar).

#### 12) RetenciÃ³n
- (dÃ­a 2) explica en 2 frases quÃ© te dice la direcciÃ³n de `-âˆ‡f`.

#### 13) DiferenciaciÃ³n
- Avanzado: conecta `||âˆ‡f||` con â€œquÃ© tan empinadaâ€ es la superficie.

#### 14) Recursos
- GLOSARIO: Gradient.

#### 15) Nota docente
- Exigir `allclose`/comparaciÃ³n numÃ©rica para gradientes nuevos (hÃ¡bito tipo â€œgrad-check miniâ€).
</details>

### 2.2 VisualizaciÃ³n del Gradiente

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica
import matplotlib.pyplot as plt  # Importar librerÃ­a para visualizaciÃ³n

def visualize_gradient():  # Definir funciÃ³n de visualizaciÃ³n del gradiente
    """Visualiza el gradiente como campo vectorial."""

    # Crear grid
    x = np.linspace(-3, 3, 15)  # Crear 15 puntos en eje x
    y = np.linspace(-3, 3, 15)  # Crear 15 puntos en eje y
    X, Y = np.meshgrid(x, y)  # Crear malla 2D

    # FunciÃ³n: f(x,y) = xÂ² + yÂ²
    Z = X**2 + Y**2  # Evaluar funciÃ³n en la malla

    # Gradiente: âˆ‡f = [2x, 2y]
    U = 2 * X  # âˆ‚f/âˆ‚x  # Componente x del gradiente
    V = 2 * Y  # âˆ‚f/âˆ‚y  # Componente y del gradiente

    # Normalizar para visualizaciÃ³n
    magnitude = np.sqrt(U**2 + V**2)  # Calcular magnitud del gradiente
    U_norm = U / (magnitude + 0.1)  # Normalizar componente x
    V_norm = V / (magnitude + 0.1)  # Normalizar componente y

    plt.figure(figsize=(10, 8))  # Crear figura

    # Contornos de nivel
    plt.contour(X, Y, Z, levels=20, cmap='viridis', alpha=0.5)  # Dibujar contornos
    plt.colorbar(label='f(x,y) = xÂ² + yÂ²')  # Agregar barra de color

    # Flechas del gradiente
    plt.quiver(X, Y, U_norm, V_norm, magnitude, cmap='Reds', alpha=0.8)  # Dibujar campo vectorial

    # Punto mÃ­nimo
    plt.plot(0, 0, 'g*', markersize=15, label='MÃ­nimo global')  # Marcar mÃ­nimo global

    plt.xlabel('x')  # Etiqueta eje x
    plt.ylabel('y')  # Etiqueta eje y
    plt.title('Gradiente de f(x,y) = xÂ² + yÂ²\nLas flechas apuntan hacia ARRIBA (mÃ¡ximo ascenso)')  # TÃ­tulo
    plt.legend()  # Mostrar leyenda
    plt.axis('equal')  # Ejes iguales
    plt.grid(True, alpha=0.3)  # CuadrÃ­cula
    plt.show()  # Mostrar grÃ¡fico

# visualize_gradient()  # Descomentar para ejecutar

```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 2.2: VisualizaciÃ³n del Gradiente</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Campo vectorial y contornos: ver `âˆ‡f` en acciÃ³n
- **ID (opcional):** `M03-T02_2`
- **DuraciÃ³n estimada:** 45â€“90 min
- **Nivel:** Fundamentos
- **Dependencias:** 2.1

#### 2) Objetivos
- Interpretar un campo vectorial del gradiente y relacionarlo con contornos de nivel.
- Explicar por quÃ© las flechas apuntan hacia mÃ¡ximo ascenso.

#### 3) Relevancia
- Evita que Gradient Descent se convierta en â€œrecetaâ€: aquÃ­ ves el porquÃ© geomÃ©trico.

#### 4) Conceptos clave
- curvas de nivel
- direcciÃ³n perpendicular
- normalizaciÃ³n para visualizaciÃ³n

#### 5) FÃ³rmulas esenciales
- Para `f(x,y)=xÂ²+yÂ²`: `âˆ‡f=[2x,2y]`.

#### 6) ExplicaciÃ³n didÃ¡ctica
- Contornos = â€œmisma alturaâ€; gradiente apunta al cambio mÃ¡s rÃ¡pido â†’ cruza contornos en Ã¡ngulo recto.

#### 7) Ejemplo modelado
- Flechas alrededor del origen apuntan hacia afuera (sube); para bajar, irÃ­as hacia adentro.

#### 8) PrÃ¡ctica guiada
- Cambia `Z` a `X**2 + 10*Y**2` y observa cÃ³mo cambia el campo.

#### 9) PrÃ¡ctica independiente
- Prueba una funciÃ³n con â€œvalleâ€ (tipo Rosenbrock) y discute por quÃ© el gradiente puede zigzaguear.

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© normalizar `U,V` ayuda a visualizar pero no cambia la direcciÃ³n?

#### 11) Errores comunes
- Interpretar el tamaÃ±o de flecha sin considerar la normalizaciÃ³n.

#### 12) RetenciÃ³n
- (dÃ­a 7) dibuja a mano contornos y gradiente para una funciÃ³n simple.

#### 13) DiferenciaciÃ³n
- Avanzado: conecta con Hessiano (curvatura) (preview de ejercicios).

#### 14) Recursos
- `visualizations/viz_gradient_3d.py` (para trayectoria + superficie).

#### 15) Nota docente
- Pedir una explicaciÃ³n oral: â€œpor quÃ© el gradiente es perpendicular a contornosâ€.
</details>

---

### IntuiciÃ³n: Gradient Descent como â€œbajar una montaÃ±a en la nieblaâ€

Imagina que estÃ¡s en una montaÃ±a con niebla: no ves el valle (mÃ­nimo), pero puedes **sentir la pendiente local**.

- **El gradiente** `âˆ‡f(x)` apunta hacia el â€œsubir mÃ¡s rÃ¡pidoâ€.
- Para bajar, te mueves en la direcciÃ³n opuesta: `-âˆ‡f(x)`.
- El `learning_rate (Î±)` es el tamaÃ±o del paso: demasiado grande â†’ te pasas/oscillas; demasiado pequeÃ±o â†’ avanzas lento.

Checklist de diagnÃ³stico rÃ¡pido:

- **Si diverge:** `Î±` es demasiado grande o tu gradiente estÃ¡ mal.
- **Si converge muy lento:** `Î±` demasiado pequeÃ±o.
- **Si el loss baja y luego sube:** posible oscilaciÃ³n (reduce `Î±`).
- **Si no baja nunca:** gradiente incorrecto (haz gradient checking).

## ğŸ’» Parte 3: Gradient Descent

### 3.1 Algoritmo BÃ¡sico

#### CÃ³digo generador de intuiciÃ³n (Protocolo D): superficie 3D + slider de `learning_rate`

Ejecuta el script (genera un HTML interactivo):

- [`visualizations/viz_gradient_3d.py`](../visualizations/viz_gradient_3d.py)

Ejemplos:

```bash
python3 visualizations/viz_gradient_3d.py --lr 0.01 --steps 30 --html-out artifacts/gd_lr0_01.html
python3 visualizations/viz_gradient_3d.py --lr 1.0 --steps 30 --html-out artifacts/gd_lr1_0.html
```

Checklist de uso:

- cambia `lr` a valores pequeÃ±os (ej. `0.01`) y observa convergencia suave
- sube `lr` (ej. `0.5` o `1.0`) y observa oscilaciÃ³n/divergencia

Objetivo: que puedas explicar la frase:

> â€œEl learning rate no es un nÃºmero mÃ¡gico: controla cuÃ¡nto avanzas en la direcciÃ³n del gradiente, y si te pasas, rebotas.â€

"""
GRADIENT DESCENT: Algoritmo de optimizaciÃ³n iterativo.

Idea: Para minimizar f(x), moverse en direcciÃ³n opuesta al gradiente.

Algoritmo:
    1. Inicializar xâ‚€
    2. Repetir hasta convergencia:
       x_{t+1} = x_t - Î± Â· âˆ‡f(x_t)

Donde Î± (alpha) es el "learning rate" (tasa de aprendizaje).
"""

def gradient_descent(
    f: Callable,
    grad_f: Callable,
    x0: np.ndarray,
    learning_rate: float = 0.1,
    max_iterations: int = 100,
    tolerance: float = 1e-6
) -> Tuple[np.ndarray, List[np.ndarray], List[float]]:
    """
    Gradient Descent para minimizar f.

    Args:
        f: funciÃ³n a minimizar
        grad_f: gradiente de f
        x0: punto inicial
        learning_rate: tasa de aprendizaje (Î±)
        max_iterations: mÃ¡ximo de iteraciones
        tolerance: criterio de parada (norma del gradiente)

    Returns:
        x_final: soluciÃ³n encontrada
        history_x: trayectoria de x
        history_f: valores de f en cada paso
    """
    x = x0.copy()
    history_x = [x.copy()]
    history_f = [f(x)]

    for i in range(max_iterations):
        # Calcular gradiente
        grad = grad_f(x)

        # Verificar convergencia
        if np.linalg.norm(grad) < tolerance:
            print(f"ConvergiÃ³ en iteraciÃ³n {i}")
            break

        # Actualizar x
        x = x - learning_rate * grad

        # Guardar historia
        history_x.append(x.copy())
        history_f.append(f(x))

    return x, history_x, history_f


# Ejemplo: Minimizar f(x,y) = xÂ² + yÂ²
def f(p: np.ndarray) -> float:
    return p[0]**2 + p[1]**2

            # Ejecutar
            x0 = np.array([4.0, 3.0])
            x_final, history_x, history_f = gradient_descent(f, grad_f, x0, learning_rate=0.1)

            print(f"\nPunto inicial: {x0}")  # Mostrar punto inicial
            print(f"MÃ­nimo encontrado: {x_final}")  # Mostrar punto mÃ­nimo encontrado
            print(f"f(mÃ­nimo) = {f(x_final):.6f}")
            print(f"Iteraciones: {len(history_f)}")

            <details open>
            <summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 3.1: Algoritmo BÃ¡sico (Gradient Descent)</strong></summary>

            #### 1) Metadatos
            - **TÃ­tulo:** Gradient Descent como iteraciÃ³n `x â† x - Î±âˆ‡f(x)`
            - **ID (opcional):** `M03-T03_1`
            - **DuraciÃ³n estimada:** 90â€“150 min
            - **Nivel:** Intermedio
            - **Dependencias:** 2.1 (gradiente), 2.2 (intuiciÃ³n geomÃ©trica)

#### 1) Metadatos
- **TÃ­tulo:** Gradient Descent como iteraciÃ³n `x â† x - Î±âˆ‡f(x)`
- **ID (opcional):** `M03-T03_1`
- **DuraciÃ³n estimada:** 90â€“150 min
- **Nivel:** Intermedio
- **Dependencias:** 2.1 (gradiente), 2.2 (intuiciÃ³n geomÃ©trica)

#### 2) Objetivos
- Implementar GD 2D y **explicar** el rol de `Î±` y el criterio `||âˆ‡f|| < tol`.
- Diagnosticar convergencia/overshooting a partir del historial de `f`.

#### 3) Relevancia
- Es el nÃºcleo de entrenamiento en ML (con variantes: SGD, Adam).

#### 4) Conceptos clave
- `learning_rate` (Î±)
- criterio de parada
- trayectoria (historia)

#### 5) FÃ³rmulas
- `x_{t+1} = x_t - Î± âˆ‡f(x_t)`.

#### 6) DidÃ¡ctica
- Siempre guarda `history_x` y `history_f` para â€œverâ€ si aprende.

#### 7) Ejemplo modelado
- `f(x,y)=xÂ²+yÂ²` converge al origen.

#### 8) PrÃ¡ctica guiada
- Cambia `Î±` y observa nÃºmero de iteraciones.

#### 9) Transferencia
- Usa el mismo patrÃ³n con una funciÃ³n elÃ­ptica (mal condicionada).

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© `-âˆ‡f` baja localmente la funciÃ³n?

#### 11) Errores comunes
- `Î±` grande â†’ diverge; `Î±` pequeÃ±o â†’ lento.

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe el update rule y nombra cada tÃ©rmino.

#### 13) DiferenciaciÃ³n
- Avanzado: diferencia entre stopping por `||âˆ‡f||` vs cambio en `f`.

#### 14) Recursos
- `visualizations/viz_gradient_3d.py`.

#### 15) Nota docente
- Pedir â€œreporte de diagnÃ³sticoâ€: converge/divege y por quÃ©.
</details>

### 3.2 Efecto del Learning Rate

"""
El learning rate (Î±) controla la velocidad de convergencia.

- Î± muy pequeÃ±o: Convergencia lenta
- Î± Ã³ptimo: Convergencia rÃ¡pida y estable
- Î± muy grande: Oscilaciones, puede diverger
"""

import numpy as np
import matplotlib.pyplot as plt

def compare_learning_rates():
    """Compara diferentes learning rates."""

    def f(p):
        return p[0]**2 + p[1]**2

    def grad_f(p):
        return np.array([2*p[0], 2*p[1]])

    x0 = np.array([4.0, 3.0])

    learning_rates = [0.01, 0.1, 0.5, 0.9]

    plt.figure(figsize=(12, 4))

    for i, lr in enumerate(learning_rates):
        x_final, history_x, history_f = gradient_descent(
            f, grad_f, x0, learning_rate=lr, max_iterations=50
        )

        plt.subplot(1, 4, i+1)
        plt.plot(history_f, 'b-o', markersize=3)
        plt.xlabel('IteraciÃ³n')
        plt.ylabel('f(x)')
        plt.title(f'Î± = {lr}')
        plt.yscale('log')
        plt.grid(True)

    plt.tight_layout()
    plt.suptitle('Efecto del Learning Rate en Gradient Descent', y=1.02)
    plt.show()

    """
    Observaciones:
    - Î± muy pequeÃ±o (0.01): Convergencia muy lenta
    - Î± Ã³ptimo (0.1-0.5): Convergencia rÃ¡pida y estable
    - Î± muy grande (0.9): Oscilaciones, puede diverger
    - Î± > 1: Generalmente diverge para este problema
    """

# compare_learning_rates()  # Descomentar para ejecutar

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 3.2: Efecto del Learning Rate</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Estabilidad: cÃ³mo `Î±` controla convergencia vs oscilaciÃ³n
- **ID (opcional):** `M03-T03_2`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Intermedio
- **Dependencias:** 3.1

#### 2) Objetivos
- Comparar curvas de `f(x)` para distintos `Î±` y **clasificar** el comportamiento.
- Identificar seÃ±ales de inestabilidad (oscilaciÃ³n, diverge).

#### 3) Relevancia
- El ajuste de LR es una de las causas #1 de entrenamiento inestable.

#### 4) Conceptos clave
- escala log en loss
- overshooting
- sensibilidad a condiciones

#### 5) FÃ³rmulas
- GD con `Î±` fijo: estabilidad depende de curvatura (idea cualitativa).

#### 6) DidÃ¡ctica
- â€œMira la curvaâ€: suave â†’ ok, serrucho â†’ alto, explode â†’ demasiado alto.

#### 7) Ejemplo modelado
- ComparaciÃ³n de `Î± âˆˆ {0.01,0.1,0.5,0.9}`.

#### 8) PrÃ¡ctica guiada
- AÃ±ade un `Î±=1.1` y observa.

#### 9) Transferencia
- Relaciona con entrenamiento de NN (LR schedules / Adam) (preview).

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© usar escala log ayuda a comparar convergencia?

#### 11) Errores comunes
- Concluir â€œno aprendeâ€ cuando solo falta bajar `Î±`.

#### 12) RetenciÃ³n
- (dÃ­a 7) escribe 3 sÃ­ntomas y la acciÃ³n correctiva.

#### 13) DiferenciaciÃ³n
- Avanzado: conecta `Î±` con â€œcurvaturaâ€ (Hessiano) de forma conceptual.

#### 14) Recursos
- `study_tools/VISUALIZACION_GRADIENT_DESCENT.md`.

#### 15) Nota docente
- Exigir evidencia: plot + explicaciÃ³n del caso.
</details>

### 3.3 Funciones de PÃ©rdida en ML

"""
FUNCIONES DE PÃ‰RDIDA COMUNES Y SUS GRADIENTES

En ML, minimizamos una "funciÃ³n de pÃ©rdida" (loss function)
que mide quÃ© tan mal estÃ¡n nuestras predicciones.
"""

# 1. MSE (Mean Squared Error) - RegresiÃ³n
def mse_loss(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """Mean Squared Error."""
    return np.mean((y_true - y_pred) ** 2)

def mse_gradient(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:
    """Gradiente de MSE respecto a y_pred."""
    n = len(y_true)
    return 2 * (y_pred - y_true) / n


# 2. Binary Cross-Entropy - ClasificaciÃ³n binaria
def binary_cross_entropy(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-15) -> float:
    """Binary Cross-Entropy."""
    y_pred = np.clip(y_pred, eps, 1 - eps)  # Evitar log(0)
    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))

def binary_cross_entropy_gradient(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-15) -> np.ndarray:
    """Gradiente de BCE respecto a y_pred."""
    y_pred = np.clip(y_pred, eps, 1 - eps)
    return (y_pred - y_true) / (y_pred * (1 - y_pred)) / len(y_true)


# Demo
np.random.seed(42)
y_true = np.array([0, 0, 1, 1])
y_pred = np.array([0.1, 0.2, 0.8, 0.9])

print("MSE Loss:", mse_loss(y_true, y_pred))
print("BCE Loss:", binary_cross_entropy(y_true, y_pred))

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 3.3: Funciones de PÃ©rdida en ML</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Loss + gradiente: contrato mÃ­nimo para entrenar
- **ID (opcional):** `M03-T03_3`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Intermedio
- **Dependencias:** 1.2 (derivadas), 3.1

#### 2) Objetivos
- Implementar MSE y BCE y **derivar/validar** su gradiente respecto a `y_pred`.
- Explicar por quÃ© se usa `clip` en BCE (estabilidad numÃ©rica).

#### 3) Relevancia
- Sin `loss` y su gradiente correcto, no hay entrenamiento fiable.

#### 4) Conceptos clave
- MSE (regresiÃ³n)
- BCE (clasificaciÃ³n)
- estabilidad: `log(0)`

#### 5) FÃ³rmulas esenciales
- `MSE = mean((y-Å·)^2)`; `âˆ‚MSE/âˆ‚Å· = 2(Å·-y)/n`.

#### 6) DidÃ¡ctica
- Separar: (1) definiciÃ³n de loss (2) gradiente (3) sanity-check numÃ©rico.

#### 7) Ejemplo modelado
- Dataset mini con `y_true` y `y_pred` y prints de losses.

#### 8) PrÃ¡ctica guiada
- Haz gradient checking de `mse_gradient` con diferencias finitas.

#### 9) PrÃ¡ctica independiente
- Conecta con `âˆ‚L/âˆ‚z` en una neurona (preview de Chain Rule).

#### 10) EvaluaciÃ³n
- Â¿QuÃ© problema evita `eps`/`clip` en BCE?

#### 11) Errores comunes
- confundir gradiente respecto a `Å·` vs respecto a parÃ¡metros.

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe MSE y su gradiente sin mirar.

#### 13) DiferenciaciÃ³n
- Avanzado: discusiÃ³n conceptual de saturaciÃ³n en sigmoid + BCE.

#### 14) Recursos
- CS231n: loss functions + numerical gradient check.

#### 15) Nota docente
- Hacer que el alumno identifique â€œdÃ³nde entra el `clip`â€ y por quÃ©.
</details>

---
## ğŸ’» Parte 4: Regla de la Cadena (Chain Rule)

### 4.0.0 IntroducciÃ³n

La Regla de la Cadena (Chain Rule) es un concepto fundamental en el cÃ¡lculo que nos permite encontrar la derivada de una funciÃ³n compuesta. En el contexto del aprendizaje automÃ¡tico, esta regla es crucial para el entrenamiento de modelos, ya que nos permite calcular la derivada de la funciÃ³n de pÃ©rdida con respecto a los parÃ¡metros del modelo.

### 4.0 VisualizaciÃ³n: Grafo computacional (computational graph)

En Deep Learning, casi todo es una composiciÃ³n de funciones. El truco mental es pensar en un **grafo**:
```
x â”€â”€â–º z = wÂ·x + b â”€â”€â–º a = Ïƒ(z) â”€â”€â–º L(a, y)

(forward)  verde: xâ†’zâ†’aâ†’L
(backward) rojo:  dL/da â†’ da/dz â†’ dz/dw, dz/db
```

Regla de oro (chain rule):

```
dL/dw = dL/da Â· da/dz Â· dz/dw
dL/db = dL/da Â· da/dz Â· dz/db
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 4.0: VisualizaciÃ³n: Grafo computacional (computational graph)</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Grafo computacional: pensar en â€œnodosâ€ y â€œrutasâ€ de derivaciÃ³n
- **ID (opcional):** `M03-T04_0`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Intermedio
- **Dependencias:** 1.2 (derivadas), 3.3 (loss), 2.1 (gradiente)

#### 2) Objetivos
- Explicar con tus palabras la diferencia entre **forward** y **backward** en el grafo.
- Usar la regla de la cadena para obtener `dL/dw` y `dL/db` como producto de factores locales.

#### 3) Relevancia
- Este patrÃ³n mental es el corazÃ³n de backpropagation: derivadas locales + composiciÃ³n.

#### 4) Mapa conceptual mÃ­nimo
- **ComposiciÃ³n:** `x â†’ u â†’ y`.
- **Backward:** se propagan derivadas desde `L` hacia los parÃ¡metros.

#### 5) Definiciones esenciales
- **Grafo computacional:** diagrama dirigido donde cada nodo es una operaciÃ³n/funciÃ³n.
- **Derivada local:** derivada de una operaciÃ³n respecto a su entrada inmediata.

#### 6) ExplicaciÃ³n didÃ¡ctica
- Regla prÃ¡ctica: para derivar respecto a una variable, multiplica las derivadas locales a lo largo del camino desde `L` hasta esa variable.

#### 7) Ejemplo modelado (micro)
- Si `z = wÂ·x + b`, entonces:
  - `dz/dw = x`
  - `dz/db = 1`
  - y `dL/dw = dL/da Â· da/dz Â· x`

#### 8) PrÃ¡ctica guiada
- A partir del mismo grafo, deriva `dL/dx` y explica el significado (sensibilidad de la pÃ©rdida a la entrada).

#### 9) PrÃ¡ctica independiente
- Dibuja un grafo para `L = ( (w1Â·x + b1)Â² ) + (w2Â·x)` y deriva `dL/dw1`, `dL/db1`, `dL/dw2`.

#### 10) AutoevaluaciÃ³n
- Â¿QuÃ© factor te faltarÃ­a si olvidas el nodo `a = Ïƒ(z)`?

#### 11) Errores comunes
- Omitir un nodo intermedio (un factor) en el producto.
- Confundir `dL/dw` con `dw/dL` (direcciÃ³n).

#### 12) RetenciÃ³n
- (dÃ­a 2) Reproduce de memoria el grafo y escribe las fÃ³rmulas de `dL/dw` y `dL/db`.

#### 13) DiferenciaciÃ³n
- Avanzado: generaliza el patrÃ³n a `z = Wx + b` (vectores/matrices) y discute formas/dimensiones.

#### 14) Recursos
- SecciÃ³n â€œcomputational graphsâ€ de cursos intro de DL (p.ej., CS231n).

#### 15) Nota docente
- Pide una â€œnarraciÃ³nâ€ del backward: `L â†’ a â†’ z â†’ (w,b)` y justificaciÃ³n de cada derivada local.
</details>

### 4.0.1 DerivaciÃ³n paso a paso: `f(x) = xÂ²`

Si `f(x) = xÂ²`, entonces:

```
f'(x) = lim_{hâ†’0} [(x+h)Â² - xÂ²] / h
      = lim_{hâ†’0} [xÂ² + 2xh + hÂ² - xÂ²] / h
      = lim_{hâ†’0} [2xh + hÂ²] / h
      = lim_{hâ†’0} [2x + h]
      = 2x
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 4.0.1: DerivaciÃ³n paso a paso: f(x) = xÂ²</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** DerivaciÃ³n por definiciÃ³n: intuiciÃ³n del lÃ­mite
- **ID (opcional):** `M03-T04_0_1`
- **DuraciÃ³n estimada:** 30â€“60 min
- **Nivel:** BÃ¡sicoâ€“Intermedio
- **Dependencias:** 1.2 (derivadas)

#### 2) Objetivos
- Reproducir el cÃ¡lculo de `f'(x)` desde la definiciÃ³n de derivada.
- Explicar quÃ© significa â€œtomar el lÃ­miteâ€ en tÃ©rminos de aproximaciÃ³n.

#### 3) Relevancia
- Esta derivaciÃ³n es un â€œpatrÃ³n baseâ€ que luego se reutiliza en chain rule y gradientes.

#### 4) Mapa conceptual
- **DefiniciÃ³n:** derivada = lÃ­mite de cociente incremental.
- **Ãlgebra:** expandir, simplificar, cancelar, aplicar lÃ­mite.

#### 5) Definiciones esenciales
- `f'(x) = lim_{hâ†’0} (f(x+h)-f(x))/h`.

#### 6) ExplicaciÃ³n didÃ¡ctica
- La cancelaciÃ³n del tÃ©rmino `xÂ²` es la pista de que el cociente incremental â€œaÃ­slaâ€ la variaciÃ³n.

#### 7) Ejemplo modelado
- ValidaciÃ³n rÃ¡pida: si `x=3`, entonces `f'(3)=6`.

#### 8) PrÃ¡ctica guiada
- Repite el proceso para `f(x)=xÂ³` y compara el resultado con la regla conocida.

#### 9) PrÃ¡ctica independiente
- Deriva `f(x)=(x+1)Â²` por definiciÃ³n y simplifica.

#### 10) AutoevaluaciÃ³n
- Â¿En quÃ© paso aparece el requisito de `hâ†’0` y por quÃ© no puedes sustituir `h=0` antes?

#### 11) Errores comunes
- Sustituir `h=0` demasiado pronto (divisiÃ³n por cero).
- Errores al expandir `(x+h)Â²`.

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe de memoria la expansiÃ³n de `(x+h)Â²` y el resultado `2x`.

#### 13) DiferenciaciÃ³n
- Avanzado: conecta el resultado `2x` con la pendiente de la parÃ¡bola en el plano.

#### 14) Recursos
- SecciÃ³n de derivada por definiciÃ³n en cualquier texto de CÃ¡lculo I.

#### 15) Nota docente
- Pedir al alumno que explique cada cancelaciÃ³n (quÃ© tÃ©rmino desaparece y por quÃ©).
</details>

### 4.0.2 DerivaciÃ³n paso a paso: sigmoide `Ïƒ(z)`

DefiniciÃ³n:

```
Ïƒ(z) = 1 / (1 + e^{-z})
```

Resultado clave:

```
Ïƒ'(z) = Ïƒ(z)(1 - Ïƒ(z))
```

DerivaciÃ³n (paso a paso, conectada a cÃ³digo):

 1) Reescribe la sigmoide como potencia:

 ```
 Ïƒ(z) = (1 + e^{-z})^{-1}
 ```

 2) Deriva usando Chain Rule (derivada de `u^{-1}` y de `e^{-z}`):

 ```
 Ïƒ'(z) = - (1 + e^{-z})^{-2} Â· d/dz(1 + e^{-z})
       = - (1 + e^{-z})^{-2} Â· (-e^{-z})
       = e^{-z} / (1 + e^{-z})^2
 ```

 3) Demuestra que es equivalente a `Ïƒ(z)(1-Ïƒ(z))`:

 ```
 1 - Ïƒ(z) = 1 - 1/(1+e^{-z})
          = (1+e^{-z}-1)/(1+e^{-z})
          = e^{-z}/(1+e^{-z})

 Ïƒ(z)(1-Ïƒ(z)) = [1/(1+e^{-z})] Â· [e^{-z}/(1+e^{-z})]
              = e^{-z}/(1+e^{-z})^2
              = Ïƒ'(z)
 ```

 ConexiÃ³n directa con `grad_check.py`:

 - En el script, esto aparece como:
   - `s = sigmoid(z)`
   - `return s * (1 - s)`
 - La razÃ³n prÃ¡ctica: si ya calculaste `s` en el forward, el backward usa `s(1-s)` y evita recalcular `exp`.

 Consejo prÃ¡ctico: cuando ya tienes `a = Ïƒ(z)`, usa `a(1-a)` para derivar, en vez de re-calcular `exp`.

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 4.0.2: DerivaciÃ³n paso a paso: sigmoide Ïƒ(z)</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Derivada de la sigmoide: forma Ãºtil para backprop
- **ID (opcional):** `M03-T04_0_2`
- **DuraciÃ³n estimada:** 30â€“60 min
- **Nivel:** Intermedio
- **Dependencias:** 4.0 (grafo), 1.2 (derivadas)

#### 2) Objetivos
- Justificar (al menos a nivel algebraico) por quÃ© `Ïƒ'(z)=Ïƒ(z)(1-Ïƒ(z))`.
- Explicar por quÃ© esta forma es computacionalmente conveniente.

#### 3) Relevancia
- La identidad `a(1-a)` aparece constantemente en redes con activaciÃ³n sigmoide.

#### 4) Mapa conceptual
- **FunciÃ³n:** `Ïƒ(z) = 1/(1+e^{-z})`
- **Derivada:** reescritura algebraica para expresar todo en funciÃ³n de `Ïƒ(z)`.

#### 5) Definiciones esenciales
- `Ïƒ(z)` y su derivada cerrada.

#### 6) ExplicaciÃ³n didÃ¡ctica
- Si ya computaste `a=Ïƒ(z)` en el forward, en el backward no recalculas exponenciales: usas `a(1-a)`.

#### 7) Ejemplo modelado
- Si `a=0.8`, entonces `Ïƒ'(z)=0.8Â·0.2=0.16`.

#### 8) PrÃ¡ctica guiada
- Calcula `Ïƒ(z)` y `Ïƒ'(z)` para `z âˆˆ {-2,0,2}` y compara magnitudes.

#### 9) PrÃ¡ctica independiente
- Explica con una frase por quÃ© la sigmoide â€œsaturaâ€ (derivada pequeÃ±a) en valores grandes de |z|.

#### 10) AutoevaluaciÃ³n
- Â¿QuÃ© ocurre con `Ïƒ'(z)` cuando `aâ‰ˆ0` o `aâ‰ˆ1`?

#### 11) Errores comunes
- Olvidar la regla de la cadena al derivar `e^{-z}`.
- Confundir `Ïƒ'(z)` con `1-Ïƒ(z)`.

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe de memoria: `Ïƒ'(z)=Ïƒ(z)(1-Ïƒ(z))`.

#### 13) DiferenciaciÃ³n
- Avanzado: conectar saturaciÃ³n con vanishing gradients en redes profundas.

#### 14) Recursos
- Notas de activaciones y derivadas (sigmoid/tanh/ReLU).

#### 15) Nota docente
- Pedir que el alumno derive la identidad y luego explique su utilidad computacional.
</details>

### 4.1 Chain Rule en 1D

!!! note "REGLA DE LA CADENA (Chain Rule)"
    Si `y = f(g(x))`, entonces:

    `dy/dx = df/dg Â· dg/dx`

    O en notaciÃ³n de composiciÃ³n:

    `(f âˆ˜ g)'(x) = f'(g(x)) Â· g'(x)`

    Esto es **fundamental** para Backpropagation.

```text
Ejemplo: y = (xÂ² + 1)Â³

Sea g(x) = xÂ² + 1  y  f(u) = uÂ³
Entonces y = f(g(x))

dy/dx = f'(g(x)) Â· g'(x)
      = 3(xÂ² + 1)Â² Â· 2x
      = 6x(xÂ² + 1)Â²
```

```python
def g(x):  # Definir funciÃ³n interna
    return x**2 + 1  # Calcular x^2 + 1


def f(u):  # Definir funciÃ³n externa
    return u**3  # Calcular u^3


def y(x):  # Definir funciÃ³n compuesta
    return f(g(x))  # Componer f con g


def dy_dx_analytical(x):  # Definir derivada analÃ­tica
    """Derivada usando chain rule."""
    return 6 * x * (x**2 + 1)**2  # Aplicar regla de la cadena


def dy_dx_numerical(x, h=1e-7):  # Definir derivada numÃ©rica
    """Derivada numÃ©rica."""
    return (y(x + h) - y(x - h)) / (2 * h)  # Calcular diferencia central


# Verificar
x = 2.0  # Punto de evaluaciÃ³n
print(f"y({x}) = {y(x)}")  # Mostrar valor de funciÃ³n
print(f"dy/dx analÃ­tica:  {dy_dx_analytical(x)}")  # Mostrar derivada analÃ­tica
print(f"dy/dx numÃ©rica:   {dy_dx_numerical(x):.6f}")  # Mostrar derivada numÃ©rica
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 4.1: Chain Rule en 1D</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Regla de la cadena en 1D: composiciÃ³n y â€œmultiplicar derivadas localesâ€
- **ID (opcional):** `M03-T04_1`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Intermedio
- **Dependencias:** 4.0 (grafo), 1.2 (derivadas)

#### 2) Objetivos
- Identificar `f` y `g` en una composiciÃ³n `y = f(g(x))`.
- Calcular `dy/dx` aplicando `dy/dx = f'(g(x))Â·g'(x)`.
- Verificar resultados comparando derivada analÃ­tica vs numÃ©rica.

#### 3) Relevancia
- Es el patrÃ³n exacto que se repite en backprop: derivadas locales encadenadas.

#### 4) Mapa conceptual
- **ComposiciÃ³n:** `x â†’ g(x) â†’ f(g(x))`.
- **DerivaciÃ³n:** â€œderivar afueraâ€ evaluado â€œadentroâ€ y multiplicar por la derivada de adentro.

#### 5) Definiciones esenciales
- Si `y = f(u)` y `u = g(x)`, entonces `dy/dx = (dy/du)(du/dx)`.

#### 6) ExplicaciÃ³n didÃ¡ctica
- TÃ©cnica: escribe primero el camino `x â†’ u â†’ y`, y luego escribe derivadas a lo largo del camino.

#### 7) Ejemplo modelado
- `y=(xÂ²+1)Â³`: identifica `u=xÂ²+1`, `f(u)=uÂ³`, luego `dy/dx=3uÂ²Â·2x`.

#### 8) PrÃ¡ctica guiada
- Calcula `dy/dx` para `y = sin(xÂ²)` y valida con diferencia finita.

#### 9) PrÃ¡ctica independiente
- Resuelve `y = exp( (3x-2)â´ )` paso a paso, nombrando variables intermedias.

#### 10) AutoevaluaciÃ³n
- Â¿Por quÃ© aparece la evaluaciÃ³n `f'(g(x))` y no solo `f'(x)`?

#### 11) Errores comunes
- Olvidar el factor `g'(x)`.
- Derivar el â€œafueraâ€ pero no evaluar en el â€œadentroâ€.

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe el patrÃ³n `f(g(x))' = f'(g(x))Â·g'(x)` y crea 2 ejemplos propios.

#### 13) DiferenciaciÃ³n
- Avanzado: usa notaciÃ³n de diferenciales `dy = f'(u)du`, `du=g'(x)dx`.

#### 14) Recursos
- Secciones de â€œfunciones compuestasâ€ en CÃ¡lculo I y notas de chain rule.

#### 15) Nota docente
- Pedir que el alumno â€œetiqueteâ€ cada subfunciÃ³n con un nombre intermedio (u, v, â€¦) antes de derivar.
</details>

### 4.2 Chain Rule para Funciones Compuestas (Backprop Preview)

!!! note "CHAIN RULE PARA REDES NEURONALES"
    Una capa de red neuronal:

    `z = Wx + b` (transformaciÃ³n lineal)

    `a = Ïƒ(z)` (activaciÃ³n)

    Si `L` es la pÃ©rdida, necesitamos:

    `âˆ‚L/âˆ‚W`, `âˆ‚L/âˆ‚b` (para actualizar los pesos)

    Usando Chain Rule:

    `âˆ‚L/âˆ‚W = âˆ‚L/âˆ‚a Â· âˆ‚a/âˆ‚z Â· âˆ‚z/âˆ‚W`

    `âˆ‚L/âˆ‚b = âˆ‚L/âˆ‚a Â· âˆ‚a/âˆ‚z Â· âˆ‚z/âˆ‚b`

```python
def simple_forward_backward():  # Definir funciÃ³n de ejemplo forward/backward
    """
    Ejemplo simplificado de forward y backward pass.

    Red: x â†’ [z = wx + b] â†’ [a = sigmoid(z)] â†’ [L = (a - y)Â²]
    """
    # Datos
    x = 2.0          # Input  # Valor de entrada
    y_true = 1.0     # Target  # Valor objetivo

    # ParÃ¡metros
    w = 0.5  # Peso inicial
    b = 0.1  # Sesgo inicial

    # ========== FORWARD PASS ==========
    z = w * x + b                    # z = wx + b  # Pre-activaciÃ³n
    a = 1 / (1 + np.exp(-z))         # a = sigmoid(z)  # ActivaciÃ³n
    L = (a - y_true) ** 2            # L = MSE  # PÃ©rdida

    print("=== FORWARD PASS ===")  # Imprimir tÃ­tulo
    print(f"z = w*x + b = {w}*{x} + {b} = {z}")  # Mostrar cÃ¡lculo de z
    print(f"a = sigmoid(z) = {a:.4f}")  # Mostrar activaciÃ³n
    print(f"L = (a - y)Â² = ({a:.4f} - {y_true})Â² = {L:.4f}")  # Mostrar pÃ©rdida

    # ========== BACKWARD PASS (Chain Rule) ==========
    # Objetivo: calcular âˆ‚L/âˆ‚w y âˆ‚L/âˆ‚b

    # Paso 1: âˆ‚L/âˆ‚a
    dL_da = 2 * (a - y_true)  # Derivada de pÃ©rdida respecto a activaciÃ³n

    # Paso 2: âˆ‚a/âˆ‚z = sigmoid'(z) = a(1-a)
    da_dz = a * (1 - a)  # Derivada de sigmoide

    # Paso 3: âˆ‚z/âˆ‚w = x,  âˆ‚z/âˆ‚b = 1
    dz_dw = x  # Derivada de z respecto a w
    dz_db = 1  # Derivada de z respecto a b

    # Aplicar Chain Rule
    dL_dz = dL_da * da_dz           # âˆ‚L/âˆ‚z = âˆ‚L/âˆ‚a Â· âˆ‚a/âˆ‚z
    dL_dw = dL_dz * dz_dw           # âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚z Â· âˆ‚z/âˆ‚w  # Gradiente respecto a w
    dL_db = dL_dz * dz_db           # âˆ‚L/âˆ‚b = âˆ‚L/âˆ‚z Â· âˆ‚z/âˆ‚b  # Gradiente respecto a b

    print("\n=== BACKWARD PASS (Chain Rule) ===")  # Imprimir tÃ­tulo
    print(f"âˆ‚L/âˆ‚a = 2(a - y) = {dL_da:.4f}")  # Mostrar gradiente respecto a a
    print(f"âˆ‚a/âˆ‚z = a(1-a) = {da_dz:.4f}")  # Mostrar gradiente respecto a z
    print(f"âˆ‚z/âˆ‚w = x = {dz_dw}")  # Mostrar derivada de z respecto a w
    print(f"âˆ‚z/âˆ‚b = 1")  # Mostrar derivada de z respecto a b
    print(f"\nâˆ‚L/âˆ‚w = âˆ‚L/âˆ‚a Â· âˆ‚a/âˆ‚z Â· âˆ‚z/âˆ‚w = {dL_dw:.4f}")  # Mostrar gradiente final de w
    print(f"âˆ‚L/âˆ‚b = âˆ‚L/âˆ‚a Â· âˆ‚a/âˆ‚z Â· âˆ‚z/âˆ‚b = {dL_db:.4f}")  # Mostrar gradiente final de b

    # ========== VERIFICACIÃ“N NUMÃ‰RICA ==========
    h = 1e-7  # Paso pequeÃ±o para diferencias finitas

    # âˆ‚L/âˆ‚w numÃ©rica
    z_plus = (w + h) * x + b  # z con w perturbado
    a_plus = 1 / (1 + np.exp(-z_plus))  # ActivaciÃ³n con w perturbado
    L_plus = (a_plus - y_true) ** 2  # PÃ©rdida con w perturbado

    z_minus = (w - h) * x + b  # z con w perturbado negativamente
    a_minus = 1 / (1 + np.exp(-z_minus))  # ActivaciÃ³n con w perturbado negativamente
    L_minus = (a_minus - y_true) ** 2  # PÃ©rdida con w perturbado negativamente

    dL_dw_numerical = (L_plus - L_minus) / (2 * h)  # Gradiente numÃ©rico de w

    print(f"\n=== VERIFICACIÃ“N ===")  # Imprimir tÃ­tulo de verificaciÃ³n
    print(f"âˆ‚L/âˆ‚w analÃ­tica: {dL_dw:.6f}")  # Mostrar gradiente analÃ­tico
    print(f"âˆ‚L/âˆ‚w numÃ©rica:  {dL_dw_numerical:.6f}")  # Mostrar gradiente numÃ©rico
    print(f"Error: {abs(dL_dw - dL_dw_numerical):.2e}")  # Mostrar error entre gradientes

    return dL_dw, dL_db  # Devolver gradientes analÃ­ticos

simple_forward_backward()  # Ejecutar ejemplo

```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 4.2: Chain Rule para Funciones Compuestas (Backprop Preview)</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Backprop como chain rule repetido (con verificaciÃ³n numÃ©rica)
- **ID (opcional):** `M03-T04_2`
- **DuraciÃ³n estimada:** 90â€“150 min
- **Nivel:** Intermedio
- **Dependencias:** 4.0 (grafo), 4.1 (chain rule), 3.3 (loss), 4.0.2 (sigmoide)

#### 2) Objetivos
- Calcular `âˆ‚L/âˆ‚w` y `âˆ‚L/âˆ‚b` en una neurona: `z=wx+b`, `a=Ïƒ(z)`, `L=(a-y)Â²`.
- Entender el â€œpipelineâ€ de derivadas locales: `âˆ‚L/âˆ‚a`, `âˆ‚a/âˆ‚z`, `âˆ‚z/âˆ‚w`, `âˆ‚z/âˆ‚b`.
- Validar la derivaciÃ³n con diferencias finitas (sanity check).

#### 3) Relevancia
- Backprop no es â€œmagiaâ€: es chain rule aplicado de forma sistemÃ¡tica.

#### 4) Mapa conceptual mÃ­nimo
- **Forward:** `x â†’ z â†’ a â†’ L`.
- **Backward:** `dL/da â†’ da/dz â†’ dz/dw, dz/db`.

#### 5) Definiciones esenciales
- **Gradiente:** vector de derivadas parciales respecto a parÃ¡metros.
- **Gradient checking:** comparar gradiente analÃ­tico vs numÃ©rico.

#### 6) ExplicaciÃ³n didÃ¡ctica
- Regla prÃ¡ctica: en backward, cada paso â€œempujaâ€ la derivada un nodo hacia atrÃ¡s multiplicando por la derivada local.

#### 7) Ejemplo modelado
- Con `dz/dw = x` y `dz/db = 1`, se obtiene `âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚z Â· x` y `âˆ‚L/âˆ‚b = âˆ‚L/âˆ‚z`.

#### 8) PrÃ¡ctica guiada
- Cambia la pÃ©rdida a `L = -[ y log(a) + (1-y)log(1-a) ]` (BCE) y escribe el nuevo `âˆ‚L/âˆ‚a`.

#### 9) PrÃ¡ctica independiente
- Implementa una funciÃ³n `grad_check` genÃ©rica que compare gradientes para distintos `h` y reporte error relativo.

#### 10) AutoevaluaciÃ³n
- Â¿Por quÃ© `h` no puede ser demasiado grande ni demasiado pequeÃ±o en diferencias finitas?

#### 11) Errores comunes
- Olvidar `Ïƒ'(z)=a(1-a)` y recalcular exponenciales innecesariamente.
- Implementar mal el gradiente numÃ©rico (forward vs central differences).

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe el pipeline: `dL/da`, `da/dz`, `dz/dw`, `dz/db` y cÃ³mo se combinan.

#### 13) DiferenciaciÃ³n
- Avanzado: extender de escalar a vector: `z = wÂ·x + b`, `âˆ‚z/âˆ‚w = x` (vector).

#### 14) Recursos
- SecciÃ³n â€œgradient checkingâ€ en cursos de DL (p.ej., CS231n).

#### 15) Nota docente
- Exigir evidencia: gradiente analÃ­tico + numÃ©rico + tolerancias (`rtol`, `atol`) y explicaciÃ³n del resultado.
</details>

### 4.3 Backpropagation en una Red de 2 Capas

!!! note "RED NEURONAL DE 2 CAPAS"
    Arquitectura:

    `x (input) â†’ zâ‚ = Wâ‚x + bâ‚ â†’ aâ‚ = sigmoid(zâ‚) â†’ zâ‚‚ = Wâ‚‚aâ‚ + bâ‚‚ â†’ aâ‚‚ = sigmoid(zâ‚‚) â†’ L = MSE(aâ‚‚, y)`

    Backpropagation usa Chain Rule repetidamente:

    `âˆ‚L/âˆ‚Wâ‚‚ = âˆ‚L/âˆ‚aâ‚‚ Â· âˆ‚aâ‚‚/âˆ‚zâ‚‚ Â· âˆ‚zâ‚‚/âˆ‚Wâ‚‚`

    `âˆ‚L/âˆ‚Wâ‚ = âˆ‚L/âˆ‚aâ‚‚ Â· âˆ‚aâ‚‚/âˆ‚zâ‚‚ Â· âˆ‚zâ‚‚/âˆ‚aâ‚ Â· âˆ‚aâ‚/âˆ‚zâ‚ Â· âˆ‚zâ‚/âˆ‚Wâ‚`

```python
class SimpleNeuralNet:  # Definir clase de red neuronal simple
    """Red neuronal de 2 capas para demostrar backprop."""

    def __init__(self, input_size: int, hidden_size: int, output_size: int):  # Constructor
        # Inicializar pesos (Xavier initialization)
        self.W1 = np.random.randn(hidden_size, input_size) * np.sqrt(2 / input_size)  # Pesos capa 1
        self.b1 = np.zeros(hidden_size)  # Sesgos capa 1
        self.W2 = np.random.randn(output_size, hidden_size) * np.sqrt(2 / hidden_size)  # Pesos capa 2
        self.b2 = np.zeros(output_size)  # Sesgos capa 2

        # Cache para backprop
        self.cache = {}  # Diccionario para guardar valores intermedios

    def sigmoid(self, z):  # Definir funciÃ³n sigmoide
        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))  # Sigmoide con clip para evitar overflow

    def sigmoid_derivative(self, a):  # Definir derivada de sigmoide
        return a * (1 - a)  # Ïƒ'(a) = Ïƒ(1-Ïƒ)

    def forward(self, x: np.ndarray) -> np.ndarray:  # Definir forward pass
        """Forward pass guardando valores intermedios."""
        # Capa 1
        z1 = self.W1 @ x + self.b1  # Pre-activaciÃ³n capa 1: z1 = W1x + b1
        a1 = self.sigmoid(z1)  # ActivaciÃ³n capa 1: a1 = sigmoid(z1)

        # Capa 2
        z2 = self.W2 @ a1 + self.b2  # Pre-activaciÃ³n capa 2: z2 = W2a1 + b2
        a2 = self.sigmoid(z2)  # ActivaciÃ³n capa 2: a2 = sigmoid(z2)

        # Guardar para backprop
        self.cache = {'x': x, 'z1': z1, 'a1': a1, 'z2': z2, 'a2': a2}  # Guardar valores intermedios

        return a2  # Devolver salida de la red

    def backward(self, y_true: np.ndarray) -> dict:  # Definir backward pass
        """
        Backward pass usando Chain Rule.

        Returns:
            Gradientes de todos los parÃ¡metros
        """
        x = self.cache['x']  # Recuperar entrada original
        a1 = self.cache['a1']  # Recuperar activaciÃ³n capa 1
        a2 = self.cache['a2']  # Recuperar activaciÃ³n capa 2

        # âˆ‚L/âˆ‚aâ‚‚ (MSE)
        dL_da2 = 2 * (a2 - y_true)  # Derivada de MSE respecto a a2

        # âˆ‚aâ‚‚/âˆ‚zâ‚‚
        da2_dz2 = self.sigmoid_derivative(a2)  # Derivada de sigmoide en a2

        # âˆ‚L/âˆ‚zâ‚‚ = âˆ‚L/âˆ‚aâ‚‚ Â· âˆ‚aâ‚‚/âˆ‚zâ‚‚
        dL_dz2 = dL_da2 * da2_dz2  # Aplicar regla de la cadena

        # Gradientes de capa 2
        # âˆ‚zâ‚‚/âˆ‚Wâ‚‚ = aâ‚, âˆ‚zâ‚‚/âˆ‚bâ‚‚ = 1
        dL_dW2 = np.outer(dL_dz2, a1)  # Gradiente respecto a W2: producto externo
        dL_db2 = dL_dz2  # Gradiente respecto a b2: mismo valor

        # Propagar hacia atrÃ¡s a capa 1
        # âˆ‚zâ‚‚/âˆ‚aâ‚ = Wâ‚‚
        dL_da1 = self.W2.T @ dL_dz2  # Propagar error hacia atrÃ¡s: W2^T Â· dL_dz2

        # âˆ‚aâ‚/âˆ‚zâ‚
        da1_dz1 = self.sigmoid_derivative(a1)  # Derivada de sigmoide en a1

        # âˆ‚L/âˆ‚zâ‚
        dL_dz1 = dL_da1 * da1_dz1  # Aplicar regla de la cadena

        # Gradientes de capa 1
        # âˆ‚zâ‚/âˆ‚Wâ‚ = x, âˆ‚zâ‚/âˆ‚bâ‚ = 1
        dL_dW1 = np.outer(dL_dz1, x)  # Gradiente respecto a W1: producto externo
        dL_db1 = dL_dz1  # Gradiente respecto a b1: mismo valor

        return {  # Devolver todos los gradientes
            'dW1': dL_dW1, 'db1': dL_db1,  # Gradientes capa 1
            'dW2': dL_dW2, 'db2': dL_db2   # Gradientes capa 2
        }  # Devolver diccionario con todos los gradientes

    def update(self, gradients: dict, learning_rate: float):  # Definir mÃ©todo de actualizaciÃ³n
        """Actualiza parÃ¡metros usando gradient descent."""
        self.W1 -= learning_rate * gradients['dW1']  # Actualizar W1: W1 = W1 - Î±Â·dW1
        self.b1 -= learning_rate * gradients['db1']  # Actualizar b1: b1 = b1 - Î±Â·db1
        self.W2 -= learning_rate * gradients['dW2']  # Actualizar W2: W2 = W2 - Î±Â·dW2
        self.b2 -= learning_rate * gradients['db2']  # Actualizar b2: b2 = b2 - Î±Â·db2


# Demo: XOR problem
def demo_xor():  # Definir demostraciÃ³n con problema XOR
    """Entrena la red para resolver XOR."""
    # XOR data
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]).T  # 2x4  # Entradas XOR transpuestas
    y = np.array([[0], [1], [1], [0]]).T              # 1x4  # Salidas XOR transpuestas

    # Crear red
    net = SimpleNeuralNet(input_size=2, hidden_size=4, output_size=1)  # Red 2-4-1

    # Entrenar
    losses = []  # Lista para guardar pÃ©rdidas
    for epoch in range(10000):  # 10000 Ã©pocas de entrenamiento
        total_loss = 0  # Inicializar pÃ©rdida total
        for i in range(4):  # Iterar sobre 4 ejemplos XOR
            # Forward
            output = net.forward(X[:, i])  # Propagar entrada i
            loss = (output - y[:, i]) ** 2  # Calcular pÃ©rdida MSE
            total_loss += loss[0]  # Acumular pÃ©rdida

            # Backward
            gradients = net.backward(y[:, i])  # Calcular gradientes

            # Update
            net.update(gradients, learning_rate=0.5)  # Actualizar pesos con lr=0.5

        losses.append(total_loss / 4)  # Guardar pÃ©rdida promedio

        if epoch % 2000 == 0:  # Imprimir cada 2000 Ã©pocas
            print(f"Epoch {epoch}: Loss = {losses[-1]:.4f}")  # Mostrar pÃ©rdida

    # Test
    print("\n=== Resultados XOR ===")  # Imprimir resultados
    for i in range(4):  # Probar cada ejemplo
        pred = net.forward(X[:, i])  # Obtener predicciÃ³n
        print(f"Input: {X[:, i]} â†’ Pred: {pred[0]:.3f} (Target: {y[0, i]})")  # Mostrar resultado

demo_xor()  # Ejecutar demostraciÃ³n
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 4.3: Backpropagation en una Red de 2 Capas</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Backprop en 2 capas: cache, gradientes y actualizaciÃ³n
- **ID (opcional):** `M03-T04_3`
- **DuraciÃ³n estimada:** 120â€“180 min
- **Nivel:** Intermedioâ€“Avanzado
- **Dependencias:** 4.2 (preview), 4.0 (grafo), 3.1â€“3.2 (GD y LR)

#### 2) Objetivos
- Entender por quÃ© el **cache** (guardar `x, z1, a1, z2, a2`) es necesario para backprop.
- Derivar/interpretar `dW2, db2, dW1, db1` y sus dimensiones.
- Conectar el cÃ¡lculo de gradientes con el update de Gradient Descent.

#### 3) Relevancia
- Este patrÃ³n (forward â†’ cache â†’ backward â†’ update) es la base de cualquier entrenamiento de NN.

#### 4) Mapa conceptual mÃ­nimo
- **Forward:** `x â†’ (z1,a1) â†’ (z2,a2) â†’ L`
- **Backward:** `dL/da2 â†’ dL/dz2 â†’ (dW2,db2) â†’ dL/da1 â†’ dL/dz1 â†’ (dW1,db1)`

#### 5) Definiciones esenciales
- **Backpropagation:** aplicaciÃ³n sistemÃ¡tica de chain rule para obtener derivadas respecto a parÃ¡metros.
- **Outer product:** usado para formar `dW = Î´ âŠ— activaciÃ³n`.

#### 6) ExplicaciÃ³n didÃ¡ctica
- Regla prÃ¡ctica de formas:
  - Si `z = W a + b`, entonces `âˆ‚L/âˆ‚W = Î´ âŠ— a` y `âˆ‚L/âˆ‚b = Î´`.
- Si te equivocas en shapes, casi siempre te falta un transpose.

#### 7) Ejemplo modelado
- El demo XOR muestra un loop completo: forward, loss, backward, update, y reporte periÃ³dico.

#### 8) PrÃ¡ctica guiada
- Imprime shapes (`W1.shape`, `dW1.shape`, etc.) y verifica coherencia en cada paso.

#### 9) PrÃ¡ctica independiente
- Cambia `hidden_size` y observa impacto en convergencia.
- AÃ±ade `learning_rate` mÃ¡s pequeÃ±o y compara estabilidad.

#### 10) AutoevaluaciÃ³n
- Â¿Por quÃ© `dW2 = outer(dL_dz2, a1)` y no `outer(a1, dL_dz2)`?

#### 11) Errores comunes
- Olvidar que `sigmoid_derivative` usa `a` (activaciÃ³n) y no `z`.
- Confundir el vector columna/fila y generar `dW` transpuesto.
- LR demasiado alto: diverge o se â€œqueda oscilandoâ€.

#### 12) RetenciÃ³n
- (dÃ­a 2) Escribe el pipeline de 2 capas: `Î´2 â†’ dW2 â†’ Î´1 â†’ dW1`.

#### 13) DiferenciaciÃ³n
- Avanzado: reemplaza MSE por BCE + sigmoid y discute estabilidad.

#### 14) Recursos
- CapÃ­tulos intro de backprop (computational graphs) y notas de â€œmatrix calculusâ€.

#### 15) Nota docente
- Pedir evidencia de comprensiÃ³n: diagrama + shapes + explicaciÃ³n de `outer`.
</details>

---
## ğŸ¯ Ejercicios por tema (progresivos) + Soluciones

Reglas:

- **Intenta primero** sin mirar la soluciÃ³n.
- **Timebox sugerido:** 15â€“30 min por ejercicio.
- **Ã‰xito mÃ­nimo:** tu soluciÃ³n debe pasar los `assert`.

---

### Ejercicio 3.1: Derivada numÃ©rica (diferencias finitas) vs derivada analÃ­tica

#### Enunciado

1) **BÃ¡sico**

- Implementa la derivada numÃ©rica central: `f'(x) â‰ˆ (f(x+h)-f(x-h))/(2h)`.

2) **Intermedio**

- Para `f(x) = x^3 + 2x`, implementa `f'(x)` analÃ­tica y compara en varios puntos.

3) **Avanzado**

- Prueba `h=1e-2, 1e-4, 1e-6` y verifica que el error no crece de forma absurda.

#### SoluciÃ³n

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica


# Aproximamos derivadas numÃ©ricamente usando *diferencias centrales*.
# IntuiciÃ³n: medir la pendiente alrededor de x de forma simÃ©trica (x+h y x-h)
# cancela tÃ©rminos de error de primer orden y suele ser mÃ¡s preciso que la
# diferencia hacia adelante.

def num_derivative_central(f, x: float, h: float = 1e-6) -> float:  # Definir derivada numÃ©rica central
    # f: funciÃ³n escalar f(x).  # FunciÃ³n a derivar
    # x: punto donde evaluamos la derivada.  # Punto de evaluaciÃ³n
    # h: tamaÃ±o de paso. Hay tradeoff:  # TamaÃ±o del paso
    # - h grande => error de truncamiento (aproximaciÃ³n) domina  # Error por paso grande
    # - h muy pequeÃ±o => cancelaciÃ³n numÃ©rica (floating point) domina  # Error por paso pequeÃ±o
    # Devolvemos float para facilitar asserts y logs.
    return float((f(x + h) - f(x - h)) / (2.0 * h))  # Calcular diferencia central


def f(x: float) -> float:  # Definir funciÃ³n de prueba
    # FunciÃ³n de prueba (suave y derivable).
    return x**3 + 2.0 * x  # FunciÃ³n cÃºbica simple


def f_prime(x: float) -> float:  # Definir derivada analÃ­tica
    # Derivada analÃ­tica:
    # d/dx (x^3) = 3x^2  # Derivada de x^3
    # d/dx (2x)  = 2  # Derivada de 2x
    return 3.0 * x**2 + 2.0  # Sumar derivadas


# Probamos varios puntos para evitar que pase "por casualidad" en un solo x.
xs = [-2.0, -0.5, 0.0, 1.0, 3.0]  # Puntos de prueba
for x in xs:  # Iterar sobre cada punto
    # AproximaciÃ³n numÃ©rica.
    approx = num_derivative_central(f, x, h=1e-6)  # Calcular derivada numÃ©rica
    # Valor exacto (analÃ­tico).
    exact = f_prime(x)  # Calcular derivada exacta
    # np.isclose compara igualdad aproximada con tolerancias:
    # - rtol: tolerancia relativa (escala con el tamaÃ±o)
    # - atol: tolerancia absoluta (Ãºtil cerca de 0)
    assert np.isclose(approx, exact, rtol=1e-6, atol=1e-6)  # Verificar coincidencia


# Estudiamos cÃ³mo cambia el error con distintos h.
# Nota: no imponemos monotonÃ­a estricta porque h extremadamente pequeÃ±o puede
# empeorar por precisiÃ³n de mÃ¡quina.
x0 = 1.234  # Punto fijo para anÃ¡lisis
errs = []  # Lista para errores
for h in [1e-2, 1e-4, 1e-6]:  # Probar diferentes tamaÃ±os de paso
    # Misma x0, distinto paso.
    approx = num_derivative_central(f, x0, h=h)  # Calcular aproximaciÃ³n
    # Error absoluto vs derivada analÃ­tica.
    errs.append(abs(approx - f_prime(x0)))  # Calcular y guardar error

# Sanidad mÃ­nima: al refinar de 1e-2 a 1e-4, no deberÃ­a empeorar.
assert errs[1] <= errs[0] + 1e-6  # Verificar que error disminuya
```

---

### Ejercicio 3.2: Derivadas parciales y gradiente (2D)

#### Enunciado

Sea `f(x, y) = x^2 y + sin(y)`.

1) **BÃ¡sico**

- Deriva analÃ­ticamente `âˆ‚f/âˆ‚x` y `âˆ‚f/âˆ‚y`.

2) **Intermedio**

- Implementa el gradiente `âˆ‡f(x,y)` y evalÃºalo en un punto.

3) **Avanzado**

- Verifica con gradiente numÃ©rico (diferencias centrales) que tu gradiente analÃ­tico es correcto.

#### SoluciÃ³n

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica

def f_xy(x: float, y: float) -> float:  # Definir funciÃ³n de 2 variables
    # FunciÃ³n escalar de 2 variables:
    # f(x, y) = x^2 * y + sin(y)
    return x**2 * y + np.sin(y)  # Evaluar funciÃ³n


def grad_f_xy(x: float, y: float) -> np.ndarray:  # Definir gradiente analÃ­tico
    # Gradiente analÃ­tico (derivadas parciales):
    # âˆ‚f/âˆ‚x = 2xy  # Derivada parcial respecto a x
    # âˆ‚f/âˆ‚y = x^2 + cos(y)  # Derivada parcial respecto a y
    dfdx = 2.0 * x * y  # Calcular derivada respecto a x
    dfdy = x**2 + np.cos(y)  # Calcular derivada respecto a y
    # Empaquetamos como vector [df/dx, df/dy].
    return np.array([dfdx, dfdy], dtype=float)  # Devolver vector gradiente


def num_grad_2d(f, x: float, y: float, h: float = 1e-6) -> np.ndarray:  # Definir gradiente numÃ©rico 2D
    # Gradiente numÃ©rico con diferencias centrales.
    # Para cada variable, perturbamos solo esa coordenada.
    dfdx = (f(x + h, y) - f(x - h, y)) / (2.0 * h)  # Calcular derivada parcial respecto a x
    dfdy = (f(x, y + h) - f(x, y - h)) / (2.0 * h)  # Calcular derivada parcial respecto a y
    # Vector gradiente.
    return np.array([dfdx, dfdy], dtype=float)  # Devolver gradiente numÃ©rico


# Punto de evaluaciÃ³n (no trivial para evitar simetrÃ­as).
x0, y0 = 1.2, -0.7  # Punto de prueba

# Gradiente analÃ­tico.
g_anal = grad_f_xy(x0, y0)  # Calcular gradiente analÃ­tico

# Gradiente numÃ©rico (check independiente).
g_num = num_grad_2d(f_xy, x0, y0)  # Calcular gradiente numÃ©rico

# Deben coincidir si las derivadas estÃ¡n bien.
assert np.allclose(g_anal, g_num, rtol=1e-5, atol=1e-6)  # Verificar coincidencia
```

---

### Ejercicio 3.3: Derivada direccional (intuiciÃ³n: el gradiente manda)

#### Enunciado

1) **BÃ¡sico**

- Para `f(x,y)=x^2 y + sin(y)`, calcula `âˆ‡f(x0,y0)`.

2) **Intermedio**

- Dado un vector direcciÃ³n unitario `u`, calcula la derivada direccional `D_u f = âˆ‡f Â· u`.

3) **Avanzado**

- Verifica numÃ©ricamente `D_u f` con diferencias finitas sobre `p(t)=p0 + t u`.

#### SoluciÃ³n

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica

def f_xy(x: float, y: float) -> float:  # Definir funciÃ³n de 2 variables
    # Misma funciÃ³n del ejercicio anterior.
    return x**2 * y + np.sin(y)  # Evaluar funciÃ³n


def grad_f_xy(x: float, y: float) -> np.ndarray:  # Definir gradiente
    # âˆ‡f(x,y) = [âˆ‚f/âˆ‚x, âˆ‚f/âˆ‚y]
    return np.array([2.0 * x * y, x**2 + np.cos(y)], dtype=float)  # Calcular gradiente


# Punto base p0 = (x0, y0).
x0, y0 = 0.5, 1.0  # Punto de evaluaciÃ³n

# Gradiente en p0.
g = grad_f_xy(x0, y0)  # Calcular gradiente en punto

# Vector direcciÃ³n (aÃºn no unitario).
u = np.array([3.0, 4.0], dtype=float)  # Vector direcciÃ³n inicial

# La derivada direccional se define sobre u unitario: ||u|| = 1.
u = u / np.linalg.norm(u)  # Normalizar vector direcciÃ³n

# Derivada direccional analÃ­tica: D_u f = âˆ‡f Â· u.
dir_anal = float(np.dot(g, u))  # Calcular producto punto

# VerificaciÃ³n numÃ©rica: avanzamos/retrocedemos h sobre la recta p(t)=p0 + t u.
h = 1e-6  # Paso pequeÃ±o
f_plus = f_xy(x0 + h * u[0], y0 + h * u[1])  # Evaluar funciÃ³n adelante
f_minus = f_xy(x0 - h * u[0], y0 - h * u[1])  # Evaluar funciÃ³n atrÃ¡s

# Diferencia central en la direcciÃ³n u.
dir_num = float((f_plus - f_minus) / (2.0 * h))  # Calcular derivada direccional numÃ©rica

# ComparaciÃ³n con tolerancia.
assert np.isclose(dir_anal, dir_num, rtol=1e-5, atol=1e-6)  # Verificar coincidencia
```

---

### Ejercicio 3.4: Jacobiano (funciÃ³n vectorial)

#### Enunciado

Sea `g(x1,x2) = [x1^2 + x2, sin(x1 x2)]`.

1) **BÃ¡sico**

- Escribe el Jacobiano `J` (matriz 2x2) a mano.

2) **Intermedio**

- Implementa `J_analytical(x)`.

3) **Avanzado**

- Verifica con Jacobiano numÃ©rico (diferencias centrales) que `J` coincide.

#### SoluciÃ³n

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica

def g(x: np.ndarray) -> np.ndarray:  # Definir funciÃ³n vectorial g
    # FunciÃ³n vectorial g: R^2 -> R^2.
    # Convertimos a float para evitar dtypes raros (int) y asegurar operaciones reales.
    x1, x2 = float(x[0]), float(x[1])  # Extraer componentes como float
    # Definimos:
    # g1 = x1^2 + x2
    # g2 = sin(x1 * x2)
    return np.array([x1**2 + x2, np.sin(x1 * x2)], dtype=float)  # Devolver array con g1 y g2


def J_analytical(x: np.ndarray) -> np.ndarray:  # Definir Jacobiano analÃ­tico
    # Jacobiano J: matriz de derivadas parciales.
    # J[i, j] = âˆ‚g_i / âˆ‚x_j
    # AquÃ­ hay 2 salidas y 2 entradas => J es 2x2.
    x1, x2 = float(x[0]), float(x[1])  # Extraer componentes como float

    # g1 = x1^2 + x2
    # âˆ‚g1/âˆ‚x1 = 2x1
    # âˆ‚g1/âˆ‚x2 = 1
    dg1_dx1 = 2.0 * x1  # Derivada parcial de g1 respecto a x1
    dg1_dx2 = 1.0  # Derivada parcial de g1 respecto a x2

    # g2 = sin(x1*x2)
    # Regla de la cadena:
    # âˆ‚g2/âˆ‚x1 = cos(x1*x2) * x2
    # âˆ‚g2/âˆ‚x2 = cos(x1*x2) * x1
    dg2_dx1 = np.cos(x1 * x2) * x2  # Derivada parcial de g2 respecto a x1
    dg2_dx2 = np.cos(x1 * x2) * x1  # Derivada parcial de g2 respecto a x2

    # Empaquetamos en una matriz 2x2.
    return np.array([[dg1_dx1, dg1_dx2], [dg2_dx1, dg2_dx2]], dtype=float)  # Devolver Jacobiano


def J_numeric(g, x: np.ndarray, h: float = 1e-6) -> np.ndarray:  # Definir Jacobiano numÃ©rico
    # Jacobiano numÃ©rico con diferencias centrales.
    # Para cada coordenada j, perturbamos x por Â±h e_j y obtenemos la columna J[:, j].
    x = x.astype(float)  # Convertir a float para operaciones
    # m: dimensiÃ³n de salida, n: dimensiÃ³n de entrada.
    m = g(x).shape[0]  # NÃºmero de salidas
    n = x.shape[0]  # NÃºmero de entradas
    # Inicializamos J.
    J = np.zeros((m, n), dtype=float)  # Inicializar Jacobiano con ceros
    for j in range(n):  # Iterar sobre cada columna (dimensiÃ³n de entrada)
        # Vector base e_j.
        e = np.zeros(n)  # Crear vector base
        e[j] = 1.0  # Poner 1 en posiciÃ³n j
        # Diferencia central para todas las salidas a la vez.
        J[:, j] = (g(x + h * e) - g(x - h * e)) / (2.0 * h)  # Calcular columna j del Jacobiano
    return J  # Devolver Jacobiano numÃ©rico


# Punto de prueba.
x0 = np.array([0.7, -1.1])  # Punto de evaluaciÃ³n

# Comparamos Jacobiano analÃ­tico vs numÃ©rico.
Ja = J_analytical(x0)  # Calcular Jacobiano analÃ­tico
Jn = J_numeric(g, x0)  # Calcular Jacobiano numÃ©rico

# Si la derivaciÃ³n estÃ¡ correcta, deben ser casi iguales.
assert np.allclose(Ja, Jn, rtol=1e-5, atol=1e-6)  # Verificar que Jacobianos sean casi iguales
```

---

### Ejercicio 3.5: Hessiano (curvatura local) + convexidad

#### Enunciado

Sea `f(x1,x2) = x1^2 + 2 x2^2`.

1) **BÃ¡sico**

- Calcula el Hessiano `H`.

2) **Intermedio**

- Verifica que `H` es simÃ©trico.

3) **Avanzado**

- Verifica que `H` es definido positivo (eigenvalores > 0).

#### SoluciÃ³n

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica

# Para f(x1,x2)=x1^2 + 2x2^2:
# - âˆ‚Â²f/âˆ‚x1Â² = 2  # Segunda derivada respecto a x1
# - âˆ‚Â²f/âˆ‚x2Â² = 4  # Segunda derivada respecto a x2
# - derivadas cruzadas = 0  # Derivadas cruzadas son cero
H = np.array([[2.0, 0.0], [0.0, 4.0]], dtype=float)  # Matriz Hessiana

# El Hessiano de una funciÃ³n escalar dos-veces derivable debe ser simÃ©trico.
assert np.allclose(H, H.T)  # Verificar simetrÃ­a

# Hessiano definido positivo => funciÃ³n estrictamente convexa.
# En particular, un criterio suficiente aquÃ­ es: eigenvalores > 0.
eigvals = np.linalg.eigvals(H)  # Calcular eigenvalores
assert np.all(eigvals > 0)  # Verificar que sean positivos
```

---

### Ejercicio 3.6: Gradient Descent 1D (convergencia)

#### Enunciado

Minimiza `f(x) = (x - 3)^2` con Gradient Descent.

1) **BÃ¡sico**

- Implementa la regla de actualizaciÃ³n: `x <- x - Î± f'(x)`.

2) **Intermedio**

- Registra `x_t` y `f(x_t)`.

3) **Avanzado**

- Usa un criterio de parada por `|grad| < tol`.

#### SoluciÃ³n

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica

def f(x: float) -> float:  # Definir funciÃ³n de pÃ©rdida
    # FunciÃ³n convexa con mÃ­nimo global en x=3.
    return (x - 3.0) ** 2  # FunciÃ³n cuadrÃ¡tica simple


def grad_f(x: float) -> float:  # Definir gradiente
    # Derivada: d/dx (x-3)^2 = 2(x-3)
    return 2.0 * (x - 3.0)  # Calcular gradiente


# InicializaciÃ³n.
x = 10.0  # Punto inicial

# Learning rate (tamaÃ±o de paso).
alpha = 0.1  # Tasa de aprendizaje

# Historial de iteraciones para inspecciÃ³n y asserts.
history = []  # Lista para guardar historial
for _ in range(200):  # Iterar 200 veces
    # Gradiente en el punto actual.
    g = grad_f(x)  # Calcular gradiente
    # Guardamos (x, f(x)) antes de actualizar.
    history.append((x, f(x)))  # Guardar en historial
    # Criterio de parada: gradiente cerca de 0 => cerca del mÃ­nimo.
    if abs(g) < 1e-8:  # Verificar si gradiente es pequeÃ±o
        break  # Salir del bucle
    # ActualizaciÃ³n de Gradient Descent.
    x = x - alpha * g  # Actualizar x

# Debe converger cerca de 3.
assert abs(x - 3.0) < 1e-4  # Verificar convergencia al mÃ­nimo

# La pÃ©rdida final no deberÃ­a ser mayor que la inicial.
assert history[-1][1] <= history[0][1]  # Verificar que pÃ©rdida disminuyÃ³
```

---

### Ejercicio 3.7: Efecto del learning rate (estabilidad)

#### Enunciado

Minimiza `f(x)=x^2` con Gradient Descent desde `x0=1`.

1) **BÃ¡sico**

- Deriva la actualizaciÃ³n: `x_{t+1} = (1 - 2Î±) x_t`.

2) **Intermedio**

- Prueba con `Î±=0.25` y verifica que `|x_t|` decrece.

3) **Avanzado**

- Prueba con `Î±=1.1` y verifica divergencia (`|x_t|` crece).

#### SoluciÃ³n

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica

def run_gd_x2(alpha: float, steps: int = 10) -> np.ndarray:  # Definir funciÃ³n de GD
    # Minimizamos f(x)=x^2 con GD. Su gradiente es 2x.
    x = 1.0  # Punto inicial
    # Guardamos la trayectoria.
    xs = [x]  # Lista para historial
    for _ in range(steps):  # Iterar pasos
        # Gradiente en el punto actual.
        grad = 2.0 * x  # Calcular gradiente
        # Paso de GD.
        x = x - alpha * grad  # Actualizar x
        # Guardamos el nuevo x.
        xs.append(x)  # Agregar a historial
    # Convertimos a np.array para anÃ¡lisis.
    return np.array(xs)  # Devolver trayectoria


# Con alpha=0.25, el factor (1-2Î±)=0.5 => converge.
xs_good = run_gd_x2(alpha=0.25, steps=10)  # Ejecutar GD con alpha bueno

# La magnitud debe decrecer.
assert abs(xs_good[-1]) < abs(xs_good[0])  # Verificar convergencia


# Con alpha=1.1, |1-2Î±| = |1-2.2| = 1.2 > 1 => diverge.
xs_bad = run_gd_x2(alpha=1.1, steps=10)  # Ejecutar GD con alpha malo
assert abs(xs_bad[-1]) > abs(xs_bad[0])  # Verificar divergencia
```

---

### Ejercicio 3.8: Gradient checking (vector) + error relativo

#### Enunciado

1) **BÃ¡sico**

- Implementa gradiente numÃ©rico (diferencias centrales) para `f(w)`.

2) **Intermedio**

- Usa `f(w)=âˆ‘ w_i^3` cuyo gradiente analÃ­tico es `3 w_i^2`.

3) **Avanzado**

- Calcula error relativo `||g_num - g_anal|| / (||g_num|| + ||g_anal|| + eps)`.

#### SoluciÃ³n

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica

def f(w: np.ndarray) -> float:  # Definir funciÃ³n escalar
    # FunciÃ³n escalar sobre un vector: f(w) = sum_i w_i^3.
    # Convertimos a float para devolver un escalar Python.
    return float(np.sum(w ** 3))  # Sumar cubos de elementos


def grad_analytical(w: np.ndarray) -> np.ndarray:  # Definir gradiente analÃ­tico
    # Gradiente analÃ­tico: âˆ‚/âˆ‚w_i (w_i^3) = 3 w_i^2.
    return 3.0 * (w ** 2)  # Calcular 3*w_i^2 para cada elemento


def grad_numeric(f, w: np.ndarray, h: float = 1e-6) -> np.ndarray:  # Definir gradiente numÃ©rico
    # Gradiente numÃ©rico con diferencias centrales.
    # Para cada coordenada i, perturbamos w por Â±h e_i.
    w = w.astype(float)  # Convertir a float
    # Vector de gradientes numÃ©ricos.
    g = np.zeros_like(w)  # Inicializar con ceros
    for i in range(w.size):  # Iterar sobre cada elemento
        # Vector base e_i.
        e = np.zeros_like(w)  # Crear vector base
        e[i] = 1.0  # Poner 1 en posiciÃ³n i
        # Diferencia central: âˆ‚f/âˆ‚w_i â‰ˆ (f(w+h e_i) - f(w-h e_i)) / (2h)
        g[i] = (f(w + h * e) - f(w - h * e)) / (2.0 * h)  # Calcular derivada parcial
    return g  # Devolver gradiente numÃ©rico


# Semilla para reproducibilidad.
np.random.seed(0)  # Fijar semilla

# Vector de prueba.
w = np.random.randn(5)  # Vector aleatorio de 5 dimensiones

# Gradientes analÃ­tico y numÃ©rico.
g_a = grad_analytical(w)  # Calcular gradiente analÃ­tico
g_n = grad_numeric(f, w)  # Calcular gradiente numÃ©rico

# Error relativo: mÃ¡s robusto que el error absoluto porque normaliza escalas.
eps = 1e-12  # PequeÃ±o valor para evitar divisiÃ³n por cero
rel_err = np.linalg.norm(g_n - g_a) / (np.linalg.norm(g_n) + np.linalg.norm(g_a) + eps)  # Calcular error relativo

# Si falla, normalmente indica error en derivada o un h inapropiado.
assert rel_err < 1e-7  # Verificar que error sea pequeÃ±o
```

---

### Ejercicio 3.9: Chain Rule (neurona + MSE) + verificaciÃ³n numÃ©rica

#### Enunciado

Una neurona:

- `z = wÂ·x + b`
- `Å· = Ïƒ(z)`
- `L = (Å· - y)^2`

1) **BÃ¡sico**

- Deriva `dL/dz` usando chain rule.

2) **Intermedio**

- Deriva `dL/dw` y `dL/db`.

3) **Avanzado**

- Verifica tus gradientes con diferencias centrales.

#### SoluciÃ³n

```python
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica

def sigmoid(z: float) -> float:  # Definir funciÃ³n sigmoide
    # Sigmoide Ïƒ(z) = 1 / (1 + exp(-z)).
    # Convertimos a float para devolver escalar.
    return float(1.0 / (1.0 + np.exp(-z)))  # Calcular sigmoide y convertir a float


def loss_mse(y_hat: float, y: float) -> float:  # Definir funciÃ³n de pÃ©rdida MSE
    # PÃ©rdida MSE para un solo ejemplo: (Å· - y)^2
    return float((y_hat - y) ** 2)  # Calcular error cuadrÃ¡tico medio


def forward(w: np.ndarray, b: float, x: np.ndarray, y: float) -> float:  # Definir forward pass
    # Forward de una neurona:
    # z = wÂ·x + b
    # Å· = Ïƒ(z)
    # L = (Å· - y)^2
    z = float(np.dot(w, x) + b)  # Calcular pre-activaciÃ³n: z = wÂ·x + b
    y_hat = sigmoid(z)  # Calcular activaciÃ³n: Å· = Ïƒ(z)
    return loss_mse(y_hat, y)  # Retornar pÃ©rdida MSE


def grads_analytical(w: np.ndarray, b: float, x: np.ndarray, y: float):  # Definir gradientes analÃ­ticos
    # Gradientes analÃ­ticos vÃ­a Chain Rule.
    z = float(np.dot(w, x) + b)  # Calcular pre-activaciÃ³n
    y_hat = sigmoid(z)  # Calcular activaciÃ³n

    # dL/dÅ· cuando L=(Å·-y)^2.
    dL_dyhat = 2.0 * (y_hat - y)  # Derivada de pÃ©rdida respecto a Å·
    # dÅ·/dz para sigmoide: Ïƒ'(z)=Ïƒ(z)(1-Ïƒ(z)).
    dyhat_dz = y_hat * (1.0 - y_hat)  # Derivada de sigmoide
    # Chain rule: dL/dz = dL/dÅ· * dÅ·/dz.
    dL_dz = dL_dyhat * dyhat_dz  # Aplicar regla de la cadena

    # z = wÂ·x + b => dz/dw = x y dz/db = 1.  # Derivadas de z respecto a pesos
    # Entonces:  # Aplicando regla de la cadena
    # dL/dw = dL/dz * x  # Gradiente respecto a w
    # dL/db = dL/dz  # Gradiente respecto a b
    dL_dw = dL_dz * x  # Calcular gradiente de w
    dL_db = dL_dz  # Calcular gradiente de b
    return dL_dw.astype(float), float(dL_db)  # Devolver gradientes como float


def grads_numeric(w: np.ndarray, b: float, x: np.ndarray, y: float, h: float = 1e-6):  # Definir gradientes numÃ©ricos
    # Gradientes numÃ©ricos por diferencias centrales.
    gw = np.zeros_like(w, dtype=float)  # Inicializar gradiente de w con ceros
    for i in range(w.size):  # Iterar sobre cada elemento de w
        # Vector base e_i.
        e = np.zeros_like(w)  # Crear vector base
        e[i] = 1.0  # Poner 1 en posiciÃ³n i
        # âˆ‚L/âˆ‚w_i â‰ˆ (L(w+h e_i) - L(w-h e_i)) / (2h)
        gw[i] = (forward(w + h * e, b, x, y) - forward(w - h * e, b, x, y)) / (2.0 * h)  # Calcular gradiente numÃ©rico

    # âˆ‚L/âˆ‚b â‰ˆ (L(b+h) - L(b-h)) / (2h)
    gb = (forward(w, b + h, x, y) - forward(w, b - h, x, y)) / (2.0 * h)  # Calcular gradiente de b
    return gw, float(gb)  # Devolver gradientes numÃ©ricos


# Reproducibilidad.
np.random.seed(1)  # Fijar semilla para reproducibilidad

# ParÃ¡metros y entrada de ejemplo.
w = np.random.randn(3)  # Pesos aleatorios de 3 dimensiones
b = 0.1  # Sesgo inicial
x = np.random.randn(3)  # Entrada aleatoria de 3 dimensiones

# Etiqueta objetivo.
y = 1.0  # Salida deseada

# Comparamos gradientes.
gw_a, gb_a = grads_analytical(w, b, x, y)  # Calcular gradientes analÃ­ticos
gw_n, gb_n = grads_numeric(w, b, x, y)  # Calcular gradientes numÃ©ricos

# Si la derivaciÃ³n por chain rule estÃ¡ bien, deben coincidir.
assert np.allclose(gw_a, gw_n, rtol=1e-5, atol=1e-6)  # Verificar gradiente de w
assert np.isclose(gb_a, gb_n, rtol=1e-5, atol=1e-6)  # Verificar gradiente de b
```

---

## Entregable del MÃ³dulo

### Script: `gradient_descent_demo.py`

```python
"""
Gradient Descent Demo - VisualizaciÃ³n de OptimizaciÃ³n

Este script implementa Gradient Descent desde cero y visualiza
la trayectoria de optimizaciÃ³n en diferentes funciones.

Autor: [Tu nombre]  # Nombre del autor
MÃ³dulo: 03 - CÃ¡lculo Multivariante  # MÃ³dulo al que pertenece
"""

import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica
import matplotlib.pyplot as plt  # Importar librerÃ­a para visualizaciÃ³n
from typing import Callable, Tuple, List  # Importar tipos para anotaciones


def gradient_descent(  # Definir funciÃ³n de descenso por gradiente
    f: Callable[[np.ndarray], float],  # FunciÃ³n objetivo a minimizar
    grad_f: Callable[[np.ndarray], np.ndarray],  # Gradiente de la funciÃ³n
    x0: np.ndarray,  # Punto inicial de optimizaciÃ³n
    learning_rate: float = 0.1,  # Tasa de aprendizaje (alpha)
    max_iterations: int = 100,  # MÃ¡ximo nÃºmero de iteraciones
    tolerance: float = 1e-8  # Criterio de convergencia por gradiente
) -> Tuple[np.ndarray, List[np.ndarray], List[float]]:  # Tipos de retorno
    """
    ImplementaciÃ³n de Gradient Descent.

    Args:
        f: funciÃ³n objetivo
        grad_f: gradiente de f
        x0: punto inicial
        learning_rate: Î±
        max_iterations: mÃ¡ximo de iteraciones
        tolerance: criterio de convergencia

    Returns:
        x_final, history_x, history_f
    """
    x = x0.copy().astype(float)  # Copiar punto inicial y convertir a float
    history_x = [x.copy()]  # Guardar histÃ³rico de posiciones
    history_f = [f(x)]  # Guardar histÃ³rico de valores de funciÃ³n

    for i in range(max_iterations):  # Iterar hasta mÃ¡ximo de iteraciones
        grad = grad_f(x)  # Calcular gradiente en punto actual

        if np.linalg.norm(grad) < tolerance:  # Verificar criterio de convergencia
            break  # Salir si gradiente es pequeÃ±o

        x = x - learning_rate * grad  # Actualizar posiciÃ³n: x = x - Î±âˆ‡f
        history_x.append(x.copy())  # Guardar nueva posiciÃ³n
        history_f.append(f(x))  # Guardar nuevo valor de funciÃ³n

    return x, history_x, history_f  # Devolver posiciÃ³n final e histÃ³ricos


def visualize_optimization(  # Definir funciÃ³n para visualizar optimizaciÃ³n
    f: Callable,  # FunciÃ³n objetivo
    grad_f: Callable,  # Gradiente de la funciÃ³n
    x0: np.ndarray,  # Punto inicial
    learning_rate: float,  # Tasa de aprendizaje
    title: str,  # TÃ­tulo para la grÃ¡fica
    xlim: Tuple[float, float] = (-5, 5),  # LÃ­mites en eje x
    ylim: Tuple[float, float] = (-5, 5)  # LÃ­mites en eje y
):  # Cerrar definiciÃ³n de funciÃ³n de visualizaciÃ³n
    """Visualiza la trayectoria de optimizaciÃ³n."""

    x_final, history_x, history_f = gradient_descent(  # Ejecutar descenso por gradiente
        f, grad_f, x0, learning_rate, max_iterations=50  # Con mÃ¡ximo 50 iteraciones
    )  # Cerrar llamada a gradient_descent

    # Crear grid para contornos
    x = np.linspace(xlim[0], xlim[1], 100)  # Crear 100 puntos en eje x
    y = np.linspace(ylim[0], ylim[1], 100)  # Crear 100 puntos en eje y
    X, Y = np.meshgrid(x, y)  # Crear malla 2D
    Z = np.array([[f(np.array([xi, yi])) for xi, yi in zip(row_x, row_y)]  # Evaluar funciÃ³n en cada punto
                  for row_x, row_y in zip(X, Y)])  # Usando list comprehension anidada

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))  # Crear figura con 2 subgrÃ¡ficos

    # Plot 1: Contornos y trayectoria
    ax1 = axes[0]  # Primer subplot para contornos
    contour = ax1.contour(X, Y, Z, levels=30, cmap='viridis')  # Dibujar contornos
    ax1.clabel(contour, inline=True, fontsize=8)  # Etiquetar niveles de contorno

    # Trayectoria
    history_x = np.array(history_x)  # Convertir histÃ³rico a array numpy
    ax1.plot(history_x[:, 0], history_x[:, 1], 'r.-', markersize=8, linewidth=1.5)  # Dibujar trayectoria
    ax1.plot(history_x[0, 0], history_x[0, 1], 'go', markersize=12, label='Inicio')  # Marcar inicio
    ax1.plot(history_x[-1, 0], history_x[-1, 1], 'r*', markersize=15, label='Final')  # Marcar final

    ax1.set_xlabel('x')  # Etiqueta eje x
    ax1.set_ylabel('y')  # Etiqueta eje y
    ax1.set_title(f'{title}\nÎ± = {learning_rate}')  # TÃ­tulo con tasa de aprendizaje
    ax1.legend()  # Mostrar leyenda
    ax1.set_xlim(xlim)  # Establecer lÃ­mites x
    ax1.set_ylim(ylim)  # Establecer lÃ­mites y

    # Plot 2: Convergencia
    ax2 = axes[1]  # Segundo subplot para convergencia
    ax2.semilogy(history_f, 'b-o', markersize=4)  # GrÃ¡fico logarÃ­tmico de convergencia
    ax2.set_xlabel('IteraciÃ³n')  # Etiqueta eje x
    ax2.set_ylabel('f(x) (escala log)')  # Etiqueta eje y
    ax2.set_title('Convergencia')  # TÃ­tulo
    ax2.grid(True)  # Activar cuadrÃ­cula

    plt.tight_layout()  # Ajustar diseÃ±o automÃ¡ticamente
    plt.savefig(f'gd_{title.lower().replace(" ", "_")}.png', dpi=150)  # Guardar grÃ¡fico
    plt.show()  # Mostrar grÃ¡fico en pantalla

    print(f"\n{title}")  # Imprimir tÃ­tulo del resultado
    print(f"  Punto inicial: {x0}")  # Mostrar punto inicial
    print(f"  MÃ­nimo encontrado: {x_final}")  # Mostrar punto mÃ­nimo encontrado
    print(f"  f(mÃ­nimo): {f(x_final):.6f}")  # Mostrar valor mÃ­nimo con 6 decimales
    print(f"  Iteraciones: {len(history_f)}")  # Mostrar nÃºmero de iteraciones


def main():  # Definir funciÃ³n principal
    """Ejecutar demos."""

    # === FunciÃ³n 1: Paraboloide ===
    def paraboloid(p):  # Definir paraboloide simple
        return p[0]**2 + p[1]**2  # f(x,y) = xÂ² + yÂ²

    def grad_paraboloid(p):  # Gradiente del paraboloide
        return np.array([2*p[0], 2*p[1]])  # âˆ‡f = [2x, 2y]

    visualize_optimization(  # Visualizar optimizaciÃ³n del paraboloide
        paraboloid, grad_paraboloid,  # FunciÃ³n y gradiente
        x0=np.array([4.0, 3.0]),  # Punto inicial
        learning_rate=0.1,  # Tasa de aprendizaje
        title="Paraboloide f(x,y) = xÂ² + yÂ²"  # TÃ­tulo
    )  # Cerrar llamada a visualize_optimization para paraboloide

    # === FunciÃ³n 2: Rosenbrock (mÃ¡s difÃ­cil) ===
    def rosenbrock(p):  # Definir funciÃ³n de Rosenbrock
        return (1 - p[0])**2 + 100*(p[1] - p[0]**2)**2  # f(x,y) = (1-x)Â² + 100(y-xÂ²)Â²

    def grad_rosenbrock(p):  # Gradiente de Rosenbrock
        dx = -2*(1 - p[0]) - 400*p[0]*(p[1] - p[0]**2)  # Derivada respecto a x
        dy = 200*(p[1] - p[0]**2)  # Derivada respecto a y
        return np.array([dx, dy])  # Retornar gradiente

    visualize_optimization(  # Visualizar optimizaciÃ³n de Rosenbrock
        rosenbrock, grad_rosenbrock,  # FunciÃ³n y gradiente
        x0=np.array([-1.0, 1.0]),  # Punto inicial
        learning_rate=0.001,  # Tasa de aprendizaje pequeÃ±a
        title="Rosenbrock f(x,y) = (1-x)Â² + 100(y-xÂ²)Â²",  # TÃ­tulo
        xlim=(-2, 2),  # LÃ­mites en x
        ylim=(-1, 3)  # LÃ­mites en y
    )  # Cerrar llamada a visualize_optimization para Rosenbrock

    # === FunciÃ³n 3: CuadrÃ¡tica elÃ­ptica ===
    def elliptic(p):  # Definir funciÃ³n elÃ­ptica
        return p[0]**2 + 10*p[1]**2  # f(x,y) = xÂ² + 10yÂ²

    def grad_elliptic(p):  # Gradiente de funciÃ³n elÃ­ptica
        return np.array([2*p[0], 20*p[1]])  # âˆ‡f = [2x, 20y]

    visualize_optimization(  # Visualizar optimizaciÃ³n elÃ­ptica
        elliptic, grad_elliptic,  # FunciÃ³n y gradiente
        x0=np.array([4.0, 2.0]),  # Punto inicial
        learning_rate=0.05,  # Tasa de aprendizaje
        title="ElÃ­ptica f(x,y) = xÂ² + 10yÂ²"  # TÃ­tulo
    )  # Cerrar llamada a visualize_optimization para funciÃ³n elÃ­ptica


if __name__ == "__main__":  # Si se ejecuta como script
    main()  # Ejecutar funciÃ³n principal

```


---
## Entregable Obligatorio v3.3

### Script: `grad_check.py`

```python
"""
Gradient Checking - ValidaciÃ³n de Derivadas
TÃ©cnica estÃ¡ndar de CS231n Stanford para debugging de backprop.

Autor: [Tu nombre]  # Nombre del autor
MÃ³dulo: 03 - CÃ¡lculo Multivariante  # MÃ³dulo al que pertenece
"""
import numpy as np  # Importar librerÃ­a para computaciÃ³n numÃ©rica
from typing import Callable, Dict, Tuple  # Importar tipos para anotaciones


def numerical_gradient(  # Definir funciÃ³n para calcular gradiente numÃ©rico
    f: Callable[[np.ndarray], float],  # FunciÃ³n escalar a minimizar
    x: np.ndarray,  # Punto donde calcular el gradiente (vector)
    epsilon: float = 1e-5  # TamaÃ±o pequeÃ±o del paso para diferencias
) -> np.ndarray:  # Retornar array numpy con gradiente
    """
    Calcula el gradiente numÃ©rico usando diferencias centrales.

    Args:
        f: FunciÃ³n escalar f(x) -> float
        x: Punto donde calcular el gradiente
        epsilon: TamaÃ±o del paso (default: 1e-5)

    Returns:
        Gradiente numÃ©rico aproximado
    """
    grad = np.zeros_like(x)  # Inicializar gradiente con ceros del mismo tamaÃ±o que x

    # Iterar sobre cada dimensiÃ³n
    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])  # Iterador multidimensional
    while not it.finished:  # Mientras haya elementos por procesar
        idx = it.multi_index  # Obtener Ã­ndice multidimensional actual
        old_value = x[idx]  # Guardar valor original para restaurar despuÃ©s

        # f(x + epsilon)
        x[idx] = old_value + epsilon  # Perturbar elemento con +epsilon
        fx_plus = f(x)  # Evaluar funciÃ³n en x + epsilon

        # f(x - epsilon)
        x[idx] = old_value - epsilon  # Perturbar elemento con -epsilon
        fx_minus = f(x)  # Evaluar funciÃ³n en x - epsilon

        # Diferencias centrales: (f(x+Îµ) - f(x-Îµ)) / 2Îµ
        grad[idx] = (fx_plus - fx_minus) / (2 * epsilon)  # Calcular derivada central

        # Restaurar valor original
        x[idx] = old_value  # Restaurar valor original del elemento
        it.iternext()  # Avanzar al siguiente elemento del iterador

    return grad  # Devolver gradiente numÃ©rico calculado


def gradient_check(  # Definir funciÃ³n para comparar gradientes
    analytic_grad: np.ndarray,  # Gradiente calculado analÃ­ticamente
    numerical_grad: np.ndarray,  # Gradiente calculado numÃ©ricamente
    threshold: float = 1e-7  # Umbral de error aceptable
) -> Tuple[bool, float]:  # Retornar tupla con resultado y error
    """
    Compara gradiente analÃ­tico vs numÃ©rico.

    Args:
        analytic_grad: Gradiente calculado con backprop
        numerical_grad: Gradiente calculado numÃ©ricamente
        threshold: Umbral de error aceptable

    Returns:
        (passed, relative_error)
    """
    # Error relativo: ||a - n|| / (||a|| + ||n||)
    diff = np.linalg.norm(analytic_grad - numerical_grad)  # Calcular norma de la diferencia
    norm_sum = np.linalg.norm(analytic_grad) + np.linalg.norm(numerical_grad)  # Sumar normas

    if norm_sum == 0:  # Evitar divisiÃ³n por cero
        relative_error = 0.0  # Si ambas normas son cero, error es cero
    else:  # Si la suma de normas no es cero
        relative_error = diff / norm_sum  # Calcular error relativo

    passed = relative_error < threshold  # Verificar si estÃ¡ bajo el umbral
    return passed, relative_error  # Devolver resultado y error


# === EJEMPLO: Validar gradiente de MSE Loss ===

def mse_loss(y_pred: np.ndarray, y_true: np.ndarray) -> float:  # Definir funciÃ³n de pÃ©rdida MSE
    """Mean Squared Error."""
    return float(np.mean((y_pred - y_true) ** 2))  # Calcular promedio de errores cuadrÃ¡ticos

def mse_gradient_analytic(y_pred: np.ndarray, y_true: np.ndarray) -> np.ndarray:  # Definir gradiente analÃ­tico MSE
    """Gradiente analÃ­tico de MSE respecto a y_pred."""
    n = len(y_true)  # Obtener nÃºmero de muestras
    return 2 * (y_pred - y_true) / n  # Calcular derivada: 2(y_pred - y_true)/n


def test_mse_gradient():  # Definir funciÃ³n para probar gradiente MSE
    """Test: Validar gradiente de MSE."""
    print("=" * 60)  # Imprimir lÃ­nea separadora
    print("GRADIENT CHECK: MSE Loss")  # Imprimir tÃ­tulo
    print("=" * 60)  # Imprimir lÃ­nea separadora

    np.random.seed(42)  # Fijar semilla para reproducibilidad
    y_pred = np.random.randn(10)  # Generar predicciones aleatorias
    y_true = np.random.randn(10)  # Generar valores verdaderos aleatorios

    # Gradiente analÃ­tico
    grad_analytic = mse_gradient_analytic(y_pred, y_true)  # Calcular gradiente analÃ­tico

    # Gradiente numÃ©rico
    def loss_fn(pred):  # Definir funciÃ³n de pÃ©rdida interna
        return mse_loss(pred, y_true)  # Retornar pÃ©rdida MSE

    grad_numerical = numerical_gradient(loss_fn, y_pred.copy())  # Calcular gradiente numÃ©rico

    # Comparar
    passed, error = gradient_check(grad_analytic, grad_numerical)  # Comparar gradientes

    print(f"Gradiente AnalÃ­tico: {grad_analytic[:3]}...")  # Mostrar primeros 3 valores
    print(f"Gradiente NumÃ©rico:  {grad_numerical[:3]}...")  # Mostrar primeros 3 valores
    print(f"Error Relativo: {error:.2e}")  # Mostrar error en notaciÃ³n cientÃ­fica
    print(f"Resultado: {'âœ“ PASSED' if passed else 'âœ— FAILED'}")  # Mostrar resultado

    return passed  # Devolver si pasÃ³ la prueba


# === EJEMPLO: Validar gradiente de Sigmoid ===

def sigmoid(z: np.ndarray) -> np.ndarray:  # Definir funciÃ³n sigmoide
    """Sigmoid activation."""
    return 1 / (1 + np.exp(-z))  # Calcular sigmoide: 1/(1+e^-z)

def sigmoid_derivative_analytic(z: np.ndarray) -> np.ndarray:  # Definir derivada sigmoide
    """Derivada analÃ­tica: Ïƒ'(z) = Ïƒ(z)(1 - Ïƒ(z))"""
    s = sigmoid(z)  # Calcular sigmoide
    return s * (1 - s)  # Calcular derivada: Ïƒ(1-Ïƒ)


def test_sigmoid_gradient():  # Definir funciÃ³n para probar gradiente sigmoide
    """Test: Validar derivada de sigmoid."""
    print("\n" + "=" * 60)  # Imprimir lÃ­nea separadora con salto
    print("GRADIENT CHECK: Sigmoid Derivative")  # Imprimir tÃ­tulo
    print("=" * 60)  # Imprimir lÃ­nea separadora

    np.random.seed(42)  # Fijar semilla para reproducibilidad
    z = np.random.randn(5)  # Generar valores aleatorios para sigmoide

    # Derivada analÃ­tica
    grad_analytic = sigmoid_derivative_analytic(z)  # Calcular derivada analÃ­tica

    # Derivada numÃ©rica (para cada elemento)
    def sigmoid_element(z_arr):  # Definir funciÃ³n auxiliar para gradiente numÃ©rico
        return float(np.sum(sigmoid(z_arr)))  # Suma para tener escalar

    grad_numerical = numerical_gradient(sigmoid_element, z.copy())  # Calcular gradiente numÃ©rico

    # Comparar
    passed, error = gradient_check(grad_analytic, grad_numerical)  # Comparar gradientes

    print(f"Derivada AnalÃ­tica: {grad_analytic}")  # Mostrar derivada analÃ­tica
    print(f"Derivada NumÃ©rica:  {grad_numerical}")  # Mostrar derivada numÃ©rica
    print(f"Error Relativo: {error:.2e}")  # Mostrar error en notaciÃ³n cientÃ­fica
    print(f"Resultado: {'âœ“ PASSED' if passed else 'âœ— FAILED'}")  # Mostrar resultado

    return passed  # Devolver si pasÃ³ la prueba


# === EJEMPLO: Validar gradiente de una capa lineal ===

def test_linear_layer_gradient():  # Definir funciÃ³n para probar gradiente de capa lineal
    """Test: Validar gradiente de capa lineal y = Wx + b."""
    print("\n" + "=" * 60)  # Imprimir lÃ­nea separadora con salto
    print("GRADIENT CHECK: Linear Layer (y = Wx + b)")  # Imprimir tÃ­tulo
    print("=" * 60)  # Imprimir lÃ­nea separadora

    np.random.seed(42)  # Fijar semilla para reproducibilidad

    # Dimensiones
    n_in, n_out = 4, 3  # Definir dimensiones de entrada y salida

    # ParÃ¡metros
    W = np.random.randn(n_out, n_in)  # Inicializar pesos aleatorios
    b = np.random.randn(n_out)  # Inicializar sesgos aleatorios
    x = np.random.randn(n_in)  # Generar entrada aleatoria
    y_true = np.random.randn(n_out)  # Generar salida verdadera aleatoria

    # Forward + Loss
    def forward_and_loss(W_flat):  # Definir funciÃ³n para forward y pÃ©rdida
        W_reshaped = W_flat.reshape(n_out, n_in)  # Redimensionar pesos
        y_pred = W_reshaped @ x + b  # Calcular predicciÃ³n: Wx + b
        return mse_loss(y_pred, y_true)  # Retornar pÃ©rdida MSE

    # Gradiente analÃ­tico de W
    y_pred = W @ x + b  # Calcular predicciÃ³n actual
    dL_dy = 2 * (y_pred - y_true) / n_out  # Gradiente de MSE respecto a y
    dL_dW_analytic = np.outer(dL_dy, x)    # âˆ‚L/âˆ‚W = âˆ‚L/âˆ‚y Â· x^T (producto externo)

    # Gradiente numÃ©rico de W
    dL_dW_numerical = numerical_gradient(forward_and_loss, W.flatten().copy())  # Calcular gradiente numÃ©rico
    dL_dW_numerical = dL_dW_numerical.reshape(n_out, n_in)  # Redimensionar gradiente

    # Comparar
    passed, error = gradient_check(  # Comparar gradientes
        dL_dW_analytic.flatten(),  # Aplanar gradiente analÃ­tico
        dL_dW_numerical.flatten()  # Aplanar gradiente numÃ©rico
    )  # Cerrar llamada a gradient_check

    print(f"Error Relativo: {error:.2e}")  # Mostrar error en notaciÃ³n cientÃ­fica
    print(f"Resultado: {'âœ“ PASSED' if passed else 'âœ— FAILED'}")  # Mostrar resultado

    return passed  # Devolver si pasÃ³ la prueba


def main():  # Definir funciÃ³n principal
    """Ejecutar todos los gradient checks."""
    print("\n" + "=" * 60)  # Imprimir lÃ­nea separadora con salto
    print("       GRADIENT CHECKING SUITE")  # Imprimir tÃ­tulo
    print("       ValidaciÃ³n MatemÃ¡tica v3.3")  # Imprimir versiÃ³n
    print("=" * 60)  # Imprimir lÃ­nea separadora

    results = []  # Inicializar lista de resultados
    results.append(("MSE Loss", test_mse_gradient()))  # Ejecutar test MSE
    results.append(("Sigmoid", test_sigmoid_gradient()))  # Ejecutar test sigmoide
    results.append(("Linear Layer", test_linear_layer_gradient()))  # Ejecutar test capa lineal

    print("\n" + "=" * 60)  # Imprimir lÃ­nea separadora con salto
    print("RESUMEN")  # Imprimir tÃ­tulo resumen
    print("=" * 60)  # Imprimir lÃ­nea separadora

    all_passed = True  # Inicializar bandera de todos pasados
    for name, passed in results:  # Iterar sobre resultados
        status = "âœ“ PASSED" if passed else "âœ— FAILED"  # Determinar estado
        print(f"  {name}: {status}")  # Mostrar resultado
        all_passed = all_passed and passed  # Actualizar bandera

    print("-" * 60)  # Imprimir lÃ­nea separadora
    if all_passed:  # Si todos pasaron
        print("âœ“ TODOS LOS GRADIENT CHECKS PASARON")  # Mensaje de Ã©xito
        print("  Tu implementaciÃ³n de derivadas es correcta.")  # FelicitaciÃ³n
    else:  # Si alguno fallÃ³
        print("âœ— ALGUNOS GRADIENT CHECKS FALLARON")  # Mensaje de error
        print("  Revisa tu implementaciÃ³n de backprop.")  # RecomendaciÃ³n

    return all_passed  # Devolver si todos pasaron


if __name__ == "__main__":  # Si se ejecuta como script
    main()  # Ejecutar funciÃ³n principal

```
---
## ğŸ§© ConsolidaciÃ³n (errores comunes + debugging v5 + reto Feynman)

### Errores comunes

- **Confundir derivada local con â€œdirecciÃ³n globalâ€:** el gradiente solo te da informaciÃ³n local.
- **`learning_rate` demasiado grande:** puede oscilar o divergir aunque el gradiente sea correcto.
- **Estabilidad numÃ©rica:** `exp(z)` puede overflow; usa `np.clip` cuando aplique.
- **Gradient checking mal aplicado:** `Îµ` demasiado pequeÃ±o puede amplificar ruido numÃ©rico.

### Debugging / validaciÃ³n (v5)

- Si tu entrenamiento es inestable o no baja el loss, valida derivadas con `grad_check.py`.
- Registra hallazgos en `study_tools/DIARIO_ERRORES.md`.
- Protocolos completos:
  - [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md)
  - [PLAN_V5_ESTRATEGICO.md](PLAN_V5_ESTRATEGICO.md)

### Reto Feynman (tablero blanco)

Explica en 5 lÃ­neas o menos:

1) Â¿QuÃ© significa â€œseguir `-âˆ‡f`â€ y por quÃ© eso baja la funciÃ³n?
2) Dibuja el grafo `xâ†’zâ†’aâ†’L` y explica por quÃ© multiplicas derivadas.
3) Â¿Por quÃ© gradient checking detecta bugs de backprop?

---

## âœ… Checklist de FinalizaciÃ³n (v3.3)

### Conocimiento
- [ ] Puedo calcular derivadas de funciones comunes (polinomios, exp, log)
- [ ] Entiendo derivadas parciales y puedo calcularlas
- [ ] Puedo calcular el gradiente de una funciÃ³n multivariable
- [ ] ImplementÃ© Gradient Descent desde cero
- [ ] Entiendo el efecto del learning rate
- [ ] Puedo aplicar la Chain Rule a funciones compuestas
- [ ] Entiendo cÃ³mo la Chain Rule se aplica en Backpropagation
- [ ] Puedo derivar âˆ‚L/âˆ‚w para una neurona simple

### Entregables v3.3
- [ ] `gradient_descent_demo.py` funcional
- [ ] **`grad_check.py` implementado y todos los tests pasan**
- [ ] ValidÃ© mis derivadas de sigmoid, MSE y capa lineal

### MetodologÃ­a Feynman
- [ ] Puedo explicar Chain Rule en 5 lÃ­neas sin jerga
- [ ] Puedo explicar por quÃ© gradient checking funciona

---

## ğŸ”— NavegaciÃ³n

| Anterior | Ãndice | Siguiente |
|----------|--------|-----------|
| [02_ALGEBRA_LINEAL_ML](02_ALGEBRA_LINEAL_ML.md) | [00_INDICE](00_INDICE.md) | [04_PROBABILIDAD_ML](04_PROBABILIDAD_ML.md) |
