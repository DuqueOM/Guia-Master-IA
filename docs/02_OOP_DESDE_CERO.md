# M√≥dulo 02 - OOP desde Cero

> **üéØ Objetivo:** Dise√±ar clases profesionales que representen documentos y colecciones, aplicando principios SOLID b√°sicos  
> **Fase:** Fundamentos | **Prerrequisito para:** Todos los m√≥dulos siguientes

---

## üß† Analog√≠a: La F√°brica de Documentos

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                             ‚îÇ
‚îÇ   CLASE = PLANO DE F√ÅBRICA                                                  ‚îÇ
‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                                 ‚îÇ
‚îÇ   Document (plano)  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  doc1, doc2, doc3 (productos)                   ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ   El plano define:                                                          ‚îÇ
‚îÇ   ‚Ä¢ Qu√© propiedades tiene cada documento (id, contenido, tokens)            ‚îÇ
‚îÇ   ‚Ä¢ Qu√© puede hacer cada documento (tokenizar, contar palabras)             ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ   CORPUS = ALMAC√âN                                                          ‚îÇ
‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                                         ‚îÇ
‚îÇ   Corpus (almac√©n)  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  Contiene m√∫ltiples documentos                  ‚îÇ
‚îÇ                              Sabe agregar, buscar, iterar                   ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìã Contenido

1. [Clases y Objetos B√°sicos](#1-clases-basicas)
2. [M√©todos M√°gicos](#2-metodos-magicos)
3. [Properties y Encapsulamiento](#3-properties)
4. [Composici√≥n vs Herencia](#4-composicion)
5. [Principios SOLID B√°sicos](#5-solid)
6. [Dataclasses](#6-dataclasses)

---

## 1. Clases y Objetos B√°sicos {#1-clases-basicas}

### 1.1 Anatom√≠a de una Clase

```python
class Document:
    """Represents a single document in the corpus."""
    
    # Atributo de clase (compartido por todas las instancias)
    document_count: int = 0
    
    def __init__(self, doc_id: int, content: str) -> None:
        """Initialize a new Document.
        
        Args:
            doc_id: Unique identifier for this document.
            content: Raw text content of the document.
        """
        # Atributos de instancia (√∫nicos para cada objeto)
        self.doc_id: int = doc_id
        self.content: str = content
        self.tokens: list[str] = []
        
        # Incrementar contador de clase
        Document.document_count += 1
    
    def tokenize(self) -> list[str]:
        """Split content into lowercase tokens.
        
        Returns:
            List of tokens extracted from content.
        """
        self.tokens = self.content.lower().split()
        return self.tokens
    
    def word_count(self) -> int:
        """Return the number of tokens.
        
        Note:
            Must call tokenize() first, or returns 0.
        """
        return len(self.tokens)
```

### 1.2 Creando y Usando Objetos

```python
# Crear instancias (objetos)
doc1 = Document(1, "Hello World")
doc2 = Document(2, "Goodbye World")

# Llamar m√©todos
doc1.tokenize()
print(doc1.tokens)  # ['hello', 'world']
print(doc1.word_count())  # 2

# Acceder al atributo de clase
print(Document.document_count)  # 2
```

### 1.3 Self: La Referencia al Objeto Actual

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  self = "yo mismo"                                              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Cuando llamas doc1.tokenize(), Python traduce a:               ‚îÇ
‚îÇ  Document.tokenize(doc1)                                        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  self es simplemente el objeto sobre el que se llama el m√©todo  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2. M√©todos M√°gicos (Dunder Methods) {#2-metodos-magicos}

### 2.1 Los M√°s Importantes

| M√©todo | Cu√°ndo se llama | Prop√≥sito |
|--------|-----------------|-----------|
| `__init__` | Al crear objeto | Inicializar atributos |
| `__repr__` | `repr(obj)`, debugger | Representaci√≥n t√©cnica |
| `__str__` | `str(obj)`, `print(obj)` | Representaci√≥n legible |
| `__eq__` | `obj1 == obj2` | Comparar igualdad |
| `__len__` | `len(obj)` | Retornar "longitud" |
| `__iter__` | `for x in obj` | Hacer iterable |

### 2.2 Implementaci√≥n Completa

```python
class Document:
    def __init__(self, doc_id: int, content: str) -> None:
        self.doc_id = doc_id
        self.content = content
        self.tokens: list[str] = []
    
    def __repr__(self) -> str:
        """Technical representation for debugging.
        
        Example:
            >>> doc = Document(1, "Hello World")
            >>> repr(doc)
            "Document(doc_id=1, content='Hello World')"
        """
        return f"Document(doc_id={self.doc_id}, content='{self.content[:20]}...')"
    
    def __str__(self) -> str:
        """Human-readable representation.
        
        Example:
            >>> print(doc)
            Document #1: Hello World (2 words)
        """
        word_count = len(self.tokens) if self.tokens else "not tokenized"
        return f"Document #{self.doc_id}: {self.content[:30]}... ({word_count} words)"
    
    def __eq__(self, other: object) -> bool:
        """Check equality based on doc_id.
        
        Two documents are equal if they have the same doc_id.
        """
        if not isinstance(other, Document):
            return NotImplemented
        return self.doc_id == other.doc_id
    
    def __len__(self) -> int:
        """Return number of tokens (after tokenization)."""
        return len(self.tokens)
    
    def __hash__(self) -> int:
        """Make Document hashable (usable in sets/dicts)."""
        return hash(self.doc_id)
```

### 2.3 Uso de M√©todos M√°gicos

```python
doc = Document(1, "Hello World from Archimedes")
doc.tokenize()

# __repr__ (en debugger o consola)
>>> doc
Document(doc_id=1, content='Hello World from Arc...')

# __str__ (con print)
>>> print(doc)
Document #1: Hello World from Archimedes... (4 words)

# __len__
>>> len(doc)
4

# __eq__
doc2 = Document(1, "Different content")
>>> doc == doc2
True  # Mismo doc_id

# __hash__ permite usar en sets
>>> docs_set = {doc, doc2}
>>> len(docs_set)
1  # Son "iguales" por doc_id
```

---

## 3. Properties y Encapsulamiento {#3-properties}

### 3.1 ¬øPor Qu√© Encapsular?

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PROBLEMA: Acceso directo sin validaci√≥n                        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  doc.doc_id = -5     # ¬øID negativo? ¬°Inv√°lido!                 ‚îÇ
‚îÇ  doc.content = None  # ¬øContenido None? ¬°Error futuro!          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  SOLUCI√ìN: Properties con validaci√≥n                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  doc.doc_id = -5     # Lanza ValueError                         ‚îÇ
‚îÇ  doc.content = None  # Lanza TypeError                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.2 Implementando Properties

```python
class Document:
    def __init__(self, doc_id: int, content: str) -> None:
        # Usar los setters para validar desde el inicio
        self._doc_id: int = 0  # Atributo "privado" (convenci√≥n)
        self._content: str = ""
        
        # Estos llaman a los setters
        self.doc_id = doc_id
        self.content = content
        self.tokens: list[str] = []
    
    @property
    def doc_id(self) -> int:
        """Get document ID."""
        return self._doc_id
    
    @doc_id.setter
    def doc_id(self, value: int) -> None:
        """Set document ID with validation."""
        if not isinstance(value, int):
            raise TypeError(f"doc_id must be int, got {type(value).__name__}")
        if value < 0:
            raise ValueError(f"doc_id must be non-negative, got {value}")
        self._doc_id = value
    
    @property
    def content(self) -> str:
        """Get document content."""
        return self._content
    
    @content.setter
    def content(self, value: str) -> None:
        """Set content with validation."""
        if not isinstance(value, str):
            raise TypeError(f"content must be str, got {type(value).__name__}")
        if not value.strip():
            raise ValueError("content cannot be empty or whitespace only")
        self._content = value
    
    @property
    def is_tokenized(self) -> bool:
        """Check if document has been tokenized (read-only)."""
        return len(self.tokens) > 0
```

### 3.3 Uso de Properties

```python
doc = Document(1, "Hello World")

# Lectura transparente (parece atributo normal)
print(doc.doc_id)  # 1

# Escritura con validaci√≥n autom√°tica
doc.doc_id = 5     # OK
doc.doc_id = -1    # ValueError: doc_id must be non-negative

# Property de solo lectura
print(doc.is_tokenized)  # False
doc.tokenize()
print(doc.is_tokenized)  # True
# doc.is_tokenized = True  # AttributeError: can't set attribute
```

---

## 4. Composici√≥n vs Herencia {#4-composicion}

### 4.1 La Regla de Oro

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                 ‚îÇ
‚îÇ   "Favor composition over inheritance"                          ‚îÇ
‚îÇ   (Prefiere composici√≥n sobre herencia)                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ   HERENCIA: "ES UN" (is-a)                                      ‚îÇ
‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                     ‚îÇ
‚îÇ   Un Perro ES UN Animal                                         ‚îÇ
‚îÇ   ‚úÖ Tiene sentido                                              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ   COMPOSICI√ìN: "TIENE UN" (has-a)                               ‚îÇ
‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                               ‚îÇ
‚îÇ   Un Corpus TIENE Documentos                                    ‚îÇ
‚îÇ   ‚úÖ M√°s flexible                                               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 4.2 Composici√≥n: Corpus Contiene Documents

```python
class Corpus:
    """A collection of documents."""
    
    def __init__(self, name: str) -> None:
        """Initialize an empty corpus.
        
        Args:
            name: Name of this corpus.
        """
        self.name: str = name
        self._documents: dict[int, Document] = {}  # Composici√≥n: contiene Documents
    
    def add_document(self, doc: Document) -> None:
        """Add a document to the corpus.
        
        Args:
            doc: Document to add.
        
        Raises:
            ValueError: If document with same ID already exists.
        """
        if doc.doc_id in self._documents:
            raise ValueError(f"Document with id {doc.doc_id} already exists")
        self._documents[doc.doc_id] = doc
    
    def get_document(self, doc_id: int) -> Document | None:
        """Retrieve a document by ID.
        
        Args:
            doc_id: ID of document to retrieve.
        
        Returns:
            The Document if found, None otherwise.
        """
        return self._documents.get(doc_id)
    
    def remove_document(self, doc_id: int) -> bool:
        """Remove a document by ID.
        
        Returns:
            True if document was removed, False if not found.
        """
        if doc_id in self._documents:
            del self._documents[doc_id]
            return True
        return False
    
    def __len__(self) -> int:
        """Return number of documents in corpus."""
        return len(self._documents)
    
    def __iter__(self):
        """Iterate over documents."""
        return iter(self._documents.values())
    
    def __contains__(self, doc_id: int) -> bool:
        """Check if document ID exists."""
        return doc_id in self._documents
```

### 4.3 Cu√°ndo Usar Herencia

La herencia es apropiada cuando hay una relaci√≥n "es un" clara:

```python
from abc import ABC, abstractmethod

class Tokenizer(ABC):
    """Abstract base class for tokenizers."""
    
    @abstractmethod
    def tokenize(self, text: str) -> list[str]:
        """Tokenize text into words."""
        pass

class SimpleTokenizer(Tokenizer):
    """Basic whitespace tokenizer."""
    
    def tokenize(self, text: str) -> list[str]:
        return text.lower().split()

class AdvancedTokenizer(Tokenizer):
    """Tokenizer that also removes punctuation."""
    
    def __init__(self, min_length: int = 2) -> None:
        self.min_length = min_length
    
    def tokenize(self, text: str) -> list[str]:
        # Remove punctuation
        cleaned = ''.join(c if c.isalnum() or c.isspace() else ' ' for c in text)
        words = cleaned.lower().split()
        return [w for w in words if len(w) >= self.min_length]
```

---

## 5. Principios SOLID B√°sicos {#5-solid}

### 5.1 S - Single Responsibility Principle

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PRINCIPIO: Una clase debe tener una sola raz√≥n para cambiar    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚ùå MAL: Document que hace todo                                 ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                    ‚îÇ
‚îÇ  class Document:                                                ‚îÇ
‚îÇ      def tokenize(self): ...                                    ‚îÇ
‚îÇ      def save_to_file(self): ...      # Persistencia            ‚îÇ
‚îÇ      def compute_tfidf(self): ...     # C√°lculo ML              ‚îÇ
‚îÇ      def render_html(self): ...       # Presentaci√≥n            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚úÖ BIEN: Responsabilidades separadas                           ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                             ‚îÇ
‚îÇ  class Document:          # Solo datos del documento            ‚îÇ
‚îÇ  class Tokenizer:         # Solo tokenizaci√≥n                   ‚îÇ
‚îÇ  class DocumentStorage:   # Solo persistencia                   ‚îÇ
‚îÇ  class TFIDFCalculator:   # Solo c√°lculos                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 5.2 O - Open/Closed Principle

```python
# ‚úÖ Abierto para extensi√≥n, cerrado para modificaci√≥n

class Tokenizer(ABC):
    @abstractmethod
    def tokenize(self, text: str) -> list[str]:
        pass

# Extender sin modificar la clase base
class SpanishTokenizer(Tokenizer):
    """Tokenizer with Spanish stop words."""
    
    STOP_WORDS = {"el", "la", "los", "las", "de", "en"}
    
    def tokenize(self, text: str) -> list[str]:
        words = text.lower().split()
        return [w for w in words if w not in self.STOP_WORDS]
```

### 5.3 Aplicaci√≥n en el Proyecto

```python
# Cada clase tiene una responsabilidad clara:

class Document:
    """Solo almacena datos de un documento."""
    pass

class Corpus:
    """Solo administra una colecci√≥n de documentos."""
    pass

class Tokenizer:
    """Solo convierte texto en tokens."""
    pass

class InvertedIndex:
    """Solo indexa documentos para b√∫squeda."""
    pass

class SearchEngine:
    """Orquesta los dem√°s componentes."""
    pass
```

---

## 6. Dataclasses {#6-dataclasses}

### 6.1 Simplificando Clases de Datos

```python
from dataclasses import dataclass, field

# ‚ùå Mucho boilerplate
class DocumentOld:
    def __init__(self, doc_id: int, content: str, title: str = "") -> None:
        self.doc_id = doc_id
        self.content = content
        self.title = title
    
    def __repr__(self) -> str:
        return f"Document(doc_id={self.doc_id}, content='{self.content[:20]}...', title='{self.title}')"
    
    def __eq__(self, other: object) -> bool:
        if not isinstance(other, DocumentOld):
            return NotImplemented
        return self.doc_id == other.doc_id and self.content == other.content

# ‚úÖ Dataclass: autom√°tico
@dataclass
class Document:
    doc_id: int
    content: str
    title: str = ""
    tokens: list[str] = field(default_factory=list)
    
    # Puedes agregar m√©todos normalmente
    def tokenize(self) -> list[str]:
        self.tokens = self.content.lower().split()
        return self.tokens
```

### 6.2 Opciones de Dataclass

```python
@dataclass(frozen=True)  # Inmutable (no se puede modificar)
class ImmutableDocument:
    doc_id: int
    content: str

@dataclass(order=True)  # Permite comparar <, >, etc.
class RankedDocument:
    score: float  # Primer campo = criterio de ordenamiento
    doc_id: int
    content: str

# Uso
docs = [RankedDocument(0.8, 1, "doc1"), RankedDocument(0.9, 2, "doc2")]
sorted_docs = sorted(docs, reverse=True)  # Ordenar por score
```

### 6.3 Cu√°ndo Usar Dataclass

| Usa Dataclass cuando... | Usa Clase normal cuando... |
|------------------------|---------------------------|
| Principalmente almacena datos | L√≥gica compleja de validaci√≥n |
| __init__, __repr__, __eq__ est√°ndar | Necesitas control total |
| Quieres c√≥digo conciso | Properties con setters |

---

## ‚ö†Ô∏è Errores Comunes y C√≥mo Evitarlos

### Error 1: Olvidar self

```python
# ‚ùå Error: NameError: name 'doc_id' is not defined
class Document:
    def __init__(self, doc_id: int) -> None:
        doc_id = doc_id  # ¬°No guarda nada!

# ‚úÖ Correcto
class Document:
    def __init__(self, doc_id: int) -> None:
        self.doc_id = doc_id
```

### Error 2: Mutar lista compartida

```python
# ‚ùå Bug: todos los documentos comparten la misma lista
class Document:
    tokens: list[str] = []  # ¬°Atributo de clase!

# ‚úÖ Correcto: inicializar en __init__
class Document:
    def __init__(self) -> None:
        self.tokens: list[str] = []  # Atributo de instancia
```

### Error 3: __eq__ sin __hash__

```python
# ‚ùå Si defines __eq__, Python elimina __hash__ por defecto
class Document:
    def __eq__(self, other): ...
    # No se puede usar en sets/dicts

# ‚úÖ Definir ambos
class Document:
    def __eq__(self, other): ...
    def __hash__(self): return hash(self.doc_id)
```

---

## üîß Ejercicios Pr√°cticos

### Ejercicio 2.1: Clase Document B√°sica
Ver [EJERCICIOS.md](EJERCICIOS.md#ejercicio-21)

### Ejercicio 2.2: M√©todos M√°gicos
Ver [EJERCICIOS.md](EJERCICIOS.md#ejercicio-22)

### Ejercicio 2.3: Properties con Validaci√≥n
Ver [EJERCICIOS.md](EJERCICIOS.md#ejercicio-23)

### Ejercicio 2.4: Clase Corpus
Ver [EJERCICIOS.md](EJERCICIOS.md#ejercicio-24)

### Ejercicio 2.5: Refactorizar a SOLID
Ver [EJERCICIOS.md](EJERCICIOS.md#ejercicio-25)

---

## üìö Recursos Externos

| Recurso | Tipo | Prioridad |
|---------|------|-----------|
| [Real Python: OOP](https://realpython.com/python3-object-oriented-programming/) | Tutorial | üî¥ Obligatorio |
| [Dataclasses Documentation](https://docs.python.org/3/library/dataclasses.html) | Docs | üü° Recomendado |
| [SOLID Principles](https://realpython.com/solid-principles-python/) | Tutorial | üü° Recomendado |

---

## üîó Referencias del Glosario

- [Clase](GLOSARIO.md#clase)
- [Instancia](GLOSARIO.md#instancia)
- [M√©todo M√°gico](GLOSARIO.md#metodo-magico)
- [Property](GLOSARIO.md#property)
- [Composici√≥n](GLOSARIO.md#composicion)
- [SOLID](GLOSARIO.md#solid)

---

## üß≠ Navegaci√≥n

| ‚Üê Anterior | √çndice | Siguiente ‚Üí |
|------------|--------|-------------|
| [01_PYTHON_PROFESIONAL](01_PYTHON_PROFESIONAL.md) | [00_INDICE](00_INDICE.md) | [03_LOGICA_DISCRETA](03_LOGICA_DISCRETA.md) |
