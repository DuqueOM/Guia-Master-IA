# üìã Syllabus - MS in AI Pathway

> **10 M√≥dulos Obligatorios | 6 Meses | 100% Enfocado en el Pathway**

---

## üéØ Objetivo √önico

Prepararte para aprobar las **6 materias** del Performance-Based Admission Pathway de CU Boulder.

---

## üìä Estructura: 10 M√≥dulos Obligatorios

| M√≥dulo | Nombre | Semanas | Fase | Curso del Pathway |
|--------|--------|---------|------|-------------------|
| **01** | Python Profesional | 2 | Fundamentos | - |
| **02** | OOP desde Cero | 2 | Fundamentos | - |
| **03** | √Ålgebra Lineal para ML | 2 | Fundamentos | - |
| **04** | Fundamentos de Probabilidad | 3 | ‚≠ê Pathway L2 | Probability Fundamentals |
| **05** | Estad√≠stica Inferencial | 3 | ‚≠ê Pathway L2 | Statistical Estimation |
| **06** | Markov y Monte Carlo | 2 | ‚≠ê Pathway L2 | Markov Chains & Monte Carlo |
| **07** | ML Supervisado | 3 | ‚≠ê Pathway L1 | Intro to ML: Supervised |
| **08** | ML No Supervisado | 2 | ‚≠ê Pathway L1 | Unsupervised Algorithms |
| **09** | Deep Learning | 3 | ‚≠ê Pathway L1 | Intro to Deep Learning |
| **10** | Proyecto Final | 4 | Integraci√≥n | - |

**Total: 26 semanas = 6 meses** (6h/d√≠a, L-S)

---

## üìö Mapeo M√≥dulos ‚Üí C√≥digo ‚Üí Cursos

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 1: FUNDAMENTOS (Semanas 1-6)                                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ M√≥dulos: 01, 02, 03                                                         ‚îÇ
‚îÇ C√≥digo:  src/vector.py, src/matrix.py                                       ‚îÇ
‚îÇ Entregable: Clases Vector y Matrix con operaciones desde cero               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 2: PROBABILIDAD Y ESTAD√çSTICA ‚≠ê PATHWAY L√çNEA 2 (Semanas 7-14)        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ M√≥dulos: 04, 05, 06                                                         ‚îÇ
‚îÇ C√≥digo:  src/probability.py, src/statistics.py, src/markov.py               ‚îÇ
‚îÇ Cursos:  Probability, Statistical Estimation, Markov Chains                 ‚îÇ
‚îÇ Entregable: Bayes, MLE, MCMC, PageRank desde cero                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 3: MACHINE LEARNING ‚≠ê PATHWAY L√çNEA 1 (Semanas 15-22)                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ M√≥dulos: 07, 08, 09                                                         ‚îÇ
‚îÇ C√≥digo:  src/naive_bayes.py, src/kmeans.py, src/neural_network.py           ‚îÇ
‚îÇ Cursos:  Supervised Learning, Unsupervised, Deep Learning                   ‚îÇ
‚îÇ Entregable: Regresi√≥n, NB, K-Means, MLP con backprop desde cero             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 4: PROYECTO FINAL (Semanas 23-26)                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ M√≥dulo: 10                                                                  ‚îÇ
‚îÇ C√≥digo:  src/pipeline.py (integra todo)                                     ‚îÇ
‚îÇ Entregable: Pipeline ML completo + comparaci√≥n estad√≠stica de modelos       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìñ Detalle por M√≥dulo

### M√≥dulo 01: Python Profesional

| Contenido | Entregable |
|-----------|------------|
| Type hints y anotaciones | C√≥digo tipado con `mypy` pasando |
| Funciones puras vs impuras | Funciones sin side effects |
| PEP8 y estilo consistente | C√≥digo que pasa `ruff` o `flake8` |
| Docstrings y documentaci√≥n | Cada funci√≥n documentada |

**Mini-proyecto:** Funci√≥n `clean_text(text: str) -> str` tipada y documentada.

**Validaci√≥n:** `mypy src/ && ruff check src/`

---

### M√≥dulo 02: OOP desde Cero

| Contenido | Entregable |
|-----------|------------|
| Clases y objetos | Clase `Document` con atributos |
| `__init__`, `__repr__`, `__str__` | M√©todos m√°gicos implementados |
| Encapsulamiento | Properties y validaci√≥n |
| Composici√≥n vs Herencia | Clase `Corpus` que contiene `Document`s |
| Principios SOLID b√°sicos | Single Responsibility aplicado |

**Mini-proyecto:** Clases `Document` y `Corpus` funcionales.

**Validaci√≥n:** `python -m pytest tests/test_document.py -v`

---

### M√≥dulo 03: √Ålgebra Lineal para ML

| Contenido | Entregable |
|-----------|------------|
| Vectores y matrices en Python puro | Representaciones en `list` |
| Suma, producto punto y norma | `vector.py` con operaciones b√°sicas |
| Producto matriz-vector | `matrix_vector_mult()` |
| Intuici√≥n geom√©trica | Explicar similitud como √°ngulo |

**Mini-proyecto:** M√≥dulo `vector.py` y `matrix.py` usados en los m√≥dulos de ML.

---

### M√≥dulo 04: Fundamentos de Probabilidad ‚≠ê

| Contenido | Entregable |
|-----------|------------|
| Espacio muestral y eventos | Funciones para experimentos simples |
| Probabilidad condicional y Bayes | Implementar Teorema de Bayes |
| Variables aleatorias y distribuciones | Simulaciones de Bernoulli, Binomial, Normal |
| Esperanza y varianza | Funciones `expected_value()` y `variance()` |

**Mini-proyecto:** Simulador de lanzamiento de monedas/dados con comparaci√≥n te√≥rica vs emp√≠rica.

---

### M√≥dulo 05: Estad√≠stica Inferencial ‚≠ê

| Contenido | Entregable |
|-----------|------------|
| Estimadores puntuales | Funciones para media, varianza, proporciones |
| MLE y MAP (introducci√≥n) | Implementar estimaci√≥n de par√°metros sencillos |
| Intervalos de confianza | C√°lculo para media y proporci√≥n |
| Tests de hip√≥tesis b√°sicos | Z-test / t-test simplificados |

**Mini-proyecto:** Peque√±o experimento (por ejemplo, conversi√≥n en A/B test) con estimaci√≥n de intervalo y decisi√≥n estad√≠stica.

---

### M√≥dulo 06: Cadenas de Markov y Monte Carlo ‚≠ê

| Contenido | Entregable |
|-----------|------------|
| Cadenas de Markov de tiempo discreto | Matriz de transici√≥n e iteraci√≥n |
| Distribuci√≥n estacionaria | C√°lculo num√©rico v√≠a potencia |
| PageRank simplificado | Implementaci√≥n desde cero |
| Monte Carlo y MCMC | Simulaci√≥n y muestreo b√°sico |

**Mini-proyecto:** Implementaci√≥n de un PageRank simple y un ejemplo de Monte Carlo para integrar funciones.

---

### M√≥dulo 07: Machine Learning Supervisado ‚≠ê

| Contenido | Entregable |
|-----------|------------|
| Pipeline de ML (train/val/test) | Script de entrenamiento b√°sico |
| Regresi√≥n lineal | Implementaci√≥n con Gradient Descent |
| Regresi√≥n log√≠stica | Clasificador binario desde cero |
| √Årboles de decisi√≥n (visi√≥n simplificada) | √Årbol peque√±o implementado a mano |
| M√©tricas de evaluaci√≥n | Accuracy, precision, recall, F1 |

**Mini-proyecto:** Clasificador binario desde cero (por ejemplo, spam/no spam) con regresi√≥n log√≠stica.

---

### M√≥dulo 08: Machine Learning No Supervisado ‚≠ê

| Contenido | Entregable |
|-----------|------------|
| K-Means clustering | Implementaci√≥n de K-Means |
| PCA | Reducci√≥n de dimensionalidad con autovectores |
| Detecci√≥n de anomal√≠as (simple) | Umbrales sobre distancia al centroide |

**Mini-proyecto:** Segmentaci√≥n de clientes o agrupamiento de textos usando K-Means + PCA.

---

### M√≥dulo 09: Introducci√≥n al Deep Learning ‚≠ê

| Contenido | Entregable |
|-----------|------------|
| Perceptr√≥n y neurona artificial | Implementaci√≥n de una neurona |
| MLP (Multilayer Perceptron) | Red de 2‚Äì3 capas con backpropagation |
| Funciones de activaci√≥n | ReLU, Sigmoid, Tanh |
| Entrenamiento con Gradient Descent | Entrenar en un dataset peque√±o |

**Mini-proyecto:** MLP sencillo para clasificar puntos 2D o d√≠gitos muy simples.

---

### M√≥dulo 10: Proyecto Final

| Contenido | Entregable |
|-----------|------------|
| Dise√±o del pipeline ML completo | `pipeline.py` integrando todos los m√≥dulos |
| Integraci√≥n de probabilidad y estad√≠stica | Comparaci√≥n de modelos con m√©tricas e intervalos |
| Comparaci√≥n de modelos | Tabla de resultados y an√°lisis |
| Documentaci√≥n y presentaci√≥n | README y defensa t√©cnica |

**Entregable final:**
1. Pipeline ML completo funcional (scripts + m√≥dulos `src/`).
2. Informe comparando al menos 2‚Äì3 modelos.
3. README en ingl√©s explicando decisiones.

---

## üìä R√∫brica General (100 puntos)

| Dimensi√≥n | Puntos | Criterio |
|-----------|--------|----------|
| **Funcionalidad** | 30 | El pipeline entrena, eval√∫a y compara modelos correctamente |
| **C√≥digo limpio** | 20 | PEP8, type hints, docstrings |
| **Tests** | 20 | Cobertura razonable de funciones cr√≠ticas |
| **An√°lisis estad√≠stico** | 20 | Uso correcto de m√©tricas, intervalos e interpretaci√≥n |
| **Documentaci√≥n** | 10 | README claro, en ingl√©s |

### Niveles

| Puntuaci√≥n | Nivel |
|------------|-------|
| 90-100 | Listo para Pathway y entrevistas t√©cnicas de ML |
| 75-89 | Buen nivel, reforzar √°reas concretas |
| 60-74 | Necesita m√°s pr√°ctica antes del Pathway |
| <60 | Revisar m√≥dulos fundamentales |

---

## üéØ Preparaci√≥n para Pathway - CURSOS EXACTOS

El Pathway tiene **2 l√≠neas con 6 cursos espec√≠ficos**:

### L√çNEA 1: Machine Learning (3 cr√©ditos)

| Curso del Pathway | M√≥dulo Preparaci√≥n | Temas Cubiertos |
|-------------------|-------------------|-----------------|
| **Introduction to ML: Supervised Learning** | 07 | Regresi√≥n, clasificaci√≥n, m√©tricas |
| **Unsupervised Algorithms in ML** | 08 | K-Means, clustering, PCA, anomal√≠as |
| **Introduction to Deep Learning** | 09 | Perceptr√≥n, MLP, backprop, conceptos CNN/RNN |

### L√çNEA 2: Probability & Statistics (3 cr√©ditos)

| Curso del Pathway | M√≥dulo Preparaci√≥n | Temas Cubiertos |
|-------------------|-------------------|-----------------|
| **Probability Fundamentals for DS and AI** | 04 | Bayes, distribuciones, esperanza, varianza |
| **Discrete-Time Markov Chains and Monte Carlo Methods** | 06 | Cadenas de Markov, PageRank, MCMC |
| **Statistical Estimation for DS and AI** | 05 | MLE, MAP, intervalos, hip√≥tesis |

### Cobertura de esta Gu√≠a

| Componente del Pathway | ¬øCubierto? | Evidencia |
|------------------------|------------|-----------|
| Naive Bayes | ‚úÖ | M√≥dulos 04 + 07 |
| Regresi√≥n Lineal/Log√≠stica | ‚úÖ | M√≥dulo 07 |
| √Årboles de Decisi√≥n (b√°sico) | ‚úÖ | M√≥dulo 07 |
| K-Means Clustering | ‚úÖ | M√≥dulo 08 |
| PCA | ‚úÖ | M√≥dulo 08 |
| Redes Neuronales | ‚úÖ | M√≥dulo 09 |
| Backpropagation | ‚úÖ | M√≥dulo 09 |
| Teorema de Bayes | ‚úÖ | M√≥dulo 04 |
| Cadenas de Markov | ‚úÖ | M√≥dulo 06 |
| MLE/MAP | ‚úÖ | M√≥dulo 05 |
| Intervalos de Confianza | ‚úÖ | M√≥dulo 05 |

---

## üìÖ Cronograma Sugerido

Ver [PLAN_ESTUDIOS.md](PLAN_ESTUDIOS.md) para el cronograma resumido de 26 semanas.

---

## ‚úÖ Checklist de Finalizaci√≥n del Programa

### Fundamentos (M√≥dulos 01-03)
- [ ] Python profesional con type hints
- [ ] OOP y dise√±o SOLID b√°sico
- [ ] √Ålgebra lineal implementada en Python puro

### L√≠nea 2: Probabilidad (M√≥dulos 04-06)
- [ ] Teorema de Bayes explicado y aplicado
- [ ] MLE y MAP implementados en ejemplos sencillos
- [ ] Cadenas de Markov y MCMC entendidos y simulados
- [ ] Intervalos de confianza calculados

### L√≠nea 1: Machine Learning (M√≥dulos 07-09)
- [ ] Regresi√≥n lineal/log√≠stica desde cero
- [ ] K-Means y PCA implementados
- [ ] Red neuronal con backpropagation
- [ ] M√©tricas de evaluaci√≥n dominadas

### Proyecto Integrador (M√≥dulo 10)
- [ ] Pipeline ML completo funcional
- [ ] Comparaci√≥n estad√≠stica de modelos
- [ ] README en ingl√©s
- [ ] Demo presentable

### Preparaci√≥n Final
- [ ] Simulacro de entrevista completado (100+ preguntas)
- [ ] Capaz de explicar cada modelo en ingl√©s
- [ ] Cursos del Pathway auditados en Coursera

---

> üí° **Recuerda:** El objetivo es aprobar los 6 cursos del Pathway. Esta gu√≠a te prepara para todos ellos. ¬°No uses sklearn hasta dominar las implementaciones desde cero!
