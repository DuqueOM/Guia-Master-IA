# ğŸ¯ Simulacro de Entrevista - MS in AI Pathway

> 120+ preguntas con respuestas detalladas para las **2 lÃ­neas del Pathway**

---

## ğŸ“‹ Estructura del Simulacro

| SecciÃ³n | CategorÃ­a | Preguntas | Tiempo |
|---------|-----------|-----------|--------|
| 1. Python y OOP | [PRERREQUISITO] | 10 | 15 min |
| 2. Estructuras de Datos | [PRERREQUISITO] | 15 | 25 min |
| 3. Trees y Graphs | [PRERREQUISITO] | 15 | 30 min |
| 4. Algoritmos y DP | [PRERREQUISITO] | 20 | 40 min |
| 5. MatemÃ¡ticas y Big O | [PRERREQUISITO] | 20 | 30 min |
| **6. Probabilidad y EstadÃ­stica** | â­ [PATHWAY LÃNEA 2] | 20 | 30 min |
| **7. Machine Learning** | â­ [PATHWAY LÃNEA 1] | 20 | 35 min |

**Total:** 120+ preguntas, ~205 minutos

---

## âœ… Checklist MÃ­nimo Pathway

Si tienes poco tiempo, **prioriza las secciones 6 y 7**:
- [ ] SecciÃ³n 6: 20 preguntas de Probabilidad/EstadÃ­stica
- [ ] SecciÃ³n 7: 20 preguntas de Machine Learning

---

## SecciÃ³n 1: Python y OOP [PRERREQUISITO]

### P1: Â¿QuÃ© son los type hints y por quÃ© usarlos?
**R:** Anotaciones que indican tipos esperados. Beneficios: documentaciÃ³n viva, detecciÃ³n de errores con mypy, mejor autocompletado.

```python
def greet(name: str) -> str:
    return f"Hello, {name}"
```

### P2: Â¿CuÃ¡l es la diferencia entre `list` y `tuple`?
**R:** 
- `list`: mutable, se puede modificar
- `tuple`: inmutable, no se puede cambiar despuÃ©s de crear
- `tuple` es hashable (puede ser clave de dict), `list` no

### P3: Â¿QuÃ© significa que Python sea "pass by object reference"?
**R:** Se pasa referencia al objeto. Si el objeto es mutable, cambios dentro de la funciÃ³n afectan al original. Si es inmutable, se crea nuevo objeto.

### P4: Â¿Para quÃ© sirve `__init__`?
**R:** Inicializar atributos de instancia cuando se crea un objeto. Es el constructor de la clase.

### P5: Â¿CuÃ¡l es la diferencia entre `__str__` y `__repr__`?
**R:** 
- `__str__`: para usuarios, legible
- `__repr__`: para desarrolladores, sin ambigÃ¼edad, idealmente eval-able

### P6: Â¿QuÃ© es un property en Python?
**R:** Mecanismo para controlar acceso a atributos con getter/setter, manteniendo sintaxis de atributo.

### P7: Â¿QuÃ© significa "composiciÃ³n sobre herencia"?
**R:** Preferir contener objetos de otra clase (has-a) sobre heredar (is-a). MÃ¡s flexible y menos acoplado.

### P8: Â¿QuÃ© es una funciÃ³n pura?
**R:** FunciÃ³n que siempre retorna mismo output para mismo input y no tiene efectos secundarios.

### P9: Â¿Para quÃ© sirve `@dataclass`?
**R:** Genera automÃ¡ticamente `__init__`, `__repr__`, `__eq__` para clases que principalmente almacenan datos.

### P10: Â¿CÃ³mo harÃ­as una clase inmutable?
**R:** Usar `@dataclass(frozen=True)` o definir `__setattr__` para prevenir modificaciones.

---

## SecciÃ³n 2: Estructuras de Datos [PRERREQUISITO]

### P11: Â¿CuÃ¡l es la complejidad de buscar en una lista vs en un set?
**R:** Lista: O(n), Set: O(1) promedio. Set usa hashing.

### P12: Â¿CÃ³mo funciona internamente un diccionario?
**R:** Hash table. La clave se hashea para determinar posiciÃ³n en array interno. Colisiones se resuelven con probing.

### P13: Â¿Por quÃ© `dict` es O(1) para acceso?
**R:** Hash de la clave da posiciÃ³n directa. No necesita buscar secuencialmente.

### P14: Â¿QuÃ© es una colisiÃ³n en hash table?
**R:** Cuando dos claves diferentes producen el mismo hash. Se resuelve buscando siguiente slot disponible.

### P15: Â¿QuÃ© puede ser clave de diccionario?
**R:** Solo objetos hashables (inmutables): str, int, float, tuple, frozenset. No: list, set, dict.

### P16: Â¿CuÃ¡l es la diferencia entre `set` y `frozenset`?
**R:** `set` es mutable, `frozenset` inmutable. frozenset puede ser clave de dict o elemento de otro set.

### P17: Â¿QuÃ© es un Ã­ndice invertido?
**R:** Estructura que mapea tÃ©rminos a documentos que los contienen. `{"word": [doc1, doc2, ...]}`. Base de motores de bÃºsqueda.

### P18: Â¿Por quÃ© usarÃ­as un set para stop words?
**R:** BÃºsqueda O(1). Si son 50 stop words y 1000 tokens, con lista serÃ­a O(50Ã—1000)=O(50000), con set O(1000).

### P19: Â¿CuÃ¡l es la complejidad de `list.append()` vs `list.insert(0, x)`?
**R:** 
- append: O(1) amortizado
- insert(0): O(n) porque mueve todos los elementos

### P20: Â¿QuÃ© estructura usarÃ­as para un contador de frecuencias?
**R:** `dict` o `collections.Counter`. Mapea elemento a conteo, acceso O(1).

### P21: Â¿CÃ³mo implementarÃ­as bÃºsqueda AND con sets?
**R:** IntersecciÃ³n: `set1 & set2`. Retorna elementos en ambos.

### P22: Â¿CÃ³mo implementarÃ­as bÃºsqueda OR con sets?
**R:** UniÃ³n: `set1 | set2`. Retorna elementos en cualquiera.

### P23: Â¿QuÃ© es Document Frequency?
**R:** NÃºmero de documentos que contienen un tÃ©rmino. Usado para calcular IDF.

### P24: Â¿CuÃ¡ndo usarÃ­as `defaultdict`?
**R:** Cuando quieres valores por defecto automÃ¡ticos. Ej: `defaultdict(list)` crea listas vacÃ­as para claves nuevas.

### P25: Â¿QuÃ© es un posting list?
**R:** Lista de documentos que contienen un tÃ©rmino, almacenada en Ã­ndice invertido.

---

## SecciÃ³n 3: Trees y Graphs [PRERREQUISITO]

### P26: Â¿QuÃ© es un Binary Tree?
**R:** Ãrbol donde cada nodo tiene mÃ¡ximo 2 hijos (left y right).

### P27: Â¿CuÃ¡l es la diferencia entre Binary Tree y BST?
**R:** 
- Binary Tree: cualquier Ã¡rbol con mÃ¡x 2 hijos
- BST: Binary tree donde left < root < right

### P28: Â¿CuÃ¡les son los tres traversals DFS de un Ã¡rbol?
**R:** 
- Inorder: Left, Root, Right (en BST da orden ascendente)
- Preorder: Root, Left, Right
- Postorder: Left, Right, Root

### P29: Â¿CÃ³mo implementarÃ­as level-order traversal?
**R:** Usar Queue (BFS). Agregar root, luego procesar nivel por nivel.

### P30: Â¿CuÃ¡l es la complejidad de search en BST?
**R:** O(log n) promedio, O(n) peor caso (Ã¡rbol desbalanceado/lineal).

### P31: Â¿QuÃ© es un grafo dirigido vs no dirigido?
**R:** 
- Dirigido: edges tienen direcciÃ³n (Aâ†’B no implica Bâ†’A)
- No dirigido: conexiÃ³n bidireccional (Aâ†”B)

### P32: Â¿CuÃ¡les son las dos formas de representar un grafo?
**R:** 
- Adjacency List: dict de listas, O(V+E) espacio
- Adjacency Matrix: matriz VÃ—V, O(VÂ²) espacio

### P33: Â¿CuÃ¡l es la diferencia entre BFS y DFS?
**R:** 
- BFS: explora por niveles, usa Queue, encuentra shortest path
- DFS: explora en profundidad, usa Stack/recursiÃ³n

### P34: Â¿CuÃ¡ndo usar BFS vs DFS?
**R:** 
- BFS: shortest path (no ponderado), nivel por nivel
- DFS: detectar ciclos, caminos, backtracking

### P35: Â¿CÃ³mo detectar un ciclo en un grafo?
**R:** DFS marcando nodos como "en progreso" y "visitado". Si encuentras nodo "en progreso", hay ciclo.

### P36: Â¿QuÃ© es un DAG?
**R:** Directed Acyclic Graph. Grafo dirigido sin ciclos. Permite topological sort.

### P37: Â¿CuÃ¡l es la complejidad de BFS/DFS?
**R:** O(V + E) donde V = vÃ©rtices, E = edges.

### P38: Â¿QuÃ© estructura usa BFS y cuÃ¡l DFS?
**R:** 
- BFS: Queue (FIFO)
- DFS: Stack (LIFO) o recursiÃ³n

### P39: Â¿Por quÃ© BFS garantiza shortest path en grafos no ponderados?
**R:** Porque explora todos los nodos a distancia k antes de los de distancia k+1.

### P40: Â¿CÃ³mo encontrarÃ­as camino mÃ¡s corto en grafo ponderado?
**R:** Dijkstra's algorithm (no cubierto en detalle, pero saber que existe).

---

## SecciÃ³n 4: Algoritmos y DP [PRERREQUISITO]

### P41: Explica cÃ³mo funciona QuickSort.
**R:** 
1. Elegir pivote
2. Particionar: menores a izquierda, mayores a derecha
3. Recursivamente ordenar cada particiÃ³n
Complejidad: O(n log n) promedio, O(nÂ²) peor caso.

### P42: Â¿Por quÃ© QuickSort puede ser O(nÂ²)?
**R:** Si el pivote siempre es el mÃ­nimo o mÃ¡ximo. Ej: lista ya ordenada con pivote fijo al final. Cada particiÃ³n solo reduce en 1.

### P28: Â¿CÃ³mo evitar el peor caso de QuickSort?
**R:** Random pivot selection. Aleatoriza la elecciÃ³n del pivote.

### P29: Explica MergeSort.
**R:**
1. Dividir lista en dos mitades
2. Ordenar cada mitad recursivamente
3. Fusionar las mitades ordenadas
Complejidad: O(n log n) siempre.

### P30: Â¿CuÃ¡l es la diferencia entre QuickSort y MergeSort?
**R:**
- QuickSort: in-place, O(log n) espacio, no estable
- MergeSort: O(n) espacio, estable, siempre O(n log n)

### P31: Â¿QuÃ© significa que un sort sea "estable"?
**R:** Elementos iguales mantienen su orden relativo original.

### P32: Explica Binary Search.
**R:** En lista ordenada, comparar con elemento medio. Si menor, buscar en mitad izquierda; si mayor, en derecha. Complejidad: O(log n).

### P33: Â¿CuÃ¡l es el error off-by-one mÃ¡s comÃºn en binary search?
**R:** Usar `while left < right` en lugar de `left <= right`, o no ajustar correctamente mid+1/mid-1.

### P34: Â¿QuÃ© es recursiÃ³n?
**R:** FunciÃ³n que se llama a sÃ­ misma. Requiere caso base (termina) y caso recursivo (se llama con input menor).

### P35: Â¿QuÃ© es el call stack?
**R:** Pila que guarda estado de cada llamada a funciÃ³n. Cada llamada recursiva agrega un frame.

### P36: Â¿QuÃ© es memoization?
**R:** Cachear resultados de funciones para evitar recÃ¡lculo. Ãštil en recursiÃ³n con subproblemas repetidos.

### P37: Â¿Por quÃ© Fibonacci naive es O(2^n)?
**R:** Cada llamada hace dos llamadas. Ãrbol de llamadas crece exponencialmente. fib(n) se recalcula muchas veces.

### P38: Â¿CÃ³mo optimizar Fibonacci a O(n)?
**R:** Memoization: guardar resultados en dict/cache. Cada valor se calcula solo una vez.

### P39: Â¿QuÃ© es Divide & Conquer?
**R:** PatrÃ³n que divide problema en subproblemas, resuelve cada uno, y combina soluciones. Ej: MergeSort, QuickSort.

### P43: Â¿CÃ³mo fusionarÃ­as dos listas ordenadas?
**R:** Two pointers: comparar elementos actuales de ambas, agregar el menor al resultado, avanzar ese puntero. O(n+m).

### P44: Â¿QuÃ© es Dynamic Programming?
**R:** TÃ©cnica que guarda resultados de subproblemas para evitar recÃ¡lculo. Requiere optimal substructure + overlapping subproblems.

### P45: Â¿CuÃ¡les son los dos enfoques de DP?
**R:** 
- Top-down: Recursivo con memoization
- Bottom-up: Iterativo con tabulation

### P46: Â¿QuÃ© es la recurrencia de Coin Change?
**R:** dp[amount] = min(dp[amount - coin] + 1) para todas las monedas vÃ¡lidas.

### P47: Â¿CuÃ¡ndo usar Greedy vs DP?
**R:** 
- Greedy: Si la mejor opciÃ³n local lleva al Ã³ptimo global
- DP: Si necesitas explorar todas las opciones

### P48: Â¿QuÃ© es "greedy choice property"?
**R:** Propiedad donde elegir el Ã³ptimo local en cada paso lleva al Ã³ptimo global.

### P49: Â¿CÃ³mo funciona Activity Selection greedy?
**R:** Ordenar por tiempo de fin, siempre elegir la que termina primero y no se superpone.

### P50: Â¿QuÃ© es un Heap?
**R:** Ãrbol binario completo con propiedad heap (parent <= children para min-heap).

### P51: Â¿CuÃ¡les son las complejidades de operaciones en Heap?
**R:** Insert: O(log n), Extract-min: O(log n), Peek: O(1), Heapify: O(n).

### P52: Â¿CÃ³mo encontrar los K elementos mÃ¡s grandes?
**R:** Usar min-heap de tamaÃ±o k. Para cada elemento, si es mayor que el mÃ­nimo del heap, reemplazar.

### P53: Â¿Por quÃ© usar min-heap para K largest?
**R:** Min-heap mantiene el k-Ã©simo mÃ¡s grande en la raÃ­z. Elementos mÃ¡s grandes que la raÃ­z entran al heap.

### P54: Â¿QuÃ© es Priority Queue?
**R:** Cola donde elementos salen por prioridad, no por orden de llegada. Se implementa con Heap.

### P55: Â¿CÃ³mo hacer max-heap en Python?
**R:** heapq es min-heap. Para max-heap, negar los valores al insertar y al extraer.

---

## SecciÃ³n 5: MatemÃ¡ticas y Big O [PRERREQUISITO]

### P56: Â¿QuÃ© significa O(n)?
**R:** El tiempo crece linealmente con el tamaÃ±o de entrada. Duplicar n duplica el tiempo.

### P57: Ordena de menor a mayor: O(nÂ²), O(1), O(n log n), O(log n), O(n)
**R:** O(1) < O(log n) < O(n) < O(n log n) < O(nÂ²)

### P58: Â¿CuÃ¡ntas comparaciones hace binary search en 1 millÃ³n de elementos?
**R:** logâ‚‚(1,000,000) â‰ˆ 20 comparaciones.

### P59: Â¿QuÃ© es el producto punto?
**R:** Suma de productos de componentes correspondientes: aÂ·b = aâ‚bâ‚ + aâ‚‚bâ‚‚ + ... Resultado es escalar.

### P45: Â¿QuÃ© es la norma de un vector?
**R:** Su longitud/magnitud. ||v|| = âˆš(vâ‚Â² + vâ‚‚Â² + ...). Distancia del origen al punto.

### P46: Â¿QuÃ© mide la similitud de coseno?
**R:** El coseno del Ã¡ngulo entre vectores. 1 = misma direcciÃ³n, 0 = perpendiculares. Mide similitud ignorando magnitud.

### P47: Â¿QuÃ© es TF (Term Frequency)?
**R:** Frecuencia de un tÃ©rmino en un documento, normalizada por longitud. TF = count/total_terms.

### P48: Â¿QuÃ© es IDF (Inverse Document Frequency)?
**R:** Mide quÃ© tan raro es un tÃ©rmino. IDF = log(N/df). TÃ©rminos raros tienen IDF alto.

### P49: Â¿Por quÃ© usamos TF-IDF en lugar de solo TF?
**R:** TF solo mide frecuencia local. IDF penaliza palabras comunes ("the", "is"). TF-IDF balancea ambos.

### P50: Â¿CuÃ¡l es la complejidad de calcular similitud de coseno?
**R:** O(V) donde V es la dimensiÃ³n del vector (tamaÃ±o del vocabulario). Hay que recorrer todos los componentes.

---

---

## SecciÃ³n 6: Probabilidad y EstadÃ­stica â­ [PATHWAY LÃNEA 2]

### P60: Â¿QuÃ© es el Teorema de Bayes y para quÃ© se usa en ML?
**R:** P(A|B) = P(B|A) Ã— P(A) / P(B). Permite actualizar creencias (prior) dado nueva evidencia (likelihood). Base de clasificadores Naive Bayes y modelos probabilÃ­sticos.

### P61: Â¿CuÃ¡l es la diferencia entre probabilidad y likelihood?
**R:** 
- Probabilidad: P(data|params) - probabilidad de datos dados parÃ¡metros fijos
- Likelihood: L(params|data) - quÃ© tan probables son los parÃ¡metros dados los datos

### P62: Â¿QuÃ© es MLE (Maximum Likelihood Estimation)?
**R:** Encontrar los parÃ¡metros Î¸ que maximizan la probabilidad de observar los datos: Î¸Ì‚ = argmax P(data|Î¸). Es cÃ³mo se entrenan la mayorÃ­a de modelos de ML.

### P63: Â¿QuÃ© es MAP y cÃ³mo se relaciona con regularizaciÃ³n?
**R:** Maximum A Posteriori incorpora un prior: Î¸Ì‚ = argmax P(Î¸|data) âˆ P(data|Î¸) Ã— P(Î¸). Prior gaussiano â†’ L2 regularization. Prior laplaciano â†’ L1 regularization.

### P64: Â¿QuÃ© es la distribuciÃ³n normal y por quÃ© es importante?
**R:** DistribuciÃ³n "campana de Gauss". Importante por el Teorema del LÃ­mite Central: la suma de muchas variables independientes tiende a normal. Muchos errores en ML se asumen normales.

### P65: Â¿QuÃ© es esperanza y varianza?
**R:** 
- E[X] = Î£ x Ã— P(x) = "valor promedio esperado"
- Var(X) = E[(X - Î¼)Â²] = "spread" alrededor de la media

### P66: Â¿QuÃ© es una cadena de Markov?
**R:** Proceso estocÃ¡stico donde el futuro solo depende del estado actual, no del pasado: P(Xâ‚™â‚Šâ‚|Xâ‚™, Xâ‚™â‚‹â‚, ...) = P(Xâ‚™â‚Šâ‚|Xâ‚™). Usado en PageRank, modelos de lenguaje.

### P67: Â¿QuÃ© es la distribuciÃ³n estacionaria de una cadena de Markov?
**R:** DistribuciÃ³n Ï€ tal que Ï€ = Ï€P. DespuÃ©s de muchos pasos, la cadena converge a esta distribuciÃ³n sin importar el estado inicial.

### P68: Â¿QuÃ© es MCMC y para quÃ© se usa?
**R:** Markov Chain Monte Carlo. TÃ©cnica para muestrear de distribuciones complejas construyendo una cadena de Markov cuya distribuciÃ³n estacionaria es la distribuciÃ³n objetivo.

### P69: Explica el algoritmo Metropolis-Hastings.
**R:**
1. Proponer nuevo estado x' desde distribuciÃ³n q(x'|x)
2. Aceptar con probabilidad min(1, P(x')/P(x))
3. Si acepta, mover a x'; si no, quedarse en x
4. Repetir

### P70: Â¿QuÃ© es un intervalo de confianza?
**R:** Rango [a,b] tal que si repitiÃ©ramos el experimento muchas veces, el parÃ¡metro real estarÃ­a dentro del intervalo en (1-Î±)% de las veces (ej: 95%).

### P71: Â¿CuÃ¡l es la diferencia entre error Tipo I y Tipo II?
**R:**
- Tipo I (Î±): Rechazar Hâ‚€ cuando es verdadera (falso positivo)
- Tipo II (Î²): No rechazar Hâ‚€ cuando es falsa (falso negativo)

### P72: Â¿QuÃ© es covarianza y correlaciÃ³n?
**R:**
- Cov(X,Y) = E[(X-Î¼â‚“)(Y-Î¼áµ§)] - RelaciÃ³n lineal, no normalizada
- Correlation = Cov(X,Y)/(Ïƒâ‚“Ïƒáµ§) - Normalizada a [-1, 1]

### P73: Â¿QuÃ© es la distribuciÃ³n Bernoulli y Binomial?
**R:**
- Bernoulli: Un solo experimento con prob p de Ã©xito
- Binomial: k Ã©xitos en n experimentos Bernoulli independientes

### P74: Â¿Por quÃ© usamos log-likelihood en lugar de likelihood?
**R:** Producto de probabilidades pequeÃ±as â†’ underflow. Logaritmo convierte productos en sumas, numÃ©ricamente mÃ¡s estable.

### P75: Â¿QuÃ© es el Teorema del LÃ­mite Central?
**R:** La distribuciÃ³n de la media muestral tiende a una normal cuando n â†’ âˆ, sin importar la distribuciÃ³n original. Justifica asumir normalidad en muchos contextos.

### P76: Â¿QuÃ© es independencia condicional?
**R:** P(A,B|C) = P(A|C) Ã— P(B|C). A y B son independientes dado C. Base de Naive Bayes: features son independientes dado la clase.

### P77: Â¿QuÃ© es estimador insesgado?
**R:** Estimador cuyo valor esperado es igual al parÃ¡metro real: E[Î¸Ì‚] = Î¸. Ejemplo: media muestral es insesgada para la media poblacional.

### P78: Â¿QuÃ© es bootstrap?
**R:** TÃ©cnica de remuestreo: crear muchas muestras tomando con reemplazo de los datos originales. Usado para estimar varianza de estimadores.

### P79: Â¿QuÃ© es el p-value?
**R:** Probabilidad de observar resultados tan extremos como los observados, asumiendo que Hâ‚€ es verdadera. Si p < Î±, rechazamos Hâ‚€.

---

## SecciÃ³n 7: Machine Learning â­ [PATHWAY LÃNEA 1]

### P80: Â¿CuÃ¡l es la diferencia entre aprendizaje supervisado y no supervisado?
**R:**
- Supervisado: Datos etiquetados (X, y). Objetivo: predecir y dado X.
- No supervisado: Solo datos X. Objetivo: encontrar estructura (clusters, dimensiones).

### P81: Â¿QuÃ© es el bias-variance tradeoff?
**R:** Error = BiasÂ² + Variance + Ruido irreducible.
- Bias alto â†’ underfitting (modelo muy simple)
- Variance alta â†’ overfitting (modelo muy complejo)
Objetivo: encontrar el balance Ã³ptimo.

### P82: Â¿QuÃ© es overfitting y cÃ³mo detectarlo?
**R:** Modelo aprende ruido del train set y no generaliza. Se detecta cuando train accuracy >> test accuracy. Soluciones: mÃ¡s datos, regularizaciÃ³n, menos complejidad.

### P83: Â¿QuÃ© es cross-validation y para quÃ© sirve?
**R:** Dividir datos en k folds, entrenar en k-1 y validar en 1, rotar. Da estimaciÃ³n mÃ¡s robusta del rendimiento que un solo train/test split.

### P84: Explica gradient descent.
**R:** Algoritmo de optimizaciÃ³n: w = w - lr Ã— âˆ‚L/âˆ‚w. Sigue la direcciÃ³n de mÃ¡xima pendiente descendente para minimizar la funciÃ³n de pÃ©rdida.

### P85: Â¿CuÃ¡l es la diferencia entre batch, mini-batch y SGD?
**R:**
- Batch: Usa todos los datos para cada update
- Mini-batch: Usa subconjunto (ej: 32 samples)
- SGD: Usa 1 sample por update
Mini-batch es el mÃ¡s comÃºn: balance entre estabilidad y velocidad.

### P86: Â¿QuÃ© es regularizaciÃ³n L1 y L2?
**R:**
- L1 (Lasso): Suma de |w|. Produce sparsity (pesos = 0).
- L2 (Ridge): Suma de wÂ². Shrinks pesos pero no a cero.
Ambas previenen overfitting al penalizar pesos grandes.

### P87: Explica regresiÃ³n logÃ­stica.
**R:** Clasificador lineal: P(y=1|x) = Ïƒ(wáµ€x + b). Usa sigmoid para mapear a [0,1]. Se entrena minimizando binary cross-entropy con gradient descent.

### P88: Â¿CÃ³mo funciona un Ã¡rbol de decisiÃ³n?
**R:** Divide recursivamente los datos segÃºn el feature que maximiza ganancia de informaciÃ³n (o minimiza Gini). Hojas contienen predicciones. FÃ¡cil de interpretar, propenso a overfitting.

### P89: Â¿QuÃ© es Random Forest?
**R:** Ensemble de Ã¡rboles de decisiÃ³n. Cada Ã¡rbol entrena en bootstrap sample con subset de features aleatorio. PredicciÃ³n final = promedio/voto mayoritario. Reduce variance.

### P90: Explica K-Nearest Neighbors.
**R:** Predice segÃºn el voto de los k vecinos mÃ¡s cercanos. No-paramÃ©trico (no entrena). Complejidad O(nÃ—d) por predicciÃ³n. Sensible a escala de features.

### P91: Â¿QuÃ© es SVM y cuÃ¡l es la idea del kernel trick?
**R:** SVM encuentra hiperplano con mÃ¡ximo margen entre clases. Kernel trick: proyectar a dimensiÃ³n superior donde datos son linealmente separables, sin calcular la proyecciÃ³n explÃ­cita.

### P92: Â¿QuÃ© mÃ©tricas usarÃ­as para clasificaciÃ³n desbalanceada?
**R:** Accuracy engaÃ±a. Mejor usar:
- Precision: TP/(TP+FP) - de los predichos +, cuÃ¡ntos son +
- Recall: TP/(TP+FN) - de los reales +, cuÃ¡ntos encontramos
- F1: armonic mean de precision y recall
- AUC-ROC

### P93: Explica K-Means clustering.
**R:**
1. Inicializar k centroides aleatorios
2. Asignar cada punto al centroide mÃ¡s cercano
3. Actualizar centroides al promedio de sus puntos
4. Repetir hasta convergencia
Requiere especificar k. Sensible a inicializaciÃ³n.

### P94: Â¿CÃ³mo elegir el nÃºmero de clusters en K-Means?
**R:**
- Elbow method: graficar inertia vs k, buscar "codo"
- Silhouette score: mide cohesiÃ³n vs separaciÃ³n
- Domain knowledge

### P95: Â¿QuÃ© es PCA y para quÃ© sirve?
**R:** Principal Component Analysis. Reduce dimensionalidad proyectando a direcciones de mÃ¡xima varianza (eigenvectors de la matriz de covarianza). Usado para visualizaciÃ³n, compresiÃ³n, preprocesamiento.

### P96: Â¿QuÃ© es una red neuronal?
**R:** ComposiciÃ³n de funciones: y = f(Wâ‚ƒ Ã— f(Wâ‚‚ Ã— f(Wâ‚x + bâ‚) + bâ‚‚) + bâ‚ƒ). Cada capa es transformaciÃ³n lineal + activaciÃ³n no lineal. Aprende features automÃ¡ticamente.

### P97: Explica backpropagation.
**R:** Algoritmo para calcular gradientes en redes neuronales usando la regla de la cadena. Forward pass calcula output, backward pass propaga gradientes desde el loss hacia atrÃ¡s.

### P98: Â¿QuÃ© son funciones de activaciÃ³n y cuÃ¡les conoces?
**R:** Funciones no lineales entre capas.
- Sigmoid: (0,1), problemas de vanishing gradient
- ReLU: max(0,x), estÃ¡ndar para capas ocultas
- Softmax: para output de clasificaciÃ³n multiclase

### P99: Â¿QuÃ© es una CNN y para quÃ© se usa?
**R:** Convolutional Neural Network. Capas de convoluciÃ³n extraen features espaciales. Usadas para imÃ¡genes. Ventaja: comparten parÃ¡metros, detectan patrones independiente de posiciÃ³n.

### P100: Â¿QuÃ© es una RNN y cuÃ¡l es el problema del vanishing gradient?
**R:** Recurrent Neural Network. Estado oculto depende del anterior, captura secuencias. Vanishing gradient: gradientes se vuelven muy pequeÃ±os en secuencias largas. SoluciÃ³n: LSTM, GRU.

---

## ğŸ¯ AutoevaluaciÃ³n

| Respuestas Correctas | Nivel |
|---------------------|-------|
| 100-120 | ğŸ† Listo para Pathway - Ambas lÃ­neas |
| 80-99 | âœ… Buen nivel, reforzar gaps |
| 60-79 | âš ï¸ Necesita mÃ¡s estudio |
| <60 | âŒ Revisar mÃ³dulos |

---

## ğŸ’¡ Tips para la Entrevista Real

1. **Explica tu pensamiento:** Verbaliza mientras resuelves
2. **Empieza simple:** Primero soluciÃ³n bruta, luego optimiza
3. **Pregunta si dudas:** Clarifica requisitos
4. **Analiza Big O:** Siempre menciona complejidad
5. **Practica en inglÃ©s:** Todo el Pathway es en inglÃ©s
6. **Conecta conceptos:** ML usa probabilidad, DL usa Ã¡lgebra lineal
7. **Implementa desde cero:** Demuestra que entiendes, no solo usas sklearn
