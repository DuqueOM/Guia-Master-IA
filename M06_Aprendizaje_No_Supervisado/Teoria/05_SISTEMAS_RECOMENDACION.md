# MÃ³dulo 6.5: Sistemas de RecomendaciÃ³n

> **Semana:** 15 | **Curso Alineado:** CSCA 5632 - Unsupervised Learning
> **Prerequisitos:** SVD, PCA, Ãlgebra Lineal

---

## ðŸŽ¯ Objetivos de Aprendizaje

Al finalizar este mÃ³dulo serÃ¡s capaz de:

1. **Distinguir** entre filtrado colaborativo y basado en contenido
2. **Implementar** factorizaciÃ³n de matrices con SVD para recomendaciones
3. **Construir** un recomendador funcional con el dataset MovieLens
4. **Evaluar** sistemas de recomendaciÃ³n con mÃ©tricas apropiadas
5. **Comprender** el problema del cold-start y estrategias de mitigaciÃ³n

---

## ðŸ“š Tabla de Contenidos

1. [IntroducciÃ³n a Sistemas de RecomendaciÃ³n](#1-introducciÃ³n)
2. [TaxonomÃ­a de MÃ©todos](#2-taxonomÃ­a-de-mÃ©todos)
3. [Filtrado Colaborativo](#3-filtrado-colaborativo)
4. [FactorizaciÃ³n de Matrices](#4-factorizaciÃ³n-de-matrices)
5. [SVD para Recomendaciones](#5-svd-para-recomendaciones)
6. [ImplementaciÃ³n PrÃ¡ctica: MovieLens](#6-implementaciÃ³n-prÃ¡ctica)
7. [MÃ©tricas de EvaluaciÃ³n](#7-mÃ©tricas-de-evaluaciÃ³n)
8. [Problemas y Soluciones](#8-problemas-y-soluciones)
9. [Ejercicios](#9-ejercicios)

---

## 1. IntroducciÃ³n a Sistemas de RecomendaciÃ³n

### 1.1 MotivaciÃ³n: El Problema de la Sobrecarga de InformaciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EL PROBLEMA DE ESCALA                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Netflix:     ~15,000 tÃ­tulos                                   â”‚
â”‚  Amazon:      ~350 millones de productos                        â”‚
â”‚  Spotify:     ~100 millones de canciones                        â”‚
â”‚  YouTube:     500 horas de video subidas por MINUTO             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Pregunta: Â¿CÃ³mo encuentra el usuario lo que le interesa?       â”‚
â”‚  Respuesta: SISTEMAS DE RECOMENDACIÃ“N                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Impacto EconÃ³mico

| Empresa | MÃ©trica | Fuente |
|---------|---------|--------|
| **Netflix** | 80% del contenido visto proviene de recomendaciones | Netflix Tech Blog |
| **Amazon** | 35% de ventas provienen de recomendaciones | McKinsey |
| **YouTube** | 70% del tiempo de visualizaciÃ³n | YouTube Creator Academy |
| **Spotify** | Discover Weekly: 40M usuarios activos semanales | Spotify |

### 1.3 FormalizaciÃ³n del Problema

**DefiniciÃ³n Formal:**

Dado:
- Conjunto de usuarios U = {uâ‚, uâ‚‚, ..., uâ‚˜}
- Conjunto de items I = {iâ‚, iâ‚‚, ..., iâ‚™}
- Matriz de ratings R âˆˆ â„áµË£â¿ (parcialmente observada)

Objetivo:
- Predecir los ratings faltantes RÌ‚áµ¤áµ¢ para (u,i) no observados
- Generar lista ordenada de top-K recomendaciones para cada usuario

```
         Items
         iâ‚  iâ‚‚  iâ‚ƒ  iâ‚„  iâ‚…
       â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
   uâ‚  â”‚ 5 â”‚ ? â”‚ 3 â”‚ ? â”‚ 1 â”‚
       â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
U  uâ‚‚  â”‚ ? â”‚ 4 â”‚ ? â”‚ 2 â”‚ ? â”‚   R = Matriz de Ratings
s      â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤       (sparse)
e  uâ‚ƒ  â”‚ 4 â”‚ ? â”‚ ? â”‚ 5 â”‚ ? â”‚
r      â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
s  uâ‚„  â”‚ ? â”‚ 3 â”‚ 4 â”‚ ? â”‚ 5 â”‚
       â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜

       ? = valores a predecir
```

---

## 2. TaxonomÃ­a de MÃ©todos

### 2.1 ClasificaciÃ³n Principal

```
                    Sistemas de RecomendaciÃ³n
                              â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                   â”‚                   â”‚
          â–¼                   â–¼                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Content   â”‚      â”‚Collaborativeâ”‚     â”‚  Hybrid   â”‚
    â”‚  Based    â”‚      â”‚ Filtering  â”‚      â”‚           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚
          â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
          â”‚           â”‚               â”‚
          â–¼           â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Atributos â”‚ â”‚Memory â”‚    â”‚  Model    â”‚
    â”‚ de items  â”‚ â”‚ Based â”‚    â”‚  Based    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚               â”‚
                â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                â”‚           â”‚   â”‚           â”‚
             User-       Item- â”‚Matrix     â”‚Deep
             Based       Based â”‚Factor.    â”‚Learning
```

### 2.2 ComparaciÃ³n de Enfoques

| Aspecto | Content-Based | Collaborative Filtering |
|---------|---------------|------------------------|
| **Datos requeridos** | Atributos de items | Solo ratings |
| **Cold-start usuarios** | SÃ­ (si hay perfil) | ProblemÃ¡tico |
| **Cold-start items** | SÃ­ (si hay atributos) | ProblemÃ¡tico |
| **Serendipity** | Baja (burbuja de filtro) | Alta |
| **Escalabilidad** | Alta | Media (memory-based) |
| **Explicabilidad** | Alta | Media-Baja |

---

## 3. Filtrado Colaborativo

### 3.1 IntuiciÃ³n Fundamental

> "Si a usuarios similares les gustaron items similares en el pasado,
> probablemente les gustarÃ¡n items similares en el futuro."

**AnalogÃ­a del Cine:**
```
TÃº viste y te gustaron: Matrix, Inception, Interstellar
Tu amigo vio: Matrix, Inception, Interstellar, Arrival
â†’ RecomendaciÃ³n: Arrival (porque tu amigo tiene gustos similares)
```

### 3.2 User-Based Collaborative Filtering

**Algoritmo:**
1. Encontrar usuarios similares al usuario objetivo
2. Agregar ratings de usuarios similares para items no vistos
3. Recomendar items con mayor rating predicho

```python
def predict_rating_user_based(user_u, item_i, ratings_matrix, k=10):
    """
    PredicciÃ³n basada en usuarios similares.

    rÌ‚(u,i) = rÌ„áµ¤ + Î£ sim(u,v) * (ráµ¥áµ¢ - rÌ„áµ¥) / Î£ |sim(u,v)|
    """
    # Encontrar usuarios que han calificado item_i
    users_who_rated_i = ratings_matrix[:, item_i].nonzero()[0]

    # Calcular similaridad con cada usuario
    similarities = []
    for v in users_who_rated_i:
        if v != user_u:
            sim = cosine_similarity(ratings_matrix[user_u], ratings_matrix[v])
            similarities.append((v, sim))

    # Tomar top-k mÃ¡s similares
    top_k = sorted(similarities, key=lambda x: x[1], reverse=True)[:k]

    # PredicciÃ³n ponderada
    user_mean = ratings_matrix[user_u].mean()
    numerator = sum(sim * (ratings_matrix[v, item_i] - ratings_matrix[v].mean())
                    for v, sim in top_k)
    denominator = sum(abs(sim) for _, sim in top_k)

    return user_mean + numerator / denominator if denominator > 0 else user_mean
```

### 3.3 Item-Based Collaborative Filtering

**Diferencia clave:** En lugar de buscar usuarios similares, buscamos items similares.

**Ventaja:** La similaridad entre items es mÃ¡s estable que entre usuarios (los gustos de usuarios cambian mÃ¡s frecuentemente).

```python
def predict_rating_item_based(user_u, item_i, ratings_matrix, k=10):
    """
    PredicciÃ³n basada en items similares.

    rÌ‚(u,i) = Î£ sim(i,j) * ráµ¤â±¼ / Î£ |sim(i,j)|

    donde j son items calificados por usuario u similares a item i
    """
    # Items calificados por usuario u
    items_rated_by_u = ratings_matrix[user_u].nonzero()[0]

    # Calcular similaridad con item_i
    similarities = []
    for j in items_rated_by_u:
        if j != item_i:
            sim = cosine_similarity(ratings_matrix[:, item_i], ratings_matrix[:, j])
            similarities.append((j, sim))

    # Top-k items mÃ¡s similares
    top_k = sorted(similarities, key=lambda x: x[1], reverse=True)[:k]

    # PredicciÃ³n ponderada
    numerator = sum(sim * ratings_matrix[user_u, j] for j, sim in top_k)
    denominator = sum(abs(sim) for _, sim in top_k)

    return numerator / denominator if denominator > 0 else 0
```

### 3.4 MÃ©tricas de Similaridad

| MÃ©trica | FÃ³rmula | Uso |
|---------|---------|-----|
| **Cosine** | cos(u,v) = uÂ·v / (â€–uâ€–â€–vâ€–) | Ratings implÃ­citos |
| **Pearson** | Ï(u,v) = cov(u,v) / (Ïƒáµ¤Ïƒáµ¥) | Ratings explÃ­citos (considera bias) |
| **Jaccard** | J(u,v) = \|uâˆ©v\| / \|uâˆªv\| | Datos binarios (comprÃ³/no comprÃ³) |

---

## 4. FactorizaciÃ³n de Matrices

### 4.1 La Gran Idea

> **HipÃ³tesis de Baja Dimensionalidad:**
> Los gustos de usuarios y caracterÃ­sticas de items pueden representarse
> en un espacio latente de dimensiÃ³n k << min(m, n).

```
Matriz R (mÃ—n)           â‰ˆ    P (mÃ—k)    Ã—    Q (kÃ—n)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚             â”‚       â”‚      â”‚         â”‚
â”‚  Ratings    â”‚      â‰ˆ      â”‚ User  â”‚   Ã—  â”‚  Item   â”‚
â”‚  Observados â”‚             â”‚Factorsâ”‚      â”‚ Factors â”‚
â”‚             â”‚             â”‚       â”‚      â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  (sparse)                    (dense)        (dense)

Ejemplo: k = 20 factores latentes
- Factor 1: Â¿Es pelÃ­cula de acciÃ³n?
- Factor 2: Â¿Tiene romance?
- Factor 3: Â¿Es para adultos?
- ... (la mayorÃ­a no son interpretables)
```

### 4.2 RepresentaciÃ³n MatemÃ¡tica

Para predecir el rating del usuario u para el item i:

```
rÌ‚áµ¤áµ¢ = Î¼ + báµ¤ + báµ¢ + páµ¤áµ€ Â· qáµ¢

donde:
- Î¼  = media global de ratings
- báµ¤ = bias del usuario u (Â¿califica generalmente alto/bajo?)
- báµ¢ = bias del item i (Â¿es generalmente bien/mal calificado?)
- páµ¤ = vector latente del usuario (k dimensiones)
- qáµ¢ = vector latente del item (k dimensiones)
```

### 4.3 FunciÃ³n de PÃ©rdida

Minimizar el error de reconstrucciÃ³n con regularizaciÃ³n:

```
L = Î£ (ráµ¤áµ¢ - rÌ‚áµ¤áµ¢)Â² + Î»(â€–páµ¤â€–Â² + â€–qáµ¢â€–Â² + báµ¤Â² + báµ¢Â²)
    (u,i)âˆˆÎ©

donde Î© = conjunto de ratings observados
      Î» = parÃ¡metro de regularizaciÃ³n
```

### 4.4 OptimizaciÃ³n: SGD vs ALS

**Stochastic Gradient Descent (SGD):**
```python
def sgd_update(u, i, rating, P, Q, b_u, b_i, mu, lr=0.01, reg=0.1):
    """Una actualizaciÃ³n de SGD"""
    # PredicciÃ³n actual
    pred = mu + b_u[u] + b_i[i] + np.dot(P[u], Q[i])
    error = rating - pred

    # Actualizar biases
    b_u[u] += lr * (error - reg * b_u[u])
    b_i[i] += lr * (error - reg * b_i[i])

    # Actualizar factores latentes
    P[u] += lr * (error * Q[i] - reg * P[u])
    Q[i] += lr * (error * P[u] - reg * Q[i])
```

**Alternating Least Squares (ALS):**
- Fijar Q, optimizar P (problema de mÃ­nimos cuadrados)
- Fijar P, optimizar Q
- Repetir hasta convergencia
- **Ventaja:** Paralelizable, usado por Spark MLlib

---

## 5. SVD para Recomendaciones

### 5.1 SVD ClÃ¡sico vs SVD para RecSys

**SVD ClÃ¡sico** (Ãlgebra Lineal):
```
A = UÎ£Váµ€

donde:
- U: vectores singulares izquierdos (mÃ—m)
- Î£: valores singulares (diagonal, mÃ—n)
- V: vectores singulares derechos (nÃ—n)
```

**Problema:** SVD clÃ¡sico requiere matriz completa (sin valores faltantes).

**SVD para RecSys:** TÃ©cnicamente es **factorizaciÃ³n de matrices** (no SVD puro), pero se llama "SVD" por convenciÃ³n en la literatura de recomendaciÃ³n.

### 5.2 Truncated SVD para ReducciÃ³n de Dimensionalidad

```python
import numpy as np
from scipy.sparse.linalg import svds

def truncated_svd_recommendation(ratings_matrix, k=50):
    """
    AproximaciÃ³n de baja dimensiÃ³n usando SVD truncado.
    Solo funciona si la matriz es densa (se rellenan valores faltantes).
    """
    # Rellenar valores faltantes con media (simple)
    ratings_filled = ratings_matrix.copy()
    ratings_filled[ratings_filled == 0] = ratings_matrix[ratings_matrix > 0].mean()

    # SVD truncado
    U, sigma, Vt = svds(ratings_filled, k=k)

    # Reconstruir matriz aproximada
    sigma_diag = np.diag(sigma)
    predictions = U @ sigma_diag @ Vt

    return predictions
```

### 5.3 Algoritmo SVD++ (Koren, 2008)

**Mejora:** Incorporar feedback implÃ­cito (quÃ© items ha visto el usuario, aunque no los haya calificado).

```
rÌ‚áµ¤áµ¢ = Î¼ + báµ¤ + báµ¢ + qáµ¢áµ€ Â· (páµ¤ + |N(u)|^(-1/2) Î£â±¼âˆˆN(u) yâ±¼)

donde:
- N(u) = conjunto de items que usuario u ha interactuado
- yâ±¼ = vector de feedback implÃ­cito para item j
```

### 5.4 ImplementaciÃ³n con Surprise Library

```python
from surprise import SVD, Dataset, Reader, accuracy
from surprise.model_selection import cross_validate, train_test_split

# Cargar datos MovieLens
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_builtin('ml-100k')

# Dividir datos
trainset, testset = train_test_split(data, test_size=0.2)

# Entrenar SVD
algo = SVD(
    n_factors=100,      # Dimensionalidad del espacio latente
    n_epochs=20,        # NÃºmero de Ã©pocas
    lr_all=0.005,       # Learning rate
    reg_all=0.02,       # RegularizaciÃ³n
    biased=True         # Incluir biases
)
algo.fit(trainset)

# Evaluar
predictions = algo.test(testset)
rmse = accuracy.rmse(predictions)
print(f"RMSE: {rmse:.4f}")

# Hacer una predicciÃ³n
user_id = '196'
item_id = '302'
pred = algo.predict(user_id, item_id)
print(f"PredicciÃ³n para user {user_id}, item {item_id}: {pred.est:.2f}")
```

---

## 6. ImplementaciÃ³n PrÃ¡ctica: MovieLens

### 6.1 DescripciÃ³n del Dataset

| VersiÃ³n | Ratings | Usuarios | PelÃ­culas | Densidad |
|---------|---------|----------|-----------|----------|
| ml-100k | 100,000 | 943 | 1,682 | 6.3% |
| ml-1m | 1,000,000 | 6,040 | 3,706 | 4.5% |
| ml-10m | 10,000,000 | 71,567 | 10,681 | 1.3% |
| ml-25m | 25,000,000 | 162,541 | 62,423 | 0.2% |

### 6.2 ExploraciÃ³n Inicial

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Cargar MovieLens 100k
ratings = pd.read_csv('ml-100k/u.data', sep='\t',
                      names=['user_id', 'item_id', 'rating', 'timestamp'])

# EstadÃ­sticas bÃ¡sicas
print(f"Total ratings: {len(ratings):,}")
print(f"Usuarios Ãºnicos: {ratings.user_id.nunique()}")
print(f"Items Ãºnicos: {ratings.item_id.nunique()}")
print(f"Rating promedio: {ratings.rating.mean():.2f}")
print(f"Densidad: {len(ratings) / (ratings.user_id.nunique() * ratings.item_id.nunique()) * 100:.2f}%")

# DistribuciÃ³n de ratings
ratings.rating.value_counts().sort_index().plot(kind='bar')
plt.title('DistribuciÃ³n de Ratings')
plt.xlabel('Rating')
plt.ylabel('Frecuencia')
plt.show()

# Long-tail de popularidad
item_counts = ratings.groupby('item_id').size().sort_values(ascending=False)
plt.figure(figsize=(12, 4))
plt.plot(range(len(item_counts)), item_counts.values)
plt.xlabel('Item (ordenado por popularidad)')
plt.ylabel('NÃºmero de ratings')
plt.title('Long-tail: DistribuciÃ³n de popularidad de items')
plt.yscale('log')
plt.show()
```

### 6.3 Pipeline Completo de RecomendaciÃ³n

```python
import numpy as np
import pandas as pd
from scipy.sparse import csr_matrix
from sklearn.model_selection import train_test_split

class MatrixFactorizationRecommender:
    """
    Recomendador basado en factorizaciÃ³n de matrices con SGD.
    """

    def __init__(self, n_factors=50, n_epochs=20, lr=0.01, reg=0.1):
        self.n_factors = n_factors
        self.n_epochs = n_epochs
        self.lr = lr
        self.reg = reg

    def fit(self, ratings_df, user_col='user_id', item_col='item_id', rating_col='rating'):
        """Entrenar el modelo."""
        # Crear mapeos de IDs
        self.user_ids = ratings_df[user_col].unique()
        self.item_ids = ratings_df[item_col].unique()
        self.user_to_idx = {u: i for i, u in enumerate(self.user_ids)}
        self.item_to_idx = {i: j for j, i in enumerate(self.item_ids)}

        self.n_users = len(self.user_ids)
        self.n_items = len(self.item_ids)

        # Inicializar parÃ¡metros
        self.global_mean = ratings_df[rating_col].mean()
        self.b_u = np.zeros(self.n_users)
        self.b_i = np.zeros(self.n_items)
        self.P = np.random.normal(0, 0.1, (self.n_users, self.n_factors))
        self.Q = np.random.normal(0, 0.1, (self.n_items, self.n_factors))

        # Convertir a arrays numpy
        users = ratings_df[user_col].map(self.user_to_idx).values
        items = ratings_df[item_col].map(self.item_to_idx).values
        ratings = ratings_df[rating_col].values

        # Entrenamiento con SGD
        for epoch in range(self.n_epochs):
            # Shuffle
            indices = np.random.permutation(len(ratings))
            total_loss = 0

            for idx in indices:
                u, i, r = users[idx], items[idx], ratings[idx]

                # PredicciÃ³n
                pred = self.global_mean + self.b_u[u] + self.b_i[i] + self.P[u] @ self.Q[i]
                error = r - pred
                total_loss += error ** 2

                # Actualizar parÃ¡metros
                self.b_u[u] += self.lr * (error - self.reg * self.b_u[u])
                self.b_i[i] += self.lr * (error - self.reg * self.b_i[i])

                P_u_old = self.P[u].copy()
                self.P[u] += self.lr * (error * self.Q[i] - self.reg * self.P[u])
                self.Q[i] += self.lr * (error * P_u_old - self.reg * self.Q[i])

            rmse = np.sqrt(total_loss / len(ratings))
            print(f"Epoch {epoch+1}/{self.n_epochs}, RMSE: {rmse:.4f}")

        return self

    def predict(self, user_id, item_id):
        """Predecir rating para un usuario e item."""
        if user_id not in self.user_to_idx or item_id not in self.item_to_idx:
            return self.global_mean

        u = self.user_to_idx[user_id]
        i = self.item_to_idx[item_id]

        pred = self.global_mean + self.b_u[u] + self.b_i[i] + self.P[u] @ self.Q[i]
        return np.clip(pred, 1, 5)

    def recommend(self, user_id, n=10, exclude_seen=True, seen_items=None):
        """Generar top-N recomendaciones para un usuario."""
        if user_id not in self.user_to_idx:
            return []

        u = self.user_to_idx[user_id]

        # Predecir todos los items
        predictions = []
        for item_id in self.item_ids:
            if exclude_seen and seen_items and item_id in seen_items:
                continue
            predictions.append((item_id, self.predict(user_id, item_id)))

        # Ordenar por predicciÃ³n
        predictions.sort(key=lambda x: x[1], reverse=True)
        return predictions[:n]

# Uso
model = MatrixFactorizationRecommender(n_factors=50, n_epochs=20)
model.fit(ratings)

# Recomendaciones para usuario 1
seen = set(ratings[ratings.user_id == 1].item_id)
recommendations = model.recommend(user_id=1, n=10, seen_items=seen)
print("Top 10 recomendaciones para usuario 1:")
for item_id, score in recommendations:
    print(f"  Item {item_id}: {score:.2f}")
```

---

## 7. MÃ©tricas de EvaluaciÃ³n

### 7.1 MÃ©tricas de Rating Prediction

| MÃ©trica | FÃ³rmula | InterpretaciÃ³n |
|---------|---------|----------------|
| **RMSE** | âˆš(Î£(ráµ¤áµ¢ - rÌ‚áµ¤áµ¢)Â²/N) | Error cuadrÃ¡tico medio (penaliza errores grandes) |
| **MAE** | Î£\|ráµ¤áµ¢ - rÌ‚áµ¤áµ¢\|/N | Error absoluto medio |

### 7.2 MÃ©tricas de Ranking (Top-K)

| MÃ©trica | DescripciÃ³n | FÃ³rmula |
|---------|-------------|---------|
| **Precision@K** | ProporciÃ³n de items relevantes en top-K | \|Rec âˆ© Rel\| / K |
| **Recall@K** | ProporciÃ³n de items relevantes recuperados | \|Rec âˆ© Rel\| / \|Rel\| |
| **NDCG@K** | Normalized Discounted Cumulative Gain | DCG / IDCG |
| **MAP** | Mean Average Precision | Promedio de AP sobre usuarios |
| **Hit Rate** | ProporciÃ³n de usuarios con al menos 1 hit | |

### 7.3 ImplementaciÃ³n de MÃ©tricas

```python
def precision_at_k(recommended, relevant, k):
    """Precision@K"""
    recommended_k = set(recommended[:k])
    relevant_set = set(relevant)
    return len(recommended_k & relevant_set) / k

def recall_at_k(recommended, relevant, k):
    """Recall@K"""
    recommended_k = set(recommended[:k])
    relevant_set = set(relevant)
    if len(relevant_set) == 0:
        return 0
    return len(recommended_k & relevant_set) / len(relevant_set)

def ndcg_at_k(recommended, relevant, k):
    """NDCG@K"""
    def dcg(scores, k):
        return sum(s / np.log2(i + 2) for i, s in enumerate(scores[:k]))

    # Relevance scores (1 if in relevant, 0 otherwise)
    scores = [1 if item in relevant else 0 for item in recommended[:k]]
    ideal_scores = sorted(scores, reverse=True)

    dcg_val = dcg(scores, k)
    idcg_val = dcg(ideal_scores, k)

    return dcg_val / idcg_val if idcg_val > 0 else 0

# Ejemplo de uso
recommended = ['item1', 'item2', 'item3', 'item4', 'item5']
relevant = ['item2', 'item5', 'item7']

print(f"Precision@5: {precision_at_k(recommended, relevant, 5):.2f}")
print(f"Recall@5: {recall_at_k(recommended, relevant, 5):.2f}")
print(f"NDCG@5: {ndcg_at_k(recommended, relevant, 5):.2f}")
```

---

## 8. Problemas y Soluciones

### 8.1 El Problema del Cold-Start

| Tipo | Problema | Soluciones |
|------|----------|------------|
| **Nuevo usuario** | No hay ratings histÃ³ricos | Content-based, demografÃ­a, preguntas iniciales |
| **Nuevo item** | Nadie lo ha calificado | Content-based, item attributes |
| **Nuevo sistema** | Pocos datos totales | HÃ­brido, exploraciÃ³n activa |

### 8.2 Sparsity

**Problema:** En sistemas reales, la matriz de ratings tiene >99% de valores faltantes.

**Soluciones:**
- RegularizaciÃ³n fuerte
- FactorizaciÃ³n de matrices (reduce dimensionalidad)
- Incorporar datos auxiliares (grafos sociales, atributos)

### 8.3 Scalability

```
           Complejidad Computacional

Method              Time           Space
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
User-Based CF       O(mÂ²n)         O(mÂ²)
Item-Based CF       O(mnÂ²)         O(nÂ²)
Matrix Fact.        O(nnzÂ·kÂ·T)     O((m+n)k)

m = usuarios, n = items, k = factores
nnz = nÃºmero de ratings, T = Ã©pocas
```

### 8.4 Burbuja de Filtro (Filter Bubble)

**Problema:** Sistema solo recomienda items similares a los ya vistos.

**Soluciones:**
- DiversificaciÃ³n explÃ­cita en recomendaciones
- ExploraciÃ³n (Îµ-greedy, Thompson Sampling)
- MÃ©tricas de diversidad (ILS, coverage)

---

## 9. Ejercicios

### Ejercicio 1: Implementar Similaridad Coseno

```python
"""
Implementar la funciÃ³n de similaridad coseno para vectores sparse.
Usarla para encontrar los 5 items mÃ¡s similares a un item dado.
"""
def cosine_similarity_sparse(vec1, vec2):
    # Tu implementaciÃ³n
    pass
```

### Ejercicio 2: Comparar User-Based vs Item-Based

```python
"""
1. Cargar MovieLens 100k
2. Implementar ambos mÃ©todos (user-based e item-based)
3. Comparar RMSE en conjunto de test
4. Analizar tiempos de predicciÃ³n
"""
```

### Ejercicio 3: Tune SVD con Grid Search

```python
"""
Usar Surprise para hacer grid search sobre:
- n_factors: [20, 50, 100, 200]
- n_epochs: [10, 20, 30]
- reg_all: [0.01, 0.02, 0.1]

Reportar mejor configuraciÃ³n y RMSE.
"""
from surprise.model_selection import GridSearchCV
# Tu cÃ³digo
```

### Ejercicio 4: Implementar NDCG desde cero

```python
"""
Implementar NDCG@K con relevancia binaria y graduada.
Validar contra implementaciÃ³n de sklearn.
"""
```

---

## 10. Resumen

| Concepto | Punto Clave |
|----------|-------------|
| **Filtrado Colaborativo** | Usuarios similares â†’ items similares |
| **FactorizaciÃ³n** | R â‰ˆ P Ã— Qáµ€ (espacio latente) |
| **SVD** | TÃ©cnica fundamental, Netflix Prize winner |
| **EvaluaciÃ³n** | RMSE para ratings, NDCG para ranking |
| **Cold-Start** | HÃ­brido content + collaborative |

---

## 11. Lecturas Recomendadas

1. **"Matrix Factorization Techniques for Recommender Systems"** (Koren et al., IEEE 2009) - Paper fundamental

2. **"The BellKor Solution to the Netflix Prize"** (2009) - Caso de estudio detallado

3. **Surprise Library Documentation** - https://surprise.readthedocs.io/

4. **"Recommender Systems Handbook"** (Ricci et al., 2015) - Referencia completa

---

*Material desarrollado para el MS-AI Pathway - University of Colorado Boulder*
*Semana 15 - CSCA 5632: Unsupervised Learning*
