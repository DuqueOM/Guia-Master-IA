# M√≥dulo 04: Probabilidad Esencial para Machine Learning

> **Semana 8 | Prerequisito para entender Loss Functions y GMM**
> **Filosof√≠a: Solo la probabilidad que necesitas para la L√≠nea 1**

---

## üéØ Objetivo del M√≥dulo

Dominar los **conceptos m√≠nimos de probabilidad** necesarios para:

1. Entender **Logistic Regression** como modelo probabil√≠stico
2. Comprender **Cross-Entropy Loss** y por qu√© funciona
3. Prepararte para **Gaussian Mixture Models (GMM)** en Unsupervised
4. Entender **Softmax** como distribuci√≥n de probabilidad

> ‚ö†Ô∏è **Nota:** Este NO es el curso completo de Probabilidad (L√≠nea 2). Es solo lo esencial para ML.

---

<a id="m04-0"></a>

## üß≠ C√≥mo usar este m√≥dulo (modo 0‚Üí100)

**Prop√≥sito:** conectar probabilidad con lo que realmente usar√°s en el Pathway:

- p√©rdidas (cross-entropy) como *negative log-likelihood*
- clasificaci√≥n probabil√≠stica (logistic/softmax)
- gaussianas como base de modelos generativos (GMM)
- estabilidad num√©rica (evitar `NaN`)

### Objetivos de aprendizaje (medibles)

Al terminar el m√≥dulo podr√°s:

- **Explicar** `P(A|B)` y el teorema de Bayes con un ejemplo de clasificaci√≥n.
- **Aplicar** el punto de vista de MLE: ‚Äúelegir par√°metros que hacen los datos m√°s probables‚Äù.
- **Derivar** por qu√© minimizar cross-entropy equivale a maximizar log-likelihood (binaria y multiclase).
- **Implementar** softmax y log-softmax de forma num√©ricamente estable (log-sum-exp).
- **Diagnosticar** fallos t√≠picos: `log(0)`, overflow/underflow, probabilidades que no suman 1.

### Prerrequisitos

- De `M√≥dulo 01`: NumPy (vectorizaci√≥n, `axis`, broadcasting).
- De `M√≥dulo 03`: Chain Rule y gradiente (para entender el salto a `M√≥dulo 05/07`).

Enlaces r√°pidos:

- [RECURSOS.md](RECURSOS.md)
- [GLOSARIO: Binary Cross-Entropy](GLOSARIO.md#binary-cross-entropy)
- [GLOSARIO: Softmax](GLOSARIO.md#softmax)
- [GLOSARIO: Chain Rule](GLOSARIO.md#chain-rule)

### Integraci√≥n con Plan v4/v5

- [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md)
- [PLAN_V5_ESTRATEGICO.md](PLAN_V5_ESTRATEGICO.md)
- Registro de errores: `study_tools/DIARIO_ERRORES.md`
- Evaluaci√≥n (r√∫brica): [study_tools/RUBRICA_v1.md](../study_tools/RUBRICA_v1.md) (scope `M04` en `rubrica.csv`; incluye PB-8)

### Recursos (cu√°ndo usarlos)

| Prioridad | Recurso | Cu√°ndo usarlo en este m√≥dulo | Para qu√© |
|----------|---------|------------------------------|----------|
| **Obligatorio** | `study_tools/DIARIO_ERRORES.md` | Cada vez que aparezca `NaN`, `inf`, `log(0)` u overflow/underflow | Registrar el caso y crear un ‚Äúfix‚Äù reproducible |
| **Obligatorio** | [StatQuest - Maximum Likelihood](https://www.youtube.com/watch?v=XepXtl9YKwc) | Antes (o durante) la secci√≥n de MLE y cross-entropy | Alinear intuici√≥n de ‚Äúmaximizar verosimilitud‚Äù |
| **Complementario** | [3Blue1Brown - Bayes Theorem](https://www.youtube.com/watch?v=HZGCoVF3YvM) | Cuando Bayes se sienta ‚Äúf√≥rmula sin sentido‚Äù (d√≠a 3-4) | Visualizar prior/likelihood/posterior |
| **Complementario** | [Mathematics for ML (book)](https://mml-book.github.io/) | Al implementar Gaussiana multivariada y covarianza | Refuerzo de notaci√≥n y derivaciones |
| **Opcional** | [RECURSOS.md](RECURSOS.md) | Al terminar el m√≥dulo (para planificar L√≠nea 2 o profundizar) | Elegir rutas de estudio sin romper el foco de L√≠nea 1 |

### Mapa conceptual (qu√© conecta con qu√©)

- **MLE ‚Üí Cross-Entropy:** sustenta Logistic Regression (M√≥dulo 05) y BCE/CCE en Deep Learning (M√≥dulo 07).
- **Gaussiana multivariada:** es el ‚Äú√°tomo‚Äù de GMM (M√≥dulo 06).
- **Softmax + Log-Sum-Exp:** evita inestabilidad num√©rica en clasificaci√≥n multiclase (M√≥dulo 05/07).

### Ritmo semanal recomendado (Semana 8, sin extender)

- **Lunes y Martes (Concepto):** Bayes + MLE como idea central (qu√© maximizas y respecto a qu√© variable).
- **Mi√©rcoles y Jueves (Implementaci√≥n):** implementa versiones estables (log-sum-exp, `clip/eps`) y valida con ejemplos peque√±os.
- **Viernes (Romper cosas):** provoca `log(0)`, overflow/underflow y documenta el fix (esto se repite en M05/M07).

### Ajuste cr√≠tico de profundidad (Semana 8): MLE como ‚Äúpuente obligatorio‚Äù a Cross-Entropy

Este m√≥dulo es corto por dise√±o, pero MLE NO es opcional si quieres entender por qu√© usamos cross-entropy.

- Objetivo m√≠nimo: poder explicar en 5‚Äì10 l√≠neas por qu√©
  - **maximizar likelihood**
  - equivale a **minimizar negative log-likelihood (NLL)**
  - y por qu√© eso se ve como **cross-entropy** en clasificaci√≥n.

Prompt sugerido (si usas IA):

- "Expl√≠came Maximum Likelihood Estimation (MLE) y mu√©strame c√≥mo la cross-entropy es el negative log-likelihood para una Bernoulli (BCE) y para una distribuci√≥n categ√≥rica (softmax). No te saltes pasos."

---

## üìö Contenido

### D√≠a 1-2: Fundamentos de Probabilidad

#### 1.1 Probabilidad B√°sica

```text
P(A) = casos favorables / casos totales

Propiedades:
- 0 ‚â§ P(A) ‚â§ 1
- P(Œ©) = 1 (espacio muestral)
- P(‚àÖ) = 0 (evento imposible)
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 1.1: Probabilidad B√°sica</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Probabilidad como ‚Äúregla de conteo‚Äù + axiomas m√≠nimos
- **ID (opcional):** `M04-T01_1`
- **Duraci√≥n estimada:** 45‚Äì90 min
- **Nivel:** B√°sico
- **Dependencias:** M01 (manejo b√°sico de notaci√≥n y n√∫meros)

#### 2) Objetivos
- Calcular `P(A)` en ejemplos discretos simples y verificar que `0 ‚â§ P(A) ‚â§ 1`.
- Explicar qu√© son `Œ©`, `‚àÖ` y por qu√© `P(Œ©)=1`.

#### 3) Relevancia
- En ML casi todo termina siendo ‚Äúprobabilidad‚Äù o ‚Äúlog-probabilidad‚Äù (p√©rdidas como NLL).

#### 4) Mapa conceptual m√≠nimo
- **Espacio muestral (`Œ©`)** ‚Üí posibles resultados.
- **Evento (`A`)** ‚äÜ `Œ©` ‚Üí subconjunto de resultados.
- **Probabilidad** ‚Üí n√∫mero en [0,1] que cuantifica qu√© tan ‚Äúfrecuente‚Äù es el evento.

#### 5) Definiciones esenciales
- `Œ©`: conjunto de resultados posibles.
- `A`: evento.
- `P(A)`: probabilidad del evento.

#### 6) Explicaci√≥n did√°ctica
- Regla de sanidad: si te da `P(A)>1` o negativa, tu modelado est√° mal.

#### 7) Ejemplo modelado
- Dado un dado justo: `P(A=‚Äúsale par‚Äù) = 3/6 = 0.5`.

#### 8) Pr√°ctica guiada
- Escribe 3 eventos distintos en un dado (por ejemplo `{1}`, `{1,2,3}`, `{2,4,6}`) y calcula `P`.

#### 9) Pr√°ctica independiente
- Baraja est√°ndar: calcula `P(A=‚Äúcarta roja‚Äù)` y `P(B=‚Äúcoraz√≥n‚Äù)`.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© `P(‚àÖ)=0` es consistente con la idea de ‚Äúcasos favorables/casos totales‚Äù?

#### 11) Errores comunes
- Confundir ‚Äúprobabilidad‚Äù con ‚Äúconteo‚Äù sin normalizar por el total.
- Olvidar definir el espacio muestral antes de calcular probabilidades.

#### 12) Retenci√≥n
- (d√≠a 2) define `Œ©`, `A` y escribe las 3 propiedades b√°sicas (rango, `P(Œ©)`, `P(‚àÖ)`).

#### 13) Diferenciaci√≥n
- Avanzado: interpreta probabilidad como frecuencia relativa l√≠mite (intuici√≥n frequentista).

#### 14) Recursos
- StatQuest (intro de probabilidad) / cualquier texto de probabilidad b√°sica.

#### 15) Nota docente
- Exigir siempre: ‚Äú¬øCu√°l es `Œ©`?‚Äù antes de aceptar un `P(A)`.
</details>

#### 1.2 Probabilidad Condicional

```text
P(A|B) = P(A ‚à© B) / P(B)

"Probabilidad de A dado que B ocurri√≥"
```

**Ejemplo en ML:**
- P(spam | contiene "gratis") = ¬øQu√© tan probable es spam si el email dice "gratis"?

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 1.2: Probabilidad Condicional</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Condicionar = restringir el universo a ‚ÄúB ocurri√≥‚Äù
- **ID (opcional):** `M04-T01_2`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** B√°sico‚ÄìIntermedio
- **Dependencias:** 1.1

#### 2) Objetivos
- Interpretar `P(A|B)` en lenguaje natural (‚Äúprobabilidad de A dado B‚Äù).
- Usar `P(A|B)=P(A‚à©B)/P(B)` y reconocer cu√°ndo aplica (si `P(B)>0`).

#### 3) Relevancia
- Clasificaci√≥n probabil√≠stica en ML se formula como `P(clase|datos)`.

#### 4) Mapa conceptual m√≠nimo
- **Intersecci√≥n** `A‚à©B`: ambos ocurren.
- **Condici√≥n** `|B`: nos quedamos solo con los casos donde B ocurre.

#### 5) Definiciones esenciales
- `P(A‚à©B)`: probabilidad conjunta.
- `P(A|B)`: probabilidad condicional.

#### 6) Explicaci√≥n did√°ctica
- Intuici√≥n: al condicionar, el denominador cambia; ya no divides entre ‚Äútodo‚Äù, sino entre ‚Äúlos casos con B‚Äù.

#### 7) Ejemplo modelado
- Si en un dataset el 10% son spam, pero si contiene ‚Äúgratis‚Äù el 80% son spam, entonces `P(spam|gratis)=0.8`.

#### 8) Pr√°ctica guiada
- Construye una tabla 2√ó2 (spam/ham vs contiene gratis/no) y calcula `P(spam|gratis)`.

#### 9) Pr√°ctica independiente
- Da un ejemplo donde `P(A|B) > P(A)` y explica por qu√© no es contradictorio.

#### 10) Autoevaluaci√≥n
- ¬øQu√© ocurre si `P(B)=0`? ¬øPor qu√© la definici√≥n falla?

#### 11) Errores comunes
- Confundir `P(A|B)` con `P(B|A)`.
- Olvidar que `P(A‚à©B)` no es `P(A)P(B)` a menos que haya independencia.

#### 12) Retenci√≥n
- (d√≠a 2) escribe la f√≥rmula de `P(A|B)` y un ejemplo en una frase.

#### 13) Diferenciaci√≥n
- Avanzado: conecta con ‚Äúactualizaci√≥n de creencias‚Äù (preview a Bayes).

#### 14) Recursos
- Secci√≥n de probabilidad condicional en cualquier material de probabilidad.

#### 15) Nota docente
- Pedir al alumno que primero responda verbalmente (‚Äú¬øqu√© significa dado B?‚Äù) antes de calcular.
</details>

#### 1.3 Independencia

```text
A y B son independientes si:
P(A ‚à© B) = P(A) ¬∑ P(B)

Equivalente a:
P(A|B) = P(A)
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 1.3: Independencia</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Independencia: ‚Äúsaber B no cambia A‚Äù
- **ID (opcional):** `M04-T01_3`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 1.1, 1.2

#### 2) Objetivos
- Reconocer equivalencias: `P(A‚à©B)=P(A)P(B)` y `P(A|B)=P(A)`.
- Evaluar con ejemplos si una suposici√≥n de independencia es razonable.

#### 3) Relevancia
- Naive Bayes se sostiene sobre una suposici√≥n fuerte de independencia condicional.

#### 4) Mapa conceptual m√≠nimo
- **Dependencia**: informaci√≥n sobre B cambia tu probabilidad de A.
- **Independencia**: no cambia.

#### 5) Definiciones esenciales
- A y B independientes si `P(A|B)=P(A)` (cuando `P(B)>0`).

#### 6) Explicaci√≥n did√°ctica
- La independencia casi nunca es exacta en datos reales; se usa como aproximaci√≥n √∫til.

#### 7) Ejemplo modelado
- En una moneda justa: eventos ‚Äúsale cara‚Äù y ‚Äúsale cruz‚Äù en el mismo tiro no aplican (mutuamente excluyentes), ojo: no es independencia.

#### 8) Pr√°ctica guiada
- Da un ejemplo de eventos independientes (dos tiros de moneda) y uno claramente dependiente.

#### 9) Pr√°ctica independiente
- Explica por qu√© ‚Äúmutuamente excluyente‚Äù no implica ‚Äúindependiente‚Äù.

#### 10) Autoevaluaci√≥n
- ¬øQu√© valor deber√≠a tener `P(A‚à©B)` si A y B son independientes?

#### 11) Errores comunes
- Confundir independencia con exclusi√≥n mutua.
- Asumir independencia sin justificar (y luego sorprenderse por resultados malos en Naive Bayes).

#### 12) Retenci√≥n
- (d√≠a 2) memoriza una equivalencia: `P(A‚à©B)=P(A)P(B)`.

#### 13) Diferenciaci√≥n
- Avanzado: independencia condicional `P(A,B|C)=P(A|C)P(B|C)` (preview a Naive Bayes).

#### 14) Recursos
- Lecturas de independencia y diagramas de Venn.

#### 15) Nota docente
- Pedir al alumno que traduzca a lenguaje natural: ‚Äúsaber B no me da info sobre A‚Äù.
</details>

---

### D√≠a 3-4: Teorema de Bayes (Cr√≠tico para ML)

#### 2.1 La F√≥rmula

```text
            P(B|A) ¬∑ P(A)
P(A|B) = ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
               P(B)

Donde:
- P(A|B) = Posterior (lo que queremos calcular)
- P(B|A) = Likelihood (verosimilitud)
- P(A)   = Prior (conocimiento previo)
- P(B)   = Evidence (normalizador)
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 2.1: Teorema de Bayes (la f√≥rmula)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Bayes = reordenar condicionales (posterior = likelihood¬∑prior / evidence)
- **ID (opcional):** `M04-T02_1`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 1.2 (condicional), 1.3 (independencia como contraste)

#### 2) Objetivos
- Identificar los 4 t√©rminos: posterior, likelihood, prior, evidence.
- Aplicar Bayes en un ejemplo tipo clasificaci√≥n y explicar qu√© significa cada t√©rmino.

#### 3) Relevancia
- Mucho ML supervisado puede verse como inferencia: estimar `P(clase|datos)`.

#### 4) Mapa conceptual m√≠nimo
- **Prior**: lo que cre√≠as antes.
- **Likelihood**: qu√© tan compatibles son los datos con la clase.
- **Posterior**: lo que crees despu√©s de ver datos.
- **Evidence**: normalizador para que sume 1.

#### 5) Definiciones esenciales
- `P(A|B) = P(B|A)P(A) / P(B)`.

#### 6) Explicaci√≥n did√°ctica
- Para comparar clases, muchas veces basta el numerador `P(datos|clase)P(clase)` (posterior sin normalizar).

#### 7) Ejemplo modelado
- Spam: `P(spam|palabras) ‚àù P(palabras|spam)¬∑P(spam)`.

#### 8) Pr√°ctica guiada
- Define un prior `P(spam)` y dos likelihoods y calcula qu√© clase gana (sin normalizar).

#### 9) Pr√°ctica independiente
- Crea un ejemplo con una enfermedad rara: prior peque√±o, likelihood grande; discute el resultado.

#### 10) Autoevaluaci√≥n
- ¬øQu√© rol cumple `P(B)`? ¬øPor qu√© no depende de A?

#### 11) Errores comunes
- Confundir posterior con likelihood.
- Mezclar `P(A|B)` con `P(B|A)`.

#### 12) Retenci√≥n
- (d√≠a 2) escribe de memoria: posterior = likelihood √ó prior / evidence.

#### 13) Diferenciaci√≥n
- Avanzado: conecta con Naive Bayes (producto de likelihoods por feature en log).

#### 14) Recursos
- 3Blue1Brown Bayes (visual), StatQuest Bayes (intuici√≥n).

#### 15) Nota docente
- Pedir ‚Äútraducci√≥n verbal‚Äù de cada t√©rmino antes de hacer n√∫meros.
</details>

#### 2.2 Interpretaci√≥n para ML

```text
              P(datos|clase) ¬∑ P(clase)
P(clase|datos) = ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                      P(datos)

Ejemplo: Clasificaci√≥n de spam
- P(spam|palabras) = P(palabras|spam) ¬∑ P(spam) / P(palabras)
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 2.2: Interpretaci√≥n de Bayes para ML</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Bayes como clasificador: comparar posteriors (a veces sin normalizar)
- **ID (opcional):** `M04-T02_2`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 2.1, 1.2

#### 2) Objetivos
- Reescribir un problema de clasificaci√≥n como `argmax_c P(c|x)`.
- Explicar por qu√© `P(x)` puede omitirse al comparar clases (misma evidencia).

#### 3) Relevancia
- Este marco conecta directamente con Logistic Regression/Softmax: ‚Äúsalidas como probabilidades‚Äù.

#### 4) Mapa conceptual m√≠nimo
- **Modelo generativo (tipo Bayes/Naive Bayes):** modela `P(x|c)` y `P(c)`.
- **Inferencia:** obtiene `P(c|x)`.

#### 5) Definiciones esenciales
- **Posterior sin normalizar:** `score(c) = P(x|c)¬∑P(c)`.
- **Decisi√≥n MAP:** elegir la clase con mayor posterior.

#### 6) Explicaci√≥n did√°ctica
- Si solo quieres la clase, no necesitas `P(x)`; si quieres probabilidades calibradas, s√≠.

#### 7) Ejemplo modelado
- Spam vs ham: compara `P(palabras|spam)P(spam)` contra `P(palabras|ham)P(ham)`.

#### 8) Pr√°ctica guiada
- Usa dos priors distintos (spam raro vs frecuente) y observa c√≥mo cambia la decisi√≥n.

#### 9) Pr√°ctica independiente
- Explica un caso donde el likelihood gana pero el prior lo revierte (o viceversa).

#### 10) Autoevaluaci√≥n
- ¬øCu√°ndo te importa `P(x)`? (pista: cuando quieres una probabilidad real, no solo ranking)

#### 11) Errores comunes
- Confundir ‚Äúlikelihood‚Äù con ‚Äúposterior‚Äù.
- Creer que omitir `P(x)` es ‚Äúincorrecto‚Äù en clasificaci√≥n (no lo es para argmax).

#### 12) Retenci√≥n
- (d√≠a 2) memoriza: `P(c|x) ‚àù P(x|c)P(c)`.

#### 13) Diferenciaci√≥n
- Avanzado: en vez de multiplicar, usa logs: `log P(x|c) + log P(c)`.

#### 14) Recursos
- StatQuest: Bayes classifier / Naive Bayes.

#### 15) Nota docente
- Pedir al alumno que se√±ale qu√© t√©rmino es ‚Äúmodelo‚Äù (`P(x|c)`) y cu√°l es ‚Äúcreencia previa‚Äù (`P(c)`).
</details>

#### 2.3 Implementaci√≥n en Python

```python
import numpy as np  # Importa NumPy para arrays y operaciones num√©ricas en el demo

def bayes_classifier(x: np.ndarray,  # features del email (placeholder en este ejemplo)
                     likelihood_spam: float,  # P(x|spam): verosimilitud de observar x si es spam
                     likelihood_ham: float,  # P(x|ham): verosimilitud de observar x si es ham
                     prior_spam: float = 0.3) -> str:  # P(spam): prior (creencia previa) de clase spam
    """
    Clasificador Bayesiano simple.

    Args:
        x: Caracter√≠sticas del email (simplificado)
        likelihood_spam: P(x|spam)
        likelihood_ham: P(x|ham)
        prior_spam: P(spam) - conocimiento previo

    Returns:
        'spam' o 'ham'
    """
    prior_ham = 1 - prior_spam  # prior complementario: P(ham)=1-P(spam)

    # Posterior (sin normalizar, solo comparamos)
    posterior_spam = likelihood_spam * prior_spam  # score proporcional a P(x|spam)P(spam)
    posterior_ham = likelihood_ham * prior_ham  # score proporcional a P(x|ham)P(ham)

    return 'spam' if posterior_spam > posterior_ham else 'ham'  # decide por argmax (sin calcular P(x))


# Ejemplo: Email con palabra "gratis"
# P("gratis"|spam) = 0.8, P("gratis"|ham) = 0.1
result = bayes_classifier(  # ejecuta la regla Bayesiana con priors y likelihoods de ejemplo
    x=None,  # simplificado
    likelihood_spam=0.8,  # probabilidad de observar la se√±al x si es spam
    likelihood_ham=0.1,  # probabilidad de observar la se√±al x si es ham
    prior_spam=0.3  # prior: probabilidad a priori de spam
)  # cierra llamada al clasificador
print(f"Clasificaci√≥n: {result}")  # spam
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 2.3: Implementaci√≥n de Bayes en Python</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** De la f√≥rmula a c√≥digo: calcular scores y decidir
- **ID (opcional):** `M04-T02_3`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 2.1, 2.2

#### 2) Objetivos
- Implementar un clasificador Bayesiano m√≠nimo y explicar cada variable.
- Separar ‚Äúc√°lculo de score‚Äù de ‚Äúdecisi√≥n final‚Äù (`argmax`).

#### 3) Relevancia
- Te entrena a convertir f√≥rmulas en implementaciones legibles (habilidad clave para ML desde cero).

#### 4) Mapa conceptual m√≠nimo
- **Inputs:** likelihoods + priors.
- **Procesamiento:** score por clase.
- **Output:** clase ganadora.

#### 5) Definiciones esenciales
- `posterior_spam ‚àù likelihood_spam * prior_spam`.

#### 6) Explicaci√≥n did√°ctica
- En problemas reales, multiplicar muchas probabilidades causa underflow ‚Üí usar log-sum (preview).

#### 7) Ejemplo modelado
- El ejemplo usa ‚Äúposterior sin normalizar‚Äù para comparar clases.

#### 8) Pr√°ctica guiada
- Extiende el c√≥digo para que devuelva tambi√©n el score de ambas clases.

#### 9) Pr√°ctica independiente
- Cambia priors y likelihoods y escribe 3 casos donde el resultado cambie.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© no aparece `P(datos)` en el c√≥digo?

#### 11) Errores comunes
- Tratar `x` como si se usara cuando el ejemplo lo deja simplificado.
- Mezclar probabilidades con porcentajes (0.8 vs 80).

#### 12) Retenci√≥n
- (d√≠a 2) escribe una funci√≥n que compare 2 clases usando `score = likelihood*prior`.

#### 13) Diferenciaci√≥n
- Avanzado: reescribe el clasificador en log-espacio: `log_score = log_likelihood + log_prior`.

#### 14) Recursos
- Numpy docs: `np.log`, manejo de underflow/overflow.

#### 15) Nota docente
- Pedir que el alumno comente (en voz) qu√© representa cada par√°metro: prior vs likelihood.
</details>

#### 2.4 Naive Bayes (Conexi√≥n con Supervised Learning)

```python
def naive_bayes_predict(X: np.ndarray,  # matriz de features discretas (por muestra)
                        class_priors: np.ndarray,  # priors por clase P(c)
                        feature_probs: dict) -> np.ndarray:  # probabilidades por feature P(x_i|c)
    """
    Naive Bayes asume independencia entre features:
    P(x1, x2, ..., xn | clase) = P(x1|clase) ¬∑ P(x2|clase) ¬∑ ... ¬∑ P(xn|clase)

    Esta "ingenuidad" simplifica mucho el c√°lculo.
    """
    n_samples = X.shape[0]  # n√∫mero de muestras a clasificar
    n_classes = len(class_priors)  # n√∫mero de clases posibles

    log_posteriors = np.zeros((n_samples, n_classes))  # matriz para acumular log-scores por clase

    for c in range(n_classes):  # recorre cada clase y computa su score logar√≠tmico
        # Log para evitar underflow con muchas features
        log_prior = np.log(class_priors[c])  # log P(c): prior en espacio log
        log_likelihood = np.sum(np.log(feature_probs[c][X]), axis=1)  # suma de log P(x_i|c) por muestra
        log_posteriors[:, c] = log_prior + log_likelihood  # log posterior no normalizado por muestra

    return np.argmax(log_posteriors, axis=1)  # predice la clase con score m√°ximo por muestra
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 2.4: Naive Bayes</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Naive Bayes: independencia condicional para escalar a muchas features
- **ID (opcional):** `M04-T02_4`
- **Duraci√≥n estimada:** 60‚Äì150 min
- **Nivel:** Intermedio
- **Dependencias:** 1.3 (independencia), 2.1 (Bayes)

#### 2) Objetivos
- Explicar la suposici√≥n: `P(x1,‚Ä¶,xn|c) = Œ†_i P(xi|c)`.
- Entender por qu√© se usa log: `log Œ† = Œ£ log` (evitar underflow).

#### 3) Relevancia
- Es un baseline fuerte en texto y problemas discretos; ense√±a buenas pr√°cticas num√©ricas.

#### 4) Mapa conceptual m√≠nimo
- **Modelo:** aprende `P(xi|c)` por feature y `P(c)`.
- **Predicci√≥n:** suma log-likelihoods + log-prior.

#### 5) Definiciones esenciales
- `log_posterior(c|x) = log P(c) + Œ£_i log P(x_i|c)`.

#### 6) Explicaci√≥n did√°ctica
- ‚ÄúNaive‚Äù no significa in√∫til: significa *suposici√≥n simplificadora* para poder multiplicar muchos t√©rminos.

#### 7) Ejemplo modelado
- En texto (bag-of-words): cada palabra aporta un t√©rmino de log-likelihood.

#### 8) Pr√°ctica guiada
- Implementa una versi√≥n binaria con 2 clases y 3 features discretas y verifica con un mini dataset.

#### 9) Pr√°ctica independiente
- Discute un caso donde la independencia condicional es claramente falsa (features redundantes) y qu√© esperas que pase.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© `np.log` transforma multiplicaciones en sumas y por qu√© eso ayuda en c√≥mputo?

#### 11) Errores comunes
- No suavizar probabilidades ‚Üí `log(0)`.
- Confundir `P(x|c)` con `P(c|x)`.

#### 12) Retenci√≥n
- (d√≠a 2) memoriza el score: `log_prior + sum(log_likelihoods)`.

#### 13) Diferenciaci√≥n
- Avanzado: introduce Laplace smoothing (Œ±) para evitar ceros.

#### 14) Recursos
- StatQuest Naive Bayes; notas de smoothing.

#### 15) Nota docente
- Pedir una demostraci√≥n de underflow: multiplicar 100 probabilidades ~0.01 y ver que colapsa sin log.
</details>

---

## üß© Micro-Cap√≠tulo Maestro: Maximum Likelihood Estimation (MLE) ‚Äî Nivel: Avanzado

### 1) Intuici√≥n (la met√°fora del detective)

Imagina que eres un detective que llega a una escena del crimen (tus **datos** `X`).

- Tienes una lista de sospechosos (tus **modelos**).
- Cada sospechoso tiene un comportamiento ajustable por perillas (tus **par√°metros** `Œ∏`).

MLE pregunta:

> **¬øQu√© valores de `Œ∏` hacen M√ÅS PROBABLE que estos datos espec√≠ficos hayan ocurrido?**

Importante:

- No estamos diciendo ‚Äúqu√© par√°metro es m√°s probable‚Äù (eso ser√≠a un enfoque Bayesiano).
- Estamos diciendo ‚Äúqu√© par√°metro le da la mayor probabilidad a los datos que YA vimos‚Äù.

### 2) Formalizaci√≥n (likelihood y log-likelihood)

Sea `X = {x1, x2, ..., xn}` un conjunto de datos i.i.d.

La **likelihood** es:

`L(Œ∏ | X) = P(X | Œ∏) = Œ†_{i=1}^{n} P(x_i | Œ∏)`

Como multiplicar muchos n√∫meros peque√±os causa underflow, usamos log:

`‚Ñì(Œ∏) = log L(Œ∏|X) = Œ£_{i=1}^{n} log P(x_i | Œ∏)`

Como `log` es mon√≥tona creciente, maximizar `L` y maximizar `‚Ñì` es equivalente:

`Œ∏_MLE = argmax_Œ∏ ‚Ñì(Œ∏)`

### 3) Derivaci√≥n clave: de MLE a MSE (Regresi√≥n Lineal)

La idea conceptual: cuando usas **MSE**, est√°s asumiendo impl√≠citamente un modelo de ruido.

Sup√≥n que tu regresi√≥n lineal es:

`y = XŒ≤ + Œµ` con `Œµ ~ N(0, œÉ¬≤ I)`

Entonces la probabilidad de observar `y` dado `Œ≤` es Gaussiana:

`P(y | X, Œ≤) ‚àù exp( - (1/(2œÉ¬≤)) ||y - XŒ≤||¬≤ )`

Tomando log-likelihood y tirando constantes que no dependen de `Œ≤`:

`‚Ñì(Œ≤) = const - (1/(2œÉ¬≤)) ||y - XŒ≤||¬≤`

Maximizar `‚Ñì(Œ≤)` equivale a minimizar `||y - XŒ≤||¬≤`.

Conclusi√≥n:

- Minimizar **SSE/MSE** es exactamente hacer **MLE** bajo ruido Gaussiano.
- Esta conexi√≥n es el puente directo hacia **Statistical Estimation** (L√≠nea 2).

### 4) Conexi√≥n L√≠nea 2: estimadores, sesgo y varianza (intuici√≥n)

En L√≠nea 2, la palabra clave es **estimador**: una regla que convierte datos en un par√°metro.

- Un **estimador** es una funci√≥n: `\hat{Œ∏} = g(X)`.
- **Sesgo (bias):** si `E[\hat{Œ∏}]` no coincide con el valor real `Œ∏`.
- **Varianza:** cu√°nto cambia `\hat{Œ∏}` si repites el muestreo.

Regla mental:

- **M√°s bias** suele dar **menos varianza**.
- **Menos bias** suele dar **m√°s varianza**.

Esto reaparece en ML como *bias-variance tradeoff*.

### 5) Teor√≠a de Estimadores (lo que te eval√∫an en proyectos/examen)

Aqu√≠ pasamos de la intuici√≥n a una formalizaci√≥n que aparece mucho en evaluaci√≥n.

#### 5.1 Sesgo, varianza y MSE (descomposici√≥n clave)

Si quieres estimar un par√°metro real `Œ∏` con un estimador `\hat{Œ∏}`, el error cuadr√°tico medio es:

`MSE(\hat{Œ∏}) = E[(\hat{Œ∏} - Œ∏)^2]`

La identidad importante es:

`MSE(\hat{Œ∏}) = Var(\hat{Œ∏}) + Bias(\hat{Œ∏})^2`

Donde:

- `Bias(\hat{Œ∏}) = E[\hat{Œ∏}] - Œ∏`
- `Var(\hat{Œ∏}) = E[(\hat{Œ∏} - E[\hat{Œ∏}])^2]`

Lectura mental:

- Puedes reducir MSE bajando varianza, aunque suba un poco el sesgo.
- O puedes ‚Äúperseguir cero sesgo‚Äù y pagar con alta varianza.

Esto es exactamente el *bias-variance trade-off* en ML (por ejemplo, regularizar o simplificar modelos).

#### 5.2 Unbiased vs consistente (2 propiedades distintas)

- **Unbiased (insesgado):** `E[\hat{Œ∏}] = Œ∏`.
- **Consistente:** cuando `n ‚Üí ‚àû`, `\hat{Œ∏} ‚Üí Œ∏` (en un sentido probabil√≠stico).

Un estimador puede ser sesgado y aun as√≠ consistente (y a veces es preferible si reduce varianza para `n` finito).

#### 5.3 Conexi√≥n directa con regularizaci√≥n (puente a ML)

Ejemplo mental:

- **Ridge / L2** introduce sesgo (empuja coeficientes hacia 0).
- A cambio suele reducir varianza (soluci√≥n m√°s estable ante ruido y colinealidad).

En t√©rminos de la descomposici√≥n:

- sube `Bias^2`
- baja `Var`

Si el total baja, mejora el `MSE` esperado fuera de muestra.

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Micro-Cap√≠tulo: Maximum Likelihood Estimation (MLE)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** MLE como filosof√≠a unificadora: de ‚Äúajustar perillas‚Äù a p√©rdidas en ML
- **ID (opcional):** `M04-MICRO-MLE`
- **Duraci√≥n estimada:** 120‚Äì180 min
- **Nivel:** Intermedio‚ÄìAvanzado
- **Dependencias:** 1.1‚Äì2.4 (probabilidad + Bayes), M03 (gradiente/chain rule como preview)

#### 2) Objetivos
- Explicar qu√© maximiza MLE (verosimilitud de datos observados) y por qu√© se usa log-likelihood.
- Conectar MLE con p√©rdidas: MSE ‚Üî Gaussiana, BCE/CCE ‚Üî Bernoulli/Categorical.
- Interpretar sesgo/varianza/MSE como puente a regularizaci√≥n.

#### 3) Relevancia
- Te da el ‚Äúpor qu√©‚Äù de cross-entropy: no es un truco, es NLL.

#### 4) Mapa conceptual m√≠nimo
- **Modelo** `P(D|Œ∏)` ‚Üí define c√≥mo ‚Äúgenera‚Äù datos.
- **Likelihood** `L(Œ∏|D)` ‚Üí probabilidad de D dado Œ∏.
- **Log-likelihood** `‚Ñì(Œ∏)` ‚Üí suma (estable) en vez de producto.
- **Entrenamiento** ‚Üí minimizar `-‚Ñì(Œ∏)`.

#### 5) Definiciones esenciales
- `Œ∏_MLE = argmax_Œ∏ P(D|Œ∏)`.
- `‚Ñì(Œ∏)=Œ£ log P(x_i|Œ∏)`.

#### 6) Explicaci√≥n did√°ctica
- ‚ÄúMLE elige la perilla que hace que tus datos se vean menos sorprendentes bajo el modelo‚Äù.

#### 7) Ejemplo modelado
- Moneda Bernoulli: `p_MLE` = proporci√≥n de caras.

#### 8) Pr√°ctica guiada
- Repite el worked example cambiando la secuencia de datos y verifica que `p_MLE` cambia como frecuencia.

#### 9) Pr√°ctica independiente
- Explica por qu√© maximizar log-likelihood y maximizar likelihood dan el mismo argmax.

#### 10) Autoevaluaci√≥n
- ¬øQu√© diferencia hay entre ‚Äúpar√°metro m√°s probable‚Äù (Bayes) y ‚Äúpar√°metro que hace los datos m√°s probables‚Äù (MLE)?

#### 11) Errores comunes
- Confundir `P(Œ∏|D)` con `P(D|Œ∏)`.
- Olvidar que log convierte producto en suma (y por qu√© ayuda num√©ricamente).

#### 12) Retenci√≥n
- (d√≠a 2) escribe: `Œ∏_MLE = argmax_Œ∏ Œ£ log p(x_i|Œ∏)`.

#### 13) Diferenciaci√≥n
- Avanzado: conectar con MAP (regularizaci√≥n como prior) (preview).

#### 14) Recursos
- StatQuest: Maximum Likelihood.

#### 15) Nota docente
- Pedir al alumno que diga ‚Äúqu√© asume el modelo‚Äù antes de escribir `P(D|Œ∏)`.
</details>

## üß© Micro-Cap√≠tulo Maestro: Introducci√≥n a Markov Chains ‚Äî Nivel: Intermedio

### 1) Concepto

Una cadena de Markov es un sistema que salta entre estados.

Propiedad de Markov (‚Äúfalta de memoria‚Äù):

`P(S_{t+1} | S_t, S_{t-1}, ...) = P(S_{t+1} | S_t)`

### 2) Representaci√≥n matricial (puente con √Ålgebra Lineal)

Si tienes 3 estados (Sol, Nube, Lluvia), defines una matriz de transici√≥n `P` (3√ó3) donde cada fila suma 1.

Si `œÄ_t` es un vector fila (1√ó3) con la distribuci√≥n ‚Äúhoy‚Äù, entonces:

`œÄ_{t+1} = œÄ_t P`

Y en `k` pasos:

`œÄ_{t+k} = œÄ_t P^k`

### 3) Reto mental: estacionariedad = eigenvector

Si repites multiplicaciones, muchas cadenas convergen a una distribuci√≥n estacionaria `œÄ*` tal que:

`œÄ* = œÄ* P`

Eso significa (en la perspectiva correcta) que `œÄ*` es un **eigenvector** asociado al **eigenvalue 1**.

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Micro-Cap√≠tulo: Introducci√≥n a Markov Chains</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Markov Chains como din√°mica lineal sobre distribuciones (œÄ_{t+1}=œÄ_t P)
- **ID (opcional):** `M04-MICRO-MARKOV`
- **Duraci√≥n estimada:** 90‚Äì150 min
- **Nivel:** Intermedio
- **Dependencias:** M02 (multiplicaci√≥n de matrices, eigenvectors), probabilidad b√°sica (distribuciones)

#### 2) Objetivos
- Interpretar `P(S_{t+1}|S_t)` como ‚Äúmemoria de 1 paso‚Äù.
- Usar `œÄ_{t+1}=œÄ_t P` y verificar que `œÄ_t` sigue sumando 1.
- Explicar la condici√≥n de estacionariedad `œÄ*=œÄ*P`.

#### 3) Relevancia
- Conecta probabilidad con √°lgebra lineal; reaparece en modelos secuenciales y Monte Carlo (L√≠nea 2).

#### 4) Mapa conceptual m√≠nimo
- **Estados** ‚Üí categor√≠as discretas.
- **Matriz P** ‚Üí transiciones (filas suman 1).
- **Distribuci√≥n œÄ** ‚Üí vector de probabilidades.
- **Evoluci√≥n temporal** ‚Üí multiplicaciones repetidas.

#### 5) Definiciones esenciales
- Matriz estoc√°stica por filas: cada fila suma 1.
- Distribuci√≥n estacionaria: `œÄ* = œÄ*P`.

#### 6) Explicaci√≥n did√°ctica
- Piensa en `œÄ` como ‚Äúmezcla‚Äù de estados; multiplicar por P redistribuye masa.

#### 7) Ejemplo modelado
- 2 estados con `P=[[0.9,0.1],[0.2,0.8]]`: interpreta cada fila como ‚Äúdesde d√≥nde vienes‚Äù.

#### 8) Pr√°ctica guiada
- Elige un `œÄ_0` y calcula `œÄ_1`, `œÄ_2` a mano.

#### 9) Pr√°ctica independiente
- Encuentra (conceptualmente) `œÄ*` resolviendo `œÄ*=œÄ*P` + suma=1.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© el eigenvalue asociado a `œÄ*` es 1?

#### 11) Errores comunes
- Confundir si `œÄ` es vector fila o columna (y d√≥nde multiplicar P).
- Usar una P donde filas no suman 1.

#### 12) Retenci√≥n
- (d√≠a 7) escribe `œÄ_{t+1}=œÄ_tP` y explica en una frase qu√© hace.

#### 13) Diferenciaci√≥n
- Avanzado: discutir condiciones de convergencia (ergodicidad) (solo conceptual).

#### 14) Recursos
- Material introductorio de Markov Chains + conexi√≥n con eigenvectors.

#### 15) Nota docente
- Obligar ‚Äúsanity check‚Äù: despu√©s de multiplicar, verificar suma=1.
</details>

---

### D√≠a 5: Distribuci√≥n Gaussiana (Normal)

#### 3.1 La Distribuci√≥n M√°s Importante en ML

```text
                    1              (x - Œº)¬≤
f(x) = ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ¬∑ exp(- ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ)
       œÉ ¬∑ ‚àö(2œÄ)                   2œÉ¬≤

Par√°metros:
- Œº (mu): Media (centro de la campana)
- œÉ (sigma): Desviaci√≥n est√°ndar (ancho)
- œÉ¬≤ (sigma¬≤): Varianza
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 3.1: Distribuci√≥n Gaussiana (definici√≥n)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** PDF Gaussiana: forma, par√°metros y lectura correcta
- **ID (opcional):** `M04-T03_1`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 1.1 (probabilidad), noci√≥n de funci√≥n exponencial/log

#### 2) Objetivos
- Identificar qu√© controla `Œº` (desplazamiento) y `œÉ`/`œÉ¬≤` (dispersi√≥n).
- Distinguir ‚Äúdensidad‚Äù `f(x)` de ‚Äúprobabilidad‚Äù (√°rea bajo la curva).

#### 3) Relevancia
- La Gaussiana es el √°tomo de modelos generativos (GMM) y del supuesto de ruido que conecta con MSE.

#### 4) Mapa conceptual m√≠nimo
- **PDF** `f(x)` describe densidad.
- **Par√°metros**: `Œº` centra, `œÉ` escala.
- **Probabilidad**: integral de `f(x)` sobre un intervalo.

#### 5) Definiciones esenciales
- `X ~ N(Œº, œÉ¬≤)`.
- `f(x)` es densidad (puede ser >1), pero el √°rea total integra a 1.

#### 6) Explicaci√≥n did√°ctica
- Error cl√°sico: interpretar `f(0.5)=0.3` como ‚Äú30% de probabilidad en x=0.5‚Äù (en continuas eso es falso).

#### 7) Ejemplo modelado
- ‚ÄúCampana‚Äù est√°ndar: `N(0,1)`.

#### 8) Pr√°ctica guiada
- Describe qu√© pasa si duplicas `œÉ`: el pico baja y la curva se ensancha.

#### 9) Pr√°ctica independiente
- Explica qu√© significa ‚Äú2 desviaciones est√°ndar‚Äù alrededor de la media en t√©rminos cualitativos.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© `P(X = x) = 0` en una variable continua aunque `f(x)` sea positiva?

#### 11) Errores comunes
- Confundir `œÉ` con `œÉ¬≤`.
- Confundir densidad con probabilidad.

#### 12) Retenci√≥n
- (d√≠a 2) escribe la forma general de la PDF y nombra sus par√°metros.

#### 13) Diferenciaci√≥n
- Avanzado: conecta con log-likelihood de una Gaussiana (preview a MLE).

#### 14) Recursos
- Secci√≥n ‚ÄúNormal distribution‚Äù (cualquier referencia de probabilidad).

#### 15) Nota docente
- Exigir que el alumno diga: ‚Äúdensidad ‚â† probabilidad; probabilidad = √°rea‚Äù.
</details>

#### 3.2 Por Qu√© es Importante

1. **Muchos fen√≥menos naturales** siguen esta distribuci√≥n
2. **Teorema del L√≠mite Central:** promedios de cualquier distribuci√≥n ‚Üí Normal
3. **GMM usa Gaussianas** para modelar clusters
4. **Inicializaci√≥n de pesos** en redes neuronales

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 3.2: Por qu√© la Gaussiana importa en ML</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Normal como ‚Äúdefault‚Äù estad√≠stico: TLC, ruido y modelos
- **ID (opcional):** `M04-T03_2`
- **Duraci√≥n estimada:** 45‚Äì90 min
- **Nivel:** Intermedio
- **Dependencias:** 3.1

#### 2) Objetivos
- Explicar 3 usos t√≠picos: ruido Gaussiano ‚Üî MSE, GMM, inicializaci√≥n.
- Conectar el TLC con ‚Äúpromedios tienden a normal‚Äù.

#### 3) Relevancia
- Entender esto evita que la Normal se sienta como ‚Äúf√≥rmula que memorizas‚Äù sin uso.

#### 4) Mapa conceptual m√≠nimo
- **TLC** ‚Üí por qu√© aparece en promedios.
- **Ruido** `Œµ~N(0,œÉ¬≤)` ‚Üí por qu√© MSE es natural.
- **GMM** ‚Üí mezcla de gaussianas para clustering.

#### 5) Definiciones esenciales
- TLC (enunciado informal): suma/promedio de muchas variables ‚Üí aproximadamente normal.

#### 6) Explicaci√≥n did√°ctica
- Muchos modelos lineales asumen ruido Gaussiano: no porque sea ‚Äúverdad absoluta‚Äù, sino porque da un modelo tractable.

#### 7) Ejemplo modelado
- Regresi√≥n lineal con ruido: minimizas SSE/MSE como MLE Gaussiano (puente a D√≠a 6).

#### 8) Pr√°ctica guiada
- Da un ejemplo cotidiano donde ‚Äúmuchas fuentes peque√±as de variaci√≥n‚Äù sugiere normalidad.

#### 9) Pr√°ctica independiente
- Explica por qu√© en pesos de NN se usan gaussianas peque√±as (inicializaci√≥n) y qu√© pasa si son muy grandes.

#### 10) Autoevaluaci√≥n
- ¬øQu√© aspecto de la normal explica que valores extremos sean raros (colas)?

#### 11) Errores comunes
- Creer que ‚Äútodo es normal‚Äù sin validar.
- Confundir ‚Äúdistribuci√≥n de datos‚Äù con ‚Äúdistribuci√≥n de ruido‚Äù.

#### 12) Retenci√≥n
- (d√≠a 2) enumera 3 conexiones: MSE, GMM, inicializaci√≥n.

#### 13) Diferenciaci√≥n
- Avanzado: discusi√≥n de heavy tails y por qu√© a veces Laplace/Student-t es mejor.

#### 14) Recursos
- StatQuest: Normal distribution / Central Limit Theorem.

#### 15) Nota docente
- Pedir una justificaci√≥n: ‚Äú¬øqu√© hip√≥tesis hace que MSE tenga sentido?‚Äù.
</details>

#### 3.3 Implementaci√≥n

```python
import numpy as np  # NumPy: arrays, operaciones vectorizadas y funciones matem√°ticas (exp, sqrt)

def gaussian_pdf(x: np.ndarray, mu: float, sigma: float) -> np.ndarray:  # PDF univariada: f(x) de N(Œº, œÉ¬≤)
    """
    Probability Density Function de la Gaussiana.

    Args:
        x: Puntos donde evaluar
        mu: Media
        sigma: Desviaci√≥n est√°ndar

    Returns:
        Densidad de probabilidad en cada punto
    """
    coefficient = 1 / (sigma * np.sqrt(2 * np.pi))  # Coeficiente de normalizaci√≥n: 1/(œÉ‚àö(2œÄ))
    exponent = -((x - mu) ** 2) / (2 * sigma ** 2)  # Exponente: - (x-Œº)¬≤ / (2œÉ¬≤) (forma est√°ndar)
    return coefficient * np.exp(exponent)  # Evaluaci√≥n final: coef * exp(exponente) (vectorizado)


# Visualizaci√≥n
import matplotlib.pyplot as plt  # Matplotlib: gr√°ficos para construir intuici√≥n visual

x = np.linspace(-5, 5, 1000)  # Eje 1D de evaluaci√≥n (1000 puntos para curva suave)

# Diferentes Gaussianas
plt.figure(figsize=(10, 6))  # Crea un lienzo con tama√±o controlado
plt.plot(x, gaussian_pdf(x, mu=0, sigma=1), label='Œº=0, œÉ=1 (est√°ndar)')  # Curva ‚Äúcampana‚Äù est√°ndar
plt.plot(x, gaussian_pdf(x, mu=0, sigma=2), label='Œº=0, œÉ=2 (m√°s ancha)')  # Aumentar œÉ ensancha y baja el pico
plt.plot(x, gaussian_pdf(x, mu=2, sigma=1), label='Œº=2, œÉ=1 (desplazada)')  # Cambiar Œº desplaza la curva
plt.legend()  # Muestra leyenda con labels
plt.title('Distribuciones Gaussianas')  # T√≠tulo descriptivo
plt.xlabel('x')  # Etiqueta del eje x
plt.ylabel('f(x)')  # Etiqueta del eje y (densidad)
plt.grid(True)  # Rejilla para lectura m√°s f√°cil
plt.savefig('gaussian_distributions.png')  # Guarda imagen (√∫til para reportes)
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 3.3: Implementaci√≥n de la PDF Gaussiana (univariada)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Implementar PDF: normalizaci√≥n, vectorizaci√≥n y sanity checks
- **ID (opcional):** `M04-T03_3`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 3.1

#### 2) Objetivos
- Implementar `gaussian_pdf` sin errores de forma y con vectorizaci√≥n.
- Identificar el rol del coeficiente y del exponente.

#### 3) Relevancia
- Te entrena para implementar funciones de densidad y luego reutilizarlas en log-likelihood/EM.

#### 4) Mapa conceptual m√≠nimo
- **Coeficiente** `1/(œÉ‚àö(2œÄ))` normaliza.
- **Exponente** penaliza distancia al centro.
- **Vectorizaci√≥n**: evaluar muchos x de una vez.

#### 5) Definiciones esenciales
- `œÉ>0` (si `œÉ<=0` el modelo no tiene sentido).

#### 6) Explicaci√≥n did√°ctica
- Sanity check num√©rico: la curva debe ser no negativa y ‚Äúparecer campana‚Äù.

#### 7) Ejemplo modelado
- Comparaci√≥n de distintas `Œº` y `œÉ` para construir intuici√≥n visual.

#### 8) Pr√°ctica guiada
- A√±ade una verificaci√≥n: `assert np.all(gaussian_pdf(x,mu,sigma) >= 0)`.

#### 9) Pr√°ctica independiente
- (conceptual) ¬øQu√© deber√≠a pasar con el pico cuando `œÉ` se hace muy peque√±o?

#### 10) Autoevaluaci√≥n
- ¬øQu√© parte del c√≥digo cambia si reemplazas `œÉ` por `œÉ¬≤` como par√°metro?

#### 11) Errores comunes
- Overflow/underflow en `exp` cuando `œÉ` es muy peque√±o o `|x-Œº|` grande.
- Olvidar que `sigma` es desviaci√≥n est√°ndar (no varianza).

#### 12) Retenci√≥n
- (d√≠a 2) escribe la funci√≥n en pseudo-c√≥digo: coef √ó exp(exponente).

#### 13) Diferenciaci√≥n
- Avanzado: implementar `log_gaussian_pdf` estable y comparar.

#### 14) Recursos
- Numpy `np.exp`, estabilidad num√©rica.

#### 15) Nota docente
- Pedir al alumno que explique qu√© controla `Œº` y qu√© controla `œÉ` viendo los plots.
</details>

#### 3.4 Gaussiana Multivariada (Para GMM)

```python
def multivariate_gaussian_pdf(x: np.ndarray,  # x:(d,) vector de caracter√≠sticas (una muestra)
                               mu: np.ndarray,  # mu:(d,) vector de medias
                               cov: np.ndarray) -> float:  # cov:(d,d) matriz de covarianza
    """
    Gaussiana multivariada para vectores.

    Args:
        x: Vector de caracter√≠sticas (d,)
        mu: Vector de medias (d,)
        cov: Matriz de covarianza (d, d)

    Returns:
        Densidad de probabilidad
    """
    d = len(mu)  # d: dimensi√≥n del espacio (n√∫mero de features)
    diff = x - mu  # diff:(d,) centra el punto restando la media

    # Determinante e inversa de la covarianza
    det_cov = np.linalg.det(cov)  # |Œ£|: controla el ‚Äúvolumen‚Äù de la elipse gaussiana
    inv_cov = np.linalg.inv(cov)  # Œ£^{-1}: aparece en la forma cuadr√°tica (Mahalanobis)

    # Coeficiente de normalizaci√≥n
    coefficient = 1 / (np.sqrt((2 * np.pi) ** d * det_cov))  # 1 / sqrt((2œÄ)^d |Œ£|)

    # Exponente (forma cuadr√°tica)
    exponent = -0.5 * diff.T @ inv_cov @ diff  # -(1/2)(x-Œº)^T Œ£^{-1} (x-Œº)

    return coefficient * np.exp(exponent)  # Devuelve densidad (escala) * exp(exponente)


# Ejemplo 2D
mu = np.array([0, 0])  # Œº:(2,) media en 2D
cov = np.array([[1, 0.5],  # Œ£[0,0]=var(x1), Œ£[0,1]=cov(x1,x2)
                [0.5, 1]])  # Correlaci√≥n positiva: elipses rotadas respecto a los ejes

x = np.array([0.5, 0.5])  # Punto a evaluar (una muestra)
prob = multivariate_gaussian_pdf(x, mu, cov)  # Escalar: densidad en ese punto
print(f"P(x=[0.5, 0.5]) = {prob:.4f}")  # Imprime densidad (ojo: no es probabilidad discreta)
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 3.4: Gaussiana Multivariada</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Multivariada: covarianza, elipses y Mahalanobis
- **ID (opcional):** `M04-T03_4`
- **Duraci√≥n estimada:** 90‚Äì150 min
- **Nivel:** Intermedio‚ÄìAvanzado
- **Dependencias:** M02 (det/inv, formas cuadr√°ticas), 3.1

#### 2) Objetivos
- Interpretar el rol de `Œ£` (covarianza) como escala + correlaci√≥n.
- Reconocer la forma cuadr√°tica `(x-Œº)^T Œ£^{-1} (x-Œº)` como ‚Äúdistancia el√≠ptica‚Äù.

#### 3) Relevancia
- Es el n√∫cleo matem√°tico de GMM y de muchas t√©cnicas estad√≠sticas.

#### 4) Mapa conceptual m√≠nimo
- `Œº` fija el centro.
- `Œ£` fija la elipse (forma/orientaci√≥n).
- `|Œ£|` controla volumen.

#### 5) Definiciones esenciales
- Covarianza v√°lida: sim√©trica y PSD (idealmente PD para invertir).

#### 6) Explicaci√≥n did√°ctica
- Si `Œ£` tiene covarianzas fuera de la diagonal, la elipse rota.

#### 7) Ejemplo modelado
- Caso 2D con correlaci√≥n positiva (`0.5`) para ver rotaci√≥n.

#### 8) Pr√°ctica guiada
- Cambia `cov` a diagonal y compara con el caso correlacionado.

#### 9) Pr√°ctica independiente
- Explica qu√© pasa si `det_cov` es casi 0 (covarianza casi singular).

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© aparece `Œ£^{-1}` en lugar de `Œ£` en el exponente?

#### 11) Errores comunes
- Invertir `Œ£` singular (num√©ricamente inestable).
- Confundir densidad con probabilidad.

#### 12) Retenci√≥n
- (d√≠a 7) escribe la forma: coeficiente √ó exp(-0.5 * Mahalanobis).

#### 13) Diferenciaci√≥n
- Avanzado: usar Cholesky para estabilidad en lugar de `inv`/`det` directos.

#### 14) Recursos
- Material de GMM / multivariate normal.

#### 15) Nota docente
- Pedir al alumno que dibuje c√≥mo cambia la elipse al variar covarianza.
</details>

#### 3.5 GMM Just-in-Time: Mezcla de 3 gaussianas + contornos (pre√°mbulo a Unsupervised)

**Objetivo:** que la ‚ÄúGaussiana multivariada‚Äù no se quede te√≥rica: vas a **generar datos** de una mezcla de 3 gaussianas y a **visualizar contornos** (componentes y mezcla). Esto es el puente directo a **GMM** (M√≥dulo 06).

- **Ejecutable:**
  - `python3 scripts/gmm_3_gaussians_contours.py`
- **Entregable:**
  - una figura (pantallazo o archivo guardado con `--out`) y una explicaci√≥n breve:
    - **Qu√© representa** el contorno negro (mezcla)
    - **Qu√© representan** los contornos coloreados (componentes)
    - **Qu√© cambia** si modificas una covarianza (rotaci√≥n / elongaci√≥n)

- **Preguntas (nivel maestr√≠a):**
  - **K-Means vs GMM:** ¬øpor qu√© K-Means es *hard assignment* y GMM es *soft assignment*?
  - **Covarianza:** ¬øqu√© hace `Œ£` geom√©tricamente (orientaci√≥n/forma) y por qu√© aparece `Œ£^{-1}` en el exponente?

---

### D√≠a 6: Maximum Likelihood Estimation (MLE)

#### 4.0 MLE ‚Üí Cross-Entropy (la conexi√≥n que te piden en ex√°menes)

**Idea:** si un modelo produce probabilidades `P(y|x, Œ∏)`, entrenar por MLE significa:

- maximizar `Œ†·µ¢ P(y·µ¢|x·µ¢, Œ∏)`

Por estabilidad num√©rica y conveniencia, trabajamos con log:

- maximizar `Œ£·µ¢ log P(y·µ¢|x·µ¢, Œ∏)`

Y como optimizadores minimizan, entrenamos minimizando:

- `-Œ£·µ¢ log P(y·µ¢|x·µ¢, Œ∏)`  (negative log-likelihood)

Ese t√©rmino es exactamente la **cross-entropy** que usas en:

- Logistic Regression (BCE) en `M√≥dulo 05`
- clasificaci√≥n multiclase (CCE) en `M√≥dulo 07`

**Cheat sheet:**

- **MLE:** maximizar likelihood
- **Entrenamiento:** minimizar negative log-likelihood
- **En clasificaci√≥n:** eso se llama cross-entropy

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 4.0: MLE ‚Üí Cross-Entropy (la conexi√≥n que te piden en ex√°menes)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** De maximizar likelihood a minimizar cross-entropy (NLL)
- **ID (opcional):** `M04-T04_0`
- **Duraci√≥n estimada:** 45‚Äì90 min
- **Nivel:** Intermedio
- **Dependencias:** 2.1‚Äì2.3 (probabilidad condicional/Bayes), noci√≥n de logaritmo

#### 2) Objetivos
- Conectar el producto de probabilidades con suma de log-probabilidades.
- Explicar por qu√© optimizamos **NLL** (negative log-likelihood) en vez de maximizar likelihood.
- Reconocer que en clasificaci√≥n la NLL se escribe como **cross-entropy**.

#### 3) Relevancia
- Esta equivalencia es el ‚Äúpuente‚Äù entre probabilidad y entrenamiento: explica por qu√© la loss t√≠pica en clasificaci√≥n es cross-entropy.

#### 4) Mapa conceptual m√≠nimo
- **Likelihood** `P(D|Œ∏)` (producto)
- **Log-likelihood** `log P(D|Œ∏)` (suma)
- **NLL** `-log P(D|Œ∏)` (minimizaci√≥n)
- **Cross-entropy** (forma est√°ndar de la NLL en clasificaci√≥n)

#### 5) Definiciones esenciales
- **Likelihood:** probabilidad de observar los datos si el modelo tuviera par√°metros `Œ∏`.
- **NLL:** `-Œ£ log P(y·µ¢|x·µ¢,Œ∏)`; es una loss no negativa (en promedio) que penaliza probabilidades peque√±as asignadas a la etiqueta correcta.

#### 6) Explicaci√≥n did√°ctica
- El producto `Œ† P(y·µ¢|x·µ¢,Œ∏)` se vuelve num√©ricamente peque√±o; el log lo transforma en suma y evita underflow.
- Cambiar de ‚Äúmaximizar‚Äù a ‚Äúminimizar‚Äù es solo conveniencia (los optimizadores t√≠picos minimizan).

#### 7) Ejemplo modelado
- Si el modelo asigna `P(y=correcto|x)=0.01`, entonces `-log(0.01)` es grande: el entrenamiento ‚Äúsiente‚Äù fuerte ese error.

#### 8) Pr√°ctica guiada
- Reescribe el objetivo para un dataset de 3 muestras y verifica el paso:
  - `max Œ† p·µ¢` ‚Üí `max Œ£ log p·µ¢` ‚Üí `min -Œ£ log p·µ¢`.

#### 9) Pr√°ctica independiente
- Describe qu√© pasa con la NLL si duplicas el dataset (mismas muestras dos veces). ¬øPor qu√© se suele usar promedio `1/m`?

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© `log` convierte productos en sumas y por qu√© eso ayuda a optimizar?

#### 11) Errores comunes
- Confundir **cross-entropy** con accuracy: una es funci√≥n suave optimizable, la otra no.
- Olvidar el signo: minimizar `-log(p)` equivale a maximizar `log(p)`.

#### 12) Retenci√≥n
- Regla mnem√≥nica: **MLE ‚áí max log-likelihood ‚áí min NLL ‚áí cross-entropy (clasificaci√≥n)**.

#### 13) Diferenciaci√≥n
- Avanzado: compara NLL con label smoothing (c√≥mo cambia la penalizaci√≥n cuando `y` no es one-hot perfecto).

#### 14) Recursos
- Funci√≥n `log` y propiedades: `log(ab)=log(a)+log(b)`.

#### 15) Nota docente
- Pedir al alumno que explique ‚Äúpor qu√© el log es un truco num√©rico y algebraico a la vez‚Äù.
</details>

---

### Extensi√≥n Estrat√©gica (L√≠nea 2): Statistical Estimation

#### MLE como filosof√≠a: ‚Äúajustar perillas‚Äù

MLE no es solo una f√≥rmula: es una forma de pensar.

- Tienes un modelo con par√°metros `Œ∏` (las ‚Äúperillas‚Äù).
- Ya viste datos `D`.
- Pregunta: ¬øqu√© valores de `Œ∏` hacen que `D` sea lo m√°s probable posible?

Formalmente:

```text
Œ∏_MLE = argmax_Œ∏ P(D | Œ∏)
```

Como `P(D|Œ∏)` suele ser un producto grande, usamos log:

```text
Œ∏_MLE = argmax_Œ∏ log P(D | Œ∏)
```

Esto es el puente directo a **Statistical Estimation** (L√≠nea 2): estimadores, sesgo, varianza, y por qu√© ‚Äúpromedio‚Äù aparece en tantos lados.

#### Worked example: Moneda (Bernoulli) ‚Üí estimador MLE

Modelo:

- `X_i ~ Bernoulli(p)` donde `p = P(cara)`.

Datos:

- `D = {x_1, ..., x_n}` con `x_i ‚àà {0,1}`.

Likelihood:

```text
P(D | p) = Œ†_i p^{x_i} (1-p)^{(1-x_i)}
```

Log-likelihood:

```text
‚Ñì(p) = Œ£_i [x_i log p + (1-x_i) log(1-p)]
```

Derivar y hacer 0 (intuici√≥n: el m√°ximo ocurre cuando la ‚Äúprobabilidad del modelo‚Äù coincide con la frecuencia observada):

```text
d‚Ñì/dp = Œ£_i [x_i/p - (1-x_i)/(1-p)] = 0
```

Soluci√≥n:

```text
p_MLE = (1/n) Œ£_i x_i
```

Interpretaci√≥n: el MLE de `p` es simplemente la **proporci√≥n de caras**. Este patr√≥n (media muestral) reaparece en gaussianas y en muchos estimadores.

#### 4.1 La Idea Central

```text
MLE: Encontrar los par√°metros Œ∏ que maximizan la probabilidad
     de observar los datos que tenemos.

Œ∏_MLE = argmax P(datos | Œ∏)
            Œ∏
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 4.1: La Idea Central</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Qu√© significa ‚Äúajustar Œ∏ para explicar los datos‚Äù
- **ID (opcional):** `M04-T04_1`
- **Duraci√≥n estimada:** 30‚Äì60 min
- **Nivel:** B√°sico‚ÄìIntermedio
- **Dependencias:** 4.0

#### 2) Objetivos
- Interpretar `argmax_Œ∏ P(datos|Œ∏)` como ‚Äúbuscar el Œ∏ que hace los datos m√°s probables‚Äù.
- Identificar qu√© es **dato**, qu√© es **par√°metro** y qu√© es **modelo**.

#### 3) Relevancia
- Esta idea aparece en regresi√≥n log√≠stica, Naive Bayes, gaussianas, GMM y en general en modelos probabil√≠sticos.

#### 4) Mapa conceptual m√≠nimo
- **Modelo** `P(x|Œ∏)` / `P(y|x,Œ∏)`
- **Datos** `D={x·µ¢,y·µ¢}`
- **Par√°metros** `Œ∏`
- **Objetivo** `argmax` (o `argmin` NLL)

#### 5) Definiciones esenciales
- `argmax`: devuelve el valor del par√°metro que maximiza una funci√≥n.
- i.i.d. (supuesto t√≠pico): cada muestra aporta un factor multiplicativo a la likelihood.

#### 6) Explicaci√≥n did√°ctica
- Piensa en `Œ∏` como ‚Äúperillas‚Äù del generador de datos: MLE elige las perillas que hacen ‚Äúcre√≠ble‚Äù el dataset observado.

#### 7) Ejemplo modelado
- Moneda: `Œ∏=p`; si observas muchas caras, el `p` que mejor explica el dato es alto.

#### 8) Pr√°ctica guiada
- Identifica `Œ∏` en:
  - Bernoulli (`p`),
  - Gaussiana (`Œº,œÉ`),
  - Softmax (`W`).

#### 9) Pr√°ctica independiente
- Escribe en una l√≠nea qu√© maximiza MLE para un modelo `P(y|x,Œ∏)`.

#### 10) Autoevaluaci√≥n
- ¬øQu√© cambia si los datos no fueran independientes?

#### 11) Errores comunes
- Mezclar `P(Œ∏|datos)` (Bayes) con `P(datos|Œ∏)` (MLE).

#### 12) Retenci√≥n
- Frase clave: **MLE mira datos‚ÜíŒ∏ (qu√© Œ∏ explica mejor lo observado)**.

#### 13) Diferenciaci√≥n
- Avanzado: contrasta MLE con MAP (`argmax P(Œ∏|D)`), aunque ambos suelen acabar en minimizar una loss.

#### 14) Recursos
- Repasar diferencia entre prior, likelihood y posterior.

#### 15) Nota docente
- Verbalizaci√≥n obligatoria: ‚Äú¬øqu√© estoy maximizando exactamente y respecto a qu√© variable?‚Äù
</details>

#### 4.2 Por Qu√© es Fundamental

- **Logistic Regression** usa MLE para encontrar los pesos
- **Cross-Entropy Loss** viene de maximizar likelihood
- **GMM** usa MLE (via EM algorithm)

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 4.2: Por Qu√© es Fundamental</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Por qu√© MLE est√° ‚Äúdebajo‚Äù de p√©rdidas y modelos comunes
- **ID (opcional):** `M04-T04_2`
- **Duraci√≥n estimada:** 30‚Äì60 min
- **Nivel:** Intermedio
- **Dependencias:** 4.0‚Äì4.1

#### 2) Objetivos
- Identificar al menos 3 lugares del stack ML donde MLE aparece impl√≠citamente.
- Conectar *modelado probabil√≠stico* con *funci√≥n de p√©rdida*.

#### 3) Relevancia
- Te permite ‚Äúleer‚Äù una loss como una suposici√≥n probabil√≠stica (qu√© distribuci√≥n est√°s asumiendo).

#### 4) Mapa conceptual m√≠nimo
- **Modelo probabil√≠stico** ‚Üí **log-likelihood** ‚Üí **NLL** ‚Üí **gradiente/optimizaci√≥n**

#### 5) Definiciones esenciales
- **Estimador:** regla que produce un par√°metro `\hat{Œ∏}` desde datos.
- **Loss probabil√≠stica:** una loss que puede interpretarse como NLL bajo un modelo.

#### 6) Explicaci√≥n did√°ctica
- Cuando eliges cross-entropy, eliges impl√≠citamente ‚Äúel dato `y` sigue una distribuci√≥n categ√≥rica parametrizada por el modelo‚Äù.

#### 7) Ejemplo modelado
- Regresi√≥n:
  - Si asumes ruido Gaussiano, la NLL se parece a MSE.
  - Si asumes Bernoulli/categ√≥rica, la NLL se vuelve BCE/CCE.

#### 8) Pr√°ctica guiada
- Para cada bullet del tema (LogReg, Cross-Entropy, GMM), completa la frase:
  - ‚ÄúLa loss es la NLL de una distribuci√≥n ____‚Äù.

#### 9) Pr√°ctica independiente
- ¬øQu√© suposici√≥n probabil√≠stica hay detr√°s de usar MSE como loss?

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© ‚Äúmaximizar likelihood‚Äù y ‚Äúminimizar NLL‚Äù son el mismo objetivo?

#### 11) Errores comunes
- Creer que MLE ‚Äúsolo‚Äù es una t√©cnica estad√≠stica: en ML moderno es una forma est√°ndar de derivar losses.

#### 12) Retenci√≥n
- F√≥rmula mental: **modelar `P(y|x)` ‚áí entrenar = maximizar `P(y|x,Œ∏)`**.

#### 13) Diferenciaci√≥n
- Avanzado: discute cu√°ndo preferir MAP/regularizaci√≥n como ‚Äúprior‚Äù impl√≠cito.

#### 14) Recursos
- Lectura corta: interpretaci√≥n probabil√≠stica de MSE/BCE/CCE.

#### 15) Nota docente
- Mini-debate: ‚Äú¬øuna loss define un modelo o un modelo define una loss?‚Äù
</details>

#### 4.3 MLE para Gaussiana

```python
def mle_gaussian(data: np.ndarray) -> tuple[float, float]:  # estima (mu, sigma) por MLE para una gaussiana
    """
    Estimar par√°metros de Gaussiana con MLE.

    Para una Gaussiana, los estimadores MLE son:
    - Œº_MLE = media muestral
    - œÉ¬≤_MLE = varianza muestral (con n, no n-1)

    Args:
        data: Muestras observadas

    Returns:
        (mu_mle, sigma_mle)
    """
    n = len(data)  # n√∫mero de muestras disponibles

    # MLE de la media
    mu_mle = np.mean(data)  # Œº_MLE: promedio muestral

    # MLE de la varianza (dividir por n, no n-1)
    sigma_squared_mle = np.sum((data - mu_mle) ** 2) / n  # œÉ¬≤_MLE: varianza muestral con divisor n
    sigma_mle = np.sqrt(sigma_squared_mle)  # œÉ_MLE: desviaci√≥n est√°ndar (ra√≠z de la varianza)

    return mu_mle, sigma_mle  # retorna estimaciones (Œº, œÉ)


# Ejemplo: Generar datos y estimar
np.random.seed(42)  # fija semilla para reproducibilidad del muestreo
true_mu, true_sigma = 5.0, 2.0  # par√°metros verdaderos usados para simular datos
samples = np.random.normal(true_mu, true_sigma, size=1000)  # genera muestras N(true_mu, true_sigma^2)

estimated_mu, estimated_sigma = mle_gaussian(samples)  # estima par√°metros a partir de las muestras simuladas
print(f"Par√°metros reales: Œº={true_mu}, œÉ={true_sigma}")  # muestra par√°metros ground truth
print(f"MLE estimados:     Œº={estimated_mu:.3f}, œÉ={estimated_sigma:.3f}")  # muestra estimaciones MLE
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 4.3: MLE para Gaussiana</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Media muestral y varianza con `n` (no `n-1`) como MLE
- **ID (opcional):** `M04-T04_3`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 3.1‚Äì3.3 (Gaussiana univariada) + 4.1

#### 2) Objetivos
- Diferenciar varianza MLE (`/n`) de varianza insesgada (`/(n-1)`).
- Implementar estimadores MLE para `Œº` y `œÉ` y validar con datos simulados.

#### 3) Relevancia
- Esta derivaci√≥n aparece en EM/GMM y en cualquier modelo que use gaussianas (ruido, priors, etc.).

#### 4) Mapa conceptual m√≠nimo
- **Asunci√≥n:** `x·µ¢ ~ N(Œº,œÉ¬≤)`
- **Objetivo:** `argmax log P(D|Œº,œÉ)`
- **Resultado:** `Œº=mean(x)` y `œÉ¬≤=mean((x-Œº)¬≤)`

#### 5) Definiciones esenciales
- `œÉ¬≤_MLE = (1/n) Œ£ (x·µ¢-Œº)¬≤`.
- Estimador insesgado: usa `1/(n-1)` (otra propiedad, objetivo distinto).

#### 6) Explicaci√≥n did√°ctica
- MLE optimiza ‚Äúqu√© par√°metros hacen m√°s probable el dataset‚Äù, no ‚Äúque el estimador sea insesgado‚Äù.

#### 7) Ejemplo modelado
- Con `n=1000`, `\hat{Œº}` y `\hat{œÉ}` deber√≠an acercarse a los par√°metros reales por ley de los grandes n√∫meros.

#### 8) Pr√°ctica guiada
- Agrega checks:
  - `assert estimated_sigma > 0`.
  - `assert abs(estimated_mu-true_mu) < 0.2` (con `n` grande).

#### 9) Pr√°ctica independiente
- Repite con `n=10` y observa la variabilidad de `\hat{œÉ}`.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© `/(n-1)` no sale de MLE cuando maximizas likelihood?

#### 11) Errores comunes
- Usar `np.std(data, ddof=1)` y decir que es MLE (eso es insesgado, no MLE).
- Confundir `œÉ` con `œÉ¬≤` en el retorno.

#### 12) Retenci√≥n
- Regla: **MLE de media = promedio; MLE de varianza = promedio de cuadrados centrados**.

#### 13) Diferenciaci√≥n
- Avanzado: deriva la log-likelihood de la Gaussiana y ubica d√≥nde aparece el t√©rmino `log œÉ`.

#### 14) Recursos
- Numpy: `np.mean`, `np.sum`, `np.sqrt`.

#### 15) Nota docente
- Pregunta guiadora: ‚Äú¬øqu√© propiedad est√°s optimizando: likelihood o sesgo?‚Äù
</details>

#### 4.4 Conexi√≥n con Cross-Entropy Loss

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 4.4: Conexi√≥n con Cross-Entropy Loss</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Cross-entropy como NLL: la forma ‚Äúest√°ndar‚Äù de escribir MLE en clasificaci√≥n
- **ID (opcional):** `M04-T04_4`
- **Duraci√≥n estimada:** 30‚Äì60 min
- **Nivel:** Intermedio
- **Dependencias:** 4.0 + 2.1 (probabilidades condicionadas)

#### 2) Objetivos
- Escribir expl√≠citamente la NLL en binario y multiclase.
- Identificar la ‚Äúclase correcta‚Äù como el t√©rmino que se queda en la suma cuando `y` es one-hot.

#### 3) Relevancia
- Esta conexi√≥n explica por qu√© la loss tiene logs y por qu√© penaliza con fuerza probabilidades peque√±as.

#### 4) Mapa conceptual m√≠nimo
- `P(y|x,Œ∏)` ‚Üí `log P(y|x,Œ∏)` ‚Üí `-log P(y|x,Œ∏)`
- One-hot `y` ‚Äúselecciona‚Äù la clase correcta en `Œ£ y_k log(p_k)`

#### 5) Definiciones esenciales
- **Cross-entropy (multiclase):** `H(y,p)= -Œ£_k y_k log(p_k)`.
- Si `y` es one-hot, entonces `H(y,p) = -log(p_clase_correcta)`.

#### 6) Explicaci√≥n did√°ctica
- No hay ‚Äúmagia‚Äù: el log aparece por MLE y por estabilidad num√©rica.

#### 7) Ejemplo modelado
- Si `p_correcta=0.9`, p√©rdida ‚âà `0.105`; si `p_correcta=0.01`, p√©rdida ‚âà `4.605`.

#### 8) Pr√°ctica guiada
- Calcula `-log(p_correcta)` para `p‚àà{0.9,0.5,0.1,0.01}` y ord√©nalos.

#### 9) Pr√°ctica independiente
- Explica por qu√© una predicci√≥n ‚Äúmuy segura y equivocada‚Äù recibe mucha penalizaci√≥n.

#### 10) Autoevaluaci√≥n
- ¬øQu√© pasa con la loss si el modelo siempre predice `p_correcta=1/K`?

#### 11) Errores comunes
- Calcular `np.log(softmax(z))` de forma ingenua y sufrir underflow/NaN (ver d√≠a 7).

#### 12) Retenci√≥n
- Frase: **cross-entropy = costo de sorprenderte al ver la etiqueta verdadera**.

#### 13) Diferenciaci√≥n
- Avanzado: conecta con KL: `H(y,p)=H(y)+KL(y||p)` (cuando `y` es distribuci√≥n).

#### 14) Recursos
- Revisi√≥n: propiedades de `log` y estabilidad num√©rica.

#### 15) Nota docente
- Pedir que el alumno derive la forma one-hot ‚Üí `-log(p_correcta)` en 3 l√≠neas.
</details>

#### 4.5 MLE para multiclase (Softmax + Categorical Cross-Entropy)

Para `K` clases, `y` es one-hot y el modelo produce probabilidades con softmax:

- `p = softmax(z)` donde `z = XW` son logits

Likelihood (por muestra):

- `P(y|x) = Œ†_k p_k^{y_k}`

Log-likelihood:

- `log P(y|x) = Œ£_k y_k log(p_k)`

Negative log-likelihood promedio:

- `L = -(1/m) Œ£·µ¢ Œ£_k y_{ik} log(p_{ik})`

Eso es exactamente **Categorical Cross-Entropy**.

```python
def cross_entropy_from_mle():  # demuestra cross-entropy como NLL (derivada desde MLE)
    """
    Demostraci√≥n de que Cross-Entropy viene de MLE.

    Para clasificaci√≥n binaria con Bernoulli:
    P(y|x, Œ∏) = p^y ¬∑ (1-p)^(1-y)

    Donde p = œÉ(Œ∏·µÄx) (predicci√≥n del modelo)

    Log-likelihood:
    log P(y|x, Œ∏) = y¬∑log(p) + (1-y)¬∑log(1-p)

    Maximizar likelihood = Minimizar negative log-likelihood
    = Minimizar Cross-Entropy!
    """
    # Ejemplo num√©rico
    y_true = np.array([1, 0, 1, 1, 0])  # etiquetas reales (0/1)
    y_pred = np.array([0.9, 0.1, 0.8, 0.7, 0.2])  # probabilidades predichas p(y=1|x)

    # Cross-Entropy (negative log-likelihood promedio)
    epsilon = 1e-15  # Para evitar log(0)
    ce = -np.mean(  # NLL promedio: -E[y log(p) + (1-y) log(1-p)]
        y_true * np.log(y_pred + epsilon) +  # contribuci√≥n de ejemplos positivos (y=1)
        (1 - y_true) * np.log(1 - y_pred + epsilon)  # contribuci√≥n de ejemplos negativos (y=0)
    )  # cierra promedio de cross-entropy

    print(f"Cross-Entropy Loss: {ce:.4f}")  # imprime el valor de la loss para inspecci√≥n
    return ce  # retorna la cross-entropy calculada

cross_entropy_from_mle()  # ejecuta la demo de MLE‚Üícross-entropy
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 4.5: MLE para multiclase (Softmax + Categorical Cross-Entropy)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** De `Œ† p_k^{y_k}` a `-Œ£ y_k log(p_k)` (y por qu√© eso es entrenable)
- **ID (opcional):** `M04-T04_5`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 4.0 + noci√≥n de one-hot + softmax (d√≠a 7)

#### 2) Objetivos
- Derivar la log-likelihood multiclase usando one-hot.
- Interpretar la CCE como ‚Äúcastigo‚Äù a la probabilidad asignada a la clase correcta.
- Reconocer el rol de `epsilon` como protecci√≥n de `log(0)`.

#### 3) Relevancia
- Esta es la base de entrenamiento para redes neuronales multiclase y modelos lineales con softmax.

#### 4) Mapa conceptual m√≠nimo
- **Logits** `z` ‚Üí **Softmax** `p` ‚Üí **Log-prob** `log(p)` ‚Üí **CCE/NLL**

#### 5) Definiciones esenciales
- One-hot: `y_k‚àà{0,1}`, `Œ£_k y_k = 1`.
- CCE por muestra: `L = -Œ£_k y_k log(p_k)`.

#### 6) Explicaci√≥n did√°ctica
- El producto `Œ†_k p_k^{y_k}` ‚Äúselecciona‚Äù exactamente la probabilidad de la clase verdadera.
- El log convierte ese producto en suma (y vuelve diferenciable y m√°s estable el entrenamiento).

#### 7) Ejemplo modelado
- Para `K=3`, si la clase verdadera es 2, la loss es `-log(p_2)`.

#### 8) Pr√°ctica guiada
- Construye un `y` one-hot y un vector `p` y verifica a mano que:
  - `-Œ£ y_k log(p_k)` coincide con `-log(p_clase_correcta)`.

#### 9) Pr√°ctica independiente
- Explica por qu√© se promedia en batch (`1/m`) y no se usa suma sin normalizar.

#### 10) Autoevaluaci√≥n
- ¬øQu√© problema num√©rico aparece si `p_k` llega a 0 exacto?

#### 11) Errores comunes
- Usar softmax + log de manera ingenua y obtener `-inf/NaN`.
- Confundir `logits` (sin normalizar) con probabilidades.

#### 12) Retenci√≥n
- Regla: **CCE = NLL de una categ√≥rica parametrizada por softmax**.

#### 13) Diferenciaci√≥n
- Avanzado: describe por qu√© en pr√°ctica se prefiere ‚ÄúCE desde logits‚Äù con `log_softmax`.

#### 14) Recursos
- Estabilidad num√©rica: Log-Sum-Exp trick (d√≠a 7).

#### 15) Nota docente
- Pedir que el alumno identifique, en una implementaci√≥n, d√≥nde se aplica `max(z)` para estabilizar.
</details>

---

### D√≠a 6.5: Teor√≠a de la Informaci√≥n (Entrop√≠a + KL-Divergence)

Este bloque existe para que puedas leer ‚Äúcross-entropy‚Äù como **divergencia KL + constante** y para que puedas derivar la equivalencia central:

- **Minimizar KL** (entre distribuci√≥n real y modelo) es **maximizar log-likelihood**.

#### 6.5.1 Entrop√≠a

Para una distribuci√≥n discreta `p`:

```text
H(p) = - Œ£_x p(x) log p(x)
```

Intuici√≥n: ‚Äúcosto promedio de sorpresa‚Äù bajo `p`.

#### 6.5.2 Divergencia KL

Para dos distribuciones discretas `p` y `q`:

```text
KL(p||q) = Œ£_x p(x) log( p(x) / q(x) )
         = Œ£_x p(x) log p(x) - Œ£_x p(x) log q(x)
```

#### 6.5.3 Derivaci√≥n clave: minimizar KL ‚áî maximizar log-likelihood

Sea `p_data` la distribuci√≥n ‚Äúreal‚Äù y `p_Œ∏` tu modelo.

```text
KL(p_data || p_Œ∏)
= E_{x~p_data}[log p_data(x)] - E_{x~p_data}[log p_Œ∏(x)]
```

El primer t√©rmino no depende de `Œ∏`. Por lo tanto:

```text
argmin_Œ∏ KL(p_data || p_Œ∏)  =  argmax_Œ∏ E_{x~p_data}[log p_Œ∏(x)]
```

Y con datos i.i.d. `{x_i}`:

```text
E_{p_data}[log p_Œ∏(x)]  ‚âà  (1/n) Œ£_i log p_Œ∏(x_i)
```

As√≠ conectas KL directamente con MLE.

#### 6.5.4 Cross-Entropy como KL + constante

Cuando `y` es una distribuci√≥n (por ejemplo one-hot) y `p` es la predicci√≥n:

```text
H(y,p) = H(y) + KL(y||p)
```

Como `H(y)` es constante respecto al modelo, minimizar cross-entropy equivale a minimizar `KL(y||p)`.

## üå± Extensi√≥n Estrat√©gica (L√≠nea 2): Markov Chains (intro conceptual)

> Esta secci√≥n es conceptual: no vas a implementar Markov Chains en L√≠nea 1, pero s√≠ necesitas que la idea te resulte familiar cuando entres al curso de **Discrete-Time Markov Chains and Monte Carlo Methods**.

### Idea central: estados y transiciones

Una cadena de Markov modela un sistema que ‚Äúsalta‚Äù entre **estados**.

- Hoy est√°s en un estado `S_t`.
- Ma√±ana est√°s en `S_{t+1}`.
- Lo importante: `P(S_{t+1} | S_t)` depende solo del estado actual (memoria de 1 paso).

### Matriz de transici√≥n (conexi√≥n con √Ålgebra Lineal)

Definimos una matriz `P` donde:

- `P[i, j] = P(estado j | estado i)`
- Cada fila suma 1 (matriz estoc√°stica por filas)

Si `œÄ_t` es un vector fila con la distribuci√≥n de probabilidad sobre estados en el tiempo `t`, entonces:

```text
œÄ_{t+1} = œÄ_t P
```

Esto conecta directamente con `M√≥dulo 02`: es **multiplicaci√≥n de matrices** aplicada a probabilidades.

### Ejemplo m√≠nimo (2 estados)

Estados: `A` y `B`.

```text
P = [[0.9, 0.1],
     [0.2, 0.8]]
```

Interpretaci√≥n:

- Si est√°s en `A`, te quedas en `A` con 0.9, pasas a `B` con 0.1.
- Si est√°s en `B`, pasas a `A` con 0.2, te quedas en `B` con 0.8.

### Estacionariedad (semilla para L√≠nea 2)

Una distribuci√≥n estacionaria `œÄ*` satisface:

```text
œÄ* = œÄ* P
```

En otras palabras: es un **autovector** (eigenvector) asociado al eigenvalue `1` (visto desde la perspectiva correcta). Esto vuelve a conectar Markov Chains con eigenvalues/eigenvectors.

---

### D√≠a 7: Softmax como Distribuci√≥n de Probabilidad

#### 5.1 De Logits a Probabilidades

```text
                     exp(z·µ¢)
softmax(z)·µ¢ = ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
               Œ£‚±º exp(z‚±º)

Propiedades:
- Cada salida ‚àà (0, 1)
- Suma de salidas = 1 (distribuci√≥n v√°lida)
- Preserva el orden (mayor logit ‚Üí mayor probabilidad)
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 5.1: De Logits a Probabilidades</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Softmax como distribuci√≥n: de scores a probabilidades comparables
- **ID (opcional):** `M04-T05_1`
- **Duraci√≥n estimada:** 45‚Äì90 min
- **Nivel:** Intermedio
- **Dependencias:** 4.5 (CCE desde MLE), √°lgebra b√°sica de exponentes

#### 2) Objetivos
- Explicar qu√© son **logits** y por qu√© no son probabilidades.
- Interpretar softmax como una normalizaci√≥n positiva que suma 1.
- Reconocer invariancia por desplazamiento: `softmax(z)=softmax(z+c)`.

#### 3) Relevancia
- Softmax es la salida est√°ndar en clasificaci√≥n multiclase y conecta directamente con la CCE.

#### 4) Mapa conceptual m√≠nimo
- **Logits** `z` ‚Üí `exp(z)` ‚Üí **normalizaci√≥n** `Œ£ exp(z)` ‚Üí **probabilidades**

#### 5) Definiciones esenciales
- **Logit:** score sin normalizar (puede ser cualquier real).
- **Distribuci√≥n v√°lida:** entradas en `(0,1)` y suma 1.

#### 6) Explicaci√≥n did√°ctica
- `exp` asegura positividad; dividir por la suma fuerza ‚Äúcompetencia‚Äù entre clases.

#### 7) Ejemplo modelado
- Si una clase sube su logit, su probabilidad sube y las dem√°s bajan para mantener suma 1.

#### 8) Pr√°ctica guiada
- Verifica (a mano) que `softmax([0,0]) = [0.5,0.5]`.

#### 9) Pr√°ctica independiente
- Demuestra en 2 l√≠neas la invariancia: `softmax(z)=softmax(z-c)` para cualquier constante `c`.

#### 10) Autoevaluaci√≥n
- ¬øQu√© sucede si sumas 100 a todos los logits? ¬øCambia el resultado?

#### 11) Errores comunes
- Interpretar logits como probabilidades.
- Olvidar que softmax depende de las diferencias relativas entre logits.

#### 12) Retenci√≥n
- Regla: **softmax convierte scores relativos en probabilidades que compiten**.

#### 13) Diferenciaci√≥n
- Avanzado: explora el efecto de la temperatura `softmax(z/T)`.

#### 14) Recursos
- Relaci√≥n con CCE: `L = -log p(clase correcta)`.

#### 15) Nota docente
- Pregunta r√°pida: ‚Äúsi una probabilidad sube, ¬øqu√© debe pasar con las otras y por qu√©?‚Äù

</details>

#### 5.2 El Problema de Estabilidad Num√©rica (v3.3)

```text
‚ö†Ô∏è PROBLEMA: exp() puede causar overflow/underflow

Ejemplo peligroso:
    z = [1000, 1001, 1002]
    exp(z) = [inf, inf, inf]  ‚Üí NaN en softmax!

Ejemplo underflow:
    z = [-1000, -1001, -1002]
    exp(z) = [0, 0, 0]  ‚Üí 0/0 = NaN!
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 5.2: El Problema de Estabilidad Num√©rica</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Por qu√© `exp` rompe y c√≥mo reconocer overflow/underflow
- **ID (opcional):** `M04-T05_2`
- **Duraci√≥n estimada:** 30‚Äì60 min
- **Nivel:** Intermedio
- **Dependencias:** 5.1

#### 2) Objetivos
- Identificar s√≠ntomas: `inf`, `0`, `NaN` en softmax.
- Explicar por qu√© `inf/inf` y `0/0` aparecen.
- Justificar la necesidad de un truco algebraico (no ‚Äúparche‚Äù).

#### 3) Relevancia
- Este error es com√∫n en entrenamiento real y puede arruinar gradients (loss NaN).

#### 4) Mapa conceptual m√≠nimo
- logits grandes ‚Üí `exp(z)` overflow ‚Üí `inf` ‚Üí `inf/inf` ‚Üí `NaN`
- logits muy negativos ‚Üí `exp(z)` underflow ‚Üí `0` ‚Üí `0/0` ‚Üí `NaN`

#### 5) Definiciones esenciales
- **Overflow:** n√∫mero demasiado grande para representarse (‚Üí `inf`).
- **Underflow:** n√∫mero tan peque√±o que se aproxima a 0.

#### 6) Explicaci√≥n did√°ctica
- Softmax es sensible al rango num√©rico por el `exp`. El objetivo es mantener exponentes en un rango seguro.

#### 7) Ejemplo modelado
- `z=[1000,1001,1002]` es un caso ‚Äúconceptualmente f√°cil‚Äù (deber√≠a ganar la √∫ltima clase) pero num√©ricamente peligroso.

#### 8) Pr√°ctica guiada
- ¬øCu√°l de estos casos produce `inf` y cu√°l produce `0`?
  - `exp(1000)`, `exp(-1000)`.

#### 9) Pr√°ctica independiente
- Explica por qu√© aunque el resultado final de softmax est√© en `(0,1)`, el c√°lculo intermedio puede romper.

#### 10) Autoevaluaci√≥n
- ¬øQu√© dos operaciones generan `NaN` t√≠picamente en este contexto?

#### 11) Errores comunes
- ‚ÄúSolucionar‚Äù con `epsilon` dentro de `exp` (no resuelve overflow).

#### 12) Retenci√≥n
- Se√±al roja: **si ves logits con magnitud ~1e3, softmax naive es sospechoso**.

#### 13) Diferenciaci√≥n
- Avanzado: discute por qu√© el problema empeora con batch grande y/o modelos profundos.

#### 14) Recursos
- IEEE-754, l√≠mites de `float64/float32` (intuitivo: `exp(88)` ya es enorme en `float32`).

#### 15) Nota docente
- Pide al alumno que describa el fallo como ‚Äúoperaci√≥n indefinida‚Äù (`inf/inf`, `0/0`).

</details>

#### 5.3 Log-Sum-Exp Trick (Estabilidad Num√©rica)

```text
TRUCO: softmax(z) = softmax(z - max(z))

Demostraci√≥n:
    softmax(z - c)·µ¢ = exp(z·µ¢ - c) / Œ£‚±º exp(z‚±º - c)
                    = exp(z·µ¢)¬∑exp(-c) / Œ£‚±º exp(z‚±º)¬∑exp(-c)
                    = exp(z·µ¢) / Œ£‚±º exp(z‚±º)
                    = softmax(z)·µ¢

Al restar max(z), todos los exponentes son ‚â§ 0, evitando overflow.
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 5.3: Log-Sum-Exp Trick</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Shift por `max(z)` para hacer `exp` seguro sin cambiar softmax
- **ID (opcional):** `M04-T05_3`
- **Duraci√≥n estimada:** 45‚Äì90 min
- **Nivel:** Intermedio
- **Dependencias:** 5.2

#### 2) Objetivos
- Probar que restar una constante no cambia softmax.
- Entender por qu√© usar `max(z)` es una elecci√≥n √≥ptima simple.
- Reconocer el patr√≥n ‚Äúlog-sum-exp‚Äù como herramienta general.

#### 3) Relevancia
- Es la base de implementaciones estables de softmax/log-softmax y cross-entropy desde logits.

#### 4) Mapa conceptual m√≠nimo
- invariancia por shift ‚Üí elegir `c=max(z)` ‚Üí exponentes ‚â§ 0 ‚Üí sin overflow

#### 5) Definiciones esenciales
- **Shift/centrado:** `z' = z - c`.
- **log-sum-exp:** `log(Œ£ exp(z))` computado de forma estable.

#### 6) Explicaci√≥n did√°ctica
- Restar `max(z)` hace que el mayor exponente sea `exp(0)=1` y el resto `‚â§1`.

#### 7) Ejemplo modelado
- Si `z=[1000,1001,1002]`, entonces `z'=[-2,-1,0]` (seguro) y softmax no cambia.

#### 8) Pr√°ctica guiada
- Repite la demostraci√≥n de invariancia para `softmax(z-c)` con s√≠mbolos.

#### 9) Pr√°ctica independiente
- ¬øPor qu√© no basta con restar un n√∫mero fijo como 100? ¬øQu√© hace especial a `max(z)`?

#### 10) Autoevaluaci√≥n
- ¬øQu√© garantiza que `exp(z')` no overflow si `max(z')=0`?

#### 11) Errores comunes
- Restar el `max` sin `keepdims=True` y romper shapes en batch.

#### 12) Retenci√≥n
- Mantra: **softmax es invariante a shift; usa `max` para estabilidad**.

#### 13) Diferenciaci√≥n
- Avanzado: conecta con `log_softmax(z)=z-logsumexp(z)`.

#### 14) Recursos
- B√∫squeda: ‚Äúlogsumexp trick‚Äù (patr√≥n general en modelos probabil√≠sticos).

#### 15) Nota docente
- Pide al alumno que identifique d√≥nde aparece la misma idea en `log_softmax`.

</details>

#### 5.4 Implementaci√≥n Num√©ricamente Estable

```python
import numpy as np  # NumPy: necesario para exp/log/max/sum en softmax estable

def softmax(z: np.ndarray) -> np.ndarray:  # convierte logits a probabilidades (softmax estable)
    """
    Softmax num√©ricamente estable usando Log-Sum-Exp trick.

    Truco: Restar el m√°ximo para evitar overflow en exp()
    softmax(z) = softmax(z - max(z))

    Args:
        z: Logits (scores antes de activaci√≥n)

    Returns:
        Probabilidades que suman 1
    """
    # Log-Sum-Exp trick: restar el m√°ximo
    z_stable = z - np.max(z, axis=-1, keepdims=True)  # Shift: ancla num√©rica por fila (mantiene invariancia)

    exp_z = np.exp(z_stable)  # exp() seguro: valores ‚â§ 0 evitan overflow
    return exp_z / np.sum(exp_z, axis=-1, keepdims=True)  # Normaliza para que sumen 1 (distribuci√≥n)


def log_softmax(z: np.ndarray) -> np.ndarray:  # calcula log(softmax(z)) de forma estable
    """
    Log-Softmax estable (√∫til para Cross-Entropy).

    log(softmax(z)) calculado de forma estable.
    Evita calcular softmax primero y luego log (pierde precisi√≥n).
    """
    z_stable = z - np.max(z, axis=-1, keepdims=True)  # Mismo shift: reduce rango num√©rico
    log_sum_exp = np.log(np.sum(np.exp(z_stable), axis=-1, keepdims=True))  # log(sum(exp(z_stable))) por fila
    return z_stable - log_sum_exp  # log_softmax = z - logsumexp(z)


def categorical_cross_entropy_from_logits(y_true: np.ndarray, logits: np.ndarray) -> float:  # CCE estable usando logits
    """
    Cross-entropy estable usando logits directamente.

    Evita calcular softmax expl√≠cito.
    √ötil cuando entrenas modelos y quieres estabilidad.
    """
    log_probs = log_softmax(logits)  # Convierte logits a log-probabilidades estables
    return -np.mean(np.sum(y_true * log_probs, axis=1))  # NLL promedio: -E[log p(clase correcta)]


# ============================================================
# DEMOSTRACI√ìN: Por qu√© el trick es necesario
# ============================================================

def demo_numerical_stability():  # muestra overflow/NaN en softmax ingenuo vs estable
    """Muestra por qu√© necesitamos el Log-Sum-Exp trick."""

    # Caso peligroso: logits muy grandes
    z_dangerous = np.array([1000.0, 1001.0, 1002.0])  # Logits extremos: exp() desborda sin protecci√≥n

    # Sin el trick (INCORRECTO)
    def softmax_naive(z):  # softmax ingenuo (puede overflow con logits grandes)
        exp_z = np.exp(z)  # ¬°Overflow! exp(1000) -> inf
        return exp_z / np.sum(exp_z)  # inf/inf -> NaN (resultado no es una distribuci√≥n v√°lida)

    # Con el trick (CORRECTO)
    def softmax_stable(z):  # softmax estable (resta max antes de exp)
        z_stable = z - np.max(z)  # Restar max: invariancia de softmax pero con estabilidad
        exp_z = np.exp(z_stable)  # Ahora exp() es seguro (valores ‚â§ 0)
        return exp_z / np.sum(exp_z)  # Normaliza a suma 1

    print("Logits peligrosos:", z_dangerous)  # muestra logits extremos que rompen exp sin protecci√≥n
    print()  # l√≠nea en blanco: separa secciones en la salida

    # Naive (falla)
    import warnings  # m√≥dulo para controlar/ignorar warnings durante la demo
    with warnings.catch_warnings():  # captura warnings (overflow) para no ensuciar la salida
        warnings.simplefilter("ignore")  # Ignora warning esperado por overflow (demo)
        result_naive = softmax_naive(z_dangerous)  # Resultado ingenuo (suele contener NaN)
        print(f"Softmax NAIVE: {result_naive}")  # Imprime el vector (para ver NaN/inf)
        print(f"  ‚Üí Suma: {np.sum(result_naive)} (deber√≠a ser 1.0)")  # Verifica que no normaliza bien

    # Estable (funciona)
    result_stable = softmax_stable(z_dangerous)  # Resultado estable: finito y normalizado
    print(f"\nSoftmax ESTABLE: {result_stable}")  # Imprime el vector estable
    print(f"  ‚Üí Suma: {np.sum(result_stable):.6f} ‚úì")  # Suma ~1 confirma distribuci√≥n v√°lida

demo_numerical_stability()  # ejecuta la demo de estabilidad num√©rica


# Ejemplo: Clasificaci√≥n multiclase (d√≠gitos 0-9)
logits = np.array([2.0, 1.0, 0.1, -1.0, 3.0, 0.5, -0.5, 1.5, 0.0, -2.0])  # logits de ejemplo para 10 clases
probs = softmax(logits)  # convierte logits a probabilidades (softmax)

print("\nLogits ‚Üí Probabilidades:")  # encabezado: muestra mapeo logit‚Üíprobabilidad
for i, (l, p) in enumerate(zip(logits, probs)):  # recorre clases y sus probabilidades
    print(f"  Clase {i}: logit={l:+.1f} ‚Üí prob={p:.3f}")  # imprime probabilidad por clase
print(f"\nSuma de probabilidades: {np.sum(probs):.6f}")  # sanity check: suma debe ser ~1
print(f"Clase predicha: {np.argmax(probs)}")  # predicci√≥n: clase con probabilidad m√°xima

```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Tema 5.4: Implementaci√≥n Num√©ricamente Estable</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Implementar `softmax`/`log_softmax` sin NaN (y por qu√© funciona)
- **ID (opcional):** `M04-T05_4`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 5.2‚Äì5.3

#### 2) Objetivos
- Implementar softmax estable con `z - max(z)`.
- Entender por qu√© `log_softmax` es preferible a `np.log(softmax(z))`.
- Verificar propiedades: probabilidades finitas y suma 1.

#### 3) Relevancia
- Esta es una de las fuentes m√°s comunes de `loss=NaN` en entrenamiento real (overflow/underflow en `exp`).

#### 4) Mapa conceptual m√≠nimo
- logits `z` ‚Üí shift `z-max(z)` ‚Üí `exp` seguro ‚Üí normalizar ‚Üí softmax
- logits `z` ‚Üí `log_softmax(z)=z-logsumexp(z)` ‚Üí CE estable

#### 5) Definiciones esenciales
- **Shift invariante:** restar una constante a todos los logits no cambia softmax.
- **log-softmax:** log-probabilidades computadas sin pasar por probabilidades intermedias inestables.

#### 6) Explicaci√≥n did√°ctica
- Restar `max(z)` ‚Äúcentra‚Äù la fila para que el mayor exponente sea `exp(0)=1` y el resto `‚â§1`.

#### 7) Ejemplo modelado
- El demo con logits grandes muestra que la versi√≥n naive puede producir `inf/inf ‚Üí NaN`, mientras que la estable no.

#### 8) Pr√°ctica guiada
- A√±ade checks:
  - `assert np.all(np.isfinite(softmax(z)))`
  - `assert np.allclose(np.sum(softmax(z)), 1.0)` (vector) o por fila (batch).

#### 9) Pr√°ctica independiente
- Implementa soporte batch `(n_samples, n_classes)` y verifica que `axis=-1` es el correcto.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© `argmax(softmax(z)) == argmax(z)` aunque cambien los valores?

#### 11) Errores comunes
- Olvidar `keepdims=True` y romper broadcasting.
- Normalizar sobre el eje incorrecto.

#### 12) Retenci√≥n
- Regla: **si ves `exp`, piensa en estabilidad y en restar `max`**.

#### 13) Diferenciaci√≥n
- Avanzado: compara el comportamiento en `float32` vs `float64`.

#### 14) Recursos
- Patr√≥n: ‚Äúlog-sum-exp trick‚Äù (idea general en modelos probabil√≠sticos).

#### 15) Nota docente
- Pide al alumno explicar el fallo del naive como ‚Äúoperaci√≥n indefinida‚Äù (`inf/inf`, `0/0`).
</details>

#### 5.5 Categorical Cross-Entropy (Multiclase)

```python
def categorical_cross_entropy(y_true: np.ndarray,  # labels one-hot (n_samples, n_classes)
                               y_pred: np.ndarray) -> float:  # probabilidades predichas (softmax) (n_samples, n_classes)
    """
    Loss para clasificaci√≥n multiclase.

    Args:
        y_true: One-hot encoded labels (n_samples, n_classes)
        y_pred: Probabilidades softmax (n_samples, n_classes)

    Returns:
        Loss promedio
    """
    epsilon = 1e-15  # estabilidad num√©rica: evita log(0)
    # Solo cuenta la clase correcta (donde y_true=1)
    return -np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=1))  # loss promedio: -mean(sum(y*log(p)))


# Ejemplo
y_true = np.array([  # labels one-hot para 2 muestras
    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],  # Clase 4
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # Clase 0
])  # cierra array de etiquetas y_true

y_pred = np.array([  # probabilidades predichas (cada fila suma 1)
    softmax(np.array([0, 0, 0, 0, 5, 0, 0, 0, 0, 0])),  # Confiado en 4
    softmax(np.array([3, 1, 0, 0, 0, 0, 0, 0, 0, 0])),  # Confiado en 0
])  # cierra array de probabilidades y_pred

loss = categorical_cross_entropy(y_true, y_pred)  # calcula la loss CCE para el ejemplo
print(f"Categorical Cross-Entropy: {loss:.4f}")  # imprime la loss para inspecci√≥n

```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 5.5: Categorical Cross-Entropy (Multiclase)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Implementar CCE con one-hot y entender qu√© suma realmente
- **ID (opcional):** `M04-T05_5`
- **Duraci√≥n estimada:** 45‚Äì90 min
- **Nivel:** Intermedio
- **Dependencias:** 4.5 + 5.4

#### 2) Objetivos
- Implementar CCE con protecci√≥n num√©rica (`epsilon`).
- Entender por qu√©, con one-hot, la loss selecciona la probabilidad de la clase correcta.
- Conectar CCE con NLL/MLE: minimizar CCE ‚â° maximizar likelihood categ√≥rica.

#### 3) Relevancia
- CCE es la funci√≥n de p√©rdida est√°ndar en clasificaci√≥n multiclase con softmax.

#### 4) Mapa conceptual m√≠nimo
- one-hot `y` ‚Üí selecciona clase correcta ‚Üí `-log(p_correcta)` ‚Üí promedio en batch

#### 5) Definiciones esenciales
- **One-hot:** vector con un 1 en la clase correcta y 0 en las dem√°s.
- **`epsilon`:** evita `log(0)` cuando `p` llega a 0 por redondeo.

#### 6) Explicaci√≥n did√°ctica
- El t√©rmino `np.sum(y_true * log(p), axis=1)` act√∫a como ‚Äúselector‚Äù de la clase correcta.

#### 7) Ejemplo modelado
- Si `p_correcta` pasa de `0.9` a `0.1`, la loss sube fuertemente (penaliza confianza equivocada).

#### 8) Pr√°ctica guiada
- Calcula a mano una muestra: `L=-log(p_correcta)` y valida con el print del c√≥digo.

#### 9) Pr√°ctica independiente
- Implementa la versi√≥n con √≠ndices (`y_true` como clase entera) y compara resultados.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© `epsilon` arregla `log(0)` pero no corrige overflow que ocurre antes en softmax naive?

#### 11) Errores comunes
- Pasar logits a una CE que espera probabilidades.
- No verificar que `y_pred` suma 1 por fila.

#### 12) Retenci√≥n
- F√≥rmula: **CCE = -promedio(log(probabilidad de la clase correcta))**.

#### 13) Diferenciaci√≥n
- Avanzado: discute label smoothing y c√≥mo cambia la suma `Œ£ y_k log(p_k)`.

#### 14) Recursos
- Conexi√≥n directa con el tema 4.5 (NLL y MLE).

#### 15) Nota docente
- Pregunta de control: ‚Äú¬øqu√© l√≠nea hace que solo cuente la clase correcta?‚Äù
</details>

## üéØ Ejercicios por tema (progresivos) + Soluciones

Reglas:

- **Intenta primero** sin mirar la soluci√≥n.
- **Timebox sugerido:** 15‚Äì30 min por ejercicio.
- **√âxito m√≠nimo:** tu soluci√≥n debe pasar los `assert`.

---

### Ejercicio 4.1: Probabilidad condicional (P(A|B)) y consistencia

#### Enunciado

1) **B√°sico**

- Dado un conjunto de conteos de eventos, calcula `P(A)`, `P(B)` y `P(A ‚à© B)`.

2) **Intermedio**

- Calcula `P(A|B) = P(A‚à©B)/P(B)` y verifica que est√° en `[0,1]`.

3) **Avanzado**

- Verifica que `P(A‚à©B) = P(A|B)¬∑P(B)`.

#### Soluci√≥n

```python
import numpy as np  # Importar librer√≠a para computaci√≥n num√©rica

# Simulaci√≥n con conteos (dataset peque√±o)
n = 100  # Tama√±o total del dataset
count_A = 40  # Conteo de eventos A
count_B = 50  # Conteo de eventos B
count_A_and_B = 20  # Conteo de eventos A y B simult√°neamente

P_A = count_A / n  # Calcular probabilidad de A
P_B = count_B / n  # Calcular probabilidad de B
P_A_and_B = count_A_and_B / n  # Calcular probabilidad conjunta

P_A_given_B = P_A_and_B / P_B  # Calcular probabilidad condicional P(A|B)

assert 0.0 <= P_A <= 1.0  # Verificar que P_A est√© en [0,1]
assert 0.0 <= P_B <= 1.0  # Verificar que P_B est√© en [0,1]
assert 0.0 <= P_A_given_B <= 1.0  # Verificar que P(A|B) est√© en [0,1]
assert np.isclose(P_A_and_B, P_A_given_B * P_B)  # Verificar regla del producto
```

---

### Ejercicio 4.2: Bayes en modo clasificador (posterior sin normalizar)

#### Enunciado

1) **B√°sico**

- Implementa el c√°lculo de posterior sin normalizar:
  - `score_spam = P(x|spam)¬∑P(spam)`
  - `score_ham = P(x|ham)¬∑P(ham)`

2) **Intermedio**

- Normaliza y obt√©n `P(spam|x)` y `P(ham|x)`.

3) **Avanzado**

- Verifica que las probabilidades normalizadas suman 1.

#### Soluci√≥n

```python
import numpy as np  # Importar librer√≠a para computaci√≥n num√©rica

P_spam = 0.3  # Probabilidad prior de spam
P_ham = 1.0 - P_spam  # Probabilidad prior de ham

P_x_given_spam = 0.8  # Verosimilitud P(x|spam)
P_x_given_ham = 0.1  # Verosimilitud P(x|ham)

score_spam = P_x_given_spam * P_spam  # Calcular score no normalizado para spam
score_ham = P_x_given_ham * P_ham  # Calcular score no normalizado para ham

Z = score_spam + score_ham  # Calcular constante de normalizaci√≥n
P_spam_given_x = score_spam / Z  # Calcular posterior P(spam|x)
P_ham_given_x = score_ham / Z  # Calcular posterior P(ham|x)

assert np.isclose(P_spam_given_x + P_ham_given_x, 1.0)  # Verificar que sumen 1
assert P_spam_given_x > P_ham_given_x  # Verificar que spam es m√°s probable
```

---

### Ejercicio 4.3: Independencia (test emp√≠rico)

#### Enunciado

1) **B√°sico**

- Simula dos variables binarias independientes `A` y `B`.

2) **Intermedio**

- Estima `P(A)`, `P(B)`, `P(A‚à©B)` y verifica `P(A‚à©B) ‚âà P(A)P(B)`.

3) **Avanzado**

- Simula un caso dependiente y verifica que la igualdad se rompe.

#### Soluci√≥n

```python
import numpy as np  # Importar librer√≠a para computaci√≥n num√©rica

np.random.seed(0)  # Fijar semilla para reproducibilidad
n = 20000  # Tama√±o de muestra

# Independientes
A = (np.random.rand(n) < 0.4)  # Generar eventos A con P=0.4
B = (np.random.rand(n) < 0.5)  # Generar eventos B con P=0.5

P_A = A.mean()  # Calcular P(A)
P_B = B.mean()  # Calcular P(B)
P_A_and_B = (A & B).mean()  # Calcular P(A‚à©B)

assert abs(P_A_and_B - (P_A * P_B)) < 0.01  # Verificar independencia

# Dependientes: B es casi A
B_dep = (A | (np.random.rand(n) < 0.05))  # B depende de A
P_B_dep = B_dep.mean()  # Calcular P(B)
P_A_and_B_dep = (A & B_dep).mean()  # Calcular P(A‚à©B)

assert abs(P_A_and_B_dep - (P_A * P_B_dep)) > 0.02  # Verificar dependencia
```

---

### Ejercicio 4.4: MLE de Bernoulli ("fracci√≥n de heads")

#### Enunciado

1) **B√°sico**

- Genera muestras Bernoulli con `p_true`.

2) **Intermedio**

- Implementa el estimador MLE `p_hat = mean(x)`.

3) **Avanzado**

- Verifica que `p_hat` se aproxima a `p_true` con suficientes muestras.

#### Soluci√≥n

```python
import numpy as np  # Importar librer√≠a para computaci√≥n num√©rica

np.random.seed(1)  # Fijar semilla para reproducibilidad
p_true = 0.7  # Probabilidad verdadera
n = 5000  # Tama√±o de muestra
x = (np.random.rand(n) < p_true).astype(float)  # Generar muestras Bernoulli

p_hat = float(np.mean(x))  # Estimar p mediante MLE (promedio)
assert abs(p_hat - p_true) < 0.02  # Verificar que estimaci√≥n sea cercana
```

---

### Ejercicio 4.5: PDF Gaussiana univariada (sanity check)

#### Enunciado

1) **B√°sico**

- Implementa la PDF de una normal `N(Œº,œÉ¬≤)`.

2) **Intermedio**

- Verifica que para `N(0,1)` en `x=0` la densidad ‚âà `0.39894228`.

3) **Avanzado**

- Verifica que `pdf(x)` es sim√©trica: `pdf(a) == pdf(-a)` cuando `Œº=0`.

#### Soluci√≥n

```python
import numpy as np  # Importar librer√≠a para computaci√≥n num√©rica

def gaussian_pdf(x: np.ndarray, mu: float, sigma: float) -> np.ndarray:  # Definir funci√≥n PDF gaussiana univariada
    x = np.asarray(x, dtype=float)  # Convertir x a array numpy
    sigma = float(sigma)  # Convertir sigma a float
    assert sigma > 0  # Verificar que sigma sea positivo
    z = (x - mu) / sigma  # Calcular z-score
    return (1.0 / (np.sqrt(2.0 * np.pi) * sigma)) * np.exp(-0.5 * z**2)  # Calcular PDF


val0 = gaussian_pdf(np.array([0.0]), mu=0.0, sigma=1.0)[0]  # Calcular PDF en x=0
assert np.isclose(val0, 0.39894228, atol=1e-4)  # Verificar valor ~1/‚àö(2œÄ)

a = 1.7  # Definir valor para prueba de simetr√≠a
assert np.isclose(  # Verificar simetr√≠a del PDF
    gaussian_pdf(np.array([a]), 0.0, 1.0)[0],  # PDF en x=a
    gaussian_pdf(np.array([-a]), 0.0, 1.0)[0],  # PDF en x=-a
    rtol=1e-12,  # Tolerancia relativa
    atol=1e-12,  # Tolerancia absoluta
)  # El PDF gaussiano es sim√©trico
```

---

### Ejercicio 4.6: Gaussiana multivariada (2D) + covarianza v√°lida

#### Enunciado

1) **B√°sico**

- Implementa la densidad `N(Œº, Œ£)` en 2D.

2) **Intermedio**

- Para `Œº=0` y `Œ£=I`, verifica que `pdf(0) = 1/(2œÄ)`.

3) **Avanzado**

- Verifica que `Œ£` es definida positiva (eigenvalores > 0) antes de invertir.

4) **Bonus (elipse de covarianza)**

- Para una matriz de covarianza no diagonal, genera puntos en la elipse de covarianza 2D para una escala `k` (por ejemplo, `k=2`) usando descomposici√≥n en eigenvalues/eigenvectors, y verifica que satisfacen `(x-Œº)^T Œ£^{-1} (x-Œº) ‚âà k^2`.

#### Soluci√≥n

```python
import numpy as np  # Importar librer√≠a para computaci√≥n num√©rica

def multivariate_gaussian_pdf(x: np.ndarray, mu: np.ndarray, cov: np.ndarray) -> float:  # Definir funci√≥n de densidad de probabilidad gaussiana multivariada
    x = np.asarray(x, dtype=float)  # Convertir x a array numpy
    mu = np.asarray(mu, dtype=float)  # Convertir mu a array numpy
    cov = np.asarray(cov, dtype=float)  # Convertir cov a array numpy
    d = x.shape[0]  # Obtener dimensi√≥n

    assert mu.shape == (d,)  # Verificar que mu tenga dimensi√≥n correcta
    assert cov.shape == (d, d)  # Verificar que cov sea matriz cuadrada
    assert np.allclose(cov, cov.T)  # Verificar que cov sea sim√©trica
    eigvals = np.linalg.eigvals(cov)  # Calcular eigenvalores
    assert np.all(eigvals > 0)  # Verificar que cov sea definida positiva

    diff = x - mu  # Calcular diferencia x - mu
    inv = np.linalg.inv(cov)  # Calcular inversa de cov
    det = np.linalg.det(cov)  # Calcular determinante de cov
    norm = 1.0 / (np.sqrt(((2.0 * np.pi) ** d) * det))  # Calcular factor de normalizaci√≥n
    expo = -0.5 * float(diff.T @ inv @ diff)  # Calcular exponente
    return float(norm * np.exp(expo))  # Devolver valor de PDF


mu = np.array([0.0, 0.0])  # Definir media
cov = np.eye(2)  # Definir covarianza (identidad)
pdf0 = multivariate_gaussian_pdf(np.array([0.0, 0.0]), mu, cov)  # Calcular PDF en origen
assert np.isclose(pdf0, 1.0 / (2.0 * np.pi), atol=1e-6)  # Verificar valor te√≥rico
assert pdf0 > 0.0  # Verificar que sea positivo

def covariance_ellipse_points(mu: np.ndarray, cov: np.ndarray, k: float = 2.0, n: int = 200) -> np.ndarray:  # Definir funci√≥n para generar puntos en elipse de covarianza
    mu = np.asarray(mu, dtype=float)  # Convertir mu a array numpy
    cov = np.asarray(cov, dtype=float)  # Convertir cov a array numpy
    assert mu.shape == (2,)  # Verificar que mu sea 2D
    assert cov.shape == (2, 2)  # Verificar que cov sea matriz 2x2
    assert np.allclose(cov, cov.T)  # Verificar que cov sea sim√©trica

    eigvals, eigvecs = np.linalg.eigh(cov)  # Calcular eigenvalores y eigenvectores
    assert np.all(eigvals > 0)  # Verificar que eigenvalores sean positivos

    t = np.linspace(0.0, 2.0 * np.pi, n, endpoint=False)  # Generar √°ngulos
    circle = np.stack([np.cos(t), np.sin(t)], axis=0)  # Crear c√≠rculo unitario

    transform = eigvecs @ np.diag(np.sqrt(eigvals))  # Crear matriz de transformaci√≥n
    pts = (mu.reshape(2, 1) + (k * transform @ circle)).T  # Transformar y trasladar puntos
    return pts  # Devolver puntos de la elipse


mu2 = np.array([0.0, 0.0])  # Definir media para elipse
cov2 = np.array([  # Definir covarianza no diagonal
    [2.0, 1.2],  # Varianza x=2.0, covarianza xy=1.2
    [1.2, 1.0],  # Covarianza yx=1.2, varianza y=1.0
], dtype=float)  # Matriz de covarianza 2x2
pts = covariance_ellipse_points(mu2, cov2, k=2.0, n=180)  # Generar puntos de elipse
inv2 = np.linalg.inv(cov2)  # Calcular inversa de covarianza

q = np.einsum('...i,ij,...j->...', pts - mu2, inv2, pts - mu2)  # Calcular forma cuadr√°tica
assert np.allclose(q, 4.0, atol=1e-6)  # Verificar que puntos satisfagan (x-Œº)^T Œ£^{-1} (x-Œº) ‚âà k^2
```

---

### Ejercicio 4.6B: Visualizaci√≥n (Gaussiana 2D variando covarianza) (OBLIGATORIO)

#### Enunciado

Construye una visualizaci√≥n que haga **visible** la covarianza:

1) **B√°sico**

- Crea un grid 2D y grafica contornos (`contour`) de `N(Œº, Œ£)`.

2) **Intermedio**

- Compara al menos 3 covarianzas:
  - isotr√≥pica (`Œ£ = I`)
  - el√≠ptica (varianzas distintas)
  - correlacionada (t√©rminos fuera de la diagonal)

3) **Avanzado**

- Sobre cada plot, dibuja la **elipse de covarianza** para `k=2` y verifica que sus puntos cumplen `(x-Œº)^T Œ£^{-1} (x-Œº) ‚âà k^2`.

#### Soluci√≥n

```python
import numpy as np  # NumPy: grid 2D, √°lgebra lineal y evaluaci√≥n vectorizada
import matplotlib.pyplot as plt  # Matplotlib: contornos 2D y trazado de elipses


def multivariate_gaussian_pdf_grid(xx: np.ndarray, yy: np.ndarray, mu: np.ndarray, cov: np.ndarray) -> np.ndarray:  # Definir funci√≥n para evaluar PDF en grid 2D
    # xx, yy: grids 2D (H,W) t√≠picamente creados con np.meshgrid
    xx = np.asarray(xx, dtype=float)  # Asegura dtype float para evitar ints en exp/log
    yy = np.asarray(yy, dtype=float)  # Mismo contrato: (H,W)
    mu = np.asarray(mu, dtype=float)  # mu:(2,) media 2D
    cov = np.asarray(cov, dtype=float)  # cov:(2,2) covarianza

    assert mu.shape == (2,)  # Sanidad: trabajamos en 2D
    assert cov.shape == (2, 2)  # Sanidad: covarianza 2D
    assert np.allclose(cov, cov.T)  # Debe ser sim√©trica

    eigvals = np.linalg.eigvalsh(cov)  # Eigenvalues reales para matriz sim√©trica (m√°s estable)
    assert np.all(eigvals > 0.0)  # Covarianza debe ser definida positiva (invertible)

    inv = np.linalg.inv(cov)  # Œ£^{-1} para la forma cuadr√°tica
    det = np.linalg.det(cov)  # |Œ£| para el coeficiente de normalizaci√≥n

    pos = np.dstack([xx, yy])  # pos:(H,W,2) apila coordenadas (x,y) en el √∫ltimo eje
    diff = pos - mu.reshape(1, 1, 2)  # diff:(H,W,2) resta Œº por broadcasting

    quad = np.einsum('...i,ij,...j->...', diff, inv, diff)  # (x-Œº)^T Œ£^{-1} (x-Œº) para cada punto del grid
    expo = -0.5 * quad  # Exponente de la Gaussiana

    norm = 1.0 / (2.0 * np.pi * np.sqrt(det))  # Normalizaci√≥n en 2D: 1 / (2œÄ sqrt(|Œ£|))
    pdf = norm * np.exp(expo)  # pdf:(H,W) densidad evaluada en el grid

    return pdf  # Devuelve matriz 2D lista para contour/contourf


def covariance_ellipse_points(mu: np.ndarray, cov: np.ndarray, k: float = 2.0, n: int = 200) -> np.ndarray:  # Definir funci√≥n para generar puntos en elipse de covarianza
    # Esta funci√≥n genera puntos sobre la elipse: (x-Œº)^T Œ£^{-1} (x-Œº) = k^2
    mu = np.asarray(mu, dtype=float)  # mu:(2,) asegura float
    cov = np.asarray(cov, dtype=float)  # cov:(2,2) asegura float

    assert mu.shape == (2,)  # Solo soportamos 2D para visualizaci√≥n
    assert cov.shape == (2, 2)  # Covarianza 2D
    assert np.allclose(cov, cov.T)  # Simetr√≠a

    eigvals, eigvecs = np.linalg.eigh(cov)  # Descomposici√≥n sim√©trica: cov = Q Œõ Q^T
    assert np.all(eigvals > 0.0)  # PD: eigenvalues positivos

    t = np.linspace(0.0, 2.0 * np.pi, n, endpoint=False)  # Par√°metro angular para un c√≠rculo unitario
    circle = np.stack([np.cos(t), np.sin(t)], axis=0)  # circle:(2,n) c√≠rculo unitario

    transform = eigvecs @ np.diag(np.sqrt(eigvals))  # Transformaci√≥n que mapea c√≠rculo -> elipse base (k=1)
    pts = (mu.reshape(2, 1) + (k * transform @ circle)).T  # pts:(n,2) traslada por Œº y escala por k

    return pts  # Puntos listos para plt.plot(pts[:,0], pts[:,1])


mu = np.array([0.0, 0.0], dtype=float)  # Œº:(2,) centramos en el origen para comparar solo Œ£

covs = [  # Definir lista de matrices de covarianza para visualizar
    np.eye(2, dtype=float),  # Œ£1: isotr√≥pica (c√≠rculo)
    np.array([[3.0, 0.0], [0.0, 1.0]], dtype=float),  # Œ£2: el√≠ptica (varianza distinta por eje)
    np.array([[2.0, 1.2], [1.2, 1.0]], dtype=float),  # Œ£3: correlacionada (t√©rmino fuera de diagonal)
]  # Lista de covarianzas a comparar

labels = [  # Definir etiquetas para los subgr√°ficos
    "Œ£ = I (isotr√≥pica)",  # Texto para subplot 1
    "Œ£ = diag(3,1) (el√≠ptica)",  # Texto para subplot 2
    "Œ£ con correlaci√≥n (elipse rotada)",  # Texto para subplot 3
]  # Etiquetas

grid = np.linspace(-4.0, 4.0, 250)  # Rejilla 1D para construir el grid 2D
xx, yy = np.meshgrid(grid, grid)  # xx,yy:(H,W) coordenadas del plano

fig, axes = plt.subplots(1, 3, figsize=(15, 4), constrained_layout=True)  # 1 fila, 3 columnas

for ax, cov, title in zip(axes, covs, labels):  # Iteramos por cada Œ£ y su eje
    Z = multivariate_gaussian_pdf_grid(xx, yy, mu, cov)  # Z:(H,W) densidad en el plano

    ax.contour(xx, yy, Z, levels=10)  # Contornos: l√≠neas de igual densidad

    pts = covariance_ellipse_points(mu, cov, k=2.0, n=240)  # pts:(n,2) elipse k=2
    ax.plot(pts[:, 0], pts[:, 1])  # Dibuja la elipse encima de los contornos

    inv = np.linalg.inv(cov)  # Œ£^{-1} para verificar la ecuaci√≥n cuadr√°tica
    q = np.einsum('...i,ij,...j->...', pts - mu, inv, pts - mu)  # q:(n,) valor de (x-Œº)^T Œ£^{-1} (x-Œº)
    assert np.allclose(q, 4.0, atol=1e-6)  # Debe ser ‚âà k^2 = 4 si la elipse es correcta

    ax.set_title(title)  # T√≠tulo por subplot
    ax.set_aspect('equal', 'box')  # Aspect ratio 1:1 para que la elipse no se distorsione
    ax.set_xlabel('x1')  # Eje x
    ax.set_ylabel('x2')  # Eje y

plt.savefig('gaussian_covariance_contours.png', dpi=160)  # Guarda la figura (√∫til para reportes)
```

---

### Ejercicio 4.7: Log-Sum-Exp y log-softmax estable (OBLIGATORIO)

#### Enunciado

1) **B√°sico**

- Implementa `logsumexp(z)` de forma estable (restando `max(z)`).

2) **Intermedio**

- Implementa `log_softmax(z) = z - logsumexp(z)`.

3) **Avanzado**

- Verifica que `sum(exp(log_softmax(z))) == 1` y que no hay `inf` con logits grandes.

#### Soluci√≥n

```python
import numpy as np  # NumPy: arrays, exp/log y validaci√≥n num√©rica

def logsumexp(z: np.ndarray) -> float:  # Definir funci√≥n log-sum-exp num√©ricamente estable
    z = np.asarray(z, dtype=float)  # Asegura float para que exp/log sean num√©ricamente consistentes
    m = np.max(z)  # m = max(z) sirve como ‚Äúancla‚Äù para evitar overflow en exp
    return float(m + np.log(np.sum(np.exp(z - m))))  # Log-Sum-Exp: m + log(sum(exp(z-m)))


def log_softmax(z: np.ndarray) -> np.ndarray:  # Definir funci√≥n log-softmax num√©ricamente estable
    z = np.asarray(z, dtype=float)  # Asegura float y copia segura
    return z - logsumexp(z)  # log_softmax(z) = z - log(sum(exp(z)))


z = np.array([1000.0, 0.0, -1000.0])  # Logits extremos para estresar estabilidad num√©rica
lsm = log_softmax(z)  # lsm:(3,) log-probabilidades estables
probs = np.exp(lsm)  # Convertimos a probabilidades (deben ser finitas)
assert np.isfinite(lsm).all()  # No debe haber NaN/inf en log-probabilidades
assert np.isfinite(probs).all()  # No debe haber NaN/inf en probabilidades
assert np.isclose(np.sum(probs), 1.0)  # Las probabilidades deben sumar 1
```

#### Soluci√≥n (NaN trap: naive vs estable + verificaci√≥n) (OBLIGATORIO)

```python
import numpy as np  # NumPy: exp/log y validaci√≥n num√©rica
import warnings  # warnings: suprimir warnings esperados en el caso na√Øve (overflow)


def softmax_naive(z: np.ndarray) -> np.ndarray:  # Implementaci√≥n ingenua (propensa a overflow/underflow)
    z = np.asarray(z, dtype=float)  # Asegura float para que exp opere en floats
    exp_z = np.exp(z)  # ¬°Peligro! exp(1000) -> inf (overflow)
    return exp_z / np.sum(exp_z)  # Normaliza (pero si hay inf/0 puede producir NaN)


def softmax_stable(z: np.ndarray) -> np.ndarray:  # Softmax estable: aplica el Log-Sum-Exp trick
    z = np.asarray(z, dtype=float)  # Convierte a float (contrato)
    z_shift = z - np.max(z)  # Restar max(z) no cambia softmax pero evita overflow
    exp_z = np.exp(z_shift)  # Ahora exp() recibe valores <= 0 (seguro)
    return exp_z / np.sum(exp_z)  # Normaliza para que sum(p)=1


z_big = np.array([1000.0, 1001.0, 1002.0])  # Logits peligrosos (magnitudes enormes)

with warnings.catch_warnings():  # Contexto para que el notebook/terminal no se llene de warnings
    warnings.simplefilter("ignore")  # Suprimimos RuntimeWarning por overflow (esperado aqu√≠)
    p_naive = softmax_naive(z_big)  # Resultado ingenuo (t√≠picamente NaN)

naive_ok = np.isfinite(p_naive).all() and np.isclose(np.sum(p_naive), 1.0)  # Criterio de ‚Äúdistribuci√≥n v√°lida‚Äù
assert not naive_ok  # Debe fallar: aqu√≠ demostramos el NaN/inf trap

p_stable = softmax_stable(z_big)  # Softmax estable (debe funcionar)
assert np.isfinite(p_stable).all()  # No debe haber NaN/inf
assert np.isclose(np.sum(p_stable), 1.0)  # Debe sumar 1
assert np.argmax(p_stable) == np.argmax(z_big)  # Debe preservar el orden de logits
```

---

### Ejercicio 4.8: Softmax estable (invariancia a constantes)

#### Enunciado

1) **B√°sico**

- Implementa softmax estable: `exp(z-max)/sum(exp(z-max))`.

2) **Intermedio**

- Verifica que suma 1.

3) **Avanzado**

- Verifica invariancia: `softmax(z) == softmax(z + c)`.

#### Soluci√≥n

```python
import numpy as np  # Importar librer√≠a para computaci√≥n num√©rica

def softmax(z: np.ndarray) -> np.ndarray:  # Definir funci√≥n softmax
    z = np.asarray(z, dtype=float)  # Convertir a array numpy
    z_shift = z - np.max(z)  # Restar m√°ximo para estabilidad num√©rica
    expz = np.exp(z_shift)  # Calcular exponenciales
    return expz / np.sum(expz)  # Normalizar para que sume 1


z = np.array([2.0, 1.0, 0.0])  # Definir logits
p = softmax(z)  # Calcular softmax
assert np.isclose(np.sum(p), 1.0)  # Verificar que sume 1

c = 100.0  # Definir constante grande
p2 = softmax(z + c)  # Calcular softmax con constante a√±adida
assert np.allclose(p, p2)  # Verificar invarianza a constante
assert np.argmax(p) == np.argmax(z)  # Verificar que preserva orden
```

---

### Ejercicio 4.9: Binary Cross-Entropy estable (evitar log(0))

#### Enunciado

1) **B√°sico**

- Implementa BCE: `-mean(y log(p) + (1-y) log(1-p))`.

2) **Intermedio**

- Usa `clip`/`epsilon` para evitar `log(0)`.

3) **Avanzado**

- Verifica:
  - BCE cerca de 0 para predicciones casi perfectas.
  - BCE ‚âà `-log(0.9)` cuando `y=1` y `p=0.9`.

#### Soluci√≥n

```python
import numpy as np  # Importar librer√≠a para computaci√≥n num√©rica

def binary_cross_entropy(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-15) -> float:  # Definir funci√≥n de entrop√≠a cruzada binaria
    y_true = np.asarray(y_true, dtype=float)  # Convertir y_true a array numpy
    y_pred = np.asarray(y_pred, dtype=float)  # Convertir y_pred a array numpy
    y_pred = np.clip(y_pred, eps, 1.0 - eps)  # Clipping para evitar log(0) y log(1)
    return float(-np.mean(y_true * np.log(y_pred) + (1.0 - y_true) * np.log(1.0 - y_pred)))  # Calcular BCE


y_true = np.array([1.0, 0.0, 1.0, 0.0])  # Definir etiquetas verdaderas
y_pred_good = np.array([0.999, 0.001, 0.999, 0.001])  # Definir predicciones buenas
assert binary_cross_entropy(y_true, y_pred_good) < 0.01  # Verificar que p√©rdida sea peque√±a

assert np.isclose(binary_cross_entropy(np.array([1.0]), np.array([0.9])), -np.log(0.9), atol=1e-12)  # Verificar caso simple
```

---

### Ejercicio 4.10: Categorical Cross-Entropy (multiclase) + one-hot

#### Enunciado

1) **B√°sico**

- Implementa CCE: `-mean(sum(y_true * log(y_pred)))`.

2) **Intermedio**

- Asegura que `y_pred` no contiene ceros (epsilon).

3) **Avanzado**

- Verifica que el loss baja cuando aumenta la probabilidad de la clase correcta.

#### Soluci√≥n

```python
import numpy as np  # Importar librer√≠a para computaci√≥n num√©rica

def categorical_cross_entropy(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-15) -> float:  # Definir funci√≥n de entrop√≠a cruzada categ√≥rica
    y_true = np.asarray(y_true, dtype=float)  # Convertir y_true a array numpy
    y_pred = np.asarray(y_pred, dtype=float)  # Convertir y_pred a array numpy
    y_pred = np.clip(y_pred, eps, 1.0)  # Clipping para evitar log(0)
    return float(-np.mean(np.sum(y_true * np.log(y_pred), axis=1)))  # Calcular p√©rdida promedio


y_true = np.array([[0, 1, 0], [1, 0, 0]], dtype=float)  # Definir etiquetas verdaderas (one-hot)
y_pred_bad = np.array([[0.34, 0.33, 0.33], [0.34, 0.33, 0.33]], dtype=float)  # Predicciones malas (casi uniformes)
y_pred_good = np.array([[0.05, 0.90, 0.05], [0.90, 0.05, 0.05]], dtype=float)  # Predicciones buenas (confiadas)

loss_bad = categorical_cross_entropy(y_true, y_pred_bad)  # Calcular p√©rdida para predicciones malas
loss_good = categorical_cross_entropy(y_true, y_pred_good)  # Calcular p√©rdida para predicciones buenas
assert loss_good < loss_bad  # Verificar que mejores predicciones tengan menor p√©rdida
```

---

### (Bonus) Ejercicio 4.11: Cadena de Markov (matriz de transici√≥n)

#### Enunciado

1) **B√°sico**

- Define una matriz de transici√≥n `P` (filas suman 1).

2) **Intermedio**

- Propaga una distribuci√≥n `œÄ_{t+1} = œÄ_t P` y verifica que sigue siendo distribuci√≥n.

3) **Avanzado**

- Encuentra una distribuci√≥n estacionaria aproximada iterando muchas veces y verifica `œÄ ‚âà œÄP`.

4) **Bonus (potencias de matrices)**

- Verifica que iterar `œÄ_{t+1} = œÄ_t P` por `k` pasos coincide con `œÄ_t P^k` usando `np.linalg.matrix_power`.

#### Soluci√≥n

```python
import numpy as np  # Importar librer√≠a para computaci√≥n num√©rica

P = np.array([  # Definir matriz de transici√≥n
    [0.9, 0.1],  # De estado 0: 90% queda en 0, 10% va a 1
    [0.2, 0.8],  # De estado 1: 20% va a 0, 80% queda en 1
], dtype=float)  # Matriz 2x2 de probabilidades
assert np.allclose(P.sum(axis=1), 1.0)  # Verificar que filas sumen 1

k = 50  # N√∫mero de pasos
pi0 = np.array([1.0, 0.0])  # Distribuci√≥n inicial
pi = pi0.copy()  # Copiar distribuci√≥n inicial
for _ in range(k):  # Iterar k pasos
    pi = pi @ P  # Actualizar distribuci√≥n
    assert np.isclose(np.sum(pi), 1.0)  # Verificar que sume 1
    assert np.all(pi >= 0)  # Verificar que sea no negativa

pi_power = pi0 @ np.linalg.matrix_power(P, k)  # Calcular directamente
assert np.allclose(pi, pi_power, atol=1e-12)  # Verificar equivalencia

pi_star = pi.copy()  # Guardar distribuci√≥n estacionaria
assert np.allclose(pi_star, pi_star @ P, atol=1e-6)  # Verificar estacionariedad
```

## üî® Entregables del M√≥dulo

### E1: `probability.py`

```python
"""
M√≥dulo de probabilidad esencial para ML.
Implementaciones desde cero con NumPy.
"""

import numpy as np  # Importar librer√≠a para computaci√≥n num√©rica
from typing import Tuple  # Importar tipo para tuplas

def gaussian_pdf(x: np.ndarray, mu: float, sigma: float) -> np.ndarray:  # Definir funci√≥n PDF gaussiana univariada
    """Densidad de probabilidad Gaussiana univariada."""
    pass  # Implementar

def multivariate_gaussian_pdf(x: np.ndarray,  # Definir funci√≥n PDF gaussiana multivariada
                               mu: np.ndarray,  # Vector de medias
                               cov: np.ndarray) -> float:  # Matriz de covarianza
    """Densidad de probabilidad Gaussiana multivariada."""
    pass  # Implementar

def mle_gaussian(data: np.ndarray) -> Tuple[float, float]:  # Definir funci√≥n MLE para gaussiana
    """Estimaci√≥n MLE de par√°metros de Gaussiana."""
    pass  # Implementar

def softmax(z: np.ndarray) -> np.ndarray:  # Definir funci√≥n softmax
    """Funci√≥n softmax num√©ricamente estable."""
    pass  # Implementar

def cross_entropy(y_true: np.ndarray, y_pred: np.ndarray) -> float:  # Definir funci√≥n de entrop√≠a cruzada
    """Binary cross-entropy loss."""
    pass  # Implementar

def categorical_cross_entropy(y_true: np.ndarray,  # Definir funci√≥n de entrop√≠a cruzada categ√≥rica
                               y_pred: np.ndarray) -> float:  # Predicciones de probabilidad
    """Categorical cross-entropy loss para multiclase."""
    pass  # Implementar
```

### E2: Tests

```python
# tests/test_probability.py
import numpy as np  # Importar librer√≠a para computaci√≥n num√©rica
import pytest  # Importar framework de testing
from src.probability import (  # Importar funciones a probar
    gaussian_pdf, mle_gaussian, softmax,  # Funciones de probabilidad
    cross_entropy, categorical_cross_entropy  # Funciones de p√©rdida
)  # Cerrar importaci√≥n

def test_gaussian_pdf_standard():  # Definir test para PDF gaussiano est√°ndar
    """PDF de Gaussiana est√°ndar en x=0 debe ser ~0.3989."""
    result = gaussian_pdf(np.array([0.0]), mu=0, sigma=1)  # Calcular PDF en x=0
    expected = 1 / np.sqrt(2 * np.pi)  # ~0.3989  # Valor esperado
    assert np.isclose(result[0], expected, rtol=1e-5)  # Verificar coincidencia

def test_softmax_sums_to_one():  # Definir test para suma de softmax
    """Softmax debe sumar 1."""
    z = np.random.randn(10)  # Generar logits aleatorios
    probs = softmax(z)  # Calcular softmax
    assert np.isclose(np.sum(probs), 1.0)  # Verificar que suma sea 1

def test_softmax_preserves_order():  # Definir test para orden de softmax
    """Mayor logit ‚Üí mayor probabilidad."""
    z = np.array([1.0, 2.0, 3.0])  # Definir logits ordenados
    probs = softmax(z)  # Calcular softmax
    assert probs[2] > probs[1] > probs[0]  # Verificar orden preservado

def test_mle_gaussian_accuracy():  # Definir test para MLE gaussiano
    """MLE debe recuperar par√°metros con suficientes datos."""
    np.random.seed(42)  # Fijar semilla para reproducibilidad
    true_mu, true_sigma = 10.0, 3.0  # Definir par√°metros verdaderos
    data = np.random.normal(true_mu, true_sigma, size=10000)  # Generar datos

    est_mu, est_sigma = mle_gaussian(data)  # Estimar par√°metros

    assert np.isclose(est_mu, true_mu, rtol=0.05)  # Verificar media estimada
    assert np.isclose(est_sigma, true_sigma, rtol=0.05)  # Verificar sigma estimado

def test_cross_entropy_perfect_prediction():  # Definir test para entrop√≠a cruzada
    """CE debe ser ~0 para predicciones perfectas."""
    y_true = np.array([1, 0, 1])  # Definir etiquetas verdaderas
    y_pred = np.array([0.999, 0.001, 0.999])  # Definir predicciones casi perfectas

    loss = cross_entropy(y_true, y_pred)  # Calcular p√©rdida
    assert loss < 0.01  # Verificar que p√©rdida sea peque√±a
```

---

## üìä Resumen Visual

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PROBABILIDAD PARA ML - MAPA CONCEPTUAL                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  TEOREMA DE BAYES                                               ‚îÇ
‚îÇ       ‚îÇ                                                         ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ Naive Bayes Classifier (M√≥dulo 05)                   ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚ñ∫ Intuici√≥n de posterior vs prior                      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  DISTRIBUCI√ìN GAUSSIANA                                         ‚îÇ
‚îÇ       ‚îÇ                                                         ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ GMM en Unsupervised (M√≥dulo 06)                      ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ Inicializaci√≥n de pesos en DL (M√≥dulo 07)            ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚ñ∫ Normalizaci√≥n de datos                               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  MAXIMUM LIKELIHOOD (MLE)                                       ‚îÇ
‚îÇ       ‚îÇ                                                         ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ Cross-Entropy Loss (Logistic Regression)             ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ Categorical CE (Softmax + Multiclase)                ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚ñ∫ EM Algorithm en GMM                                  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  SOFTMAX                                                        ‚îÇ
‚îÇ       ‚îÇ                                                         ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚ñ∫ Capa de salida en clasificaci√≥n multiclase           ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîó Conexiones con Otros M√≥dulos

| Concepto | D√≥nde se usa |
|----------|--------------|
| Teorema de Bayes | Naive Bayes en M√≥dulo 05 |
| Gaussiana | GMM en M√≥dulo 06, inicializaci√≥n en M√≥dulo 07 |
| MLE | Derivaci√≥n de Cross-Entropy en M√≥dulo 05 |
| Softmax | Capa de salida en M√≥dulo 07 |
| Cross-Entropy | Loss function principal en M√≥dulo 05 y 07 |

---

## üß© Consolidaci√≥n (errores comunes + debugging v5 + reto Feynman)

### Errores comunes

- **Confundir PDF con probabilidad:** en continuas, `f(x)` es densidad; la probabilidad requiere integrar en un intervalo.
- **`log(0)` en cross-entropy:** siempre usa `epsilon` o `np.clip`.
- **Overflow/underflow en `exp`:** aplica log-sum-exp / log-softmax.
- **MLE ‚Äúm√°gico‚Äù:** si no puedes explicar por qu√© aparece la media, repite el worked example Bernoulli.

### Debugging / validaci√≥n (v5)

- Cuando algo explote con `nan/inf`, revisa:
  - `np.log` sobre valores 0
  - `np.exp` sobre logits grandes
  - normalizaci√≥n incorrecta en probabilidades (que no suman 1)
- Registra hallazgos en `study_tools/DIARIO_ERRORES.md`.
- Protocolos completos:
  - [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md)
  - [PLAN_V5_ESTRATEGICO.md](PLAN_V5_ESTRATEGICO.md)

### Reto Feynman (tablero blanco)

Explica en 5 l√≠neas o menos:

1) ¬øPor qu√© maximizar likelihood es equivalente a minimizar negative log-likelihood?
2) ¬øPor qu√© el MLE de una moneda es ‚Äúproporci√≥n de caras‚Äù?
3) ¬øQu√© significa `œÄ_{t+1} = œÄ_t P` y por qu√© es √°lgebra lineal?

## ‚úÖ Checklist del M√≥dulo

- [ ] Puedo explicar el Teorema de Bayes con un ejemplo
- [ ] S√© calcular la PDF de una Gaussiana a mano
- [ ] Entiendo por qu√© MLE da Cross-Entropy como loss
- [ ] Puedo explicar entrop√≠a y por qu√© `cross-entropy = H(y) + KL(y||p)`
- [ ] Puedo derivar por qu√© minimizar `KL(p_data||p_Œ∏)` equivale a maximizar log-likelihood
- [ ] Implement√© softmax num√©ricamente estable
- [ ] Puedo derivar el MLE de una Bernoulli (moneda) y explicarlo
- [ ] Puedo explicar qu√© es una Markov Chain y qu√© representa una matriz de transici√≥n
- [ ] Ejecut√© `scripts/gmm_3_gaussians_contours.py` y entiendo los contornos de componentes vs mezcla
- [ ] Los tests de `probability.py` pasan

---

## üìñ Recursos Adicionales

### Videos
- [3Blue1Brown - Bayes Theorem](https://www.youtube.com/watch?v=HZGCoVF3YvM)
- [StatQuest - Maximum Likelihood](https://www.youtube.com/watch?v=XepXtl9YKwc)
- [StatQuest - Gaussian Distribution](https://www.youtube.com/watch?v=rzFX5NWojp0)

### Lecturas
- Mathematics for ML, Cap. 6 (Probability)
- Pattern Recognition and ML (Bishop), Cap. 1-2

---

> üí° **Nota Final:** Este m√≥dulo sigue siendo compacto comparado con un curso completo de probabilidad/estad√≠stica, pero aqu√≠ ya tienes el n√∫cleo de L√≠nea 1 y una ‚Äúsemilla‚Äù intencional para L√≠nea 2 (estimaci√≥n y Markov Chains).

---

**[‚Üê M√≥dulo 03: C√°lculo](03_CALCULO_MULTIVARIANTE.md)** | **[M√≥dulo 05: Supervised Learning ‚Üí](05_SUPERVISED_LEARNING.md)**
