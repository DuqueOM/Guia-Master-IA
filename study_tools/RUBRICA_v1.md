# ðŸ“ RÃºbrica de EvaluaciÃ³n (v1.0)

> Objetivo: evaluar entregables y simulacros con criterios consistentes, para calibrar â€œquÃ© tan listo estoyâ€ y detectar brechas temprano.

---

## ðŸ‘¥ Roles de evaluaciÃ³n

- **Autoevaluador (estudiante):** scoring semanal rÃ¡pido + scoring completo en checkpoints.
- **Revisor IA/pareja:** revisiÃ³n de cÃ³digo + scoring preliminar (ver `prompts/AI_CODE_REVIEWER.md`).
- **Mentor externo (si disponible):** validaciÃ³n en checkpoints grandes (ideal: PB-16 y PB-23).

---

## ðŸ§® Estructura general (100 puntos)

Puntaje base: **95 pts** + **5 pts bonus** (opcional) = **100**.

- **A. Dominio TeÃ³rico** â€” 25 pts
- **B. ImplementaciÃ³n & Calidad de CÃ³digo** â€” 25 pts
- **C. EvaluaciÃ³n en Simulacros (PB)** â€” 20 pts
- **D. Proyecto & DocumentaciÃ³n CientÃ­fica** â€” 15 pts
- **E. PrÃ¡cticas Metacognitivas y Proceso** â€” 10 pts
- **Bonus (badges/challenges)** â€” 5 pts

---

## ðŸ“Œ Niveles por criterio

Cada criterio se evalÃºa con 4 niveles. Regla de conversiÃ³n sugerida:

- **Exceeds**: 100% del subpeso
- **Meets**: 75% del subpeso
- **Approaching**: 50% del subpeso
- **Not met**: 0â€“25% del subpeso

**Evidencia requerida:** archivos, tests (`pytest`), checks de calidad (`pre-commit`), notebooks, docs, y entregables de proceso (p.ej. `DIRTY_DATA_CHECK`).

---

## ðŸš« Condiciones duras (no negociables)

- **PB-23 â‰¥ 80/100**: requisito para marcar estado **â€œListo para admisiÃ³nâ€**.
- **Entregables de cÃ³digo**: tests unitarios pasan + `pre-commit` pasa.
- **Dirty Data Check**: obligatorio en **MÃ³dulo 01** (Caso 1) y **MÃ³dulo 05** (Caso 2).

---

## ðŸ—“ï¸ CuÃ¡ndo aplicar la rÃºbrica (cronograma)

- **Semana 0 (preparaciÃ³n):** crea y calibra rÃºbrica con 1 entregable pequeÃ±o.
- **Semanas 1â€“8:** scoring rÃ¡pido semanal (en el cierre) + scoring de **PB-8**.
- **Semanas 9â€“20:** scoring completo al cierre de mÃ³dulos (**Semanas 12, 16, 20**) + scoring de **PB-16**.
- **Semanas 21â€“24:** scoring del proyecto MNIST + scoring de PB-23 (examen simulado).

---

## ðŸ§¾ Plantilla de scoring rÃ¡pido (cierre semanal)

Usa esto durante `study_tools/CIERRE_SEMANAL.md`.

```text
SEMANA: __
MÃ“DULO: __

A (TeorÃ­a) __/25
B (CÃ³digo) __/25
C (Simulacros) __/20
D (Proyecto) __/15
E (Proceso) __/10
BONUS __/5

TOTAL: __/100
ESTADO: [AÃºn no listo | En progreso | Listo]  (si PB-23 >=80)
TOP 3 BRECHAS: 1) __ 2) __ 3) __
```

---

## ðŸ§© Ejemplo granular â€” MÃ³dulo 05 (Supervised Learning)

Peso sugerido dentro de una evaluaciÃ³n de mÃ³dulo: **12 pts** (repartidos en A/B/C/E).

### A1. DerivaciÃ³n matemÃ¡tica (MSE / logÃ­stica) â€” 4 pts

- **Exceeds (4):** deriva MSE y cross-entropy paso a paso, explica supuestos, responde preguntas de seguimiento.
- **Meets (3):** derivaciÃ³n correcta con 1 error menor de notaciÃ³n.
- **Approaching (2):** conceptos entendidos, faltan pasos o error no crÃ­tico.
- **Not met (0â€“1):** no puede derivar o hay errores conceptuales.

### B1. ImplementaciÃ³n NumPy sin sklearn (logistic_regression.py) â€” 4 pts

- **Exceeds (4):** type hints, tests (edge cases), vectorizado, `pre-commit` ok.
- **Meets (3):** implementaciÃ³n correcta con faltantes menores.
- **Approaching (2):** funciona en casos simples pero falla en corner cases / shapes.
- **Not met (0â€“1):** no funciona o usa sklearn.

### C1. ValidaciÃ³n / Metrics / CV â€” 2 pts

- **Exceeds (2):** K-fold CV + learning curves + interpretaciÃ³n de bias-variance.
- **Meets (1.5):** CV correcto + documentaciÃ³n breve.
- **Approaching (1):** solo train/test.
- **Not met (0):** sin evaluaciÃ³n.

### E1. Dirty Data Check aplicado â€” 2 pts

- Evidencia: `study_tools/DIRTY_DATA_CHECK.md` (Caso 2).

---

## ðŸ§  Ejemplo granular â€” Proyecto Final â€œMNIST Analystâ€

Peso sugerido del proyecto: **25 pts** (agregando D/B/C).

### D1. Pipeline end-to-end reproducible â€” 8 pts

- **Exceeds (8):** pipeline reproducible + scripts + README en inglÃ©s + tests.
- **Meets (6):** pipeline y notebooks legibles + README mÃ­nimo.
- **Approaching (4):** pipeline incompleto o pasos manuales.
- **Not met (0â€“2):** no reproducible.

### B2. Calidad del cÃ³digo â€” 6 pts

- Evidencia: type hints, docstrings, `mypy`, tests, `pre-commit`.

### C2. Resultados / MÃ©tricas â€” 6 pts

- **Exceeds (6):** MLP > 92% y Logistic > 87% + anÃ¡lisis.
- **Meets (5):** MLP â‰¥ 90%, Logistic â‰¥ 85%.
- **Approaching (3):** MLP 85â€“90%, Logistic 80â€“85%.
- **Not met (0):** no alcanzadas.

### E2. Informe MODEL_COMPARISON.md â€” 5 pts

- **Exceeds (5):** anÃ¡lisis profundo + error analysis + grÃ¡ficos + conclusiones.
- **Meets (4):** comparativa correcta y conclusiones.
- **Approaching (2):** superficial.
- **Not met (0):** faltante.

---

## ðŸ§· Regla de admisiÃ³n (PB-23)

- Si **PB-23 < 80**, el estado es **â€œAÃºn no listoâ€** aunque el total global sea alto.
- Evidencia: scoring registrado (p.ej. en un reporte generado desde `rubrica.csv`).
