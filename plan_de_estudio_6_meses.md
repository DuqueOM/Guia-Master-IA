# ðŸ“… Plan de Estudio: 6 Meses para el MS-AI Pathway

> **DuraciÃ³n Total:** 24 semanas (~864 horas)
> **Ritmo:** 6 horas/dÃ­a, Lunes a SÃ¡bado
> **FilosofÃ­a:** From Scratch â†’ Production Ready â†’ ComunicaciÃ³n CientÃ­fica

---

## ðŸ—“ï¸ Cronograma General

| Fase | Semanas | MÃ³dulos | Enfoque | Cursos Alineados |
|------|---------|---------|---------|------------------|
| **FUNDAMENTOS** | 1-8 | M01-M04 | Python + MatemÃ¡ticas | â€” |
| **ML CORE** | 9-20 | M05-M07 | Algoritmos del Pathway â­ | CSCA 5622, 5632, 5642 |
| **CAPSTONE** | 21-24 | M08 | NLP Disaster Tweets ðŸŽ¯ | IntegraciÃ³n total |

---

## ðŸ“˜ FASE 1: FUNDAMENTOS (Semanas 1-8)

### Semanas 1-2: M01 - Python CientÃ­fico

| DÃ­a | Actividad | DuraciÃ³n | Entregable |
|-----|-----------|----------|------------|
| L-M | TeorÃ­a NumPy/Pandas | 12h | Notas en papel |
| X-J | Notebooks prÃ¡cticos | 12h | Scripts funcionando |
| V | Romper cosas (edge cases) | 6h | Diario de errores |
| S | Simulacro + Cierre | 6h | Checklist completado |

**Laboratorios Interactivos:**
- `M01_Fundamentos_Python/Laboratorios_Interactivos/`

---

### Semanas 3-5: M02 - Ãlgebra Lineal para ML

| Semana | Tema | Conceptos Clave |
|--------|------|-----------------|
| 3 | Vectores y Matrices | Dot product, normas, proyecciones |
| 4 | Transformaciones Lineales | Eigenvalues, determinantes |
| 5 | SVD y Aplicaciones | CompresiÃ³n, PCA numÃ©rico |

**Laboratorios Interactivos:**
```bash
streamlit run M02_Algebra_Lineal/Laboratorios_Interactivos/transformacion_lineal_app.py
manim -pqh M02_Algebra_Lineal/Laboratorios_Interactivos/animacion_matriz.py AnimacionMatriz
```

---

### Semanas 6-7: M03 - CÃ¡lculo y OptimizaciÃ³n

| Semana | Tema | Conceptos Clave |
|--------|------|-----------------|
| 6 | Derivadas y Gradientes | Parciales, Chain Rule |
| 7 | Gradient Descent | Learning rate, convergencia |

**Laboratorios Interactivos:**
```bash
streamlit run M03_Calculo_Optimizacion/Laboratorios_Interactivos/viz_gradient_3d.py
```

---

### Semana 8: M04 - Probabilidad y EstadÃ­stica

| DÃ­a | Tema | Conceptos Clave |
|-----|------|-----------------|
| L-M | Teorema de Bayes | Prior, Likelihood, Posterior |
| X-J | Distribuciones | Gaussiana, Bernoulli |
| V-S | MLE y Cross-Entropy | ConexiÃ³n con Loss Functions |

**Laboratorios Interactivos:**
```bash
python M04_Probabilidad_Estadistica/Laboratorios_Interactivos/gmm_3_gaussians_contours.py
```

---

## â­ FASE 2: ML CORE - PATHWAY (Semanas 9-20)

### Semanas 9-11: M05 - Aprendizaje Supervisado (CSCA 5622)

| Semana | Tema | ImplementaciÃ³n | Novedad |
|--------|------|----------------|---------|
| 9 | RegresiÃ³n Lineal | Normal Equation + GD | **+ Paridad Sklearn** |
| 10 | RegresiÃ³n LogÃ­stica + Ãrboles | Cross-Entropy, Decision Trees | **+ `sklearn.tree`** |
| 11 | **Ã‰tica IA & XAI** ðŸ†• | SHAP, LIME, Bias/Fairness | Interpretabilidad |

**Laboratorios Interactivos:**
```bash
streamlit run M05_Aprendizaje_Supervisado/Laboratorios_Interactivos/overfitting_bias_variance_app.py
streamlit run M05_Aprendizaje_Supervisado/Laboratorios_Interactivos/shap_explainer_app.py  # NUEVO
```

**Entregables:**
- [ ] `logistic_regression.py` con tests (from scratch)
- [ ] Notebook de paridad: resultados manuales == sklearn
- [ ] AnÃ¡lisis SHAP de un modelo Random Forest
- [ ] Documento de reflexiÃ³n Ã©tica (500 palabras)

---

### Semanas 12-15: M06 - Aprendizaje No Supervisado (CSCA 5632)

| Semana | Tema | ImplementaciÃ³n | Novedad |
|--------|------|----------------|---------|
| 12 | K-Means | Lloyd's algorithm, K-Means++ | Silhouette Score |
| 13 | PCA | SVD, varianza explicada | t-SNE/UMAP |
| 14 | GMM | Algoritmo EM | Latent variables |
| 15 | **Sistemas de RecomendaciÃ³n** ðŸ†• | SVD, FactorizaciÃ³n Matrices | **MovieLens** |

**Laboratorios Interactivos:**
```bash
streamlit run M06_Aprendizaje_No_Supervisado/Laboratorios_Interactivos/pca_rotation_plotly_app.py
streamlit run M06_Aprendizaje_No_Supervisado/Laboratorios_Interactivos/movie_recommender_app.py  # NUEVO
```

**Entregables:**
- [ ] `kmeans.py` y `pca.py` con tests
- [ ] `gmm.py` con algoritmo EM
- [ ] **`movie_recommender.py` usando SVD** (CRÃTICO para CSCA 5632)
- [ ] AnÃ¡lisis completo MovieLens con mÃ©tricas (RMSE, Precision@K)

---

### Semanas 16-20: M07 - Deep Learning (CSCA 5642)

> âš ï¸ **Stack Principal: Keras/TensorFlow** (alineado con curso oficial)
> PyTorch disponible en `Advanced_Track_PyTorch/` como track opcional.

| Semana | Tema | ImplementaciÃ³n | Framework |
|--------|------|----------------|-----------|
| 16 | PerceptrÃ³n y MLP | Forward pass, Backprop manual | NumPy |
| 17 | **Keras APIs** | Sequential + **Funcional** ðŸ”‘ | tf.keras |
| 18 | CNNs | Conv2D, MaxPooling2D, Flatten | Keras |
| 19 | RNNs/LSTM | LSTM, GRU, Bidirectional, Embedding | Keras |
| 20 | RegularizaciÃ³n | Dropout, EarlyStopping, Transfer Learning | Keras |

**Laboratorios Interactivos:**
```bash
streamlit run M07_Deep_Learning/Laboratorios_Interactivos/keras_training_playground_app.py
streamlit run M07_Deep_Learning/Laboratorios_Interactivos/cnn_filter_visualization_app.py
```

**CÃ³digo CrÃ­tico - API Funcional de Keras:**
```python
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.models import Model

inputs = Input(shape=(784,))
x = Dense(256, activation='relu')(inputs)
x = Dropout(0.3)(x)
outputs = Dense(10, activation='softmax')(x)

model = Model(inputs=inputs, outputs=outputs)
```

**Entregables:**
- [ ] `neural_network.py` con backprop manual
- [ ] MLP en Keras usando **API Funcional**
- [ ] CNN para MNIST con >98% accuracy (Keras)
- [ ] LSTM para clasificaciÃ³n de texto (Keras)
- [ ] Modelo con EarlyStopping y ModelCheckpoint

---

## ðŸŽ¯ FASE 3: CAPSTONE - NLP Disaster Tweets (Semanas 21-24)

> **Dataset:** [Kaggle - Real or Not? NLP with Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started)
> Este proyecto integra **CSCA 5622 + 5632 + 5642** en un pipeline completo.

### Semana 21: EDA & Preprocessing

| Tarea | TÃ©cnica | LibrerÃ­a |
|-------|---------|----------|
| Limpieza de texto | Regex (URLs, HTML, menciones) | `re` |
| TokenizaciÃ³n | Word tokenization | NLTK / SpaCy |
| LematizaciÃ³n | Reducir a raÃ­z | WordNetLemmatizer |
| VisualizaciÃ³n | WordClouds comparativas | `wordcloud` |

**Entregables:**
- [ ] `train_clean.csv` generado
- [ ] WordCloud de tweets reales vs falsos
- [ ] AnÃ¡lisis de desbalance de clases

---

### Semana 22: Baseline Models (Supervisado)

| Modelo | VectorizaciÃ³n | EvaluaciÃ³n |
|--------|---------------|------------|
| Logistic Regression | TF-IDF | F1-Score |
| Naive Bayes | Bag of Words | Matriz ConfusiÃ³n |
| SVM | TF-IDF | Precision/Recall |

**Punto CrÃ­tico:** Â¿Por quÃ© NO usar Accuracy?
```python
# En datos desbalanceados (70% clase 0), un modelo trivial tiene 70% accuracy
# F1-Score balancea Precision y Recall â†’ mÃ©trica correcta
from sklearn.metrics import f1_score
print(f"F1-Score: {f1_score(y_true, y_pred, average='macro'):.4f}")
```

**Entregables:**
- [ ] Pipeline de vectorizaciÃ³n + modelo
- [ ] Matriz de confusiÃ³n analizada
- [ ] ComparaciÃ³n F1-Score de baselines

---

### Semana 23: Deep Learning - LSTM (Deep Learning)

**Arquitectura Bidirectional LSTM:**
```python
from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, Dropout
from tensorflow.keras.models import Model

inputs = Input(shape=(max_length,))
x = Embedding(vocab_size, embedding_dim)(inputs)
x = Bidirectional(LSTM(64, return_sequences=True))(x)
x = Bidirectional(LSTM(32))(x)
x = Dropout(0.5)(x)
outputs = Dense(1, activation='sigmoid')(x)

model = Model(inputs=inputs, outputs=outputs)
```

**Opciones de Embeddings:**
- Entrenar desde cero
- Usar GloVe preentrenados (recomendado)

**Entregables:**
- [ ] LSTM bidireccional funcionando
- [ ] Curvas de learning (loss, accuracy)
- [ ] ComparaciÃ³n con/sin GloVe
- [ ] RegularizaciÃ³n: Dropout + EarlyStopping

---

### Semana 24: Transfer Learning + Reporte Final

**Bonus Track - BERT:**
```python
from transformers import BertTokenizer, TFBertForSequenceClassification

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
```

**REPORT.md - Estructura AcadÃ©mica:**
1. Abstract (150 palabras)
2. Introduction
3. Dataset Description
4. Methodology
5. Experiments & Results
6. Discussion
7. Conclusion
8. References

**Entregables Finales:**
- [ ] BERT fine-tuned (bonus)
- [ ] MODEL_COMPARISON.md con benchmarks
- [ ] **REPORT.md acadÃ©mico**
- [ ] CÃ³digo limpio y documentado

---

## ðŸ“Š Ritmo Semanal Recomendado

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LUNES - MARTES (DÃ­as de Concepto)                           â”‚
â”‚  â€¢ Leer teorÃ­a en Teoria/                                    â”‚
â”‚  â€¢ Dibujar en papel (mÃ©todo Feynman)                         â”‚
â”‚  â€¢ NO escribir cÃ³digo nuevo                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MIÃ‰RCOLES - JUEVES (DÃ­as de ImplementaciÃ³n)                 â”‚
â”‚  â€¢ Ejecutar notebooks                                        â”‚
â”‚  â€¢ Implementar from scratch + validar con Sklearn            â”‚
â”‚  â€¢ Validar con asserts                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  VIERNES (DÃ­a de "Romper Cosas")                             â”‚
â”‚  â€¢ Cambiar learning_rate de 0.01 a 10.0                      â”‚
â”‚  â€¢ Inicializar pesos en cero                                 â”‚
â”‚  â€¢ Documentar sÃ­ntomas y causas                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SÃBADO (DÃ­a de ConsolidaciÃ³n)                               â”‚
â”‚  â€¢ Simulacro de examen (1 hora)                              â”‚
â”‚  â€¢ Cierre semanal                                            â”‚
â”‚  â€¢ Ejecutar laboratorios interactivos                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Checkpoints de EvaluaciÃ³n

| Semana | Checkpoint | Criterio de Ã‰xito |
|--------|------------|-------------------|
| 8 | PB-8 | Fundamentos matemÃ¡ticos sÃ³lidos |
| 11 | PB-11 | Supervisado + Paridad Sklearn + XAI |
| 15 | PB-15 | No Supervisado + Recomendadores |
| 20 | PB-20 | Deep Learning en Keras |
| 24 | **FINAL** | Capstone NLP + REPORT.md entregado |

---

## ðŸ† Criterios de Ã‰xito del Capstone

| Criterio | MÃ­nimo | Excelente |
|----------|--------|-----------|
| F1-Score Baseline | > 0.70 | > 0.78 |
| F1-Score LSTM | > 0.75 | > 0.80 |
| F1-Score BERT | > 0.80 | > 0.85 |
| REPORT.md | Completo | Publicable |
| CÃ³digo | Funcional | Modular y testeado |

---

## ðŸ“š Recursos por Fase

### Fase 1 (Fundamentos)
- Mathematics for Machine Learning (Deisenroth)
- 3Blue1Brown - Essence of Linear Algebra

### Fase 2 (ML Core)
- Pattern Recognition and ML (Bishop)
- **Deep Learning with Python** (Chollet) - Para Keras
- DocumentaciÃ³n SHAP: https://shap.readthedocs.io/
- Surprise Library: https://surprise.readthedocs.io/

### Fase 3 (Capstone)
- CS224n Stanford - NLP with Deep Learning
- HuggingFace Course: https://huggingface.co/course
- NLTK Book: https://www.nltk.org/book/

---

## ðŸ’¡ Cambios Clave vs. Plan Anterior

| Semana | Antes | Ahora |
|--------|-------|-------|
| 11 | RegularizaciÃ³n | **Ã‰tica IA & XAI** (SHAP, LIME) |
| 15 | t-SNE/UMAP | **Sistemas de RecomendaciÃ³n** (SVD) |
| 17-20 | PyTorch | **Keras/TensorFlow** (principal) |
| 21-24 | Proyecto MNIST | **NLP Disaster Tweets** (nivel maestrÃ­a) |

---

*Plan alineado con el MS-AI Pathway de la University of Colorado Boulder*
*Cursos: CSCA 5622 (Supervised), CSCA 5632 (Unsupervised), CSCA 5642 (Deep Learning)*
