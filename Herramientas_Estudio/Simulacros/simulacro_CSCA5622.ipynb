{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d2b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulacro de Examen: CSCA 5622 - Supervised Learning\n",
    "=====================================================\n",
    "\n",
    "M√≥dulo: M05 - Aprendizaje Supervisado\n",
    "Tiempo Estimado: 90 minutos\n",
    "Puntuaci√≥n Total: 100 puntos\n",
    "\n",
    "Estructura:\n",
    "- Parte A: Preguntas Te√≥ricas (30 puntos)\n",
    "- Parte B: Ejercicios de C√≥digo (70 puntos)\n",
    "\n",
    "Criterio para aprobar con B: >= 80 puntos\n",
    "\n",
    "Instrucciones:\n",
    "1. Ejecutar todas las celdas en orden\n",
    "2. Completar las funciones marcadas con # TODO\n",
    "3. Ejecutar los tests al final para validar\n",
    "4. No modificar las funciones de test\n",
    "\n",
    "Ejecutar tests: pytest tests/test_simulacro_csca5622.py -v\n",
    "\"\"\"\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a02fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b619983",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "PARTE A: PREGUNTAS TE√ìRICAS (30 puntos)\n",
    "=============================================================================\n",
    "Responde en las variables indicadas (string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae5c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"PARTE A: PREGUNTAS TE√ìRICAS (30 puntos)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95404e36",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "Pregunta A1 (8 puntos): Bias-Variance Tradeoff\n",
    "-----------------------------------------------------------------------------\n",
    "Un modelo de regresi√≥n tiene MSE = 25 en el conjunto de test.\n",
    "Sabes que Bias¬≤ = 9 y la varianza irreducible (ruido) = 4.\n",
    "\n",
    "a) ¬øCu√°l es la Variance del modelo? (2 pts)\n",
    "b) ¬øEl modelo sufre m√°s de underfitting o overfitting? Justifica. (3 pts)\n",
    "c) ¬øQu√© acci√≥n tomar√≠as para mejorar el modelo? (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b935328",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "respuesta_A1_a: float = 0.0  # TODO: Reemplazar con el valor correcto\n",
    "respuesta_A1_b: str = \"\"  # TODO: \"underfitting\" o \"overfitting\" + justificaci√≥n\n",
    "respuesta_A1_c: str = \"\"  # TODO: Acci√≥n espec√≠fica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1d292",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "Pregunta A2 (7 puntos): Regularizaci√≥n\n",
    "-----------------------------------------------------------------------------\n",
    "En regresi√≥n Ridge, la funci√≥n de costo es:\n",
    "J(w) = MSE + Œª||w||‚ÇÇ¬≤\n",
    "\n",
    "a) ¬øQu√© sucede con los pesos w cuando Œª ‚Üí ‚àû? (2 pts)\n",
    "b) ¬øQu√© sucede cuando Œª = 0? (2 pts)\n",
    "c) ¬øPor qu√© Ridge NO produce pesos exactamente 0 pero Lasso s√≠? (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447dfa51",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "respuesta_A2_a: str = \"\"  # TODO\n",
    "respuesta_A2_b: str = \"\"  # TODO\n",
    "respuesta_A2_c: str = \"\"  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa3bef",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "Pregunta A3 (8 puntos): M√©tricas de Clasificaci√≥n\n",
    "-----------------------------------------------------------------------------\n",
    "Un clasificador de spam tiene la siguiente matriz de confusi√≥n:\n",
    "\n",
    "                   Predicho\n",
    "                 Spam    No-Spam\n",
    "Real  Spam       80        20\n",
    "      No-Spam    10       890\n",
    "\n",
    "a) Calcula Precision para la clase \"Spam\" (2 pts)\n",
    "b) Calcula Recall para la clase \"Spam\" (2 pts)\n",
    "c) Si el costo de un False Negative (spam no detectado) es 10x mayor\n",
    "   que un False Positive, ¬øqu√© m√©trica priorizar√≠as? (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96625f67",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "respuesta_A3_precision: float = 0.0  # TODO\n",
    "respuesta_A3_recall: float = 0.0  # TODO\n",
    "respuesta_A3_c: str = \"\"  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3132caa",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "Pregunta A4 (7 puntos): √Årboles de Decisi√≥n\n",
    "-----------------------------------------------------------------------------\n",
    "a) ¬øQu√© mide el Gini Impurity? Escribe la f√≥rmula. (3 pts)\n",
    "b) ¬øPor qu√© Random Forest reduce la varianza comparado con un solo √°rbol? (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c766cb81",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "respuesta_A4_a: str = \"\"  # TODO\n",
    "respuesta_A4_b: str = \"\"  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c131c",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "PARTE B: EJERCICIOS DE C√ìDIGO (70 puntos)\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PARTE B: EJERCICIOS DE C√ìDIGO (70 puntos)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0da81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Ejercicio B1 (20 puntos): Regresi√≥n Lineal desde Cero\n",
    "# -----------------------------------------------------------------------------\n",
    "def linear_regression_gradient_descent(\n",
    "    X: NDArray[np.float64],\n",
    "    y: NDArray[np.float64],\n",
    "    learning_rate: float = 0.01,\n",
    "    n_iterations: int = 1000,\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Implementa Regresi√≥n Lineal usando Gradiente Descendente.\n",
    "\n",
    "    Par√°metros\n",
    "    ----------\n",
    "    X : NDArray[np.float64]\n",
    "        Matriz de caracter√≠sticas (n_samples, n_features).\n",
    "        Ya incluye columna de 1s para el bias.\n",
    "    y : NDArray[np.float64]\n",
    "        Vector objetivo (n_samples,).\n",
    "    learning_rate : float\n",
    "        Tasa de aprendizaje Œ±.\n",
    "    n_iterations : int\n",
    "        N√∫mero de iteraciones.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    NDArray[np.float64]\n",
    "        Vector de pesos optimizados (n_features,).\n",
    "\n",
    "    F√≥rmulas:\n",
    "    ---------\n",
    "    - Predicci√≥n: ≈∑ = Xw\n",
    "    - Gradiente MSE: ‚àáw = (2/n) * X^T * (Xw - y)\n",
    "    - Actualizaci√≥n: w = w - Œ± * ‚àáw\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # TODO: Inicializar pesos con ceros\n",
    "    weights = np.zeros(n_features)  # Placeholder\n",
    "\n",
    "    # TODO: Implementar gradiente descendente\n",
    "    for _ in range(n_iterations):\n",
    "        # TODO: Calcular predicciones\n",
    "        # TODO: Calcular gradiente\n",
    "        # TODO: Actualizar pesos\n",
    "        pass\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e373966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test B1\n",
    "print(\"\\n--- Test B1: Regresi√≥n Lineal ---\")\n",
    "X_test = np.column_stack([np.ones(100), rng.standard_normal((100, 2))])\n",
    "true_weights = np.array([2.0, 1.5, -0.5])\n",
    "y_test = X_test @ true_weights + rng.standard_normal(100) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e0fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_pred = linear_regression_gradient_descent(X_test, y_test, learning_rate=0.1)\n",
    "print(f\"Pesos verdaderos: {true_weights}\")\n",
    "print(f\"Pesos estimados:  {weights_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac26706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Ejercicio B2 (25 puntos): Regresi√≥n Log√≠stica desde Cero\n",
    "# -----------------------------------------------------------------------------\n",
    "def sigmoid(z: NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "    \"\"\"Funci√≥n sigmoide: œÉ(z) = 1 / (1 + exp(-z)).\"\"\"\n",
    "    # TODO: Implementar sigmoid (manejar overflow)\n",
    "    return np.zeros_like(z)  # Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d144357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_gradient_descent(\n",
    "    X: NDArray[np.float64],\n",
    "    y: NDArray[np.float64],\n",
    "    learning_rate: float = 0.1,\n",
    "    n_iterations: int = 1000,\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Implementa Regresi√≥n Log√≠stica usando Gradiente Descendente.\n",
    "\n",
    "    Par√°metros\n",
    "    ----------\n",
    "    X : NDArray[np.float64]\n",
    "        Matriz de caracter√≠sticas (n_samples, n_features).\n",
    "    y : NDArray[np.float64]\n",
    "        Vector de labels binarios (n_samples,) con valores 0 o 1.\n",
    "    learning_rate : float\n",
    "        Tasa de aprendizaje Œ±.\n",
    "    n_iterations : int\n",
    "        N√∫mero de iteraciones.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    NDArray[np.float64]\n",
    "        Vector de pesos optimizados (n_features,).\n",
    "\n",
    "    F√≥rmulas:\n",
    "    ---------\n",
    "    - Predicci√≥n: p = œÉ(Xw)\n",
    "    - Gradiente BCE: ‚àáw = (1/n) * X^T * (p - y)\n",
    "    - Actualizaci√≥n: w = w - Œ± * ‚àáw\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # TODO: Inicializar pesos\n",
    "    weights = np.zeros(n_features)\n",
    "\n",
    "    # TODO: Implementar gradiente descendente\n",
    "    for _ in range(n_iterations):\n",
    "        # TODO: Calcular probabilidades con sigmoid\n",
    "        # TODO: Calcular gradiente\n",
    "        # TODO: Actualizar pesos\n",
    "        pass\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e39478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(\n",
    "    X: NDArray[np.float64], weights: NDArray[np.float64]\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"Predice probabilidades P(y=1|X).\"\"\"\n",
    "    # TODO: Implementar\n",
    "    return np.zeros(X.shape[0])  # Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1418c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    X: NDArray[np.float64], weights: NDArray[np.float64], threshold: float = 0.5\n",
    ") -> NDArray[np.int64]:\n",
    "    \"\"\"Predice clases binarias.\"\"\"\n",
    "    # TODO: Implementar\n",
    "    return np.zeros(X.shape[0], dtype=np.int64)  # Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db41df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test B2\n",
    "print(\"\\n--- Test B2: Regresi√≥n Log√≠stica ---\")\n",
    "X_log = np.column_stack([np.ones(200), rng.standard_normal((200, 2))])\n",
    "true_w_log = np.array([0.0, 2.0, -1.5])\n",
    "y_log = (sigmoid(X_log @ true_w_log) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_log = logistic_regression_gradient_descent(X_log, y_log, learning_rate=0.5)\n",
    "preds = predict(X_log, weights_log)\n",
    "accuracy = np.mean(preds == y_log)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd00a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Ejercicio B3 (25 puntos): √Årbol de Decisi√≥n - Gini Impurity\n",
    "# -----------------------------------------------------------------------------\n",
    "def gini_impurity(y: NDArray[np.int64]) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el Gini Impurity de un conjunto de labels.\n",
    "\n",
    "    Gini = 1 - Œ£ p_i¬≤\n",
    "\n",
    "    donde p_i es la proporci√≥n de la clase i.\n",
    "\n",
    "    Par√°metros\n",
    "    ----------\n",
    "    y : NDArray[np.int64]\n",
    "        Vector de labels (n_samples,).\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    float\n",
    "        Gini impurity entre 0 (puro) y 0.5 (m√°xima impureza para binario).\n",
    "    \"\"\"\n",
    "    if len(y) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # TODO: Implementar Gini impurity\n",
    "    return 0.0  # Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f4ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(\n",
    "    y_parent: NDArray[np.int64],\n",
    "    y_left: NDArray[np.int64],\n",
    "    y_right: NDArray[np.int64],\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calcula el Information Gain de un split.\n",
    "\n",
    "    IG = Gini(parent) - [n_left/n * Gini(left) + n_right/n * Gini(right)]\n",
    "\n",
    "    Par√°metros\n",
    "    ----------\n",
    "    y_parent : NDArray[np.int64]\n",
    "        Labels del nodo padre.\n",
    "    y_left : NDArray[np.int64]\n",
    "        Labels del hijo izquierdo.\n",
    "    y_right : NDArray[np.int64]\n",
    "        Labels del hijo derecho.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    float\n",
    "        Information gain (siempre >= 0).\n",
    "    \"\"\"\n",
    "    n = len(y_parent)\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # TODO: Implementar information gain\n",
    "    return 0.0  # Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(\n",
    "    X: NDArray[np.float64],\n",
    "    y: NDArray[np.int64],\n",
    ") -> tuple[int, float, float]:\n",
    "    \"\"\"\n",
    "    Encuentra el mejor split para un nodo.\n",
    "\n",
    "    Par√°metros\n",
    "    ----------\n",
    "    X : NDArray[np.float64]\n",
    "        Matriz de caracter√≠sticas (n_samples, n_features).\n",
    "    y : NDArray[np.int64]\n",
    "        Vector de labels (n_samples,).\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    tuple[int, float, float]\n",
    "        - best_feature: √≠ndice de la mejor caracter√≠stica\n",
    "        - best_threshold: valor del umbral\n",
    "        - best_gain: information gain del split\n",
    "    \"\"\"\n",
    "    best_feature = 0\n",
    "    best_threshold = 0.0\n",
    "    best_gain = 0.0\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # TODO: Iterar sobre features y thresholds\n",
    "    # TODO: Encontrar el split con mayor information gain\n",
    "\n",
    "    return best_feature, best_threshold, best_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15820443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test B3\n",
    "print(\"\\n--- Test B3: Gini Impurity ---\")\n",
    "y_pure = np.array([1, 1, 1, 1])\n",
    "y_impure = np.array([0, 0, 1, 1])\n",
    "y_mixed = np.array([0, 0, 0, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5580b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f\"Gini puro (esperado ~0.0): {gini_impurity(y_pure):.4f}\")\n",
    "print(f\"Gini 50/50 (esperado ~0.5): {gini_impurity(y_impure):.4f}\")\n",
    "print(f\"Gini 3/5 (esperado ~0.469): {gini_impurity(y_mixed):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69484b94",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "VALIDACI√ìN FINAL\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VALIDACI√ìN FINAL\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_simulacro() -> dict[str, bool]:\n",
    "    \"\"\"Valida todas las respuestas del simulacro.\"\"\"\n",
    "    resultados: dict[str, bool] = {}\n",
    "\n",
    "    # Validar A1\n",
    "    resultados[\"A1_variance\"] = (\n",
    "        abs(respuesta_A1_a - 12.0) < 0.1\n",
    "    )  # MSE = Bias¬≤ + Var + Noise\n",
    "    resultados[\"A1_diagnostico\"] = \"overfitting\" in respuesta_A1_b.lower()\n",
    "\n",
    "    # Validar A3 (m√©tricas)\n",
    "    resultados[\"A3_precision\"] = abs(respuesta_A3_precision - 80 / 90) < 0.01\n",
    "    resultados[\"A3_recall\"] = abs(respuesta_A3_recall - 80 / 100) < 0.01\n",
    "\n",
    "    # Validar B1 (regresi√≥n lineal)\n",
    "    X_val = np.column_stack([np.ones(50), rng.standard_normal((50, 2))])\n",
    "    true_w = np.array([1.0, 2.0, -1.0])\n",
    "    y_val = X_val @ true_w\n",
    "    w_pred = linear_regression_gradient_descent(\n",
    "        X_val, y_val, learning_rate=0.1, n_iterations=1000\n",
    "    )\n",
    "    resultados[\"B1_linear_reg\"] = np.allclose(w_pred, true_w, atol=0.1)\n",
    "\n",
    "    # Validar B2 (sigmoid)\n",
    "    resultados[\"B2_sigmoid\"] = np.allclose(\n",
    "        sigmoid(np.array([0.0])), np.array([0.5]), atol=0.01\n",
    "    )\n",
    "\n",
    "    # Validar B3 (gini)\n",
    "    resultados[\"B3_gini_pure\"] = abs(gini_impurity(np.array([1, 1, 1])) - 0.0) < 0.01\n",
    "    resultados[\"B3_gini_impure\"] = abs(gini_impurity(np.array([0, 1])) - 0.5) < 0.01\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar validaci√≥n\n",
    "print(\"\\nüîç Validando respuestas...\")\n",
    "resultados = validar_simulacro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "puntos = 0\n",
    "for test, passed in resultados.items():\n",
    "    status = \"‚úÖ\" if passed else \"‚ùå\"\n",
    "    pts = 10 if passed else 0\n",
    "    puntos += pts\n",
    "    print(f\"  {status} {test}: {pts} pts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e999c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüìä PUNTUACI√ìN ESTIMADA: {puntos}/70 (solo c√≥digo)\")\n",
    "print(\"   + Parte Te√≥rica: /30 (requiere revisi√≥n manual)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1cd0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if puntos >= 56:  # 80% de 70\n",
    "    print(\"\\nüéâ ¬°Vas bien! El c√≥digo cumple el criterio para B.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Necesitas revisar las implementaciones antes del examen real.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025432b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FIN DEL SIMULACRO\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
