# üìã Syllabus - MS in AI Pathway

> **10 M√≥dulos Obligatorios | 6 Meses | 100% Enfocado en el Pathway**

---

## üéØ Objetivo √önico

Prepararte para aprobar las **6 materias** del Performance-Based Admission Pathway de CU Boulder.

---

## üìä Estructura: 10 M√≥dulos Obligatorios

| M√≥dulo | Nombre | Semanas | Fase | Curso del Pathway |
|--------|--------|---------|------|-------------------|
| **01** | Python Profesional | 2 | Fundamentos | - |
| **02** | OOP desde Cero | 2 | Fundamentos | - |
| **03** | √Ålgebra Lineal para ML | 2 | Fundamentos | - |
| **04** | Fundamentos de Probabilidad | 3 | ‚≠ê Pathway L2 | Probability Fundamentals |
| **05** | Estad√≠stica Inferencial | 3 | ‚≠ê Pathway L2 | Statistical Estimation |
| **06** | Markov y Monte Carlo | 2 | ‚≠ê Pathway L2 | Markov Chains & Monte Carlo |
| **07** | ML Supervisado | 3 | ‚≠ê Pathway L1 | Intro to ML: Supervised |
| **08** | ML No Supervisado | 2 | ‚≠ê Pathway L1 | Unsupervised Algorithms |
| **09** | Deep Learning | 3 | ‚≠ê Pathway L1 | Intro to Deep Learning |
| **10** | Proyecto Final | 4 | Integraci√≥n | - |

**Total: 26 semanas = 6 meses** (6h/d√≠a, L-S)

---

## üìö Mapeo M√≥dulos ‚Üí C√≥digo ‚Üí Cursos

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 1: FUNDAMENTOS (Semanas 1-6)                                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ M√≥dulos: 01, 02, 03                                                         ‚îÇ
‚îÇ C√≥digo:  src/vector.py, src/matrix.py                                       ‚îÇ
‚îÇ Entregable: Clases Vector y Matrix con operaciones desde cero               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 2: PROBABILIDAD Y ESTAD√çSTICA ‚≠ê PATHWAY L√çNEA 2 (Semanas 7-14)        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ M√≥dulos: 04, 05, 06                                                         ‚îÇ
‚îÇ C√≥digo:  src/probability.py, src/statistics.py, src/markov.py               ‚îÇ
‚îÇ Cursos:  Probability, Statistical Estimation, Markov Chains                 ‚îÇ
‚îÇ Entregable: Bayes, MLE, MCMC, PageRank desde cero                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 3: MACHINE LEARNING ‚≠ê PATHWAY L√çNEA 1 (Semanas 15-22)                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ M√≥dulos: 07, 08, 09                                                         ‚îÇ
‚îÇ C√≥digo:  src/naive_bayes.py, src/kmeans.py, src/neural_network.py           ‚îÇ
‚îÇ Cursos:  Supervised Learning, Unsupervised, Deep Learning                   ‚îÇ
‚îÇ Entregable: Regresi√≥n, NB, K-Means, MLP con backprop desde cero             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 4: PROYECTO FINAL (Semanas 23-26)                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ M√≥dulo: 10                                                                  ‚îÇ
‚îÇ C√≥digo:  src/pipeline.py (integra todo)                                     ‚îÇ
‚îÇ Entregable: Pipeline ML completo + comparaci√≥n estad√≠stica de modelos       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìñ Detalle por M√≥dulo

### M√≥dulo 01: Python Profesional

| Contenido | Entregable |
|-----------|------------|
| Type hints y anotaciones | C√≥digo tipado con `mypy` pasando |
| Funciones puras vs impuras | Funciones sin side effects |
| PEP8 y estilo consistente | C√≥digo que pasa `ruff` o `flake8` |
| Docstrings y documentaci√≥n | Cada funci√≥n documentada |

**Mini-proyecto:** Funci√≥n `clean_text(text: str) -> str` tipada y documentada.

**Validaci√≥n:** `mypy src/ && ruff check src/`

---

### M√≥dulo 02: OOP desde Cero

| Contenido | Entregable |
|-----------|------------|
| Clases y objetos | Clase `Document` con atributos |
| `__init__`, `__repr__`, `__str__` | M√©todos m√°gicos implementados |
| Encapsulamiento | Properties y validaci√≥n |
| Composici√≥n vs Herencia | Clase `Corpus` que contiene `Document`s |
| Principios SOLID b√°sicos | Single Responsibility aplicado |

**Mini-proyecto:** Clases `Document` y `Corpus` funcionales.

**Validaci√≥n:** `python -m pytest tests/test_document.py -v`

---

### M√≥dulo 03: L√≥gica y Matem√°ticas Discretas

| Contenido | Entregable |
|-----------|------------|
| Teor√≠a de conjuntos | Uso correcto de `set` en Python |
| L√≥gica proposicional | Expresiones booleanas complejas |
| Notaci√≥n Big O (introducci√≥n) | Explicar O(1), O(n), O(n¬≤) |
| Demostraciones simples | Documentar "por qu√© funciona" |

**Mini-proyecto:** Lista de stop words como `set` con an√°lisis de complejidad.

**Validaci√≥n:** Documento explicando complejidad de operaciones `in` en `list` vs `set`.

---

### M√≥dulo 04: Arrays, Strings y Memoria

| Contenido | Entregable |
|-----------|------------|
| Listas en Python (bajo nivel) | Entender slicing y copia |
| Manipulaci√≥n de strings | Tokenizaci√≥n b√°sica |
| Complejidad de operaciones | Tabla de O() para list |
| Inmutabilidad vs mutabilidad | Evitar bugs de referencia |

**Mini-proyecto:** Tokenizador b√°sico que separa texto en palabras.

**Validaci√≥n:** `python -m pytest tests/test_tokenizer.py -v`

---

### M√≥dulo 05: Hash Maps y Sets

| Contenido | Entregable |
|-----------|------------|
| C√≥mo funciona un diccionario | Entender hashing |
| Colisiones y resoluci√≥n | Saber que existen, no implementar |
| Complejidad O(1) amortizada | Explicar cu√°ndo y por qu√© |
| Sets para b√∫squeda r√°pida | Stop words como `frozenset` |

**Mini-proyecto:** Diccionario de frecuencia de palabras.

**Validaci√≥n:** Benchmark `list` vs `set` para b√∫squeda (script incluido).

---

### M√≥dulo 06: √çndice Invertido

| Contenido | Entregable |
|-----------|------------|
| Qu√© es un √≠ndice invertido | Diagrama y explicaci√≥n |
| Estructura `{palabra: [doc_ids]}` | Clase `InvertedIndex` |
| Agregar documentos al √≠ndice | M√©todo `add_document()` |
| Buscar documentos por palabra | M√©todo `search(query)` |

**Mini-proyecto:** `InvertedIndex` que indexa y busca en corpus de prueba.

**Validaci√≥n:** `python -m pytest tests/test_index.py -v`

**An√°lisis requerido:** ¬øCu√°l es la complejidad de `add_document()`? ¬øY de `search()`?

---

### M√≥dulo 07: Recursi√≥n y Divide & Conquer

| Contenido | Entregable |
|-----------|------------|
| Pensamiento recursivo | Funciones recursivas simples |
| Caso base y caso recursivo | Identificar en ejemplos |
| Call stack y l√≠mites | Entender `RecursionError` |
| Divide & Conquer pattern | Factorial, Fibonacci, suma de lista |

**Mini-proyecto:** `factorial()`, `fibonacci()`, `sum_list()` recursivos.

**Validaci√≥n:** Tests que verifican casos base y casos grandes.

---

### M√≥dulo 08: Algoritmos de Ordenamiento

| Contenido | Entregable |
|-----------|------------|
| QuickSort desde cero | Implementaci√≥n funcional |
| Pivot selection | Random pivot para evitar O(n¬≤) |
| MergeSort (opcional) | Implementaci√≥n alternativa |
| An√°lisis de complejidad | O(n log n) promedio, O(n¬≤) peor |

**Mini-proyecto:** `quicksort()` y `mergesort()` en `sorting.py`.

**Validaci√≥n:** `python -m pytest tests/test_sorting.py -v`

**An√°lisis requerido:** Documento explicando cu√°ndo QuickSort es O(n¬≤).

---

### M√≥dulo 09: B√∫squeda Binaria

| Contenido | Entregable |
|-----------|------------|
| Binary Search cl√°sica | Implementaci√≥n sin errores |
| Off-by-one errors | C√≥mo evitarlos sistem√°ticamente |
| Variantes | Buscar primer/√∫ltimo elemento |
| Cu√°ndo aplicar | Lista ordenada, O(log n) |

**Mini-proyecto:** `binary_search()` con variantes en `searching.py`.

**Validaci√≥n:** `python -m pytest tests/test_searching.py -v`

---

### M√≥dulo 10: √Ålgebra Lineal sin NumPy

| Contenido | Entregable |
|-----------|------------|
| Vectores como listas | Representaci√≥n b√°sica |
| Suma de vectores | `add_vectors(v1, v2)` |
| Producto punto | `dot_product(v1, v2)` |
| Norma de un vector | `magnitude(v)` |
| Matrices como listas de listas | Representaci√≥n 2D |

**Mini-proyecto:** M√≥dulo `linear_algebra.py` con operaciones b√°sicas.

**Validaci√≥n:** Tests que verifican matem√°ticamente cada operaci√≥n.

---

### M√≥dulo 11: TF-IDF y Similitud de Coseno

| Contenido | Entregable |
|-----------|------------|
| Term Frequency (TF) | Funci√≥n `compute_tf()` |
| Inverse Document Frequency (IDF) | Funci√≥n `compute_idf()` |
| TF-IDF combinado | Funci√≥n `compute_tfidf()` |
| Similitud de coseno | Funci√≥n `cosine_similarity()` |
| Vectorizaci√≥n de documentos | Cada doc como vector TF-IDF |

**Mini-proyecto:** Sistema de ranking por relevancia.

**Validaci√≥n:** Tests + comparaci√≥n manual con resultados conocidos.

---

### M√≥dulo 12: Proyecto Integrador

| Contenido | Entregable |
|-----------|------------|
| Ensamblaje de componentes | `SearchEngine` que usa todo |
| API de b√∫squeda | M√©todo `search(query, top_k)` |
| An√°lisis Big O completo | `COMPLEXITY_ANALYSIS.md` |
| README profesional | Documentaci√≥n de uso |
| Tests de integraci√≥n | `test_engine.py` |

**Entregable final:**
1. Motor de b√∫squeda funcional
2. An√°lisis de complejidad de cada operaci√≥n
3. README en ingl√©s
4. Suite de tests con >80% coverage

**Validaci√≥n:** Demo en vivo + defensa del an√°lisis Big O.

---

## üìä R√∫brica General (100 puntos)

| Dimensi√≥n | Puntos | Criterio |
|-----------|--------|----------|
| **Funcionalidad** | 30 | El motor busca y rankea correctamente |
| **C√≥digo limpio** | 20 | PEP8, type hints, docstrings |
| **Tests** | 20 | Cobertura >80%, casos edge |
| **An√°lisis Big O** | 20 | Documento completo y correcto |
| **Documentaci√≥n** | 10 | README claro, en ingl√©s |

### Niveles

| Puntuaci√≥n | Nivel |
|------------|-------|
| 90-100 | Listo para Pathway + entrevistas t√©cnicas |
| 75-89 | Buen nivel, reforzar √°reas d√©biles |
| 60-74 | Necesita m√°s pr√°ctica antes de Pathway |
| <60 | Revisar m√≥dulos fundamentales |

---

## üéØ Preparaci√≥n para Pathway - CURSOS EXACTOS

El Pathway tiene **2 l√≠neas con 6 cursos espec√≠ficos**:

### L√çNEA 1: Machine Learning (3 cr√©ditos)

| Curso del Pathway | M√≥dulo Preparaci√≥n | Temas Cubiertos |
|-------------------|-------------------|-----------------|
| **Introduction to ML: Supervised Learning** | 22 | Regresi√≥n, clasificaci√≥n, √°rboles, SVM, evaluaci√≥n |
| **Unsupervised Algorithms in ML** | 23 | K-Means, clustering jer√°rquico, PCA, anomal√≠as |
| **Introduction to Deep Learning** | 24 | Perceptr√≥n, MLP, backprop, CNN/RNN conceptos |

### L√çNEA 2: Probability & Statistics (3 cr√©ditos)

| Curso del Pathway | M√≥dulo Preparaci√≥n | Temas Cubiertos |
|-------------------|-------------------|-----------------|
| **Probability Theory: Foundation** | 19 | Bayes, distribuciones, esperanza, varianza |
| **Discrete-Time Markov Chains** | 21 | Cadenas de Markov, PageRank, MCMC |
| **Statistical Inference** | 20 | MLE, MAP, intervalos, hip√≥tesis |

### Cobertura de esta Gu√≠a

| Componente del Pathway | ¬øCubierto? | Evidencia |
|------------------------|------------|-----------|
| Naive Bayes | ‚úÖ | M√≥dulo 19 + 22 |
| Regresi√≥n Lineal/Log√≠stica | ‚úÖ | M√≥dulo 22 |
| √Årboles de Decisi√≥n | ‚úÖ | M√≥dulo 22 |
| K-Means Clustering | ‚úÖ | M√≥dulo 23 |
| PCA | ‚úÖ | M√≥dulo 23 |
| Redes Neuronales | ‚úÖ | M√≥dulo 24 |
| Backpropagation | ‚úÖ | M√≥dulo 24 |
| Teorema de Bayes | ‚úÖ | M√≥dulo 19 |
| Cadenas de Markov | ‚úÖ | M√≥dulo 21 |
| MLE/MAP | ‚úÖ | M√≥dulo 20 |
| Intervalos de Confianza | ‚úÖ | M√≥dulo 20 |

---

## üìÖ Cronograma Sugerido

Ver [PLAN_ESTUDIOS.md](PLAN_ESTUDIOS.md) para el cronograma d√≠a a d√≠a.

---

## ‚úÖ Checklist de Finalizaci√≥n del Programa

### Prerrequisitos (M√≥dulos 01-18)
- [ ] Python profesional con type hints
- [ ] OOP y dise√±o SOLID
- [ ] Estructuras de datos implementadas
- [ ] Algoritmos cl√°sicos dominados

### L√≠nea 2: Probabilidad (M√≥dulos 19-21)
- [ ] Teorema de Bayes explicado y aplicado
- [ ] MLE y MAP implementados
- [ ] Cadenas de Markov y MCMC entendidos
- [ ] Intervalos de confianza calculados

### L√≠nea 1: Machine Learning (M√≥dulos 22-24)
- [ ] Regresi√≥n lineal/log√≠stica desde cero
- [ ] K-Means y PCA implementados
- [ ] Red neuronal con backpropagation
- [ ] M√©tricas de evaluaci√≥n dominadas

### Proyecto Integrador (M√≥dulo 12)
- [ ] Pipeline ML completo funcional
- [ ] Comparaci√≥n estad√≠stica de modelos
- [ ] README en ingl√©s
- [ ] Demo presentable

### Preparaci√≥n Final
- [ ] Simulacro de entrevista completado (100+ preguntas)
- [ ] Capaz de explicar cada modelo en ingl√©s
- [ ] Cursos del Pathway auditados en Coursera

---

> üí° **Recuerda:** El objetivo es aprobar los 6 cursos del Pathway. Esta gu√≠a te prepara para todos ellos. ¬°No uses sklearn hasta dominar las implementaciones desde cero!
