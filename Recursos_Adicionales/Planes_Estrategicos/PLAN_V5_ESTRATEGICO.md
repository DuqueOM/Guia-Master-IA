# üìã Plan de Acci√≥n Perfeccionado v5.0 ‚Äì Validaci√≥n y Certificaci√≥n

> Este plan NO cambia el contenido acad√©mico de la gu√≠a.
> A√±ade una capa de **validaci√≥n externa**, **rigor en datos** y **simulacro de examen de admisi√≥n** sobre las mismas 24 semanas.

---

## üéØ Objetivo de v5.0

- Que **t√∫** sepas que dominas el contenido (v3.x + v4.0).
- Que un **tercero** (mentor/IA/entrevistador) pueda confirmar tu nivel.
- Que tu ejecuci√≥n est√© alineada con el **formato de examen** de la maestr√≠a.

v5.0 introduce 5 protocolos sobre la gu√≠a principal:

1. **Protocolo 1 ‚Äì Data Rigor (Dirty Data Check)**
2. **Protocolo 2 ‚Äì Validaci√≥n Externa (Desaf√≠o del Tablero Blanco)**
3. **Protocolo 3 ‚Äì Examen de Admisi√≥n Simulado**
4. **Protocolo D ‚Äì Visualizaci√≥n Generativa (Intuici√≥n Geom√©trica por C√≥digo)**
5. **Protocolo E ‚Äì Rescate Cognitivo y Ejecuci√≥n (Metacognici√≥n + Puentes + Simulacros PB + Badges)**

---

## üì¶ Relaci√≥n con otros documentos

- Contenido base de 24 semanas: [PLAN_ESTUDIOS.md](PLAN_ESTUDIOS.md)
- Estrategia de estudio diario y PyTorch: [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md)
- Simulacros te√≥ricos: `study_tools/SIMULACRO_EXAMEN_TEORICO.md`
- **Nuevas herramientas v5.0:**
  - `study_tools/DIRTY_DATA_CHECK.md`
  - `study_tools/DESAFIO_TABLERO_BLANCO.md`
  - `study_tools/EXAMEN_ADMISION_SIMULADO.md`
  - `study_tools/CIERRE_SEMANAL.md`
  - `study_tools/DIARIO_METACOGNITIVO.md`
  - `study_tools/TEORIA_CODIGO_BRIDGE.md`
  - `study_tools/BADGES_CHECKPOINTS.md`
  - `study_tools/SIMULACRO_PERFORMANCE_BASED.md`

---

## 1Ô∏è‚É£ Protocolo 1 ‚Äì Data Rigor (Dirty Data Check)

> *"El c√≥digo es in√∫til si el dato es basura."*

### 1.1. M√≥dulo 01 ‚Äì Python/Pandas (Semanas 1‚Äì2)

**Cambio en el entregable de M√≥dulo 01:**

Adem√°s de cargar un CSV y convertirlo a NumPy, el entregable incluye ahora un **Dirty Data Check**:

- Identificar y documentar **al menos 5 problemas reales** en el dataset:
  - Valores nulos / NaN
  - Outliers obvios
  - Tipos incorrectos (strings donde deber√≠an ser n√∫meros)
  - Codificaciones extra√±as ("?", "N/A", "-999" como missing)
  - Duplicados
- Para cada problema:
  - Describir la **estrategia de limpieza elegida** (drop, imputaci√≥n, correcci√≥n, etc.).
  - Justificar la decisi√≥n (impacto en el modelo, tama√±o de muestra, etc.).

üìÑ Usa la plantilla:

- `study_tools/DIRTY_DATA_CHECK.md` (secci√≥n **Caso 1: M√≥dulo 01 ‚Äì CSV Inicial**).

### 1.2. M√≥dulo 05 ‚Äì Supervised Learning (Semanas 9‚Äì12)

En el primer proyecto de **Regresi√≥n Log√≠stica** (M√≥dulo 05):

- Usar un **dataset real** con:
  - Variables categ√≥ricas (requieren One-Hot Encoding).
  - Variables num√©ricas que necesitan escalado (MinMax / StandardScaler manual).
- Implementar un **pipeline de preprocesamiento** claro **antes** del modelo:
  - Limpieza b√°sica (missing, outliers).
  - Codificaci√≥n de categ√≥ricas (one-hot).
  - Escalado de num√©ricas.
  - Divisi√≥n train/test.
- Documentar este flujo en `DIRTY_DATA_CHECK.md` (Caso 2: M√≥dulo 05 ‚Äì Dataset Supervisado).

üîó Referencia cruzada en la gu√≠a:
- Ver secci√≥n **Supervised Learning (M√≥dulo 05)** en [PLAN_ESTUDIOS.md](PLAN_ESTUDIOS.md).

---

## 2Ô∏è‚É£ Protocolo 2 ‚Äì Validaci√≥n Externa (Desaf√≠o del Tablero Blanco)

> *"Si no lo puedes explicar en 5 minutos, no lo entiendes de verdad."*
> ‚Äì M√©todo Feynman aplicado a ML

La gu√≠a v3.2 ya menciona el "Reto del Tablero Blanco". v5.0 lo **formaliza**:

### 2.1. Frecuencia (Fase 1 y 2)

- **4 sesiones obligatorias**:
  - Semana 4
  - Semana 8
  - Semana 12
  - Semana 16

### 2.2. Din√°mica de cada sesi√≥n

1. Elegir **un concepto central** de las semanas previas, por ejemplo:
   - Regla de la Cadena
   - Gradient Descent
   - K-Means
   - PCA
   - Regresi√≥n Log√≠stica
   - Backpropagation
2. Preparar una **explicaci√≥n de 5 minutos** como si hablaras con un colega.
3. Grabar un **video corto** (pantalla + voz, c√°mara opcional) explicando el concepto en:
   - Un tablero blanco f√≠sico,
   - Una tablet, o
   - Una pizarra digital sencilla.
4. Pedir **feedback externo**:
   - Mentor, colega, comunidad online, o
   - Una IA avanzada (pedir evaluaci√≥n en claridad, precisi√≥n y rigor).

üìÑ Usa la plantilla:

- `study_tools/DESAFIO_TABLERO_BLANCO.md` para:
  - Registrar tema, fecha, links al video.
  - Autoevaluaci√≥n + feedback recibido.

### 2.3. Criterio de dominio (Feynman)

> Si en 5 minutos **no puedes** explicar el concepto:
> - sin leer,
> - sin abusar de jerga,
> - y sin cometer errores conceptuales,
>
> entonces **no lo has dominado** todav√≠a.

En ese caso:
- Volver al m√≥dulo correspondiente en [PLAN_ESTUDIOS.md](PLAN_ESTUDIOS.md).
- Repetir ejercicios clave.
- Reintentar el desaf√≠o en 1 semana.

---

## 3Ô∏è‚É£ Protocolo 3 ‚Äì Examen de Admisi√≥n Simulado (Semanas 22 y 23)

> *"Entrena como si ma√±ana fuera el examen real."*

Este protocolo convierte las semanas 22 y 23 en un **campo de entrenamiento de examen**.

### 3.1. Formato del Examen Simulado

- **Duraci√≥n:** 2 horas continuas.
- **Condiciones:**
  - Sin internet.
  - Sin IDE.
  - Solo papel, l√°piz y calculadora b√°sica.
- **Contenido:**
  - **40% C√≥digo (en pseudoc√≥digo / pasos):**
    - PCA paso a paso,
    - o Backpropagation en una red simple,
    - o K-Means completo.
  - **60% Te√≥rico:**
    - Derivaci√≥n de una funci√≥n de p√©rdida (e.g., Cross-Entropy).
    - Explicaci√≥n gr√°fica de Bias‚ÄìVariance.
    - Preguntas conceptuales de ML/DL.

üìÑ Detalle y plantilla:

- `study_tools/EXAMEN_ADMISION_SIMULADO.md`
  Incluye estructura sugerida, r√∫brica de calificaci√≥n y hojas para registrar resultados.

### 3.2. Calendario

- **Semana 22 ‚Äì Simulacro 1 (diagn√≥stico):**
  - Objetivo: detectar debilidades antes de la √∫ltima semana.
- **Semana 23 ‚Äì Simulacro 2 (final):**
  - Objetivo: confirmar que ya est√°s en nivel de admisi√≥n.

### 3.3. M√©trica de "Listo para Admisi√≥n"

- La nota del simulacro final (Semana 23) es tu **Puntaje de Admisi√≥n Simulado**.
- Criterio:
  - **‚â• 80%:** nivel adecuado para presentarte con confianza.
  - **< 80%:** recomendar extender 2‚Äì4 semanas m√°s, reforzar teor√≠a y repetir simulacro.

---

## 4Ô∏è‚É£ Hoja de Ruta Integrada v5.0

| Fase | Tarea Principal (Contenido) | Mejora Estrat√©gica (Ejecuci√≥n v5.0) |
|------|-----------------------------|--------------------------------------|
| Semanas 1‚Äì8 | Fundamentos Matem√°ticos (√Ålgebra, C√°lculo, Probabilidad). | **Protocolo 1 ‚Äì Data Rigor:** Dirty Data Check en M√≥dulo 01 (CSV real). |
| Semanas 9‚Äì20 | Core ML (Supervisado, No Supervisado, Deep Learning). | **Protocolo 1 + 2:** Dirty Data Check en proyecto supervisado + 4 desaf√≠os de Tablero Blanco. |
| Semanas 21‚Äì24 | Proyecto Integrador (MNIST Analyst). | **Protocolo 3:** 2 simulacros de examen (teor√≠a + pseudoc√≥digo) en Semanas 22 y 23. |

La **transici√≥n a PyTorch** sigue estando detallada en [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md) y en `study_tools/PUENTE_NUMPY_PYTORCH.md`.

---

## 5Ô∏è‚É£ C√≥mo usar v4.0 y v5.0 juntos

- **v4.0** responde: *"¬øC√≥mo estudio cada d√≠a para no abandonar?"*
  - Protocolo "sandwich".
  - Diario de errores.
  - Dry run de backprop.
  - Puente final a PyTorch.

- **v5.0** responde: *"¬øC√≥mo demuestro (a otros y a un examen) que s√≠ estoy listo?"*
  - Dirty Data Check con datasets reales.
  - Validaci√≥n externa con explicaciones orales.
  - Simulacro de examen de admisi√≥n.

Usa ambos planes como **capas** sobre [PLAN_ESTUDIOS.md](PLAN_ESTUDIOS.md):

1. Primero aseguras **ejecuci√≥n diaria y proyectos** (v4.0).
2. Luego aseguras **validaci√≥n externa y simulacro de examen** (v5.0).

---

## 6Ô∏è‚É£ Checklist R√°pido v5.0

- [ ] M√≥dulo 01: `DIRTY_DATA_CHECK.md` completado para un CSV real.
- [ ] M√≥dulo 05: Dirty Data Check aplicado a dataset supervisado con categ√≥ricas + escalado.
- [ ] 4 videos del **Desaf√≠o del Tablero Blanco** (Semanas 4, 8, 12, 16) grabados y evaluados.
- [ ] Simulacro 1 (Semana 22) completado y analizado.
- [ ] Simulacro 2 (Semana 23) ‚â• 80%.
- [ ] Diario de Errores actualizado con errores conceptuales detectados en simulacros y desaf√≠os.

## 7Ô∏è‚É£ Plan de Acci√≥n Definitivo v5.0 ‚Äì Protocolo A/B/C

> Esta secci√≥n resume c√≥mo combinar los m√≥dulos y herramientas existentes en **tres protocolos operativos** durante las 24 semanas.

### Protocolo A ‚Äì Verificaci√≥n Triple del C√≥digo (Precisi√≥n Matem√°tica)

| M√≥dulo/Semana | Acci√≥n de Validaci√≥n | Objetivo de Seguridad |
|---------------|----------------------|------------------------|
| **M√≥dulo 03 ‚Äì C√°lculo** | **Gradient Checking Obligatorio**: antes de confiar en cualquier `backward()` manual, ejecutar un chequeo de gradiente por diferencias finitas (m√©todo de diferencia central) sobre tus derivadas clave. | Detectar errores sutiles de signo o de √°lgebra en la implementaci√≥n de tus gradientes. |
| **M√≥dulo 05 ‚Äì Supervised Learning** | **Modo Sombra (Shadow Mode)**: los viernes, despu√©s de entrenar tu propia Regresi√≥n Lineal/Log√≠stica, entrenar el mismo modelo con `sklearn` y comparar accuracy y coeficientes (W, b). | Validar que tu implementaci√≥n desde cero coincide con la librer√≠a est√°ndar de la industria; si hay discrepancias grandes, el bug es tuyo. |
| **M√≥dulo 07 ‚Äì Deep Learning** | **Test de Overfitting**: entrenar tu red MLP manual para que memorice un minibatch peque√±o (5‚Äì10 ejemplos) hasta p√©rdida casi cero. | Comprobar que la l√≥gica de forward/backward es correcta; si no puede memorizar el minibatch, hay un fallo estructural en backprop. |

- Referencias:
  - Gradient checking: secci√≥n **"Gradient Checking: Validaci√≥n Matem√°tica (v3.3)"** en `03_CALCULO_MULTIVARIANTE.md`.
  - Shadow Mode: secci√≥n **"Shadow Mode: Validaci√≥n con sklearn (v3.3)"** en `05_SUPERVISED_LEARNING.md`.
  - Overfitting: implementaci√≥n y entrenamiento de MLP en `07_DEEP_LEARNING.md`.

### Protocolo B ‚Äì Rigor Acad√©mico y Validaci√≥n Externa (Examen)

| Frecuencia | Acci√≥n | Objetivo |
|-----------|--------|----------|
| **Diario (15 minutos)** | **Diario de Errores Cr√≠ticos**: registrar a mano los 5 errores conceptuales m√°s grandes del d√≠a (confusiones de definiciones, notaci√≥n, dimensiones, interpretaci√≥n de resultados, etc.). | Evitar repetir los mismos errores y construir un "resumen de examen" personalizado. |
| **Mensual (S√°bado)** | **Desaf√≠o del Tablero Blanco (Feynman Challenge)**: explicar en 5‚Äì7 minutos, sin leer notas, un concepto complejo (PCA, K-Means, Gradient Descent, Regla de la Cadena, Backpropagation, etc.) y registrar feedback externo. | Probar dominio conceptual en lenguaje sencillo, similar a una entrevista t√©cnica u oral de examen. |
| **Semanas 22‚Äì23** | **Simulacro de Examen de Admisi√≥n**: 2 horas, sin IDE ni internet, 40% pseudoc√≥digo y dimensiones, 60% teor√≠a y derivaciones. | Simular el Pathway real y obtener una m√©trica objetiva de "listo / no listo". |

- Herramientas asociadas:
  - Diario: `study_tools/DIARIO_ERRORES.md`.
  - Tablero Blanco: `study_tools/DESAFIO_TABLERO_BLANCO.md` (y secci√≥n 2 de este documento).
  - Examen: `study_tools/EXAMEN_ADMISION_SIMULADO.md` (y secci√≥n 3 de este documento).

### Protocolo C ‚Äì Puente a la Realidad (Transici√≥n a Industria)

1. **Traducci√≥n del Core ML a PyTorch (M√≥dulo 08)**
   - Despu√©s de completar el proyecto **MNIST Analyst** con tu propio c√≥digo NumPy, reescribir tu red neuronal m√°s avanzada usando PyTorch (`torch.nn.Linear`, `optim`, etc.).
   - Apoyarte en `study_tools/PUENTE_NUMPY_PYTORCH.md` y en las secciones de Deep Learning para mapear capas y operaciones.
   - Objetivo: ver c√≥mo docenas de l√≠neas de inicializaci√≥n y backprop se condensan en unas pocas capas de alto nivel.

2. **An√°lisis de Errores con Datos Reales (M√≥dulo 08)**
   - En el informe final del proyecto MNIST incluir una secci√≥n titulada **"Las 5 im√°genes peor clasificadas"**.
   - Para cada imagen:
     - Mostrar la imagen y la predicci√≥n err√≥nea del modelo.
     - Describir brevemente el tipo de error.
     - Argumentar si el fallo se debe principalmente a **Bias** (modelo demasiado simple) o **Variance** (modelo demasiado complejo / datos ruidosos o insuficientes), conectando con el an√°lisis de Bias‚ÄìVariance del proyecto.

Con estos tres protocolos, v5.0 pasa de ser solo una capa extra de herramientas a un **sistema completo de verificaci√≥n, validaci√≥n externa y transici√≥n a herramientas de producci√≥n** aplicado sobre las mismas 24 semanas del plan base.

---

### Protocolo E ‚Äì Rescate Cognitivo y Ejecuci√≥n (Metacognici√≥n + Puentes + Simulacros PB + Badges)

Objetivo: reducir **fatiga cognitiva**, aumentar **retenci√≥n** y mantener **motivaci√≥n visible** durante 24 semanas sin bajar el rigor.

Regla pr√°ctica:

- esto no es contenido extra: es **consolidaci√≥n** y **transferencia** (teor√≠a ‚Üí c√≥digo) que evita deserci√≥n.

Componentes:

1) **Cierre Cognitivo Semanal (S√°bado, 1 hora)**
   - Herramienta: `study_tools/CIERRE_SEMANAL.md`
   - Incluye mapa mental, Feynman, 3 errores comunes, checklist y mini autoevaluaci√≥n.

2) **Metacognici√≥n diaria (5 min)**
   - Herramienta: `study_tools/DIARIO_METACOGNITIVO.md`
   - Preguntas gu√≠a: qu√© entend√≠, qu√© no, patr√≥n de error, acci√≥n correctiva.

3) **Puente Teor√≠a ‚Üî C√≥digo (semanal, 20‚Äì30 min)**
   - Herramienta: `study_tools/TEORIA_CODIGO_BRIDGE.md`
   - Ejemplos: covarianza ‚Üí NumPy, gradiente MSE ‚Üí implementaci√≥n, log-sum-exp ‚Üí estabilidad.

4) **Badges y mini-victorias (por m√≥dulo)**
   - Herramienta: `study_tools/BADGES_CHECKPOINTS.md`
   - Criterio: cada badge requiere evidencia verificable (script/notebook/test/explicaci√≥n breve).

5) **Simulacros performance-based (Semanas 8, 16, 23)**
   - Herramienta: `study_tools/SIMULACRO_PERFORMANCE_BASED.md`
   - Formato: 50% teor√≠a + 50% pseudoc√≥digo/c√≥digo.


### Protocolo D ‚Äì Visualizaci√≥n Generativa (Intuici√≥n Geom√©trica por C√≥digo)

Objetivo: construir intuici√≥n geom√©trica **mediante visualizaciones reproducibles** (sin depender de im√°genes est√°ticas). El estudiante aprende a ‚Äúver‚Äù:

- matrices como deformaci√≥n del espacio
- gradiente descent como trayectoria en un valle
- convoluci√≥n como detector local de patrones

Regla pr√°ctica:

- no es ‚Äúdecoraci√≥n‚Äù: cada visualizaci√≥n debe responder una pregunta conceptual

#### Semana 3 (√Ålgebra) ‚Äì Transformaciones lineales y eigenvectors

- **Tarea:** ejecutar y modificar [`visualizations/viz_transformations.py`](../visualizations/viz_transformations.py)
- **Entregable:**
  - un plot que muestre una rejilla antes/despu√©s de `A`
  - y una breve nota: ‚Äú¬øcu√°l es el eigenvector (si existe) y qu√© le pasa?‚Äù

#### Semana 7 (C√°lculo) ‚Äì Descenso de gradiente 3D interactivo

- **Tarea:** ejecutar [`visualizations/viz_gradient_3d.py`](../visualizations/viz_gradient_3d.py) (Plotly, export a HTML)
- **Entregable:**
  - captura o export de la trayectoria con `lr` peque√±o (convergencia)
  - captura o export con `lr` grande (divergencia)
  - explicaci√≥n en 5 l√≠neas del fen√≥meno

#### Semana 19 (CNNs) ‚Äì Convoluci√≥n y feature maps (Sobel)

- **Tarea:** ejecutar [`visualizations/viz_convolution.py`](../visualizations/viz_convolution.py)
- **Entregable:**
  - cargar una imagen propia (foto) y aplicar Sobel
  - mostrar input vs feature map
  - explicar qu√© patr√≥n detecta el filtro

Herramientas requeridas:

- `matplotlib`
- `plotly`
- `ipywidgets`
