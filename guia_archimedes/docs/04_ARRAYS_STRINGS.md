# 04 - Arrays, Strings y Memoria

> **ğŸ¯ Objetivo:** Dominar la manipulaciÃ³n de listas y strings en Python, entendiendo su complejidad y construyendo un tokenizador bÃ¡sico.

---

## ğŸ§  AnalogÃ­a: El Estante de Libros

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                             â”‚
â”‚   LISTA = ESTANTE DE LIBROS NUMERADO                                        â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚                                                                             â”‚
â”‚   PosiciÃ³n:  [0]     [1]     [2]     [3]     [4]                            â”‚
â”‚              â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”                          â”‚
â”‚              â”‚ A â”‚   â”‚ B â”‚   â”‚ C â”‚   â”‚ D â”‚   â”‚ E â”‚                          â”‚
â”‚              â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜                          â”‚
â”‚                                                                             â”‚
â”‚   â€¢ Acceder a [2] â†’ Inmediato (O(1)): "Voy al estante 2"                    â”‚
â”‚   â€¢ Insertar al final â†’ RÃ¡pido: solo aÃ±adir al final                        â”‚
â”‚   â€¢ Insertar al inicio â†’ Lento: mover todos los demÃ¡s                       â”‚
â”‚                                                                             â”‚
â”‚   STRING = COLLAR DE CUENTAS (no puedes cambiar una cuenta)                 â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚
â”‚   "HELLO" â†’ Si quieres cambiar 'E' por 'A', debes hacer nuevo collar        â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Contenido

1. [Listas en Python: Bajo Nivel](#1-listas)
2. [Slicing y Copias](#2-slicing)
3. [Complejidad de Operaciones](#3-complejidad)
4. [Strings: Inmutabilidad](#4-strings)
5. [TokenizaciÃ³n: Tu Primer Componente](#5-tokenizacion)

---

## 1. Listas en Python: Bajo Nivel {#1-listas}

### 1.1 CÃ³mo Funciona una Lista

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INTERNAMENTE: Array dinÃ¡mico                                   â”‚
â”‚                                                                 â”‚
â”‚  Memoria:   [ptr0][ptr1][ptr2][ptr3][____][____]                â”‚
â”‚              â†“     â†“     â†“     â†“                                â”‚
â”‚            "hi" "world"  42   3.14                              â”‚
â”‚                                                                 â”‚
â”‚  La lista guarda PUNTEROS a los objetos, no los objetos         â”‚
â”‚  Tiene espacio extra para crecer sin reasignar                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 CreaciÃ³n y Acceso

```python
# Crear listas
words: list[str] = ["hello", "world", "python"]
numbers: list[int] = [1, 2, 3, 4, 5]
mixed: list = [1, "two", 3.0, None]  # Evitar en cÃ³digo tipado

# Acceso por Ã­ndice: O(1)
first = words[0]      # "hello"
last = words[-1]      # "python" (desde el final)

# Longitud: O(1) (Python guarda el tamaÃ±o)
length = len(words)   # 3

# ModificaciÃ³n: O(1)
words[0] = "hi"       # ["hi", "world", "python"]
```

### 1.3 Agregar y Eliminar

```python
words = ["a", "b", "c"]

# Agregar al final: O(1) amortizado
words.append("d")     # ["a", "b", "c", "d"]

# Agregar al inicio: O(n) - Â¡LENTO!
words.insert(0, "z")  # ["z", "a", "b", "c", "d"]
# Todos los elementos deben moverse

# Extender con otra lista: O(k) donde k = len(otra_lista)
words.extend(["e", "f"])  # ["z", "a", "b", "c", "d", "e", "f"]

# Eliminar del final: O(1)
last = words.pop()    # Retorna "f", words = ["z", "a", "b", "c", "d", "e"]

# Eliminar del inicio: O(n) - Â¡LENTO!
first = words.pop(0)  # Retorna "z", todos deben moverse

# Eliminar por valor: O(n) - busca y luego mueve
words.remove("c")     # Busca "c" y lo elimina
```

---

## 2. Slicing y Copias {#2-slicing}

### 2.1 Slicing BÃ¡sico

```python
nums = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

# Sintaxis: list[start:stop:step]
nums[2:5]      # [2, 3, 4]      - desde Ã­ndice 2 hasta 5 (no incluido)
nums[:3]       # [0, 1, 2]      - desde inicio hasta 3
nums[7:]       # [7, 8, 9]      - desde 7 hasta el final
nums[::2]      # [0, 2, 4, 6, 8] - cada 2 elementos
nums[::-1]     # [9, 8, ..., 0]  - reverso

# Ãndices negativos
nums[-3:]      # [7, 8, 9]      - Ãºltimos 3
nums[:-2]      # [0, 1, ..., 7] - todos menos Ãºltimos 2
```

### 2.2 Copia Superficial vs Profunda

```python
# âš ï¸ ASIGNACIÃ“N: NO ES COPIA, es alias
original = [1, 2, 3]
alias = original
alias[0] = 99
print(original)  # [99, 2, 3] Â¡Original modificado!

# âœ… COPIA SUPERFICIAL: nueva lista, mismos objetos internos
original = [1, 2, 3]
copy1 = original[:]       # Slicing
copy2 = original.copy()   # MÃ©todo copy
copy3 = list(original)    # Constructor

copy1[0] = 99
print(original)  # [1, 2, 3] Â¡Original intacto!

# âš ï¸ Con objetos anidados, copia superficial NO es suficiente
nested = [[1, 2], [3, 4]]
shallow = nested.copy()
shallow[0][0] = 99        # Modifica el objeto interno
print(nested)             # [[99, 2], [3, 4]] Â¡Modificado!

# âœ… COPIA PROFUNDA: copia todo recursivamente
import copy
nested = [[1, 2], [3, 4]]
deep = copy.deepcopy(nested)
deep[0][0] = 99
print(nested)             # [[1, 2], [3, 4]] Â¡Intacto!
```

### 2.3 CuÃ¡ndo Importa

```python
# âŒ Bug comÃºn: modificar lista mientras se itera
def remove_short_words_bad(words: list[str]) -> list[str]:
    for word in words:  # Itera sobre la misma lista
        if len(word) < 3:
            words.remove(word)  # Â¡Modifica durante iteraciÃ³n!
    return words

# âœ… SoluciÃ³n 1: crear nueva lista
def remove_short_words_good(words: list[str]) -> list[str]:
    return [w for w in words if len(w) >= 3]

# âœ… SoluciÃ³n 2: iterar sobre copia
def remove_short_words_alt(words: list[str]) -> list[str]:
    for word in words[:]:  # Copia con [:]
        if len(word) < 3:
            words.remove(word)
    return words
```

---

## 3. Complejidad de Operaciones {#3-complejidad}

### 3.1 Tabla Completa

| OperaciÃ³n | Complejidad | Ejemplo |
|-----------|-------------|---------|
| Acceso `list[i]` | O(1) | `words[5]` |
| Asignar `list[i] = x` | O(1) | `words[5] = "new"` |
| `len(list)` | O(1) | `len(words)` |
| `list.append(x)` | O(1)* | `words.append("x")` |
| `list.pop()` | O(1) | `words.pop()` |
| `list.insert(0, x)` | O(n) | `words.insert(0, "x")` |
| `list.pop(0)` | O(n) | `words.pop(0)` |
| `x in list` | O(n) | `"hello" in words` |
| `list.index(x)` | O(n) | `words.index("hello")` |
| `list.count(x)` | O(n) | `words.count("the")` |
| `list.remove(x)` | O(n) | `words.remove("hello")` |
| `list.sort()` | O(n log n) | `words.sort()` |
| Slice `list[a:b]` | O(b-a) | `words[5:10]` |
| `list.extend(k)` | O(k) | `words.extend(["a","b"])` |

*Amortizado: ocasionalmente O(n) cuando se reasigna memoria.

### 3.2 Implicaciones PrÃ¡cticas

```python
# âŒ Ineficiente: insertar al inicio muchas veces â†’ O(nÂ²) total
def build_reversed_bad(items: list[str]) -> list[str]:
    result = []
    for item in items:
        result.insert(0, item)  # O(n) cada vez
    return result

# âœ… Eficiente: append y luego revertir â†’ O(n) total
def build_reversed_good(items: list[str]) -> list[str]:
    result = []
    for item in items:
        result.append(item)  # O(1) cada vez
    result.reverse()  # O(n) una vez
    return result

# âœ… MÃ¡s pythonic
def build_reversed_best(items: list[str]) -> list[str]:
    return items[::-1]
```

---

## 4. Strings: Inmutabilidad {#4-strings}

### 4.1 Strings Son Inmutables

```python
text = "Hello"

# âŒ No puedes modificar un carÃ¡cter
text[0] = "J"  # TypeError: 'str' object does not support item assignment

# âœ… Debes crear un nuevo string
text = "J" + text[1:]  # "Jello"

# Cada operaciÃ³n crea un NUEVO string
text = "Hello"
text = text + " World"  # Nuevo objeto, no modificaciÃ³n
text = text.lower()     # Nuevo objeto
text = text.strip()     # Nuevo objeto
```

### 4.2 ConcatenaciÃ³n Eficiente

```python
# âŒ Ineficiente: muchas concatenaciones â†’ O(nÂ²)
def build_string_bad(words: list[str]) -> str:
    result = ""
    for word in words:
        result = result + word + " "  # Crea nuevo string cada vez
    return result.strip()

# âœ… Eficiente: join â†’ O(n)
def build_string_good(words: list[str]) -> str:
    return " ".join(words)

# Benchmark con 10,000 palabras:
# build_string_bad:  ~0.1s
# build_string_good: ~0.001s (100x mÃ¡s rÃ¡pido)
```

### 4.3 MÃ©todos de String Ãštiles

```python
text = "  Hello, World! How are you?  "

# Limpieza
text.strip()      # "Hello, World! How are you?"
text.lower()      # "  hello, world! how are you?  "
text.upper()      # "  HELLO, WORLD! HOW ARE YOU?  "

# BÃºsqueda
text.find("World")     # 9 (Ã­ndice) o -1 si no existe
text.count("o")        # 3
"Hello" in text        # True
text.startswith("  H") # True
text.endswith("?  ")   # True

# DivisiÃ³n
text.split()           # ["Hello,", "World!", "How", "are", "you?"]
text.split(",")        # ["  Hello", " World! How are you?  "]

# Reemplazo
text.replace("!", "")  # Sin signos de exclamaciÃ³n
text.replace(" ", "_") # Espacios por guiones bajos

# VerificaciÃ³n
"hello".isalpha()      # True (solo letras)
"hello123".isalnum()   # True (letras y nÃºmeros)
"123".isdigit()        # True (solo dÃ­gitos)
"   ".isspace()        # True (solo espacios)
```

---

## 5. TokenizaciÃ³n: Tu Primer Componente {#5-tokenizacion}

### 5.1 Â¿QuÃ© es TokenizaciÃ³n?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TOKENIZACIÃ“N = Convertir texto en unidades procesables         â”‚
â”‚                                                                 â”‚
â”‚  Entrada:  "Hello, World! How are you?"                         â”‚
â”‚  Salida:   ["hello", "world", "how", "are", "you"]              â”‚
â”‚                                                                 â”‚
â”‚  Pasos tÃ­picos:                                                 â”‚
â”‚  1. Convertir a minÃºsculas                                      â”‚
â”‚  2. Eliminar puntuaciÃ³n                                         â”‚
â”‚  3. Dividir por espacios                                        â”‚
â”‚  4. Filtrar palabras vacÃ­as (stop words)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Tokenizador BÃ¡sico

```python
def tokenize_basic(text: str) -> list[str]:
    """Split text into lowercase words.
    
    Args:
        text: Input text to tokenize.
    
    Returns:
        List of lowercase tokens.
    
    Example:
        >>> tokenize_basic("Hello, World!")
        ['hello,', 'world!']
    """
    return text.lower().split()
```

### 5.3 Tokenizador con Limpieza de PuntuaciÃ³n

```python
def remove_punctuation(text: str) -> str:
    """Remove all punctuation from text.
    
    Uses character-by-character filtering.
    
    Args:
        text: Text potentially containing punctuation.
    
    Returns:
        Text with punctuation replaced by spaces.
    """
    result = []
    for char in text:
        if char.isalnum() or char.isspace():
            result.append(char)
        else:
            result.append(' ')  # Reemplazar puntuaciÃ³n por espacio
    return ''.join(result)


def tokenize_clean(text: str) -> list[str]:
    """Tokenize text with punctuation removal.
    
    Args:
        text: Input text.
    
    Returns:
        List of clean, lowercase tokens.
    
    Example:
        >>> tokenize_clean("Hello, World! How are you?")
        ['hello', 'world', 'how', 'are', 'you']
    """
    cleaned = remove_punctuation(text)
    return cleaned.lower().split()
```

### 5.4 Tokenizador con Stop Words

```python
# Stop words comunes en inglÃ©s
STOP_WORDS: frozenset[str] = frozenset({
    "a", "an", "the", "and", "or", "but", "is", "are", "was", "were",
    "be", "been", "being", "have", "has", "had", "do", "does", "did",
    "will", "would", "could", "should", "may", "might", "must",
    "i", "you", "he", "she", "it", "we", "they", "me", "him", "her",
    "us", "them", "my", "your", "his", "its", "our", "their",
    "this", "that", "these", "those", "what", "which", "who", "whom",
    "in", "on", "at", "by", "for", "with", "about", "to", "from",
    "of", "as", "if", "then", "than", "so", "no", "not", "only"
})


def tokenize(
    text: str,
    remove_stopwords: bool = True,
    min_length: int = 2
) -> list[str]:
    """Full tokenization pipeline.
    
    Args:
        text: Input text to tokenize.
        remove_stopwords: Whether to filter out stop words.
        min_length: Minimum token length to keep.
    
    Returns:
        List of processed tokens.
    
    Example:
        >>> tokenize("The quick brown fox jumps over the lazy dog.")
        ['quick', 'brown', 'fox', 'jumps', 'over', 'lazy', 'dog']
    """
    # 1. Remove punctuation
    cleaned = remove_punctuation(text)
    
    # 2. Lowercase and split
    tokens = cleaned.lower().split()
    
    # 3. Filter by length
    tokens = [t for t in tokens if len(t) >= min_length]
    
    # 4. Remove stop words
    if remove_stopwords:
        tokens = [t for t in tokens if t not in STOP_WORDS]
    
    return tokens
```

### 5.5 Clase Tokenizer (Aplicando OOP)

```python
class Tokenizer:
    """Configurable text tokenizer.
    
    Attributes:
        stop_words: Set of words to filter out.
        min_length: Minimum token length.
    
    Example:
        >>> tokenizer = Tokenizer()
        >>> tokenizer.tokenize("Hello, World!")
        ['hello', 'world']
    """
    
    DEFAULT_STOP_WORDS: frozenset[str] = STOP_WORDS
    
    def __init__(
        self,
        stop_words: set[str] | None = None,
        min_length: int = 2
    ) -> None:
        """Initialize tokenizer with configuration.
        
        Args:
            stop_words: Custom stop words (None uses defaults).
            min_length: Minimum token length to keep.
        """
        self.stop_words: frozenset[str] = (
            frozenset(stop_words) if stop_words is not None
            else self.DEFAULT_STOP_WORDS
        )
        self.min_length: int = min_length
    
    def _remove_punctuation(self, text: str) -> str:
        """Remove punctuation from text."""
        return ''.join(
            c if c.isalnum() or c.isspace() else ' '
            for c in text
        )
    
    def tokenize(self, text: str) -> list[str]:
        """Tokenize text into clean tokens.
        
        Args:
            text: Input text.
        
        Returns:
            List of processed tokens.
        """
        cleaned = self._remove_punctuation(text)
        tokens = cleaned.lower().split()
        
        return [
            token for token in tokens
            if len(token) >= self.min_length
            and token not in self.stop_words
        ]
    
    def __repr__(self) -> str:
        return (
            f"Tokenizer(stop_words={len(self.stop_words)} words, "
            f"min_length={self.min_length})"
        )
```

### 5.6 AnÃ¡lisis de Complejidad

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COMPLEJIDAD DE tokenize(text)                                  â”‚
â”‚                                                                 â”‚
â”‚  Sea n = len(text), m = nÃºmero de tokens                        â”‚
â”‚                                                                 â”‚
â”‚  1. remove_punctuation: O(n) - recorre cada carÃ¡cter            â”‚
â”‚  2. lower(): O(n) - recorre cada carÃ¡cter                       â”‚
â”‚  3. split(): O(n) - recorre buscando espacios                   â”‚
â”‚  4. Filtrar por longitud: O(m) - recorre tokens                 â”‚
â”‚  5. Filtrar stop words: O(m) - lookup O(1) por token            â”‚
â”‚                                                                 â”‚
â”‚  TOTAL: O(n + m) â‰ˆ O(n) ya que m â‰¤ n                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš ï¸ Errores Comunes

### Error 1: Modificar lista durante iteraciÃ³n

```python
# âŒ Bug: resultado impredecible
words = ["a", "the", "b", "an", "c"]
for word in words:
    if word in {"the", "an"}:
        words.remove(word)
# Resultado: ["a", "b", "c"] pero puede fallar

# âœ… Correcto: list comprehension
words = [w for w in words if w not in {"the", "an"}]
```

### Error 2: Concatenar strings en loop

```python
# âŒ O(nÂ²) - crea nuevo string cada vez
result = ""
for word in words:
    result += word + " "

# âœ… O(n) - usa join
result = " ".join(words)
```

### Error 3: Olvidar que strings son inmutables

```python
# âŒ No hace nada
text = "hello"
text.upper()  # Retorna nuevo string, no modifica
print(text)   # "hello" (sin cambios)

# âœ… Asignar resultado
text = text.upper()
print(text)   # "HELLO"
```

---

## ğŸ”§ Ejercicios PrÃ¡cticos

### Ejercicio 4.1: ManipulaciÃ³n de Listas
Ver [EJERCICIOS.md](EJERCICIOS.md#ejercicio-41)

### Ejercicio 4.2: Tokenizador BÃ¡sico
Ver [EJERCICIOS.md](EJERCICIOS.md#ejercicio-42)

### Ejercicio 4.3: AnÃ¡lisis de Complejidad
Ver [EJERCICIOS.md](EJERCICIOS.md#ejercicio-43)

---

## ğŸ“š Recursos Externos

| Recurso | Tipo | Prioridad |
|---------|------|-----------|
| [Python Lists](https://docs.python.org/3/tutorial/datastructures.html) | Docs | ğŸ”´ Obligatorio |
| [String Methods](https://docs.python.org/3/library/stdtypes.html#string-methods) | Docs | ğŸ”´ Obligatorio |
| [Time Complexity](https://wiki.python.org/moin/TimeComplexity) | Wiki | ğŸŸ¡ Recomendado |

---

## ğŸ”— Referencias del Glosario

- [Array](GLOSARIO.md#array)
- [String](GLOSARIO.md#string)
- [Inmutabilidad](GLOSARIO.md#inmutabilidad)
- [TokenizaciÃ³n](GLOSARIO.md#tokenizacion)

---

## ğŸ§­ NavegaciÃ³n

| â† Anterior | Ãndice | Siguiente â†’ |
|------------|--------|-------------|
| [03_LOGICA_DISCRETA](03_LOGICA_DISCRETA.md) | [00_INDICE](00_INDICE.md) | [05_HASHMAPS_SETS](05_HASHMAPS_SETS.md) |
