# MÃ³dulo 03 - CÃ¡lculo Multivariante para Deep Learning

> **ğŸ¯ Objetivo:** Dominar derivadas, gradientes y la Chain Rule para entender Backpropagation
> **Fase:** 1 - Fundamentos MatemÃ¡ticos | **Semanas 6-8**
> **Prerrequisitos:** MÃ³dulo 02 (Ãlgebra Lineal para ML)

---

<a id="m03-0"></a>

## ğŸ§­ CÃ³mo usar este mÃ³dulo (modo 0â†’100)

**PropÃ³sito:** que puedas hacer 3 cosas sin depender de â€œfeâ€:

- derivar gradientes de pÃ©rdidas comunes (MSE, BCE)
- implementar y depurar optimizaciÃ³n (gradient descent)
- entender por quÃ© backprop es chain rule aplicada a un grafo

### Objetivos de aprendizaje (medibles)

Al terminar este mÃ³dulo podrÃ¡s:

- **Calcular** derivadas y derivadas parciales (a mano y con verificaciÃ³n numÃ©rica).
- **Aplicar** gradiente y direcciÃ³n de mÃ¡ximo descenso para optimizar funciones.
- **Implementar** gradient descent con criterios de convergencia razonables.
- **Explicar** la Chain Rule y usarla para derivar gradientes compuestos.
- **Validar** derivadas con gradient checking (error relativo pequeÃ±o).

### Prerrequisitos

- `MÃ³dulo 02` (producto matricial, normas, intuiciÃ³n geomÃ©trica).

Enlaces rÃ¡pidos:

- [GLOSARIO: Derivative](GLOSARIO.md#derivative)
- [GLOSARIO: Gradient](GLOSARIO.md#gradient)
- [GLOSARIO: Gradient Descent](GLOSARIO.md#gradient-descent)
- [GLOSARIO: Chain Rule](GLOSARIO.md#chain-rule)
- [RECURSOS.md](RECURSOS.md)

### IntegraciÃ³n con Plan v4/v5

- VisualizaciÃ³n de optimizaciÃ³n: `study_tools/VISUALIZACION_GRADIENT_DESCENT.md`
- Simulacros: `study_tools/SIMULACRO_EXAMEN_TEORICO.md`
- EvaluaciÃ³n (rÃºbrica): [study_tools/RUBRICA_v1.md](../study_tools/RUBRICA_v1.md) (scope `M03` en `rubrica.csv`)
- Protocolo completo:
  - [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md)
  - [PLAN_V5_ESTRATEGICO.md](PLAN_V5_ESTRATEGICO.md)

### Recursos (cuÃ¡ndo usarlos)

| Prioridad | Recurso | CuÃ¡ndo usarlo en este mÃ³dulo | Para quÃ© |
|----------|---------|------------------------------|----------|
| **Obligatorio** | `study_tools/VISUALIZACION_GRADIENT_DESCENT.md` | Al implementar Gradient Descent (cuando ajustes `learning_rate` y criterios de parada) | Ver si â€œbajaâ€ o diverge y por quÃ© |
| **Complementario** | [`visualizations/viz_gradient_3d.py`](../visualizations/viz_gradient_3d.py) | Semana 7, cuando ya entiendas `âˆ‡J` pero el `learning_rate` se sienta â€œmÃ¡gicoâ€ | Generar un HTML interactivo con superficie 3D + trayectoria (convergencia/overshooting) |
| **Complementario** | [3Blue1Brown: Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr) | Antes de Chain Rule (o si derivar se siente mecÃ¡nico) | IntuiciÃ³n visual de derivadas y composiciÃ³n |
| **Complementario** | [Mathematics for ML: Multivariate Calculus](https://www.coursera.org/learn/multivariate-calculus-machine-learning) | Cuando pases de derivadas 1D a gradiente/derivadas parciales | PrÃ¡ctica estructurada con ejercicios |
| **Obligatorio** | `study_tools/SIMULACRO_EXAMEN_TEORICO.md` | Tras terminar Chain Rule (antes de saltar a M05/M07) | Verificar que puedes derivar sin mirar apuntes |
| **Opcional** | [RECURSOS.md](RECURSOS.md) | Al cerrar el mÃ³dulo (para refuerzo) | Elegir material extra sin perder foco |

### Criterio de salida (cuÃ¡ndo puedes avanzar)

- Puedes derivar y verificar (numÃ©rico vs analÃ­tico) gradientes de MSE y BCE.
- Puedes explicar chain rule en 5 lÃ­neas y aplicarla a una composiciÃ³n.
- Puedes ejecutar gradient checking y entender quÃ© significa el error relativo.

### Ritmo semanal recomendado (aplicado a Semanas 6â€“8)

- **Lunes y Martes (Concepto):** prioriza Chain Rule. Si solo dominas 1 cosa de cÃ¡lculo para DL, es esta.
- **MiÃ©rcoles y Jueves (ImplementaciÃ³n):** implementa y valida: gradientes analÃ­ticos + diferencias finitas.
- **Viernes (Romper cosas):** fuerza fallos tÃ­picos y explÃ­cales con teorÃ­a:
  - sube `learning_rate` hasta divergir y describe la seÃ±al en `history_f`
  - prueba entradas grandes en sigmoide (`z` muy positivo/negativo) y explica saturaciÃ³n (gradiente ~ 0)
  - cambia `epsilon` en diferencias finitas y observa cuÃ¡ndo se rompe (ruido numÃ©rico)

## ğŸ§  Â¿Por QuÃ© CÃ¡lculo para ML?

### âš ï¸ CRÃTICO: Sin Chain Rule No Hay Deep Learning

```
El algoritmo de Backpropagation ES la Regla de la Cadena aplicada
a funciones compuestas de redes neuronales.

Si no entiendes:
  âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚Å· Â· âˆ‚Å·/âˆ‚z Â· âˆ‚z/âˆ‚w

NO entenderÃ¡s por quÃ© funciona una red neuronal y
probablemente REPROBARÃS el curso de Deep Learning.
```

### ConexiÃ³n con el Pathway

| Concepto | Uso en ML | Curso del Pathway |
|----------|-----------|-------------------|
| **Derivada** | Tasa de cambio, pendiente | Todos |
| **Gradiente** | DirecciÃ³n de mÃ¡ximo ascenso | Supervised Learning |
| **Gradient Descent** | OptimizaciÃ³n de parÃ¡metros | Supervised + Deep Learning |
| **Chain Rule** | Backpropagation | Deep Learning |

---

## ğŸ§­ IntuiciÃ³n geomÃ©trica (para que no sea mecÃ¡nico)

### 1) El gradiente como brÃºjula en una montaÃ±a

Piensa en la funciÃ³n de pÃ©rdida `J(Î¸)` como un terreno (montaÃ±a/valle) y tÃº como alguien parado en un punto.

- `J` te dice la altura.
- El **gradiente** `âˆ‡J` apunta hacia donde el terreno sube mÃ¡s rÃ¡pido.
- Si quieres bajar (minimizar), te mueves en la direcciÃ³n opuesta:

`Î¸_{t+1} = Î¸_t - Î± âˆ‡J(Î¸_t)`

VisualizaciÃ³n sugerida (hazlo en papel):

- curvas de nivel (contornos) alrededor de un valle
- un vector `âˆ‡J` perpendicular a las curvas de nivel

### 2) La regla de la cadena como engranajes (ratios de cambio)

Imagina tres engranajes conectados:

`x  â†’  g(x)  â†’  f(g(x))`

Si giras un poquito el primer engranaje (`x`), el Ãºltimo (`f`) gira segÃºn dos â€œratiosâ€:

- cuÃ¡nto cambia `f` si cambia `g` (`df/dg`)
- cuÃ¡nto cambia `g` si cambia `x` (`dg/dx`)

Y la regla es:

`df/dx = (df/dg) Â· (dg/dx)`

Backprop es esto mismo, pero aplicado a un grafo con muchas piezas: multiplicas ratios locales y propagas desde el final al inicio.

Diagrama sugerido (dibÃºjalo): un grafo pequeÃ±o con nodos `z = Wx + b`, `a = Ï†(z)`, `L(a)` y flechas con gradientes â€œrÃ­o arribaâ€.

## ğŸ“š Contenido del MÃ³dulo

### Semana 6: Derivadas y Derivadas Parciales
### Semana 7: Gradiente y Gradient Descent
### Semana 8: Chain Rule y PreparaciÃ³n para Backprop

---

## ğŸ’» Parte 1: Derivadas

### 1.1 Concepto de Derivada

```python
import numpy as np
import matplotlib.pyplot as plt

"""
DERIVADA: Tasa de cambio instantÃ¡nea de una funciÃ³n.

DefiniciÃ³n formal:
    f'(x) = lim[hâ†’0] (f(x+h) - f(x)) / h

InterpretaciÃ³n geomÃ©trica: pendiente de la recta tangente.

Notaciones equivalentes:
    f'(x) = df/dx = d/dx f(x) = Df(x)
"""

def numerical_derivative(f, x: float, h: float = 1e-7) -> float:
    """
    Calcula la derivada numÃ©rica usando diferencias finitas.

    MÃ©todo: diferencia central (mÃ¡s preciso)
    f'(x) â‰ˆ (f(x+h) - f(x-h)) / (2h)
    """
    return (f(x + h) - f(x - h)) / (2 * h)


# Ejemplo: f(x) = xÂ²
def f(x):
    return x ** 2

# Derivada analÃ­tica: f'(x) = 2x
def f_prime_analytical(x):
    return 2 * x

# Comparar
x = 3.0
numerical = numerical_derivative(f, x)
analytical = f_prime_analytical(x)

print(f"f(x) = xÂ² en x={x}")
print(f"Derivada numÃ©rica:  {numerical:.6f}")
print(f"Derivada analÃ­tica: {analytical:.6f}")
print(f"Error: {abs(numerical - analytical):.2e}")
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 1.1: Concepto de Derivada</strong></summary>

#### 1) Metadatos (1â€“2 lÃ­neas)
- **TÃ­tulo:** Derivada como pendiente local + verificaciÃ³n numÃ©rica
- **ID (opcional):** `M03-T01_1`
- **DuraciÃ³n estimada:** 60â€“90 min
- **Nivel:** Fundamentos
- **Dependencias:** Ãlgebra bÃ¡sica, intuiciÃ³n de funciÃ³n

#### 2) Objetivo(s) de aprendizaje (medibles)
- Calcular una derivada analÃ­tica simple (ej. `xÂ²`) y **validarla** con diferencias finitas.
- Explicar quÃ© representa `h` y cÃ³mo afecta el error numÃ©rico.

#### 3) Relevancia y contexto
- En ML, el gradiente es â€œla derivadaâ€ que guÃ­a la optimizaciÃ³n; si no controlas el concepto, backprop se vuelve magia.

#### 4) Mapa conceptual / conceptos clave
- derivada = tasa de cambio local
- recta tangente
- diferencias finitas (central)

#### 5) Definiciones y fÃ³rmulas esenciales
- `f'(x) = lim[hâ†’0] (f(x+h) - f(x-h)) / (2h)` (central).

#### 6) ExplicaciÃ³n didÃ¡ctica (2 niveles)
- **IntuiciÃ³n:** â€œquÃ© tan inclinada estÃ¡ la curva en ese puntoâ€.
- **Operativa:** compara derivada analÃ­tica vs numÃ©rica y mira el error.

#### 7) Ejemplo modelado
- `f(x)=xÂ²` â†’ `f'(x)=2x`; valida en `x=3`.

#### 8) PrÃ¡ctica guiada
- Cambia `x` (ej. `-2`, `0.5`, `10`) y observa el error.

#### 9) PrÃ¡ctica independiente / transferencia
- Repite con `f(x)=xÂ³` y `f(x)=sin(x)` (deriva y verifica).

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© la diferencia central suele ser mÃ¡s precisa que la forward difference?

#### 11) Errores comunes
- Elegir `h` demasiado pequeÃ±o (ruido numÃ©rico) o demasiado grande (sesgo).

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe el esquema â€œanalÃ­tica vs numÃ©rica â†’ errorâ€ y explica quÃ© valida.

#### 13) DiferenciaciÃ³n
- Avanzado: prueba funciones con cambios bruscos (ej. `abs`) y discute no-diferenciabilidad.

#### 14) Recursos
- GLOSARIO: Derivative.

#### 15) Nota docente
- Exigir siempre â€œderivada + validaciÃ³n numÃ©ricaâ€ al introducir un nuevo gradiente.
</details>

### 1.2 Derivadas Comunes en ML

```python
import numpy as np

"""
DERIVADAS QUE NECESITAS MEMORIZAR PARA ML:

1. Constante:     d/dx(c) = 0
2. Lineal:        d/dx(x) = 1
3. Potencia:      d/dx(xâ¿) = nÂ·x^(n-1)
4. Exponencial:   d/dx(eË£) = eË£
5. Logaritmo:     d/dx(ln x) = 1/x
6. Suma:          d/dx(f+g) = f' + g'
7. Producto:      d/dx(fÂ·g) = f'g + fg'
8. Cociente:      d/dx(f/g) = (f'g - fg')/gÂ²
9. Cadena:        d/dx(f(g(x))) = f'(g(x))Â·g'(x)
"""

# Funciones de activaciÃ³n y sus derivadas

def sigmoid(x: np.ndarray) -> np.ndarray:
    """Ïƒ(x) = 1 / (1 + e^(-x))"""
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x: np.ndarray) -> np.ndarray:
    """
    d/dx Ïƒ(x) = Ïƒ(x) Â· (1 - Ïƒ(x))

    DerivaciÃ³n:
    Ïƒ(x) = (1 + e^(-x))^(-1)
    Ïƒ'(x) = -1Â·(1 + e^(-x))^(-2) Â· (-e^(-x))
          = e^(-x) / (1 + e^(-x))Â²
          = Ïƒ(x) Â· (1 - Ïƒ(x))
    """
    s = sigmoid(x)
    return s * (1 - s)


def relu(x: np.ndarray) -> np.ndarray:
    """ReLU(x) = max(0, x)"""
    return np.maximum(0, x)

def relu_derivative(x: np.ndarray) -> np.ndarray:
    """
    d/dx ReLU(x) = { 1 si x > 0
                  { 0 si x < 0
                  { indefinido si x = 0 (usamos 0)
    """
    return (x > 0).astype(float)


def tanh_derivative(x: np.ndarray) -> np.ndarray:
    """
    d/dx tanh(x) = 1 - tanhÂ²(x)
    """
    return 1 - np.tanh(x) ** 2


# Verificar con derivada numÃ©rica
def verify_derivative(f, f_prime, x, name):
    numerical = (f(x + 1e-7) - f(x - 1e-7)) / (2e-7)
    analytical = f_prime(x)
    error = np.abs(numerical - analytical).max()
    print(f"{name}: error mÃ¡ximo = {error:.2e}")

x = np.array([-2, -1, 0.5, 1, 2])
verify_derivative(sigmoid, sigmoid_derivative, x, "Sigmoid")
verify_derivative(np.tanh, tanh_derivative, x, "Tanh")
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 1.2: Derivadas Comunes en ML</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** â€œderivadas que debes memorizarâ€ + verificaciÃ³n automÃ¡tica
- **ID (opcional):** `M03-T01_2`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Fundamentos
- **Dependencias:** 1.1

#### 2) Objetivos
- Memorizar y aplicar derivadas de `exp`, `log`, potencias y activaciones (sigmoid/tanh/ReLU).
- Implementar un verificador numÃ©rico y usar el error para detectar bugs.

#### 3) Relevancia
- Estas derivadas aparecen en backprop: activaciÃ³n + loss + capa lineal.

#### 4) Conceptos clave
- `Ïƒ'(x) = Ïƒ(x)(1-Ïƒ(x))`
- `tanh'(x) = 1-tanh(x)^2`
- ReLU derivada por tramos

#### 5) FÃ³rmulas esenciales
- Regla de la cadena (adelanto): derivadas se multiplican en composiciones.

#### 6) ExplicaciÃ³n didÃ¡ctica
- **PatrÃ³n ML:** implementa `f`, implementa `f'`, valida con diferencias finitas.

#### 7) Ejemplo modelado
- VerificaciÃ³n de `sigmoid` y `tanh` con error mÃ¡ximo.

#### 8) PrÃ¡ctica guiada
- AÃ±ade `relu` al verificador y discute el punto `x=0`.

#### 9) PrÃ¡ctica independiente
- Implementa `softplus(x)=log(1+exp(x))` y su derivada; verifica numÃ©ricamente.

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© en `sigmoid_derivative` conviene reutilizar `Ïƒ(x)` en lugar de re-computar `exp`?

#### 11) Errores comunes
- Overflow en `exp` para `x` grande (necesidad de estabilidad numÃ©rica).

#### 12) RetenciÃ³n
- (dÃ­a 7) recita 5 derivadas clave sin mirar (potencia, exp, log, sigmoid, tanh).

#### 13) DiferenciaciÃ³n
- Avanzado: explica por quÃ© ReLU â€œfuncionaâ€ pese a no ser derivable en 0.

#### 14) Recursos
- GLOSARIO: Gradient, Chain Rule.

#### 15) Nota docente
- Requerir â€œtabla personalâ€ de derivadas + mini test de verificaciÃ³n.
</details>

### 1.3 Derivadas Parciales

```python
import numpy as np

"""
DERIVADA PARCIAL: Derivada respecto a UNA variable,
manteniendo las otras constantes.

Para f(x, y):
    âˆ‚f/âˆ‚x = derivada respecto a x, tratando y como constante
    âˆ‚f/âˆ‚y = derivada respecto a y, tratando x como constante

NotaciÃ³n: âˆ‚ (partial) en lugar de d
"""

def f(x: float, y: float) -> float:
    """f(x, y) = xÂ² + 3xy + yÂ²"""
    return x**2 + 3*x*y + y**2

# Derivadas parciales analÃ­ticas:
# âˆ‚f/âˆ‚x = 2x + 3y
# âˆ‚f/âˆ‚y = 3x + 2y

def df_dx(x: float, y: float) -> float:
    """âˆ‚f/âˆ‚x = 2x + 3y"""
    return 2*x + 3*y

def df_dy(x: float, y: float) -> float:
    """âˆ‚f/âˆ‚y = 3x + 2y"""
    return 3*x + 2*y


# Derivada parcial numÃ©rica
def partial_derivative(f, var_idx: int, point: list, h: float = 1e-7) -> float:
    """
    Calcula âˆ‚f/âˆ‚xáµ¢ en un punto dado.

    Args:
        f: funciÃ³n
        var_idx: Ã­ndice de la variable (0 para x, 1 para y, etc.)
        point: punto donde evaluar [x, y, ...]
        h: paso pequeÃ±o
    """
    point_plus = point.copy()
    point_minus = point.copy()
    point_plus[var_idx] += h
    point_minus[var_idx] -= h
    return (f(*point_plus) - f(*point_minus)) / (2 * h)


# Verificar
point = [2.0, 3.0]
print(f"Punto: x={point[0]}, y={point[1]}")
print(f"f(x,y) = {f(*point)}")
print(f"\nâˆ‚f/âˆ‚x:")
print(f"  AnalÃ­tica: {df_dx(*point)}")
print(f"  NumÃ©rica:  {partial_derivative(f, 0, point):.6f}")
print(f"\nâˆ‚f/âˆ‚y:")
print(f"  AnalÃ­tica: {df_dy(*point)}")
print(f"  NumÃ©rica:  {partial_derivative(f, 1, point):.6f}")
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 1.3: Derivadas Parciales</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Parciales como â€œcongelar variablesâ€ + check numÃ©rico
- **ID (opcional):** `M03-T01_3`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Fundamentos
- **Dependencias:** 1.1

#### 2) Objetivos
- Calcular `âˆ‚f/âˆ‚x` y `âˆ‚f/âˆ‚y` y verificarlas numÃ©ricamente en un punto.
- Interpretar â€œmantener constanteâ€ y su conexiÃ³n con gradiente.

#### 3) Relevancia
- Backprop calcula parciales â€œlocalesâ€ en cada nodo del grafo.

#### 4) Conceptos clave
- parcial vs total
- punto de evaluaciÃ³n
- diferencias finitas por coordenada

#### 5) FÃ³rmulas
- `âˆ‚f/âˆ‚x â‰ˆ (f(x+h,y)-f(x-h,y)) / (2h)`.

#### 6) ExplicaciÃ³n didÃ¡ctica
- Cada parcial es â€œcÃ³mo cambia la salida si muevo solo una coordenadaâ€.

#### 7) Ejemplo modelado
- `f(x,y)=xÂ²+3xy+yÂ²` con parciales analÃ­ticas y check.

#### 8) PrÃ¡ctica guiada
- Cambia el punto (ej. `[0,0]`, `[1,-2]`) y compara parciales.

#### 9) PrÃ¡ctica independiente
- Define `g(x,y)=sin(xy)+x` y deriva parciales; valida.

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© el gradiente junta todas las parciales en un vector?

#### 11) Errores comunes
- Confundir `df/dx` (1D) con `âˆ‚f/âˆ‚x` (multivariable).

#### 12) RetenciÃ³n
- (dÃ­a 2) explica la idea de â€œcongelar variablesâ€ con un ejemplo propio.

#### 13) DiferenciaciÃ³n
- Avanzado: relacionar parciales con derivada direccional (preview del gradiente).

#### 14) Recursos
- GLOSARIO: Gradient.

#### 15) Nota docente
- Repetir: â€œprimero analÃ­tica, luego numÃ©rica, luego interpretaciÃ³nâ€.
</details>

---

## ğŸ’» Parte 2: Gradiente

### 2.1 DefiniciÃ³n del Gradiente

```python
import numpy as np

"""
GRADIENTE: Vector de todas las derivadas parciales.

Para f: Râ¿ â†’ R (funciÃ³n de n variables que retorna un escalar):

âˆ‡f = [âˆ‚f/âˆ‚xâ‚, âˆ‚f/âˆ‚xâ‚‚, ..., âˆ‚f/âˆ‚xâ‚™]

Propiedades importantes:
1. El gradiente apunta en la direcciÃ³n de MÃXIMO ASCENSO
2. La magnitud indica quÃ© tan rÃ¡pido aumenta f en esa direcciÃ³n
3. -âˆ‡f apunta en la direcciÃ³n de MÃXIMO DESCENSO (usado en optimizaciÃ³n)
"""

def compute_gradient(f, point: np.ndarray, h: float = 1e-7) -> np.ndarray:
    """
    Calcula el gradiente de f en un punto usando diferencias finitas.

    Args:
        f: funciÃ³n f(x) donde x es un array
        point: punto donde calcular el gradiente
        h: paso para diferencias finitas

    Returns:
        gradiente como array
    """
    n = len(point)
    gradient = np.zeros(n)

    for i in range(n):
        point_plus = point.copy()
        point_minus = point.copy()
        point_plus[i] += h
        point_minus[i] -= h
        gradient[i] = (f(point_plus) - f(point_minus)) / (2 * h)

    return gradient


# Ejemplo: f(x, y) = xÂ² + yÂ²
def paraboloid(p: np.ndarray) -> float:
    """Paraboloide: f(x,y) = xÂ² + yÂ²"""
    return p[0]**2 + p[1]**2

# Gradiente analÃ­tico: âˆ‡f = [2x, 2y]
def paraboloid_gradient_analytical(p: np.ndarray) -> np.ndarray:
    return np.array([2*p[0], 2*p[1]])


# Verificar
point = np.array([3.0, 4.0])
grad_numerical = compute_gradient(paraboloid, point)
grad_analytical = paraboloid_gradient_analytical(point)

print(f"Punto: {point}")
print(f"f(punto) = {paraboloid(point)}")
print(f"Gradiente numÃ©rico:  {grad_numerical}")
print(f"Gradiente analÃ­tico: {grad_analytical}")
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 2.1: DefiniciÃ³n del Gradiente</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Gradiente como vector de derivadas parciales + verificaciÃ³n numÃ©rica
- **ID (opcional):** `M03-T02_1`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Fundamentos
- **Dependencias:** 1.3 (parciales)

#### 2) Objetivos
- Calcular un gradiente analÃ­tico simple (paraboloide) y **validarlo** con diferencias finitas.
- Interpretar `âˆ‡f` como direcciÃ³n de mÃ¡ximo ascenso y `-âˆ‡f` como direcciÃ³n de descenso.

#### 3) Relevancia
- El gradiente es la seÃ±al que guÃ­a el entrenamiento en ML; si el gradiente estÃ¡ mal, el modelo no aprende.

#### 4) Conceptos clave
- `âˆ‡f` (vector)
- norma del gradiente
- diferencia central por coordenada

#### 5) FÃ³rmulas esenciales
- `âˆ‡f = [âˆ‚f/âˆ‚xâ‚, â€¦, âˆ‚f/âˆ‚xâ‚™]`.

#### 6) ExplicaciÃ³n didÃ¡ctica
- **Mentalidad de debugging:** primero deriva, luego valida numÃ©ricamente, luego interpreta.

#### 7) Ejemplo modelado
- `f(x,y)=xÂ²+yÂ²` â†’ `âˆ‡f=[2x,2y]`.

#### 8) PrÃ¡ctica guiada
- Cambia el punto (ej. `[1,1]`, `[-3,0]`) y compara gradiente analÃ­tico vs numÃ©rico.

#### 9) PrÃ¡ctica independiente
- Define `f(x,y)=xÂ²+10yÂ²` y deriva `âˆ‡f`; valida numÃ©ricamente.

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© `âˆ‡f` es perpendicular a las curvas de nivel?

#### 11) Errores comunes
- Confundir gradiente (vector) con â€œderivadaâ€ (escalar).

#### 12) RetenciÃ³n
- (dÃ­a 2) explica en 2 frases quÃ© te dice la direcciÃ³n de `-âˆ‡f`.

#### 13) DiferenciaciÃ³n
- Avanzado: conecta `||âˆ‡f||` con â€œquÃ© tan empinadaâ€ es la superficie.

#### 14) Recursos
- GLOSARIO: Gradient.

#### 15) Nota docente
- Exigir `allclose`/comparaciÃ³n numÃ©rica para gradientes nuevos (hÃ¡bito tipo â€œgrad-check miniâ€).
</details>

### 2.2 VisualizaciÃ³n del Gradiente

```python
import numpy as np
import matplotlib.pyplot as plt

def visualize_gradient():
    """Visualiza el gradiente como campo vectorial."""

    # Crear grid
    x = np.linspace(-3, 3, 15)
    y = np.linspace(-3, 3, 15)
    X, Y = np.meshgrid(x, y)

    # FunciÃ³n: f(x,y) = xÂ² + yÂ²
    Z = X**2 + Y**2

    # Gradiente: âˆ‡f = [2x, 2y]
    U = 2 * X  # âˆ‚f/âˆ‚x
    V = 2 * Y  # âˆ‚f/âˆ‚y

    # Normalizar para visualizaciÃ³n
    magnitude = np.sqrt(U**2 + V**2)
    U_norm = U / (magnitude + 0.1)
    V_norm = V / (magnitude + 0.1)

    plt.figure(figsize=(10, 8))

    # Contornos de nivel
    plt.contour(X, Y, Z, levels=20, cmap='viridis', alpha=0.5)
    plt.colorbar(label='f(x,y) = xÂ² + yÂ²')

    # Flechas del gradiente
    plt.quiver(X, Y, U_norm, V_norm, magnitude, cmap='Reds', alpha=0.8)

    # Punto mÃ­nimo
    plt.plot(0, 0, 'g*', markersize=15, label='MÃ­nimo global')

    plt.xlabel('x')
    plt.ylabel('y')
    plt.title('Gradiente de f(x,y) = xÂ² + yÂ²\nLas flechas apuntan hacia ARRIBA (mÃ¡ximo ascenso)')
    plt.legend()
    plt.axis('equal')
    plt.grid(True, alpha=0.3)
    plt.show()

# visualize_gradient()  # Descomentar para ejecutar

```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 2.2: VisualizaciÃ³n del Gradiente</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Campo vectorial y contornos: ver `âˆ‡f` en acciÃ³n
- **ID (opcional):** `M03-T02_2`
- **DuraciÃ³n estimada:** 45â€“90 min
- **Nivel:** Fundamentos
- **Dependencias:** 2.1

#### 2) Objetivos
- Interpretar un campo vectorial del gradiente y relacionarlo con contornos de nivel.
- Explicar por quÃ© las flechas apuntan hacia mÃ¡ximo ascenso.

#### 3) Relevancia
- Evita que Gradient Descent se convierta en â€œrecetaâ€: aquÃ­ ves el porquÃ© geomÃ©trico.

#### 4) Conceptos clave
- curvas de nivel
- direcciÃ³n perpendicular
- normalizaciÃ³n para visualizaciÃ³n

#### 5) FÃ³rmulas esenciales
- Para `f(x,y)=xÂ²+yÂ²`: `âˆ‡f=[2x,2y]`.

#### 6) ExplicaciÃ³n didÃ¡ctica
- Contornos = â€œmisma alturaâ€; gradiente apunta al cambio mÃ¡s rÃ¡pido â†’ cruza contornos en Ã¡ngulo recto.

#### 7) Ejemplo modelado
- Flechas alrededor del origen apuntan hacia afuera (sube); para bajar, irÃ­as hacia adentro.

#### 8) PrÃ¡ctica guiada
- Cambia `Z` a `X**2 + 10*Y**2` y observa cÃ³mo cambia el campo.

#### 9) PrÃ¡ctica independiente
- Prueba una funciÃ³n con â€œvalleâ€ (tipo Rosenbrock) y discute por quÃ© el gradiente puede zigzaguear.

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© normalizar `U,V` ayuda a visualizar pero no cambia la direcciÃ³n?

#### 11) Errores comunes
- Interpretar el tamaÃ±o de flecha sin considerar la normalizaciÃ³n.

#### 12) RetenciÃ³n
- (dÃ­a 7) dibuja a mano contornos y gradiente para una funciÃ³n simple.

#### 13) DiferenciaciÃ³n
- Avanzado: conecta con Hessiano (curvatura) (preview de ejercicios).

#### 14) Recursos
- `visualizations/viz_gradient_3d.py` (para trayectoria + superficie).

#### 15) Nota docente
- Pedir una explicaciÃ³n oral: â€œpor quÃ© el gradiente es perpendicular a contornosâ€.
</details>

---

### IntuiciÃ³n: Gradient Descent como â€œbajar una montaÃ±a en la nieblaâ€

Imagina que estÃ¡s en una montaÃ±a con niebla: no ves el valle (mÃ­nimo), pero puedes **sentir la pendiente local**.

- **El gradiente** `âˆ‡f(x)` apunta hacia el â€œsubir mÃ¡s rÃ¡pidoâ€.
- Para bajar, te mueves en la direcciÃ³n opuesta: `-âˆ‡f(x)`.
- El `learning_rate (Î±)` es el tamaÃ±o del paso: demasiado grande â†’ te pasas/oscillas; demasiado pequeÃ±o â†’ avanzas lento.

Checklist de diagnÃ³stico rÃ¡pido:

- **Si diverge:** `Î±` es demasiado grande o tu gradiente estÃ¡ mal.
- **Si converge muy lento:** `Î±` demasiado pequeÃ±o.
- **Si el loss baja y luego sube:** posible oscilaciÃ³n (reduce `Î±`).
- **Si no baja nunca:** gradiente incorrecto (haz gradient checking).

## ğŸ’» Parte 3: Gradient Descent

### 3.1 Algoritmo BÃ¡sico

#### CÃ³digo generador de intuiciÃ³n (Protocolo D): superficie 3D + slider de `learning_rate`

Ejecuta el script (genera un HTML interactivo):

- [`visualizations/viz_gradient_3d.py`](../visualizations/viz_gradient_3d.py)

Ejemplos:

```bash
python3 visualizations/viz_gradient_3d.py --lr 0.01 --steps 30 --html-out artifacts/gd_lr0_01.html
python3 visualizations/viz_gradient_3d.py --lr 1.0 --steps 30 --html-out artifacts/gd_lr1_0.html
```

Checklist de uso:

- cambia `lr` a valores pequeÃ±os (ej. `0.01`) y observa convergencia suave
- sube `lr` (ej. `0.5` o `1.0`) y observa oscilaciÃ³n/divergencia

Objetivo: que puedas explicar la frase:

> â€œEl learning rate no es un nÃºmero mÃ¡gico: controla cuÃ¡nto avanzas en la direcciÃ³n del gradiente, y si te pasas, rebotas.â€

"""
GRADIENT DESCENT: Algoritmo de optimizaciÃ³n iterativo.

Idea: Para minimizar f(x), moverse en direcciÃ³n opuesta al gradiente.

Algoritmo:
    1. Inicializar xâ‚€
    2. Repetir hasta convergencia:
       x_{t+1} = x_t - Î± Â· âˆ‡f(x_t)

Donde Î± (alpha) es el "learning rate" (tasa de aprendizaje).
"""

def gradient_descent(
    f: Callable,
    grad_f: Callable,
    x0: np.ndarray,
    learning_rate: float = 0.1,
    max_iterations: int = 100,
    tolerance: float = 1e-6
) -> Tuple[np.ndarray, List[np.ndarray], List[float]]:
    """
    Gradient Descent para minimizar f.

    Args:
        f: funciÃ³n a minimizar
        grad_f: gradiente de f
        x0: punto inicial
        learning_rate: tasa de aprendizaje (Î±)
        max_iterations: mÃ¡ximo de iteraciones
        tolerance: criterio de parada (norma del gradiente)

    Returns:
        x_final: soluciÃ³n encontrada
        history_x: trayectoria de x
        history_f: valores de f en cada paso
    """
    x = x0.copy()
    history_x = [x.copy()]
    history_f = [f(x)]

    for i in range(max_iterations):
        # Calcular gradiente
        grad = grad_f(x)

        # Verificar convergencia
        if np.linalg.norm(grad) < tolerance:
            print(f"ConvergiÃ³ en iteraciÃ³n {i}")
            break

        # Actualizar x
        x = x - learning_rate * grad

        # Guardar historia
        history_x.append(x.copy())
        history_f.append(f(x))

    return x, history_x, history_f


# Ejemplo: Minimizar f(x,y) = xÂ² + yÂ²
def f(p: np.ndarray) -> float:
    return p[0]**2 + p[1]**2

def grad_f(p: np.ndarray) -> np.ndarray:
    return np.array([2*p[0], 2*p[1]])

# Ejecutar
x0 = np.array([4.0, 3.0])
x_final, history_x, history_f = gradient_descent(f, grad_f, x0, learning_rate=0.1)

print(f"\nPunto inicial: {x0}")
print(f"MÃ­nimo encontrado: {x_final}")
print(f"f(mÃ­nimo) = {f(x_final):.6f}")
print(f"Iteraciones: {len(history_f)}")

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 3.1: Algoritmo BÃ¡sico (Gradient Descent)</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Gradient Descent como iteraciÃ³n `x â† x - Î±âˆ‡f(x)`
- **ID (opcional):** `M03-T03_1`
- **DuraciÃ³n estimada:** 90â€“150 min
- **Nivel:** Intermedio
- **Dependencias:** 2.1 (gradiente), 2.2 (intuiciÃ³n geomÃ©trica)

#### 2) Objetivos
- Implementar GD 2D y **explicar** el rol de `Î±` y el criterio `||âˆ‡f|| < tol`.
- Diagnosticar convergencia/overshooting a partir del historial de `f`.

#### 3) Relevancia
- Es el nÃºcleo de entrenamiento en ML (con variantes: SGD, Adam).

#### 4) Conceptos clave
- `learning_rate` (Î±)
- criterio de parada
- trayectoria (historia)

#### 5) FÃ³rmulas
- `x_{t+1} = x_t - Î± âˆ‡f(x_t)`.

#### 6) DidÃ¡ctica
- Siempre guarda `history_x` y `history_f` para â€œverâ€ si aprende.

#### 7) Ejemplo modelado
- `f(x,y)=xÂ²+yÂ²` converge al origen.

#### 8) PrÃ¡ctica guiada
- Cambia `Î±` y observa nÃºmero de iteraciones.

#### 9) Transferencia
- Usa el mismo patrÃ³n con una funciÃ³n elÃ­ptica (mal condicionada).

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© `-âˆ‡f` baja localmente la funciÃ³n?

#### 11) Errores comunes
- `Î±` grande â†’ diverge; `Î±` pequeÃ±o â†’ lento.

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe el update rule y nombra cada tÃ©rmino.

#### 13) DiferenciaciÃ³n
- Avanzado: diferencia entre stopping por `||âˆ‡f||` vs cambio en `f`.

#### 14) Recursos
- `visualizations/viz_gradient_3d.py`.

#### 15) Nota docente
- Pedir â€œreporte de diagnÃ³sticoâ€: converge/divege y por quÃ©.
</details>

### 3.2 Efecto del Learning Rate

"""
El learning rate (Î±) controla la velocidad de convergencia.

- Î± muy pequeÃ±o: Convergencia lenta
- Î± Ã³ptimo: Convergencia rÃ¡pida y estable
- Î± muy grande: Oscilaciones, puede diverger
"""

import numpy as np
import matplotlib.pyplot as plt

def compare_learning_rates():
    """Compara diferentes learning rates."""

    def f(p):
        return p[0]**2 + p[1]**2

    def grad_f(p):
        return np.array([2*p[0], 2*p[1]])

    x0 = np.array([4.0, 3.0])

    learning_rates = [0.01, 0.1, 0.5, 0.9]

    plt.figure(figsize=(12, 4))

    for i, lr in enumerate(learning_rates):
        x_final, history_x, history_f = gradient_descent(
            f, grad_f, x0, learning_rate=lr, max_iterations=50
        )

        plt.subplot(1, 4, i+1)
        plt.plot(history_f, 'b-o', markersize=3)
        plt.xlabel('IteraciÃ³n')
        plt.ylabel('f(x)')
        plt.title(f'Î± = {lr}')
        plt.yscale('log')
        plt.grid(True)

    plt.tight_layout()
    plt.suptitle('Efecto del Learning Rate en Gradient Descent', y=1.02)
    plt.show()

    """
    Observaciones:
    - Î± muy pequeÃ±o (0.01): Convergencia muy lenta
    - Î± Ã³ptimo (0.1-0.5): Convergencia rÃ¡pida y estable
    - Î± muy grande (0.9): Oscilaciones, puede diverger
    - Î± > 1: Generalmente diverge para este problema
    """

# compare_learning_rates()  # Descomentar para ejecutar

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 3.2: Efecto del Learning Rate</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Estabilidad: cÃ³mo `Î±` controla convergencia vs oscilaciÃ³n
- **ID (opcional):** `M03-T03_2`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Intermedio
- **Dependencias:** 3.1

#### 2) Objetivos
- Comparar curvas de `f(x)` para distintos `Î±` y **clasificar** el comportamiento.
- Identificar seÃ±ales de inestabilidad (oscilaciÃ³n, diverge).

#### 3) Relevancia
- El ajuste de LR es una de las causas #1 de entrenamiento inestable.

#### 4) Conceptos clave
- escala log en loss
- overshooting
- sensibilidad a condiciones

#### 5) FÃ³rmulas
- GD con `Î±` fijo: estabilidad depende de curvatura (idea cualitativa).

#### 6) DidÃ¡ctica
- â€œMira la curvaâ€: suave â†’ ok, serrucho â†’ alto, explode â†’ demasiado alto.

#### 7) Ejemplo modelado
- ComparaciÃ³n de `Î± âˆˆ {0.01,0.1,0.5,0.9}`.

#### 8) PrÃ¡ctica guiada
- AÃ±ade un `Î±=1.1` y observa.

#### 9) Transferencia
- Relaciona con entrenamiento de NN (LR schedules / Adam) (preview).

#### 10) EvaluaciÃ³n
- Â¿Por quÃ© usar escala log ayuda a comparar convergencia?

#### 11) Errores comunes
- Concluir â€œno aprendeâ€ cuando solo falta bajar `Î±`.

#### 12) RetenciÃ³n
- (dÃ­a 7) escribe 3 sÃ­ntomas y la acciÃ³n correctiva.

#### 13) DiferenciaciÃ³n
- Avanzado: conecta `Î±` con â€œcurvaturaâ€ (Hessiano) de forma conceptual.

#### 14) Recursos
- `study_tools/VISUALIZACION_GRADIENT_DESCENT.md`.

#### 15) Nota docente
- Exigir evidencia: plot + explicaciÃ³n del caso.
</details>

### 3.3 Funciones de PÃ©rdida en ML

"""
FUNCIONES DE PÃ‰RDIDA COMUNES Y SUS GRADIENTES

En ML, minimizamos una "funciÃ³n de pÃ©rdida" (loss function)
que mide quÃ© tan mal estÃ¡n nuestras predicciones.
"""

# 1. MSE (Mean Squared Error) - RegresiÃ³n
def mse_loss(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """Mean Squared Error."""
    return np.mean((y_true - y_pred) ** 2)

def mse_gradient(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:
    """Gradiente de MSE respecto a y_pred."""
    n = len(y_true)
    return 2 * (y_pred - y_true) / n


# 2. Binary Cross-Entropy - ClasificaciÃ³n binaria
def binary_cross_entropy(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-15) -> float:
    """Binary Cross-Entropy."""
    y_pred = np.clip(y_pred, eps, 1 - eps)  # Evitar log(0)
    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))

def binary_cross_entropy_gradient(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-15) -> np.ndarray:
    """Gradiente de BCE respecto a y_pred."""
    y_pred = np.clip(y_pred, eps, 1 - eps)
    return (y_pred - y_true) / (y_pred * (1 - y_pred)) / len(y_true)


# Demo
np.random.seed(42)
y_true = np.array([0, 0, 1, 1])
y_pred = np.array([0.1, 0.2, 0.8, 0.9])

print("MSE Loss:", mse_loss(y_true, y_pred))
print("BCE Loss:", binary_cross_entropy(y_true, y_pred))

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 3.3: Funciones de PÃ©rdida en ML</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Loss + gradiente: contrato mÃ­nimo para entrenar
- **ID (opcional):** `M03-T03_3`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Intermedio
- **Dependencias:** 1.2 (derivadas), 3.1

#### 2) Objetivos
- Implementar MSE y BCE y **derivar/validar** su gradiente respecto a `y_pred`.
- Explicar por quÃ© se usa `clip` en BCE (estabilidad numÃ©rica).

#### 3) Relevancia
- Sin `loss` y su gradiente correcto, no hay entrenamiento fiable.

#### 4) Conceptos clave
- MSE (regresiÃ³n)
- BCE (clasificaciÃ³n)
- estabilidad: `log(0)`

#### 5) FÃ³rmulas esenciales
- `MSE = mean((y-Å·)^2)`; `âˆ‚MSE/âˆ‚Å· = 2(Å·-y)/n`.

#### 6) DidÃ¡ctica
- Separar: (1) definiciÃ³n de loss (2) gradiente (3) sanity-check numÃ©rico.

#### 7) Ejemplo modelado
- Dataset mini con `y_true` y `y_pred` y prints de losses.

#### 8) PrÃ¡ctica guiada
- Haz gradient checking de `mse_gradient` con diferencias finitas.

#### 9) PrÃ¡ctica independiente
- Conecta con `âˆ‚L/âˆ‚z` en una neurona (preview de Chain Rule).

#### 10) EvaluaciÃ³n
- Â¿QuÃ© problema evita `eps`/`clip` en BCE?

#### 11) Errores comunes
- confundir gradiente respecto a `Å·` vs respecto a parÃ¡metros.

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe MSE y su gradiente sin mirar.

#### 13) DiferenciaciÃ³n
- Avanzado: discusiÃ³n conceptual de saturaciÃ³n en sigmoid + BCE.

#### 14) Recursos
- CS231n: loss functions + numerical gradient check.

#### 15) Nota docente
- Hacer que el alumno identifique â€œdÃ³nde entra el `clip`â€ y por quÃ©.
</details>

---
## ğŸ’» Parte 4: Regla de la Cadena (Chain Rule)

### 4.0.0 IntroducciÃ³n

La Regla de la Cadena (Chain Rule) es un concepto fundamental en el cÃ¡lculo que nos permite encontrar la derivada de una funciÃ³n compuesta. En el contexto del aprendizaje automÃ¡tico, esta regla es crucial para el entrenamiento de modelos, ya que nos permite calcular la derivada de la funciÃ³n de pÃ©rdida con respecto a los parÃ¡metros del modelo.

### 4.0 VisualizaciÃ³n: Grafo computacional (computational graph)

En Deep Learning, casi todo es una composiciÃ³n de funciones. El truco mental es pensar en un **grafo**:
```
x â”€â”€â–º z = wÂ·x + b â”€â”€â–º a = Ïƒ(z) â”€â”€â–º L(a, y)

(forward)  verde: xâ†’zâ†’aâ†’L
(backward) rojo:  dL/da â†’ da/dz â†’ dz/dw, dz/db
```

Regla de oro (chain rule):

```
dL/dw = dL/da Â· da/dz Â· dz/dw
dL/db = dL/da Â· da/dz Â· dz/db
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 4.0: VisualizaciÃ³n: Grafo computacional (computational graph)</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Grafo computacional: pensar en â€œnodosâ€ y â€œrutasâ€ de derivaciÃ³n
- **ID (opcional):** `M03-T04_0`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Intermedio
- **Dependencias:** 1.2 (derivadas), 3.3 (loss), 2.1 (gradiente)

#### 2) Objetivos
- Explicar con tus palabras la diferencia entre **forward** y **backward** en el grafo.
- Usar la regla de la cadena para obtener `dL/dw` y `dL/db` como producto de factores locales.

#### 3) Relevancia
- Este patrÃ³n mental es el corazÃ³n de backpropagation: derivadas locales + composiciÃ³n.

#### 4) Mapa conceptual mÃ­nimo
- **ComposiciÃ³n:** `x â†’ u â†’ y`.
- **Backward:** se propagan derivadas desde `L` hacia los parÃ¡metros.

#### 5) Definiciones esenciales
- **Grafo computacional:** diagrama dirigido donde cada nodo es una operaciÃ³n/funciÃ³n.
- **Derivada local:** derivada de una operaciÃ³n respecto a su entrada inmediata.

#### 6) ExplicaciÃ³n didÃ¡ctica
- Regla prÃ¡ctica: para derivar respecto a una variable, multiplica las derivadas locales a lo largo del camino desde `L` hasta esa variable.

#### 7) Ejemplo modelado (micro)
- Si `z = wÂ·x + b`, entonces:
  - `dz/dw = x`
  - `dz/db = 1`
  - y `dL/dw = dL/da Â· da/dz Â· x`

#### 8) PrÃ¡ctica guiada
- A partir del mismo grafo, deriva `dL/dx` y explica el significado (sensibilidad de la pÃ©rdida a la entrada).

#### 9) PrÃ¡ctica independiente
- Dibuja un grafo para `L = ( (w1Â·x + b1)Â² ) + (w2Â·x)` y deriva `dL/dw1`, `dL/db1`, `dL/dw2`.

#### 10) AutoevaluaciÃ³n
- Â¿QuÃ© factor te faltarÃ­a si olvidas el nodo `a = Ïƒ(z)`?

#### 11) Errores comunes
- Omitir un nodo intermedio (un factor) en el producto.
- Confundir `dL/dw` con `dw/dL` (direcciÃ³n).

#### 12) RetenciÃ³n
- (dÃ­a 2) Reproduce de memoria el grafo y escribe las fÃ³rmulas de `dL/dw` y `dL/db`.

#### 13) DiferenciaciÃ³n
- Avanzado: generaliza el patrÃ³n a `z = Wx + b` (vectores/matrices) y discute formas/dimensiones.

#### 14) Recursos
- SecciÃ³n â€œcomputational graphsâ€ de cursos intro de DL (p.ej., CS231n).

#### 15) Nota docente
- Pide una â€œnarraciÃ³nâ€ del backward: `L â†’ a â†’ z â†’ (w,b)` y justificaciÃ³n de cada derivada local.
</details>

### 4.0.1 DerivaciÃ³n paso a paso: `f(x) = xÂ²`

Si `f(x) = xÂ²`, entonces:

```
f'(x) = lim_{hâ†’0} [(x+h)Â² - xÂ²] / h
      = lim_{hâ†’0} [xÂ² + 2xh + hÂ² - xÂ²] / h
      = lim_{hâ†’0} [2xh + hÂ²] / h
      = lim_{hâ†’0} [2x + h]
      = 2x
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 4.0.1: DerivaciÃ³n paso a paso: f(x) = xÂ²</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** DerivaciÃ³n por definiciÃ³n: intuiciÃ³n del lÃ­mite
- **ID (opcional):** `M03-T04_0_1`
- **DuraciÃ³n estimada:** 30â€“60 min
- **Nivel:** BÃ¡sicoâ€“Intermedio
- **Dependencias:** 1.2 (derivadas)

#### 2) Objetivos
- Reproducir el cÃ¡lculo de `f'(x)` desde la definiciÃ³n de derivada.
- Explicar quÃ© significa â€œtomar el lÃ­miteâ€ en tÃ©rminos de aproximaciÃ³n.

#### 3) Relevancia
- Esta derivaciÃ³n es un â€œpatrÃ³n baseâ€ que luego se reutiliza en chain rule y gradientes.

#### 4) Mapa conceptual
- **DefiniciÃ³n:** derivada = lÃ­mite de cociente incremental.
- **Ãlgebra:** expandir, simplificar, cancelar, aplicar lÃ­mite.

#### 5) Definiciones esenciales
- `f'(x) = lim_{hâ†’0} (f(x+h)-f(x))/h`.

#### 6) ExplicaciÃ³n didÃ¡ctica
- La cancelaciÃ³n del tÃ©rmino `xÂ²` es la pista de que el cociente incremental â€œaÃ­slaâ€ la variaciÃ³n.

#### 7) Ejemplo modelado
- ValidaciÃ³n rÃ¡pida: si `x=3`, entonces `f'(3)=6`.

#### 8) PrÃ¡ctica guiada
- Repite el proceso para `f(x)=xÂ³` y compara el resultado con la regla conocida.

#### 9) PrÃ¡ctica independiente
- Deriva `f(x)=(x+1)Â²` por definiciÃ³n y simplifica.

#### 10) AutoevaluaciÃ³n
- Â¿En quÃ© paso aparece el requisito de `hâ†’0` y por quÃ© no puedes sustituir `h=0` antes?

#### 11) Errores comunes
- Sustituir `h=0` demasiado pronto (divisiÃ³n por cero).
- Errores al expandir `(x+h)Â²`.

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe de memoria la expansiÃ³n de `(x+h)Â²` y el resultado `2x`.

#### 13) DiferenciaciÃ³n
- Avanzado: conecta el resultado `2x` con la pendiente de la parÃ¡bola en el plano.

#### 14) Recursos
- SecciÃ³n de derivada por definiciÃ³n en cualquier texto de CÃ¡lculo I.

#### 15) Nota docente
- Pedir al alumno que explique cada cancelaciÃ³n (quÃ© tÃ©rmino desaparece y por quÃ©).
</details>

### 4.0.2 DerivaciÃ³n paso a paso: sigmoide `Ïƒ(z)`

DefiniciÃ³n:

```
Ïƒ(z) = 1 / (1 + e^{-z})
```

Resultado clave:

```
Ïƒ'(z) = Ïƒ(z)(1 - Ïƒ(z))
```

DerivaciÃ³n (paso a paso, conectada a cÃ³digo):

 1) Reescribe la sigmoide como potencia:

 ```
 Ïƒ(z) = (1 + e^{-z})^{-1}
 ```

 2) Deriva usando Chain Rule (derivada de `u^{-1}` y de `e^{-z}`):

 ```
 Ïƒ'(z) = - (1 + e^{-z})^{-2} Â· d/dz(1 + e^{-z})
       = - (1 + e^{-z})^{-2} Â· (-e^{-z})
       = e^{-z} / (1 + e^{-z})^2
 ```

 3) Demuestra que es equivalente a `Ïƒ(z)(1-Ïƒ(z))`:

 ```
 1 - Ïƒ(z) = 1 - 1/(1+e^{-z})
          = (1+e^{-z}-1)/(1+e^{-z})
          = e^{-z}/(1+e^{-z})

 Ïƒ(z)(1-Ïƒ(z)) = [1/(1+e^{-z})] Â· [e^{-z}/(1+e^{-z})]
              = e^{-z}/(1+e^{-z})^2
              = Ïƒ'(z)
 ```

 ConexiÃ³n directa con `grad_check.py`:

 - En el script, esto aparece como:
   - `s = sigmoid(z)`
   - `return s * (1 - s)`
 - La razÃ³n prÃ¡ctica: si ya calculaste `s` en el forward, el backward usa `s(1-s)` y evita recalcular `exp`.

 Consejo prÃ¡ctico: cuando ya tienes `a = Ïƒ(z)`, usa `a(1-a)` para derivar, en vez de re-calcular `exp`.

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 4.0.2: DerivaciÃ³n paso a paso: sigmoide Ïƒ(z)</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Derivada de la sigmoide: forma Ãºtil para backprop
- **ID (opcional):** `M03-T04_0_2`
- **DuraciÃ³n estimada:** 30â€“60 min
- **Nivel:** Intermedio
- **Dependencias:** 4.0 (grafo), 1.2 (derivadas)

#### 2) Objetivos
- Justificar (al menos a nivel algebraico) por quÃ© `Ïƒ'(z)=Ïƒ(z)(1-Ïƒ(z))`.
- Explicar por quÃ© esta forma es computacionalmente conveniente.

#### 3) Relevancia
- La identidad `a(1-a)` aparece constantemente en redes con activaciÃ³n sigmoide.

#### 4) Mapa conceptual
- **FunciÃ³n:** `Ïƒ(z) = 1/(1+e^{-z})`
- **Derivada:** reescritura algebraica para expresar todo en funciÃ³n de `Ïƒ(z)`.

#### 5) Definiciones esenciales
- `Ïƒ(z)` y su derivada cerrada.

#### 6) ExplicaciÃ³n didÃ¡ctica
- Si ya computaste `a=Ïƒ(z)` en el forward, en el backward no recalculas exponenciales: usas `a(1-a)`.

#### 7) Ejemplo modelado
- Si `a=0.8`, entonces `Ïƒ'(z)=0.8Â·0.2=0.16`.

#### 8) PrÃ¡ctica guiada
- Calcula `Ïƒ(z)` y `Ïƒ'(z)` para `z âˆˆ {-2,0,2}` y compara magnitudes.

#### 9) PrÃ¡ctica independiente
- Explica con una frase por quÃ© la sigmoide â€œsaturaâ€ (derivada pequeÃ±a) en valores grandes de |z|.

#### 10) AutoevaluaciÃ³n
- Â¿QuÃ© ocurre con `Ïƒ'(z)` cuando `aâ‰ˆ0` o `aâ‰ˆ1`?

#### 11) Errores comunes
- Olvidar la regla de la cadena al derivar `e^{-z}`.
- Confundir `Ïƒ'(z)` con `1-Ïƒ(z)`.

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe de memoria: `Ïƒ'(z)=Ïƒ(z)(1-Ïƒ(z))`.

#### 13) DiferenciaciÃ³n
- Avanzado: conectar saturaciÃ³n con vanishing gradients en redes profundas.

#### 14) Recursos
- Notas de activaciones y derivadas (sigmoid/tanh/ReLU).

#### 15) Nota docente
- Pedir que el alumno derive la identidad y luego explique su utilidad computacional.
</details>

### 4.1 Chain Rule en 1D

!!! note "REGLA DE LA CADENA (Chain Rule)"
    Si `y = f(g(x))`, entonces:

    `dy/dx = df/dg Â· dg/dx`

    O en notaciÃ³n de composiciÃ³n:

    `(f âˆ˜ g)'(x) = f'(g(x)) Â· g'(x)`

    Esto es **fundamental** para Backpropagation.

```text
Ejemplo: y = (xÂ² + 1)Â³

Sea g(x) = xÂ² + 1  y  f(u) = uÂ³
Entonces y = f(g(x))

dy/dx = f'(g(x)) Â· g'(x)
      = 3(xÂ² + 1)Â² Â· 2x
      = 6x(xÂ² + 1)Â²
```

```python
def g(x):
    return x**2 + 1


def f(u):
    return u**3


def y(x):
    return f(g(x))


def dy_dx_analytical(x):
    """Derivada usando chain rule."""
    return 6 * x * (x**2 + 1)**2


def dy_dx_numerical(x, h=1e-7):
    """Derivada numÃ©rica."""
    return (y(x + h) - y(x - h)) / (2 * h)


# Verificar
x = 2.0
print(f"y({x}) = {y(x)}")
print(f"dy/dx analÃ­tica:  {dy_dx_analytical(x)}")
print(f"dy/dx numÃ©rica:   {dy_dx_numerical(x):.6f}")
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 4.1: Chain Rule en 1D</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Regla de la cadena en 1D: composiciÃ³n y â€œmultiplicar derivadas localesâ€
- **ID (opcional):** `M03-T04_1`
- **DuraciÃ³n estimada:** 60â€“120 min
- **Nivel:** Intermedio
- **Dependencias:** 4.0 (grafo), 1.2 (derivadas)

#### 2) Objetivos
- Identificar `f` y `g` en una composiciÃ³n `y = f(g(x))`.
- Calcular `dy/dx` aplicando `dy/dx = f'(g(x))Â·g'(x)`.
- Verificar resultados comparando derivada analÃ­tica vs numÃ©rica.

#### 3) Relevancia
- Es el patrÃ³n exacto que se repite en backprop: derivadas locales encadenadas.

#### 4) Mapa conceptual
- **ComposiciÃ³n:** `x â†’ g(x) â†’ f(g(x))`.
- **DerivaciÃ³n:** â€œderivar afueraâ€ evaluado â€œadentroâ€ y multiplicar por la derivada de adentro.

#### 5) Definiciones esenciales
- Si `y = f(u)` y `u = g(x)`, entonces `dy/dx = (dy/du)(du/dx)`.

#### 6) ExplicaciÃ³n didÃ¡ctica
- TÃ©cnica: escribe primero el camino `x â†’ u â†’ y`, y luego escribe derivadas a lo largo del camino.

#### 7) Ejemplo modelado
- `y=(xÂ²+1)Â³`: identifica `u=xÂ²+1`, `f(u)=uÂ³`, luego `dy/dx=3uÂ²Â·2x`.

#### 8) PrÃ¡ctica guiada
- Calcula `dy/dx` para `y = sin(xÂ²)` y valida con diferencia finita.

#### 9) PrÃ¡ctica independiente
- Resuelve `y = exp( (3x-2)â´ )` paso a paso, nombrando variables intermedias.

#### 10) AutoevaluaciÃ³n
- Â¿Por quÃ© aparece la evaluaciÃ³n `f'(g(x))` y no solo `f'(x)`?

#### 11) Errores comunes
- Olvidar el factor `g'(x)`.
- Derivar el â€œafueraâ€ pero no evaluar en el â€œadentroâ€.

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe el patrÃ³n `f(g(x))' = f'(g(x))Â·g'(x)` y crea 2 ejemplos propios.

#### 13) DiferenciaciÃ³n
- Avanzado: usa notaciÃ³n de diferenciales `dy = f'(u)du`, `du=g'(x)dx`.

#### 14) Recursos
- Secciones de â€œfunciones compuestasâ€ en CÃ¡lculo I y notas de chain rule.

#### 15) Nota docente
- Pedir que el alumno â€œetiqueteâ€ cada subfunciÃ³n con un nombre intermedio (u, v, â€¦) antes de derivar.
</details>

### 4.2 Chain Rule para Funciones Compuestas (Backprop Preview)

!!! note "CHAIN RULE PARA REDES NEURONALES"
    Una capa de red neuronal:

    `z = Wx + b` (transformaciÃ³n lineal)

    `a = Ïƒ(z)` (activaciÃ³n)

    Si `L` es la pÃ©rdida, necesitamos:

    `âˆ‚L/âˆ‚W`, `âˆ‚L/âˆ‚b` (para actualizar los pesos)

    Usando Chain Rule:

    `âˆ‚L/âˆ‚W = âˆ‚L/âˆ‚a Â· âˆ‚a/âˆ‚z Â· âˆ‚z/âˆ‚W`

    `âˆ‚L/âˆ‚b = âˆ‚L/âˆ‚a Â· âˆ‚a/âˆ‚z Â· âˆ‚z/âˆ‚b`

```python
def simple_forward_backward():
    """
    Ejemplo simplificado de forward y backward pass.

    Red: x â†’ [z = wx + b] â†’ [a = sigmoid(z)] â†’ [L = (a - y)Â²]
    """
    # Datos
    x = 2.0          # Input
    y_true = 1.0     # Target

    # ParÃ¡metros
    w = 0.5
    b = 0.1

    # ========== FORWARD PASS ==========
    z = w * x + b                    # z = wx + b
    a = 1 / (1 + np.exp(-z))         # a = sigmoid(z)
    L = (a - y_true) ** 2            # L = MSE

    print("=== FORWARD PASS ===")
    print(f"z = w*x + b = {w}*{x} + {b} = {z}")
    print(f"a = sigmoid(z) = {a:.4f}")
    print(f"L = (a - y)Â² = ({a:.4f} - {y_true})Â² = {L:.4f}")

    # ========== BACKWARD PASS (Chain Rule) ==========
    # Objetivo: calcular âˆ‚L/âˆ‚w y âˆ‚L/âˆ‚b

    # Paso 1: âˆ‚L/âˆ‚a
    dL_da = 2 * (a - y_true)

    # Paso 2: âˆ‚a/âˆ‚z = sigmoid'(z) = a(1-a)
    da_dz = a * (1 - a)

    # Paso 3: âˆ‚z/âˆ‚w = x,  âˆ‚z/âˆ‚b = 1
    dz_dw = x
    dz_db = 1

    # Aplicar Chain Rule
    dL_dz = dL_da * da_dz           # âˆ‚L/âˆ‚z = âˆ‚L/âˆ‚a Â· âˆ‚a/âˆ‚z
    dL_dw = dL_dz * dz_dw           # âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚z Â· âˆ‚z/âˆ‚w
    dL_db = dL_dz * dz_db           # âˆ‚L/âˆ‚b = âˆ‚L/âˆ‚z Â· âˆ‚z/âˆ‚b

    print("\n=== BACKWARD PASS (Chain Rule) ===")
    print(f"âˆ‚L/âˆ‚a = 2(a - y) = {dL_da:.4f}")
    print(f"âˆ‚a/âˆ‚z = a(1-a) = {da_dz:.4f}")
    print(f"âˆ‚z/âˆ‚w = x = {dz_dw}")
    print(f"âˆ‚z/âˆ‚b = 1")
    print(f"\nâˆ‚L/âˆ‚w = âˆ‚L/âˆ‚a Â· âˆ‚a/âˆ‚z Â· âˆ‚z/âˆ‚w = {dL_dw:.4f}")
    print(f"âˆ‚L/âˆ‚b = âˆ‚L/âˆ‚a Â· âˆ‚a/âˆ‚z Â· âˆ‚z/âˆ‚b = {dL_db:.4f}")

    # ========== VERIFICACIÃ“N NUMÃ‰RICA ==========
    h = 1e-7

    # âˆ‚L/âˆ‚w numÃ©rica
    z_plus = (w + h) * x + b
    a_plus = 1 / (1 + np.exp(-z_plus))
    L_plus = (a_plus - y_true) ** 2

    z_minus = (w - h) * x + b
    a_minus = 1 / (1 + np.exp(-z_minus))
    L_minus = (a_minus - y_true) ** 2

    dL_dw_numerical = (L_plus - L_minus) / (2 * h)

    print(f"\n=== VERIFICACIÃ“N ===")
    print(f"âˆ‚L/âˆ‚w analÃ­tica: {dL_dw:.6f}")
    print(f"âˆ‚L/âˆ‚w numÃ©rica:  {dL_dw_numerical:.6f}")
    print(f"Error: {abs(dL_dw - dL_dw_numerical):.2e}")

    return dL_dw, dL_db

simple_forward_backward()

```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 4.2: Chain Rule para Funciones Compuestas (Backprop Preview)</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Backprop como chain rule repetido (con verificaciÃ³n numÃ©rica)
- **ID (opcional):** `M03-T04_2`
- **DuraciÃ³n estimada:** 90â€“150 min
- **Nivel:** Intermedio
- **Dependencias:** 4.0 (grafo), 4.1 (chain rule), 3.3 (loss), 4.0.2 (sigmoide)

#### 2) Objetivos
- Calcular `âˆ‚L/âˆ‚w` y `âˆ‚L/âˆ‚b` en una neurona: `z=wx+b`, `a=Ïƒ(z)`, `L=(a-y)Â²`.
- Entender el â€œpipelineâ€ de derivadas locales: `âˆ‚L/âˆ‚a`, `âˆ‚a/âˆ‚z`, `âˆ‚z/âˆ‚w`, `âˆ‚z/âˆ‚b`.
- Validar la derivaciÃ³n con diferencias finitas (sanity check).

#### 3) Relevancia
- Backprop no es â€œmagiaâ€: es chain rule aplicado de forma sistemÃ¡tica.

#### 4) Mapa conceptual mÃ­nimo
- **Forward:** `x â†’ z â†’ a â†’ L`.
- **Backward:** `dL/da â†’ da/dz â†’ dz/dw, dz/db`.

#### 5) Definiciones esenciales
- **Gradiente:** vector de derivadas parciales respecto a parÃ¡metros.
- **Gradient checking:** comparar gradiente analÃ­tico vs numÃ©rico.

#### 6) ExplicaciÃ³n didÃ¡ctica
- Regla prÃ¡ctica: en backward, cada paso â€œempujaâ€ la derivada un nodo hacia atrÃ¡s multiplicando por la derivada local.

#### 7) Ejemplo modelado
- Con `dz/dw = x` y `dz/db = 1`, se obtiene `âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚z Â· x` y `âˆ‚L/âˆ‚b = âˆ‚L/âˆ‚z`.

#### 8) PrÃ¡ctica guiada
- Cambia la pÃ©rdida a `L = -[ y log(a) + (1-y)log(1-a) ]` (BCE) y escribe el nuevo `âˆ‚L/âˆ‚a`.

#### 9) PrÃ¡ctica independiente
- Implementa una funciÃ³n `grad_check` genÃ©rica que compare gradientes para distintos `h` y reporte error relativo.

#### 10) AutoevaluaciÃ³n
- Â¿Por quÃ© `h` no puede ser demasiado grande ni demasiado pequeÃ±o en diferencias finitas?

#### 11) Errores comunes
- Olvidar `Ïƒ'(z)=a(1-a)` y recalcular exponenciales innecesariamente.
- Implementar mal el gradiente numÃ©rico (forward vs central differences).

#### 12) RetenciÃ³n
- (dÃ­a 2) escribe el pipeline: `dL/da`, `da/dz`, `dz/dw`, `dz/db` y cÃ³mo se combinan.

#### 13) DiferenciaciÃ³n
- Avanzado: extender de escalar a vector: `z = wÂ·x + b`, `âˆ‚z/âˆ‚w = x` (vector).

#### 14) Recursos
- SecciÃ³n â€œgradient checkingâ€ en cursos de DL (p.ej., CS231n).

#### 15) Nota docente
- Exigir evidencia: gradiente analÃ­tico + numÃ©rico + tolerancias (`rtol`, `atol`) y explicaciÃ³n del resultado.
</details>

### 4.3 Backpropagation en una Red de 2 Capas

!!! note "RED NEURONAL DE 2 CAPAS"
    Arquitectura:

    `x (input) â†’ zâ‚ = Wâ‚x + bâ‚ â†’ aâ‚ = sigmoid(zâ‚) â†’ zâ‚‚ = Wâ‚‚aâ‚ + bâ‚‚ â†’ aâ‚‚ = sigmoid(zâ‚‚) â†’ L = MSE(aâ‚‚, y)`

    Backpropagation usa Chain Rule repetidamente:

    `âˆ‚L/âˆ‚Wâ‚‚ = âˆ‚L/âˆ‚aâ‚‚ Â· âˆ‚aâ‚‚/âˆ‚zâ‚‚ Â· âˆ‚zâ‚‚/âˆ‚Wâ‚‚`

    `âˆ‚L/âˆ‚Wâ‚ = âˆ‚L/âˆ‚aâ‚‚ Â· âˆ‚aâ‚‚/âˆ‚zâ‚‚ Â· âˆ‚zâ‚‚/âˆ‚aâ‚ Â· âˆ‚aâ‚/âˆ‚zâ‚ Â· âˆ‚zâ‚/âˆ‚Wâ‚`

```python
class SimpleNeuralNet:
    """Red neuronal de 2 capas para demostrar backprop."""

    def __init__(self, input_size: int, hidden_size: int, output_size: int):
        # Inicializar pesos (Xavier initialization)
        self.W1 = np.random.randn(hidden_size, input_size) * np.sqrt(2 / input_size)
        self.b1 = np.zeros(hidden_size)
        self.W2 = np.random.randn(output_size, hidden_size) * np.sqrt(2 / hidden_size)
        self.b2 = np.zeros(output_size)

        # Cache para backprop
        self.cache = {}

    def sigmoid(self, z):
        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))

    def sigmoid_derivative(self, a):
        return a * (1 - a)

    def forward(self, x: np.ndarray) -> np.ndarray:
        """Forward pass guardando valores intermedios."""
        # Capa 1
        z1 = self.W1 @ x + self.b1
        a1 = self.sigmoid(z1)

        # Capa 2
        z2 = self.W2 @ a1 + self.b2
        a2 = self.sigmoid(z2)

        # Guardar para backprop
        self.cache = {'x': x, 'z1': z1, 'a1': a1, 'z2': z2, 'a2': a2}

        return a2

    def backward(self, y_true: np.ndarray) -> dict:
        """
        Backward pass usando Chain Rule.

        Returns:
            Gradientes de todos los parÃ¡metros
        """
        x = self.cache['x']
        a1 = self.cache['a1']
        a2 = self.cache['a2']

        # âˆ‚L/âˆ‚aâ‚‚ (MSE)
        dL_da2 = 2 * (a2 - y_true)

        # âˆ‚aâ‚‚/âˆ‚zâ‚‚
        da2_dz2 = self.sigmoid_derivative(a2)

        # âˆ‚L/âˆ‚zâ‚‚ = âˆ‚L/âˆ‚aâ‚‚ Â· âˆ‚aâ‚‚/âˆ‚zâ‚‚
        dL_dz2 = dL_da2 * da2_dz2

        # Gradientes de capa 2
        # âˆ‚zâ‚‚/âˆ‚Wâ‚‚ = aâ‚, âˆ‚zâ‚‚/âˆ‚bâ‚‚ = 1
        dL_dW2 = np.outer(dL_dz2, a1)
        dL_db2 = dL_dz2

        # Propagar hacia atrÃ¡s a capa 1
        # âˆ‚zâ‚‚/âˆ‚aâ‚ = Wâ‚‚
        dL_da1 = self.W2.T @ dL_dz2

        # âˆ‚aâ‚/âˆ‚zâ‚
        da1_dz1 = self.sigmoid_derivative(a1)

        # âˆ‚L/âˆ‚zâ‚
        dL_dz1 = dL_da1 * da1_dz1

        # Gradientes de capa 1
        dL_dW1 = np.outer(dL_dz1, x)
        dL_db1 = dL_dz1

        return {
            'dW1': dL_dW1, 'db1': dL_db1,
            'dW2': dL_dW2, 'db2': dL_db2
        }

    def update(self, gradients: dict, learning_rate: float):
        """Actualiza parÃ¡metros usando gradient descent."""
        self.W1 -= learning_rate * gradients['dW1']
        self.b1 -= learning_rate * gradients['db1']
        self.W2 -= learning_rate * gradients['dW2']
        self.b2 -= learning_rate * gradients['db2']


# Demo: XOR problem
def demo_xor():
    """Entrena la red para resolver XOR."""
    # XOR data
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]).T  # 2x4
    y = np.array([[0], [1], [1], [0]]).T              # 1x4

    # Crear red
    net = SimpleNeuralNet(input_size=2, hidden_size=4, output_size=1)

    # Entrenar
    losses = []
    for epoch in range(10000):
        total_loss = 0
        for i in range(4):
            # Forward
            output = net.forward(X[:, i])
            loss = (output - y[:, i]) ** 2
            total_loss += loss[0]

            # Backward
            gradients = net.backward(y[:, i])

            # Update
            net.update(gradients, learning_rate=0.5)

        losses.append(total_loss / 4)

        if epoch % 2000 == 0:
            print(f"Epoch {epoch}: Loss = {losses[-1]:.4f}")

    # Test
    print("\n=== Resultados XOR ===")
    for i in range(4):
        pred = net.forward(X[:, i])
        print(f"Input: {X[:, i]} â†’ Pred: {pred[0]:.3f} (Target: {y[0, i]})")

demo_xor()
```

<details open>
<summary><strong>ğŸ“Œ Complemento pedagÃ³gico â€” Tema 4.3: Backpropagation en una Red de 2 Capas</strong></summary>

#### 1) Metadatos
- **TÃ­tulo:** Backprop en 2 capas: cache, gradientes y actualizaciÃ³n
- **ID (opcional):** `M03-T04_3`
- **DuraciÃ³n estimada:** 120â€“180 min
- **Nivel:** Intermedioâ€“Avanzado
- **Dependencias:** 4.2 (preview), 4.0 (grafo), 3.1â€“3.2 (GD y LR)

#### 2) Objetivos
- Entender por quÃ© el **cache** (guardar `x, z1, a1, z2, a2`) es necesario para backprop.
- Derivar/interpretar `dW2, db2, dW1, db1` y sus dimensiones.
- Conectar el cÃ¡lculo de gradientes con el update de Gradient Descent.

#### 3) Relevancia
- Este patrÃ³n (forward â†’ cache â†’ backward â†’ update) es la base de cualquier entrenamiento de NN.

#### 4) Mapa conceptual mÃ­nimo
- **Forward:** `x â†’ (z1,a1) â†’ (z2,a2) â†’ L`
- **Backward:** `dL/da2 â†’ dL/dz2 â†’ (dW2,db2) â†’ dL/da1 â†’ dL/dz1 â†’ (dW1,db1)`

#### 5) Definiciones esenciales
- **Backpropagation:** aplicaciÃ³n sistemÃ¡tica de chain rule para obtener derivadas respecto a parÃ¡metros.
- **Outer product:** usado para formar `dW = Î´ âŠ— activaciÃ³n`.

#### 6) ExplicaciÃ³n didÃ¡ctica
- Regla prÃ¡ctica de formas:
  - Si `z = W a + b`, entonces `âˆ‚L/âˆ‚W = Î´ âŠ— a` y `âˆ‚L/âˆ‚b = Î´`.
- Si te equivocas en shapes, casi siempre te falta un transpose.

#### 7) Ejemplo modelado
- El demo XOR muestra un loop completo: forward, loss, backward, update, y reporte periÃ³dico.

#### 8) PrÃ¡ctica guiada
- Imprime shapes (`W1.shape`, `dW1.shape`, etc.) y verifica coherencia en cada paso.

#### 9) PrÃ¡ctica independiente
- Cambia `hidden_size` y observa impacto en convergencia.
- AÃ±ade `learning_rate` mÃ¡s pequeÃ±o y compara estabilidad.

#### 10) AutoevaluaciÃ³n
- Â¿Por quÃ© `dW2 = outer(dL_dz2, a1)` y no `outer(a1, dL_dz2)`?

#### 11) Errores comunes
- Olvidar que `sigmoid_derivative` usa `a` (activaciÃ³n) y no `z`.
- Confundir el vector columna/fila y generar `dW` transpuesto.
- LR demasiado alto: diverge o se â€œqueda oscilandoâ€.

#### 12) RetenciÃ³n
- (dÃ­a 2) Escribe el pipeline de 2 capas: `Î´2 â†’ dW2 â†’ Î´1 â†’ dW1`.

#### 13) DiferenciaciÃ³n
- Avanzado: reemplaza MSE por BCE + sigmoid y discute estabilidad.

#### 14) Recursos
- CapÃ­tulos intro de backprop (computational graphs) y notas de â€œmatrix calculusâ€.

#### 15) Nota docente
- Pedir evidencia de comprensiÃ³n: diagrama + shapes + explicaciÃ³n de `outer`.
</details>

---
## ğŸ¯ Ejercicios por tema (progresivos) + Soluciones

Reglas:

- **Intenta primero** sin mirar la soluciÃ³n.
- **Timebox sugerido:** 15â€“30 min por ejercicio.
- **Ã‰xito mÃ­nimo:** tu soluciÃ³n debe pasar los `assert`.

---

### Ejercicio 3.1: Derivada numÃ©rica (diferencias finitas) vs derivada analÃ­tica

#### Enunciado

1) **BÃ¡sico**

- Implementa la derivada numÃ©rica central: `f'(x) â‰ˆ (f(x+h)-f(x-h))/(2h)`.

2) **Intermedio**

- Para `f(x) = x^3 + 2x`, implementa `f'(x)` analÃ­tica y compara en varios puntos.

3) **Avanzado**

- Prueba `h=1e-2, 1e-4, 1e-6` y verifica que el error no crece de forma absurda.

#### SoluciÃ³n

```python
import numpy as np


# Aproximamos derivadas numÃ©ricamente usando *diferencias centrales*.
# IntuiciÃ³n: medir la pendiente alrededor de x de forma simÃ©trica (x+h y x-h)
# cancela tÃ©rminos de error de primer orden y suele ser mÃ¡s preciso que la
# diferencia hacia adelante.

def num_derivative_central(f, x: float, h: float = 1e-6) -> float:
    # f: funciÃ³n escalar f(x).
    # x: punto donde evaluamos la derivada.
    # h: tamaÃ±o de paso. Hay tradeoff:
    # - h grande => error de truncamiento (aproximaciÃ³n) domina
    # - h muy pequeÃ±o => cancelaciÃ³n numÃ©rica (floating point) domina
    # Devolvemos float para facilitar asserts y logs.
    return float((f(x + h) - f(x - h)) / (2.0 * h))


def f(x: float) -> float:
    # FunciÃ³n de prueba (suave y derivable).
    return x**3 + 2.0 * x


def f_prime(x: float) -> float:
    # Derivada analÃ­tica:
    # d/dx (x^3) = 3x^2
    # d/dx (2x)  = 2
    return 3.0 * x**2 + 2.0


# Probamos varios puntos para evitar que pase â€œpor casualidadâ€ en un solo x.
xs = [-2.0, -0.5, 0.0, 1.0, 3.0]
for x in xs:
    # AproximaciÃ³n numÃ©rica.
    approx = num_derivative_central(f, x, h=1e-6)
    # Valor exacto (analÃ­tico).
    exact = f_prime(x)
    # np.isclose compara igualdad aproximada con tolerancias:
    # - rtol: tolerancia relativa (escala con el tamaÃ±o)
    # - atol: tolerancia absoluta (Ãºtil cerca de 0)
    assert np.isclose(approx, exact, rtol=1e-6, atol=1e-6)


# Estudiamos cÃ³mo cambia el error con distintos h.
# Nota: no imponemos monotonÃ­a estricta porque h extremadamente pequeÃ±o puede
# empeorar por precisiÃ³n de mÃ¡quina.
x0 = 1.234
errs = []
for h in [1e-2, 1e-4, 1e-6]:
    # Misma x0, distinto paso.
    approx = num_derivative_central(f, x0, h=h)
    # Error absoluto vs derivada analÃ­tica.
    errs.append(abs(approx - f_prime(x0)))

# Sanidad mÃ­nima: al refinar de 1e-2 a 1e-4, no deberÃ­a empeorar.
assert errs[1] <= errs[0] + 1e-6
```

---

### Ejercicio 3.2: Derivadas parciales y gradiente (2D)

#### Enunciado

Sea `f(x, y) = x^2 y + sin(y)`.

1) **BÃ¡sico**

- Deriva analÃ­ticamente `âˆ‚f/âˆ‚x` y `âˆ‚f/âˆ‚y`.

2) **Intermedio**

- Implementa el gradiente `âˆ‡f(x,y)` y evalÃºalo en un punto.

3) **Avanzado**

- Verifica con gradiente numÃ©rico (diferencias centrales) que tu gradiente analÃ­tico es correcto.

#### SoluciÃ³n

```python
import numpy as np

def f_xy(x: float, y: float) -> float:
    # FunciÃ³n escalar de 2 variables:
    # f(x, y) = x^2 * y + sin(y)
    return x**2 * y + np.sin(y)


def grad_f_xy(x: float, y: float) -> np.ndarray:
    # Gradiente analÃ­tico (derivadas parciales):
    # âˆ‚f/âˆ‚x = 2xy
    # âˆ‚f/âˆ‚y = x^2 + cos(y)
    dfdx = 2.0 * x * y
    dfdy = x**2 + np.cos(y)
    # Empaquetamos como vector [df/dx, df/dy].
    return np.array([dfdx, dfdy], dtype=float)


def num_grad_2d(f, x: float, y: float, h: float = 1e-6) -> np.ndarray:
    # Gradiente numÃ©rico con diferencias centrales.
    # Para cada variable, perturbamos solo esa coordenada.
    dfdx = (f(x + h, y) - f(x - h, y)) / (2.0 * h)
    dfdy = (f(x, y + h) - f(x, y - h)) / (2.0 * h)
    # Vector gradiente.
    return np.array([dfdx, dfdy], dtype=float)


# Punto de evaluaciÃ³n (no trivial para evitar simetrÃ­as).
x0, y0 = 1.2, -0.7

# Gradiente analÃ­tico.
g_anal = grad_f_xy(x0, y0)

# Gradiente numÃ©rico (check independiente).
g_num = num_grad_2d(f_xy, x0, y0)

# Deben coincidir si las derivadas estÃ¡n bien.
assert np.allclose(g_anal, g_num, rtol=1e-5, atol=1e-6)
```

---

### Ejercicio 3.3: Derivada direccional (intuiciÃ³n: el gradiente manda)

#### Enunciado

1) **BÃ¡sico**

- Para `f(x,y)=x^2 y + sin(y)`, calcula `âˆ‡f(x0,y0)`.

2) **Intermedio**

- Dado un vector direcciÃ³n unitario `u`, calcula la derivada direccional `D_u f = âˆ‡f Â· u`.

3) **Avanzado**

- Verifica numÃ©ricamente `D_u f` con diferencias finitas sobre `p(t)=p0 + t u`.

#### SoluciÃ³n

```python
import numpy as np

def f_xy(x: float, y: float) -> float:
    # Misma funciÃ³n del ejercicio anterior.
    return x**2 * y + np.sin(y)


def grad_f_xy(x: float, y: float) -> np.ndarray:
    # âˆ‡f(x,y) = [âˆ‚f/âˆ‚x, âˆ‚f/âˆ‚y]
    return np.array([2.0 * x * y, x**2 + np.cos(y)], dtype=float)


# Punto base p0 = (x0, y0).
x0, y0 = 0.5, 1.0

# Gradiente en p0.
g = grad_f_xy(x0, y0)

# Vector direcciÃ³n (aÃºn no unitario).
u = np.array([3.0, 4.0], dtype=float)

# La derivada direccional se define sobre u unitario: ||u|| = 1.
u = u / np.linalg.norm(u)

# Derivada direccional analÃ­tica: D_u f = âˆ‡f Â· u.
dir_anal = float(np.dot(g, u))

# VerificaciÃ³n numÃ©rica: avanzamos/retrocedemos h sobre la recta p(t)=p0 + t u.
h = 1e-6
f_plus = f_xy(x0 + h * u[0], y0 + h * u[1])
f_minus = f_xy(x0 - h * u[0], y0 - h * u[1])

# Diferencia central en la direcciÃ³n u.
dir_num = float((f_plus - f_minus) / (2.0 * h))

# ComparaciÃ³n con tolerancia.
assert np.isclose(dir_anal, dir_num, rtol=1e-5, atol=1e-6)
```

---

### Ejercicio 3.4: Jacobiano (funciÃ³n vectorial)

#### Enunciado

Sea `g(x1,x2) = [x1^2 + x2, sin(x1 x2)]`.

1) **BÃ¡sico**

- Escribe el Jacobiano `J` (matriz 2x2) a mano.

2) **Intermedio**

- Implementa `J_analytical(x)`.

3) **Avanzado**

- Verifica con Jacobiano numÃ©rico (diferencias centrales) que `J` coincide.

#### SoluciÃ³n

```python
import numpy as np

def g(x: np.ndarray) -> np.ndarray:
    # FunciÃ³n vectorial g: R^2 -> R^2.
    # Convertimos a float para evitar dtypes raros (int) y asegurar operaciones reales.
    x1, x2 = float(x[0]), float(x[1])
    # Definimos:
    # g1 = x1^2 + x2
    # g2 = sin(x1 * x2)
    return np.array([x1**2 + x2, np.sin(x1 * x2)], dtype=float)


def J_analytical(x: np.ndarray) -> np.ndarray:
    # Jacobiano J: matriz de derivadas parciales.
    # J[i, j] = âˆ‚g_i / âˆ‚x_j
    # AquÃ­ hay 2 salidas y 2 entradas => J es 2x2.
    x1, x2 = float(x[0]), float(x[1])

    # g1 = x1^2 + x2
    # âˆ‚g1/âˆ‚x1 = 2x1
    # âˆ‚g1/âˆ‚x2 = 1
    dg1_dx1 = 2.0 * x1
    dg1_dx2 = 1.0

    # g2 = sin(x1*x2)
    # Regla de la cadena:
    # âˆ‚g2/âˆ‚x1 = cos(x1*x2) * x2
    # âˆ‚g2/âˆ‚x2 = cos(x1*x2) * x1
    dg2_dx1 = np.cos(x1 * x2) * x2
    dg2_dx2 = np.cos(x1 * x2) * x1

    # Empaquetamos en una matriz 2x2.
    return np.array([[dg1_dx1, dg1_dx2], [dg2_dx1, dg2_dx2]], dtype=float)


def J_numeric(g, x: np.ndarray, h: float = 1e-6) -> np.ndarray:
    # Jacobiano numÃ©rico con diferencias centrales.
    # Para cada coordenada j, perturbamos x por Â±h e_j y obtenemos la columna J[:, j].
    x = x.astype(float)
    # m: dimensiÃ³n de salida, n: dimensiÃ³n de entrada.
    m = g(x).shape[0]
    n = x.shape[0]
    # Inicializamos J.
    J = np.zeros((m, n), dtype=float)
    for j in range(n):
        # Vector base e_j.
        e = np.zeros(n)
        e[j] = 1.0
        # Diferencia central para todas las salidas a la vez.
        J[:, j] = (g(x + h * e) - g(x - h * e)) / (2.0 * h)
    return J


# Punto de prueba.
x0 = np.array([0.7, -1.1])

# Comparamos Jacobiano analÃ­tico vs numÃ©rico.
Ja = J_analytical(x0)
Jn = J_numeric(g, x0)

# Si la derivaciÃ³n estÃ¡ correcta, deben ser casi iguales.
assert np.allclose(Ja, Jn, rtol=1e-5, atol=1e-6)
```

---

### Ejercicio 3.5: Hessiano (curvatura local) + convexidad

#### Enunciado

Sea `f(x1,x2) = x1^2 + 2 x2^2`.

1) **BÃ¡sico**

- Calcula el Hessiano `H`.

2) **Intermedio**

- Verifica que `H` es simÃ©trico.

3) **Avanzado**

- Verifica que `H` es definido positivo (eigenvalores > 0).

#### SoluciÃ³n

```python
import numpy as np

# Para f(x1,x2)=x1^2 + 2x2^2:
# - âˆ‚Â²f/âˆ‚x1Â² = 2
# - âˆ‚Â²f/âˆ‚x2Â² = 4
# - derivadas cruzadas = 0
H = np.array([[2.0, 0.0], [0.0, 4.0]], dtype=float)

# El Hessiano de una funciÃ³n escalar dos-veces derivable debe ser simÃ©trico.
assert np.allclose(H, H.T)

# Hessiano definido positivo => funciÃ³n estrictamente convexa.
# En particular, un criterio suficiente aquÃ­ es: eigenvalores > 0.
eigvals = np.linalg.eigvals(H)
assert np.all(eigvals > 0)
```

---

### Ejercicio 3.6: Gradient Descent 1D (convergencia)

#### Enunciado

Minimiza `f(x) = (x - 3)^2` con Gradient Descent.

1) **BÃ¡sico**

- Implementa la regla de actualizaciÃ³n: `x <- x - Î± f'(x)`.

2) **Intermedio**

- Registra `x_t` y `f(x_t)`.

3) **Avanzado**

- Usa un criterio de parada por `|grad| < tol`.

#### SoluciÃ³n

```python
import numpy as np

def f(x: float) -> float:
    # FunciÃ³n convexa con mÃ­nimo global en x=3.
    return (x - 3.0) ** 2


def grad_f(x: float) -> float:
    # Derivada: d/dx (x-3)^2 = 2(x-3)
    return 2.0 * (x - 3.0)


# InicializaciÃ³n.
x = 10.0

# Learning rate (tamaÃ±o de paso).
alpha = 0.1

# Historial de iteraciones para inspecciÃ³n y asserts.
history = []
for _ in range(200):
    # Gradiente en el punto actual.
    g = grad_f(x)
    # Guardamos (x, f(x)) antes de actualizar.
    history.append((x, f(x)))
    # Criterio de parada: gradiente cerca de 0 => cerca del mÃ­nimo.
    if abs(g) < 1e-8:
        break
    # ActualizaciÃ³n de Gradient Descent.
    x = x - alpha * g

# Debe converger cerca de 3.
assert abs(x - 3.0) < 1e-4

# La pÃ©rdida final no deberÃ­a ser mayor que la inicial.
assert history[-1][1] <= history[0][1]
```

---

### Ejercicio 3.7: Efecto del learning rate (estabilidad)

#### Enunciado

Minimiza `f(x)=x^2` con Gradient Descent desde `x0=1`.

1) **BÃ¡sico**

- Deriva la actualizaciÃ³n: `x_{t+1} = (1 - 2Î±) x_t`.

2) **Intermedio**

- Prueba con `Î±=0.25` y verifica que `|x_t|` decrece.

3) **Avanzado**

- Prueba con `Î±=1.1` y verifica divergencia (`|x_t|` crece).

#### SoluciÃ³n

```python
import numpy as np

def run_gd_x2(alpha: float, steps: int = 10) -> np.ndarray:
    # Minimizamos f(x)=x^2 con GD. Su gradiente es 2x.
    x = 1.0
    # Guardamos la trayectoria.
    xs = [x]
    for _ in range(steps):
        # Gradiente en el punto actual.
        grad = 2.0 * x
        # Paso de GD.
        x = x - alpha * grad
        # Guardamos el nuevo x.
        xs.append(x)
    # Convertimos a np.array para anÃ¡lisis.
    return np.array(xs)


# Con alpha=0.25, el factor (1-2Î±)=0.5 => converge.
xs_good = run_gd_x2(alpha=0.25, steps=10)

# La magnitud debe decrecer.
assert abs(xs_good[-1]) < abs(xs_good[0])


# Con alpha=1.1, |1-2Î±| = |1-2.2| = 1.2 > 1 => diverge.
xs_bad = run_gd_x2(alpha=1.1, steps=10)
assert abs(xs_bad[-1]) > abs(xs_bad[0])
```

---

### Ejercicio 3.8: Gradient checking (vector) + error relativo

#### Enunciado

1) **BÃ¡sico**

- Implementa gradiente numÃ©rico (diferencias centrales) para `f(w)`.

2) **Intermedio**

- Usa `f(w)=âˆ‘ w_i^3` cuyo gradiente analÃ­tico es `3 w_i^2`.

3) **Avanzado**

- Calcula error relativo `||g_num - g_anal|| / (||g_num|| + ||g_anal|| + eps)`.

#### SoluciÃ³n

```python
import numpy as np

def f(w: np.ndarray) -> float:
    # FunciÃ³n escalar sobre un vector: f(w) = sum_i w_i^3.
    # Convertimos a float para devolver un escalar Python.
    return float(np.sum(w ** 3))


def grad_analytical(w: np.ndarray) -> np.ndarray:
    # Gradiente analÃ­tico: âˆ‚/âˆ‚w_i (w_i^3) = 3 w_i^2.
    return 3.0 * (w ** 2)


def grad_numeric(f, w: np.ndarray, h: float = 1e-6) -> np.ndarray:
    # Gradiente numÃ©rico con diferencias centrales.
    # Para cada coordenada i, perturbamos w por Â±h e_i.
    w = w.astype(float)
    # Vector de gradientes numÃ©ricos.
    g = np.zeros_like(w)
    for i in range(w.size):
        # Vector base e_i.
        e = np.zeros_like(w)
        e[i] = 1.0
        # Diferencia central: âˆ‚f/âˆ‚w_i â‰ˆ (f(w+h e_i) - f(w-h e_i)) / (2h)
        g[i] = (f(w + h * e) - f(w - h * e)) / (2.0 * h)
    return g


# Semilla para reproducibilidad.
np.random.seed(0)

# Vector de prueba.
w = np.random.randn(5)

# Gradientes analÃ­tico y numÃ©rico.
g_a = grad_analytical(w)
g_n = grad_numeric(f, w)

# Error relativo: mÃ¡s robusto que el error absoluto porque normaliza escalas.
eps = 1e-12
rel_err = np.linalg.norm(g_n - g_a) / (np.linalg.norm(g_n) + np.linalg.norm(g_a) + eps)

# Si falla, normalmente indica error en derivada o un h inapropiado.
assert rel_err < 1e-7
```

---

### Ejercicio 3.9: Chain Rule (neurona + MSE) + verificaciÃ³n numÃ©rica

#### Enunciado

Una neurona:

- `z = wÂ·x + b`
- `Å· = Ïƒ(z)`
- `L = (Å· - y)^2`

1) **BÃ¡sico**

- Deriva `dL/dz` usando chain rule.

2) **Intermedio**

- Deriva `dL/dw` y `dL/db`.

3) **Avanzado**

- Verifica tus gradientes con diferencias centrales.

#### SoluciÃ³n

```python
import numpy as np

def sigmoid(z: float) -> float:
    # Sigmoide Ïƒ(z) = 1 / (1 + exp(-z)).
    # Convertimos a float para devolver escalar.
    return float(1.0 / (1.0 + np.exp(-z)))


def loss_mse(y_hat: float, y: float) -> float:
    # PÃ©rdida MSE para un solo ejemplo: (Å· - y)^2
    return float((y_hat - y) ** 2)


def forward(w: np.ndarray, b: float, x: np.ndarray, y: float) -> float:
    # Forward de una neurona:
    # z = wÂ·x + b
    # Å· = Ïƒ(z)
    # L = (Å· - y)^2
    z = float(np.dot(w, x) + b)
    y_hat = sigmoid(z)
    return loss_mse(y_hat, y)


def grads_analytical(w: np.ndarray, b: float, x: np.ndarray, y: float):
    # Gradientes analÃ­ticos vÃ­a Chain Rule.
    z = float(np.dot(w, x) + b)
    y_hat = sigmoid(z)

    # dL/dÅ· cuando L=(Å·-y)^2.
    dL_dyhat = 2.0 * (y_hat - y)
    # dÅ·/dz para sigmoide: Ïƒ'(z)=Ïƒ(z)(1-Ïƒ(z)).
    dyhat_dz = y_hat * (1.0 - y_hat)
    # Chain rule: dL/dz = dL/dÅ· * dÅ·/dz.
    dL_dz = dL_dyhat * dyhat_dz

    # z = wÂ·x + b => dz/dw = x y dz/db = 1.
    # Entonces:
    # dL/dw = dL/dz * x
    # dL/db = dL/dz
    dL_dw = dL_dz * x
    dL_db = dL_dz
    return dL_dw.astype(float), float(dL_db)


def grads_numeric(w: np.ndarray, b: float, x: np.ndarray, y: float, h: float = 1e-6):
    # Gradientes numÃ©ricos por diferencias centrales.
    gw = np.zeros_like(w, dtype=float)
    for i in range(w.size):
        # Vector base e_i.
        e = np.zeros_like(w)
        e[i] = 1.0
        # âˆ‚L/âˆ‚w_i â‰ˆ (L(w+h e_i) - L(w-h e_i)) / (2h)
        gw[i] = (forward(w + h * e, b, x, y) - forward(w - h * e, b, x, y)) / (2.0 * h)

    # âˆ‚L/âˆ‚b â‰ˆ (L(b+h) - L(b-h)) / (2h)
    gb = (forward(w, b + h, x, y) - forward(w, b - h, x, y)) / (2.0 * h)
    return gw, float(gb)


# Reproducibilidad.
np.random.seed(1)

# ParÃ¡metros y entrada de ejemplo.
w = np.random.randn(3)
b = 0.1
x = np.random.randn(3)

# Etiqueta objetivo.
y = 1.0

# Comparamos gradientes.
gw_a, gb_a = grads_analytical(w, b, x, y)
gw_n, gb_n = grads_numeric(w, b, x, y)

# Si la derivaciÃ³n por chain rule estÃ¡ bien, deben coincidir.
assert np.allclose(gw_a, gw_n, rtol=1e-5, atol=1e-6)
assert np.isclose(gb_a, gb_n, rtol=1e-5, atol=1e-6)
```

---

## Entregable del MÃ³dulo

### Script: `gradient_descent_demo.py`

```python
"""
Gradient Descent Demo - VisualizaciÃ³n de OptimizaciÃ³n

Este script implementa Gradient Descent desde cero y visualiza
la trayectoria de optimizaciÃ³n en diferentes funciones.

Autor: [Tu nombre]
MÃ³dulo: 03 - CÃ¡lculo Multivariante
"""

import numpy as np
import matplotlib.pyplot as plt
from typing import Callable, Tuple, List


def gradient_descent(
    f: Callable[[np.ndarray], float],
    grad_f: Callable[[np.ndarray], np.ndarray],
    x0: np.ndarray,
    learning_rate: float = 0.1,
    max_iterations: int = 100,
    tolerance: float = 1e-8
) -> Tuple[np.ndarray, List[np.ndarray], List[float]]:
    """
    ImplementaciÃ³n de Gradient Descent.

    Args:
        f: funciÃ³n objetivo
        grad_f: gradiente de f
        x0: punto inicial
        learning_rate: Î±
        max_iterations: mÃ¡ximo de iteraciones
        tolerance: criterio de convergencia

    Returns:
        x_final, history_x, history_f
    """
    x = x0.copy().astype(float)
    history_x = [x.copy()]
    history_f = [f(x)]

    for i in range(max_iterations):
        grad = grad_f(x)

        if np.linalg.norm(grad) < tolerance:
            break

        x = x - learning_rate * grad
        history_x.append(x.copy())
        history_f.append(f(x))

    return x, history_x, history_f


def visualize_optimization(
    f: Callable,
    grad_f: Callable,
    x0: np.ndarray,
    learning_rate: float,
    title: str,
    xlim: Tuple[float, float] = (-5, 5),
    ylim: Tuple[float, float] = (-5, 5)
):
    """Visualiza la trayectoria de optimizaciÃ³n."""

    x_final, history_x, history_f = gradient_descent(
        f, grad_f, x0, learning_rate, max_iterations=50
    )

    # Crear grid para contornos
    x = np.linspace(xlim[0], xlim[1], 100)
    y = np.linspace(ylim[0], ylim[1], 100)
    X, Y = np.meshgrid(x, y)
    Z = np.array([[f(np.array([xi, yi])) for xi, yi in zip(row_x, row_y)]
                  for row_x, row_y in zip(X, Y)])

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Plot 1: Contornos y trayectoria
    ax1 = axes[0]
    contour = ax1.contour(X, Y, Z, levels=30, cmap='viridis')
    ax1.clabel(contour, inline=True, fontsize=8)

    # Trayectoria
    history_x = np.array(history_x)
    ax1.plot(history_x[:, 0], history_x[:, 1], 'r.-', markersize=8, linewidth=1.5)
    ax1.plot(history_x[0, 0], history_x[0, 1], 'go', markersize=12, label='Inicio')
    ax1.plot(history_x[-1, 0], history_x[-1, 1], 'r*', markersize=15, label='Final')

    ax1.set_xlabel('x')
    ax1.set_ylabel('y')
    ax1.set_title(f'{title}\nÎ± = {learning_rate}')
    ax1.legend()
    ax1.set_xlim(xlim)
    ax1.set_ylim(ylim)

    # Plot 2: Convergencia
    ax2 = axes[1]
    ax2.semilogy(history_f, 'b-o', markersize=4)
    ax2.set_xlabel('IteraciÃ³n')
    ax2.set_ylabel('f(x) (escala log)')
    ax2.set_title('Convergencia')
    ax2.grid(True)

    plt.tight_layout()
    plt.savefig(f'gd_{title.lower().replace(" ", "_")}.png', dpi=150)
    plt.show()

    print(f"\n{title}")
    print(f"  Punto inicial: {x0}")
    print(f"  MÃ­nimo encontrado: {x_final}")
    print(f"  f(mÃ­nimo): {f(x_final):.6f}")
    print(f"  Iteraciones: {len(history_f)}")


def main():
    """Ejecutar demos."""

    # === FunciÃ³n 1: Paraboloide ===
    def paraboloid(p):
        return p[0]**2 + p[1]**2

    def grad_paraboloid(p):
        return np.array([2*p[0], 2*p[1]])

    visualize_optimization(
        paraboloid, grad_paraboloid,
        x0=np.array([4.0, 3.0]),
        learning_rate=0.1,
        title="Paraboloide f(x,y) = xÂ² + yÂ²"
    )

    # === FunciÃ³n 2: Rosenbrock (mÃ¡s difÃ­cil) ===
    def rosenbrock(p):
        return (1 - p[0])**2 + 100*(p[1] - p[0]**2)**2

    def grad_rosenbrock(p):
        dx = -2*(1 - p[0]) - 400*p[0]*(p[1] - p[0]**2)
        dy = 200*(p[1] - p[0]**2)
        return np.array([dx, dy])

    visualize_optimization(
        rosenbrock, grad_rosenbrock,
        x0=np.array([-1.0, 1.0]),
        learning_rate=0.001,
        title="Rosenbrock f(x,y) = (1-x)Â² + 100(y-xÂ²)Â²",
        xlim=(-2, 2),
        ylim=(-1, 3)
    )

    # === FunciÃ³n 3: CuadrÃ¡tica elÃ­ptica ===
    def elliptic(p):
        return p[0]**2 + 10*p[1]**2

    def grad_elliptic(p):
        return np.array([2*p[0], 20*p[1]])

    visualize_optimization(
        elliptic, grad_elliptic,
        x0=np.array([4.0, 2.0]),
        learning_rate=0.05,
        title="ElÃ­ptica f(x,y) = xÂ² + 10yÂ²"
    )


if __name__ == "__main__":
    main()

```


---
## Entregable Obligatorio v3.3

### Script: `grad_check.py`

```python
"""
Gradient Checking - ValidaciÃ³n de Derivadas
TÃ©cnica estÃ¡ndar de CS231n Stanford para debugging de backprop.

Autor: [Tu nombre]
MÃ³dulo: 03 - CÃ¡lculo Multivariante
"""
import numpy as np
from typing import Callable, Dict, Tuple


def numerical_gradient(
    f: Callable[[np.ndarray], float],
    x: np.ndarray,
    epsilon: float = 1e-5
) -> np.ndarray:
    """
    Calcula el gradiente numÃ©rico usando diferencias centrales.

    Args:
        f: FunciÃ³n escalar f(x) -> float
        x: Punto donde calcular el gradiente
        epsilon: TamaÃ±o del paso (default: 1e-5)

    Returns:
        Gradiente numÃ©rico aproximado
    """
    grad = np.zeros_like(x)

    # Iterar sobre cada dimensiÃ³n
    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
    while not it.finished:
        idx = it.multi_index
        old_value = x[idx]

        # f(x + epsilon)
        x[idx] = old_value + epsilon
        fx_plus = f(x)

        # f(x - epsilon)
        x[idx] = old_value - epsilon
        fx_minus = f(x)

        # Diferencias centrales: (f(x+Îµ) - f(x-Îµ)) / 2Îµ
        grad[idx] = (fx_plus - fx_minus) / (2 * epsilon)

        # Restaurar valor original
        x[idx] = old_value
        it.iternext()

    return grad


def gradient_check(
    analytic_grad: np.ndarray,
    numerical_grad: np.ndarray,
    threshold: float = 1e-7
) -> Tuple[bool, float]:
    """
    Compara gradiente analÃ­tico vs numÃ©rico.

    Args:
        analytic_grad: Gradiente calculado con backprop
        numerical_grad: Gradiente calculado numÃ©ricamente
        threshold: Umbral de error aceptable

    Returns:
        (passed, relative_error)
    """
    # Error relativo: ||a - n|| / (||a|| + ||n||)
    diff = np.linalg.norm(analytic_grad - numerical_grad)
    norm_sum = np.linalg.norm(analytic_grad) + np.linalg.norm(numerical_grad)

    if norm_sum == 0:
        relative_error = 0.0
    else:
        relative_error = diff / norm_sum

    passed = relative_error < threshold
    return passed, relative_error


# === EJEMPLO: Validar gradiente de MSE Loss ===

def mse_loss(y_pred: np.ndarray, y_true: np.ndarray) -> float:
    """Mean Squared Error."""
    return float(np.mean((y_pred - y_true) ** 2))

def mse_gradient_analytic(y_pred: np.ndarray, y_true: np.ndarray) -> np.ndarray:
    """Gradiente analÃ­tico de MSE respecto a y_pred."""
    n = len(y_true)
    return 2 * (y_pred - y_true) / n


def test_mse_gradient():
    """Test: Validar gradiente de MSE."""
    print("=" * 60)
    print("GRADIENT CHECK: MSE Loss")
    print("=" * 60)

    np.random.seed(42)
    y_pred = np.random.randn(10)
    y_true = np.random.randn(10)

    # Gradiente analÃ­tico
    grad_analytic = mse_gradient_analytic(y_pred, y_true)

    # Gradiente numÃ©rico
    def loss_fn(pred):
        return mse_loss(pred, y_true)

    grad_numerical = numerical_gradient(loss_fn, y_pred.copy())

    # Comparar
    passed, error = gradient_check(grad_analytic, grad_numerical)

    print(f"Gradiente AnalÃ­tico: {grad_analytic[:3]}...")
    print(f"Gradiente NumÃ©rico:  {grad_numerical[:3]}...")
    print(f"Error Relativo: {error:.2e}")
    print(f"Resultado: {'âœ“ PASSED' if passed else 'âœ— FAILED'}")

    return passed


# === EJEMPLO: Validar gradiente de Sigmoid ===

def sigmoid(z: np.ndarray) -> np.ndarray:
    """Sigmoid activation."""
    return 1 / (1 + np.exp(-z))

def sigmoid_derivative_analytic(z: np.ndarray) -> np.ndarray:
    """Derivada analÃ­tica: Ïƒ'(z) = Ïƒ(z)(1 - Ïƒ(z))"""
    s = sigmoid(z)
    return s * (1 - s)


def test_sigmoid_gradient():
    """Test: Validar derivada de sigmoid."""
    print("\n" + "=" * 60)
    print("GRADIENT CHECK: Sigmoid Derivative")
    print("=" * 60)

    np.random.seed(42)
    z = np.random.randn(5)

    # Derivada analÃ­tica
    grad_analytic = sigmoid_derivative_analytic(z)

    # Derivada numÃ©rica (para cada elemento)
    def sigmoid_element(z_arr):
        return float(np.sum(sigmoid(z_arr)))  # Suma para tener escalar

    grad_numerical = numerical_gradient(sigmoid_element, z.copy())

    # Comparar
    passed, error = gradient_check(grad_analytic, grad_numerical)

    print(f"Derivada AnalÃ­tica: {grad_analytic}")
    print(f"Derivada NumÃ©rica:  {grad_numerical}")
    print(f"Error Relativo: {error:.2e}")
    print(f"Resultado: {'âœ“ PASSED' if passed else 'âœ— FAILED'}")

    return passed


# === EJEMPLO: Validar gradiente de una capa lineal ===

def test_linear_layer_gradient():
    """Test: Validar gradiente de capa lineal y = Wx + b."""
    print("\n" + "=" * 60)
    print("GRADIENT CHECK: Linear Layer (y = Wx + b)")
    print("=" * 60)

    np.random.seed(42)

    # Dimensiones
    n_in, n_out = 4, 3

    # ParÃ¡metros
    W = np.random.randn(n_out, n_in)
    b = np.random.randn(n_out)
    x = np.random.randn(n_in)
    y_true = np.random.randn(n_out)

    # Forward + Loss
    def forward_and_loss(W_flat):
        W_reshaped = W_flat.reshape(n_out, n_in)
        y_pred = W_reshaped @ x + b
        return mse_loss(y_pred, y_true)

    # Gradiente analÃ­tico de W
    y_pred = W @ x + b
    dL_dy = 2 * (y_pred - y_true) / n_out  # Gradiente de MSE
    dL_dW_analytic = np.outer(dL_dy, x)    # âˆ‚L/âˆ‚W = âˆ‚L/âˆ‚y Â· x^T

    # Gradiente numÃ©rico de W
    dL_dW_numerical = numerical_gradient(forward_and_loss, W.flatten().copy())
    dL_dW_numerical = dL_dW_numerical.reshape(n_out, n_in)

    # Comparar
    passed, error = gradient_check(
        dL_dW_analytic.flatten(),
        dL_dW_numerical.flatten()
    )

    print(f"Error Relativo: {error:.2e}")
    print(f"Resultado: {'âœ“ PASSED' if passed else 'âœ— FAILED'}")

    return passed


def main():
    """Ejecutar todos los gradient checks."""
    print("\n" + "=" * 60)
    print("       GRADIENT CHECKING SUITE")
    print("       ValidaciÃ³n MatemÃ¡tica v3.3")
    print("=" * 60)

    results = []
    results.append(("MSE Loss", test_mse_gradient()))
    results.append(("Sigmoid", test_sigmoid_gradient()))
    results.append(("Linear Layer", test_linear_layer_gradient()))

    print("\n" + "=" * 60)
    print("RESUMEN")
    print("=" * 60)

    all_passed = True
    for name, passed in results:
        status = "âœ“ PASSED" if passed else "âœ— FAILED"
        print(f"  {name}: {status}")
        all_passed = all_passed and passed

    print("-" * 60)
    if all_passed:
        print("âœ“ TODOS LOS GRADIENT CHECKS PASARON")
        print("  Tu implementaciÃ³n de derivadas es correcta.")
    else:
        print("âœ— ALGUNOS GRADIENT CHECKS FALLARON")
        print("  Revisa tu implementaciÃ³n de backprop.")

    return all_passed


if __name__ == "__main__":
    main()

```
---
## ğŸ§© ConsolidaciÃ³n (errores comunes + debugging v5 + reto Feynman)

### Errores comunes

- **Confundir derivada local con â€œdirecciÃ³n globalâ€:** el gradiente solo te da informaciÃ³n local.
- **`learning_rate` demasiado grande:** puede oscilar o divergir aunque el gradiente sea correcto.
- **Estabilidad numÃ©rica:** `exp(z)` puede overflow; usa `np.clip` cuando aplique.
- **Gradient checking mal aplicado:** `Îµ` demasiado pequeÃ±o puede amplificar ruido numÃ©rico.

### Debugging / validaciÃ³n (v5)

- Si tu entrenamiento es inestable o no baja el loss, valida derivadas con `grad_check.py`.
- Registra hallazgos en `study_tools/DIARIO_ERRORES.md`.
- Protocolos completos:
  - [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md)
  - [PLAN_V5_ESTRATEGICO.md](PLAN_V5_ESTRATEGICO.md)

### Reto Feynman (tablero blanco)

Explica en 5 lÃ­neas o menos:

1) Â¿QuÃ© significa â€œseguir `-âˆ‡f`â€ y por quÃ© eso baja la funciÃ³n?
2) Dibuja el grafo `xâ†’zâ†’aâ†’L` y explica por quÃ© multiplicas derivadas.
3) Â¿Por quÃ© gradient checking detecta bugs de backprop?

---

## âœ… Checklist de FinalizaciÃ³n (v3.3)

### Conocimiento
- [ ] Puedo calcular derivadas de funciones comunes (polinomios, exp, log)
- [ ] Entiendo derivadas parciales y puedo calcularlas
- [ ] Puedo calcular el gradiente de una funciÃ³n multivariable
- [ ] ImplementÃ© Gradient Descent desde cero
- [ ] Entiendo el efecto del learning rate
- [ ] Puedo aplicar la Chain Rule a funciones compuestas
- [ ] Entiendo cÃ³mo la Chain Rule se aplica en Backpropagation
- [ ] Puedo derivar âˆ‚L/âˆ‚w para una neurona simple

### Entregables v3.3
- [ ] `gradient_descent_demo.py` funcional
- [ ] **`grad_check.py` implementado y todos los tests pasan**
- [ ] ValidÃ© mis derivadas de sigmoid, MSE y capa lineal

### MetodologÃ­a Feynman
- [ ] Puedo explicar Chain Rule en 5 lÃ­neas sin jerga
- [ ] Puedo explicar por quÃ© gradient checking funciona

---

## ğŸ”— NavegaciÃ³n

| Anterior | Ãndice | Siguiente |
|----------|--------|-----------|
| [02_ALGEBRA_LINEAL_ML](02_ALGEBRA_LINEAL_ML.md) | [00_INDICE](00_INDICE.md) | [04_PROBABILIDAD_ML](04_PROBABILIDAD_ML.md) |
