# RUBRIC.md ‚Äî R√∫brica de Evaluaci√≥n Cuantitativa

> **Objetivo**: Criterios claros y medibles para evaluar el progreso del estudiante en el MS in AI pathway (CU Boulder/Coursera).

---

## üìä Escala de Calificaci√≥n

| Nota | Rango | Descripci√≥n |
|------|-------|-------------|
| **A** | 90-100% | Dominio excepcional, listo para investigaci√≥n/industria |
| **B** | 80-89% | Competencia s√≥lida, cumple requisitos del pathway |
| **C** | 70-79% | Comprensi√≥n b√°sica, necesita refuerzo |
| **D** | 60-69% | Insuficiente, requiere repetir m√≥dulo |
| **F** | <60% | No demuestra competencia m√≠nima |

---

## üéØ M√©tricas por M√≥dulo

### M01: Fundamentos de Python para ML

| Criterio | Peso | A (90%+) | B (80%+) | C (70%+) |
|----------|------|----------|----------|----------|
| **Sintaxis y estructuras** | 20% | C√≥digo idiom√°tico, PEP8, type hints | C√≥digo funcional, estilo consistente | C√≥digo funciona pero estilo pobre |
| **NumPy vectorizado** | 30% | Sin loops expl√≠citos, broadcasting correcto | Usa vectorizaci√≥n, algunos loops | Mezcla loops y vectorizaci√≥n |
| **Pandas fluido** | 25% | Operaciones encadenadas, sin SettingWithCopy | Manipulaci√≥n correcta, warnings menores | Funcional pero ineficiente |
| **Visualizaci√≥n** | 15% | Gr√°ficos publicables, etiquetas completas | Gr√°ficos claros, alg√∫n detalle falta | Gr√°ficos b√°sicos legibles |
| **Testing** | 10% | pytest con >80% coverage, parametrizado | Tests unitarios b√°sicos | Algunos tests manuales |

**Proyecto integrador M01**: Script ETL que procesa dataset real (>10k filas) en <5 segundos.

---

### M02: √Ålgebra Lineal

| Criterio | Peso | A (90%+) | B (80%+) | C (70%+) |
|----------|------|----------|----------|----------|
| **Operaciones matriciales** | 25% | Implementa desde cero + usa NumPy | Usa NumPy correctamente | Confunde dimensiones ocasionalmente |
| **Descomposiciones** | 25% | SVD, eigen, Cholesky aplicados a ML | Calcula descomposiciones, interpreta | Calcula pero no interpreta |
| **Espacios vectoriales** | 20% | Demuestra rango, null space, proyecciones | Conceptos claros, aplicaci√≥n parcial | Definiciones correctas |
| **Aplicaciones ML** | 20% | PCA desde cero, regularizaci√≥n L2 derivada | Usa PCA, entiende regularizaci√≥n | Aplica sin entender derivaci√≥n |
| **Eficiencia num√©rica** | 10% | Evita inversas expl√≠citas, usa solve() | C√≥digo correcto, no √≥ptimo | Funciona pero lento |

**Proyecto integrador M02**: Implementar PCA desde cero y comparar con sklearn (error < 1e-10).

---

### M03: C√°lculo y Optimizaci√≥n

| Criterio | Peso | A (90%+) | B (80%+) | C (70%+) |
|----------|------|----------|----------|----------|
| **Gradientes anal√≠ticos** | 25% | Deriva funciones complejas, verifica num√©ricamente | Gradientes correctos para funciones est√°ndar | Errores ocasionales en cadena |
| **Gradient Descent** | 30% | Implementa SGD, Adam, momentum desde cero | GD b√°sico converge, tuning manual | GD funciona con hiperpar√°metros dados |
| **Backpropagation** | 25% | Implementa backprop para MLP arbitrario | Backprop para red de 2 capas | Entiende concepto, no implementa |
| **Diagn√≥stico** | 20% | Learning curves, gradient checking, early stopping | Monitorea loss, detecta problemas | Ejecuta sin diagn√≥stico |

**Proyecto integrador M03**: Red neuronal de 3 capas entrenada con backprop manual, accuracy >85% en MNIST subset.

---

### M04: Probabilidad y Estad√≠stica

| Criterio | Peso | A (90%+) | B (80%+) | C (70%+) |
|----------|------|----------|----------|----------|
| **Distribuciones** | 20% | Deriva MLE/MAP, entiende conjugados | Aplica MLE, interpreta par√°metros | Usa distribuciones correctamente |
| **Cadenas de Markov** | 25% | Prueba convergencia, calcula mixing time | Simula cadenas, encuentra estacionaria | Entiende transiciones |
| **MCMC** | 30% | Metropolis-Hastings + Gibbs desde cero, R-hat < 1.1 | Implementa M-H, diagnostica convergencia | Usa MCMC de librer√≠a |
| **Inferencia Bayesiana** | 25% | Posterior anal√≠tico + aproximaci√≥n MCMC | Calcula posteriors conjugados | Entiende Bayes, no calcula |

**Proyecto integrador M04**: Modelo jer√°rquico bayesiano con MCMC, ESS > 1000, R-hat < 1.05.

---

### M05: Aprendizaje Supervisado (CSCA 5622)

| Criterio | Peso | A (90%+) | B (80%+) | C (70%+) |
|----------|------|----------|----------|----------|
| **Regresi√≥n** | 20% | Ridge/Lasso desde cero, cross-validation | Usa sklearn, interpreta coeficientes | Aplica regresi√≥n lineal |
| **Clasificaci√≥n** | 25% | SVM dual, kernels, log√≠stica multinomial | Log√≠stica + SVM con tuning | Clasifica con defaults |
| **√Årboles/Ensembles** | 25% | Implementa RF/XGBoost, feature importance | Usa ensembles, tuning b√°sico | Random Forest out-of-box |
| **Evaluaci√≥n** | 20% | ROC-AUC, calibraci√≥n, fairness metrics | Precision/Recall, F1, matriz confusi√≥n | Accuracy solamente |
| **Pipeline completo** | 10% | sklearn Pipeline reproducible, MLflow | Pipeline funcional | Scripts separados |

**Proyecto integrador M05**: Competencia Kaggle con F1 > 0.85 en clasificaci√≥n multiclase.

---

### M06: Aprendizaje No Supervisado (CSCA 5632)

| Criterio | Peso | A (90%+) | B (80%+) | C (70%+) |
|----------|------|----------|----------|----------|
| **Clustering** | 30% | K-means++, DBSCAN, jer√°rquico + m√©tricas internas | K-means con elbow/silhouette | Aplica clustering |
| **Reducci√≥n dimensionalidad** | 30% | PCA, t-SNE, UMAP con interpretaci√≥n | Usa t√©cnicas, visualiza | PCA b√°sico |
| **Detecci√≥n anomal√≠as** | 20% | Isolation Forest, LOF, autoencoders | Un m√©todo con threshold tuning | Detecta outliers simples |
| **Modelos generativos** | 20% | GMM, VAE b√°sico | GMM con BIC selection | Entiende mezclas |

**Proyecto integrador M06**: Sistema de detecci√≥n de anomal√≠as con precision@k > 0.7.

---

### M07: Deep Learning (CSCA 5642)

| Criterio | Peso | A (90%+) | B (80%+) | C (70%+) |
|----------|------|----------|----------|----------|
| **Fundamentos** | 20% | Backprop manual, inicializaci√≥n Xavier/He | Entiende arquitecturas, usa frameworks | Entrena redes con tutoriales |
| **CNNs** | 25% | Dise√±a arquitectura, transfer learning fine-tune | Usa ResNet/VGG preentrenados | CNN b√°sica funciona |
| **RNNs/Transformers** | 25% | Atenci√≥n desde cero, fine-tune BERT | LSTM para secuencias, usa HuggingFace | RNN simple |
| **Regularizaci√≥n** | 15% | Dropout, batch norm, data augmentation | Aplica t√©cnicas est√°ndar | Overfitting no controlado |
| **MLOps b√°sico** | 15% | Checkpoints, TensorBoard, reproducibilidad | Guarda modelos, logging b√°sico | Entrenamiento ad-hoc |

**Proyecto integrador M07**: Modelo con >92% accuracy en CIFAR-10 o fine-tuned transformer para NLP.

---

### M08: Proyecto Integrador Final

| Criterio | Peso | A (90%+) | B (80%+) | C (70%+) |
|----------|------|----------|----------|----------|
| **Definici√≥n problema** | 15% | Problema novel, m√©tricas justificadas | Problema claro, m√©tricas est√°ndar | Problema definido |
| **EDA y preprocesamiento** | 15% | An√°lisis exhaustivo, pipeline robusto | EDA completo, limpieza adecuada | Exploraci√≥n b√°sica |
| **Modelado** | 25% | M√∫ltiples modelos, ablation study | Baseline + modelo avanzado | Un modelo funcional |
| **Evaluaci√≥n rigurosa** | 20% | Test set separado, intervalos confianza | Validaci√≥n cruzada correcta | Train/test split |
| **Documentaci√≥n** | 15% | README, docstrings, notebook narrativo | C√≥digo comentado, README b√°sico | C√≥digo sin documentar |
| **Presentaci√≥n** | 10% | Demo interactiva, slides profesionales | Presentaci√≥n clara | Explicaci√≥n verbal |

---

## üìã Checklist de Autoevaluaci√≥n

### Antes de entregar cualquier m√≥dulo:

- [ ] C√≥digo pasa `ruff check` sin errores
- [ ] C√≥digo pasa `mypy --strict` (o con config del proyecto)
- [ ] Tests pasan con `pytest -v`
- [ ] Notebooks ejecutan de principio a fin sin errores
- [ ] README actualizado con instrucciones de ejecuci√≥n
- [ ] Gr√°ficos tienen t√≠tulos, ejes etiquetados, leyendas

### Para obtener B o superior:

- [ ] Type hints en todas las funciones p√∫blicas
- [ ] Docstrings con par√°metros y retornos documentados
- [ ] Al menos 3 tests por funci√≥n principal
- [ ] An√°lisis de resultados con interpretaci√≥n
- [ ] Comparaci√≥n con baseline o m√©todo alternativo

### Para obtener A:

- [ ] Implementaci√≥n desde cero de al menos un algoritmo clave
- [ ] An√°lisis de complejidad temporal/espacial
- [ ] Experimentos de ablaci√≥n o sensibilidad
- [ ] C√≥digo optimizado (profiling si aplica)
- [ ] Contribuci√≥n original o extensi√≥n del material

---

## üèÜ Ejemplos de Trabajo Nivel "B"

### M04 Lab 2 (MCMC) ‚Äî Ejemplo B:

```python
def metropolis_hastings(log_target, proposal_std, n_samples, x_init, burn_in):
    """
    Implementaci√≥n b√°sica de Metropolis-Hastings.

    - Proposal Gaussiano sim√©trico ‚úì
    - Burn-in implementado ‚úì
    - Retorna samples y acceptance rate ‚úì
    - Falta: diagn√≥sticos avanzados (ESS, trace plots autom√°ticos)
    """
    samples = np.zeros(n_samples + burn_in)
    samples[0] = x_init
    accepted = 0

    for i in range(1, n_samples + burn_in):
        proposal = samples[i-1] + np.random.normal(0, proposal_std)
        log_alpha = log_target(proposal) - log_target(samples[i-1])

        if np.log(np.random.random()) < log_alpha:
            samples[i] = proposal
            accepted += 1
        else:
            samples[i] = samples[i-1]

    return samples[burn_in:], accepted / (n_samples + burn_in)
```

**Por qu√© es B y no A**:
- ‚úì Implementaci√≥n correcta desde cero
- ‚úì Burn-in y acceptance rate
- ‚úó No incluye ESS autom√°tico
- ‚úó No incluye Gelman-Rubin para m√∫ltiples cadenas
- ‚úó No tiene adaptive proposal tuning

---

## üìà Tracking de Progreso

Usa el siguiente formato en tu `PROGRESS.md` personal:

```markdown
## Semana X ‚Äî M√≥dulo Y

### Completado
- [x] Lab 1: MLE (2.5h)
- [x] Lab 2: MCMC (3h)
- [ ] Lab 3: Markov Chains (pendiente)

### Autoevaluaci√≥n
- Distribuciones: B+ (entiendo conjugados, falta derivar posteriors complejos)
- MCMC: B (M-H funciona, R-hat implementado, ESS marginal)
- Markov: C+ (simulo cadenas, no domino mixing time)

### Plan de mejora
1. Revisar Murphy Cap. 24 para posteriors
2. Practicar m√°s ejercicios de ESS
3. Estudiar Levin-Peres para mixing time
```

---

## üéì Correspondencia con Coursera

| M√≥dulo Gu√≠a | Curso Coursera | Nota m√≠nima requerida |
|-------------|----------------|----------------------|
| M04 | APPA 5002 (Markov & Monte Carlo) | B |
| M05 | CSCA 5622 (Supervised Learning) | B |
| M06 | CSCA 5632 (Unsupervised Learning) | B |
| M07 | CSCA 5642 (Deep Learning) | B |

**Nota**: Para mantener el pathway, se requiere B (80%) en cada curso. Esta r√∫brica est√° calibrada para que un "B" aqu√≠ corresponda a un B en Coursera.

---

## üìù Feedback y Mejora Continua

Despu√©s de completar cada m√≥dulo, responde en `M08_Proyecto_Integrador/FEEDBACK.md`:

1. ¬øQu√© concepto fue m√°s dif√≠cil? ¬øPor qu√©?
2. ¬øQu√© recurso te ayud√≥ m√°s? (libro, video, c√≥digo)
3. ¬øTe sientes preparado para el examen de Coursera? (1-5)
4. Sugerencias para mejorar el material

**Meta**: >80% de estudiantes responden "4" o "5" en preparaci√≥n para examen.
