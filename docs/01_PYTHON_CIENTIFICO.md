# M√≥dulo 01 - Python Cient√≠fico + Pandas

> **üéØ Objetivo:** Dominar Pandas para datos + NumPy para matem√°ticas
> **Fase:** 1 - Fundamentos | **Semanas 1-2**
> **Prerrequisitos:** Python b√°sico (variables, funciones, listas, loops)

---

<a id="m01-0"></a>

## üß≠ C√≥mo usar este m√≥dulo (modo 0‚Üí100)

**Prop√≥sito:** que pases de ‚Äús√© Python b√°sico‚Äù a **poder trabajar con datos reales y producir arrays listos para modelos** (lo que usar√°s en TODO el Pathway).

### Objetivos de aprendizaje (medibles)

Al terminar este m√≥dulo podr√°s:

- **Aplicar** Pandas para cargar, explorar y limpiar datasets reales.
- **Convertir** datasets a `np.ndarray` con shapes correctos para ML (`X` y `y`).
- **Explicar** qu√© es vectorizaci√≥n y por qu√© NumPy elimina loops.
- **Diagnosticar** los errores de shapes m√°s comunes (`(n,)` vs `(n,1)`, broadcasting silencioso, vistas vs copias).

### Prerrequisitos

- Python b√°sico (loops, funciones, listas, diccionarios).

Enlaces r√°pidos:

- [GLOSARIO: NumPy](GLOSARIO.md#numpy)
- [GLOSARIO: Broadcasting](GLOSARIO.md#broadcasting)
- [GLOSARIO: Vectorization](GLOSARIO.md#vectorization)
- [RECURSOS.md](RECURSOS.md)

### Integraci√≥n con Plan v4/v5

- Drill diario de shapes: `study_tools/DRILL_DIMENSIONES_NUMPY.md`
- Registro de errores: `study_tools/DIARIO_ERRORES.md`
- Evaluaci√≥n (r√∫brica): [study_tools/RUBRICA_v1.md](../study_tools/RUBRICA_v1.md) (scope `M01` en `rubrica.csv`)
- Protocolo completo:
  - [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md)
  - [PLAN_V5_ESTRATEGICO.md](PLAN_V5_ESTRATEGICO.md)

### Recursos (cu√°ndo usarlos)

| Prioridad | Recurso | Cu√°ndo usarlo en este m√≥dulo | Para qu√© |
|----------|---------|------------------------------|----------|
| **Obligatorio** | [Pandas Getting Started](https://pandas.pydata.org/docs/getting_started/) | Semana 1, antes de empezar con `DataFrame/Series` y limpieza | Referencia oficial para flujo t√≠pico de carga/EDA/limpieza |
| **Obligatorio** | [NumPy Documentation (absolute beginners)](https://numpy.org/doc/stable/user/absolute_beginners.html) | Semana 2, cuando aparezcan `ndarray`, `dtype`, `reshape`, `axis`, broadcasting | Fuente oficial para resolver dudas de shapes/axis |
| **Obligatorio** | `study_tools/DRILL_DIMENSIONES_NUMPY.md` | Cada vez que te equivoques en un shape / antes del checklist de salida | Automatizar intuici√≥n de shapes |
| **Complementario** | [Real Python - NumPy](https://realpython.com/numpy-tutorial/) | Despu√©s de completar broadcasting + vectorizaci√≥n (Semana 2) | Consolidar patrones idiom√°ticos con ejemplos pr√°cticos |
| **Opcional** | [RECURSOS.md](RECURSOS.md) | Al terminar el m√≥dulo (para planificar refuerzo) | Elegir rutas de profundizaci√≥n sin dispersarte |

### Criterio de salida (cu√°ndo puedes avanzar)

- Puedes preparar un `X` y `y` desde un CSV sin errores de dtype/shape.
- Puedes explicar `axis=0` vs `axis=1` y predecir shapes sin ejecutar.
- Puedes demostrar speedup vectorizado (benchmark) y justificarlo.

## üß† ¬øPor Qu√© Este M√≥dulo?

### El Problema con Python Puro para ML

```python
# ‚ùå As√≠ NO se hace en Machine Learning
def dot_product_slow(a: list, b: list) -> float:
    """Producto punto con loop - LENTO."""
    result = 0
    for i in range(len(a)):
        result += a[i] * b[i]
    return result

# Para vectores de 1 mill√≥n de elementos:
# Tiempo: ~200ms
```

```python
# ‚úÖ As√≠ S√ç se hace en Machine Learning
import numpy as np

def dot_product_fast(a: np.ndarray, b: np.ndarray) -> float:
    """Producto punto vectorizado - R√ÅPIDO."""
    return np.dot(a, b)

# Para vectores de 1 mill√≥n de elementos:
# Tiempo: ~2ms (100x m√°s r√°pido)
```

### Conexi√≥n con el Pathway

En los cursos de CU Boulder:
- **Supervised Learning:** Multiplicaciones de matrices para regresi√≥n
- **Unsupervised Learning:** PCA requiere descomposici√≥n de matrices
- **Deep Learning:** Forward/backward pass son operaciones matriciales

**Sin NumPy, no puedes hacer ML eficiente.**

---

## üìö Contenido del M√≥dulo

### Semana 1: Pandas + NumPy B√°sico

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  D√çA 1: Pandas - DataFrame y Series                             ‚îÇ
‚îÇ  D√çA 2: Pandas - Carga de CSVs (read_csv, head, info)           ‚îÇ
‚îÇ  D√çA 3: Pandas - Limpieza (dropna, fillna, dtypes)              ‚îÇ
‚îÇ  D√çA 4: NumPy - Arrays y dtypes                                 ‚îÇ
‚îÇ  D√çA 5: NumPy - Indexing y Slicing                              ‚îÇ
‚îÇ  D√çA 6: Pandas ‚Üí NumPy (df.values, df.to_numpy())               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Semana 2: NumPy Vectorizado

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  D√çA 1: Broadcasting                                            ‚îÇ
‚îÇ  D√çA 2: Producto matricial (@, np.dot, np.matmul) + reshape/flatten ‚îÇ
‚îÇ  D√çA 3: OOP para ML (v5.1): class Tensor (__init__, __add__, @) ‚îÇ
‚îÇ  D√çA 4: Agregaciones y operaciones con ejes                     ‚îÇ
‚îÇ  D√çA 5: Random y generaci√≥n de datos sint√©ticos                 ‚îÇ
‚îÇ  D√çA 6: Entregable: Pipeline Pandas ‚Üí NumPy                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üíª Conceptos Clave

### 0. Pandas Esencial (D√≠as 1-3)

#### ¬øPor Qu√© Pandas?

En el mundo real de ML, los datos vienen en CSVs sucios, no en arrays NumPy perfectos. Antes de aplicar cualquier algoritmo necesitas:

1. **Cargar datos** desde archivos
2. **Explorar** estructura y tipos
3. **Limpiar** valores faltantes y errores
4. **Convertir** a NumPy para el modelo

```python
import pandas as pd
import numpy as np

# ========== CARGA DE DATOS ==========
# Cargar CSV
df = pd.read_csv('data/iris.csv')

# Primeras filas
print(df.head())

# Informaci√≥n del DataFrame
print(df.info())
#  Column         Non-Null Count  Dtype
# ---  ------         --------------  -----
#  0   sepal_length   150 non-null    float64
#  1   sepal_width    150 non-null    float64
#  2   petal_length   150 non-null    float64
#  3   petal_width    150 non-null    float64
#  4   species        150 non-null    object

# Estad√≠sticas b√°sicas
print(df.describe())
```

#### Limpieza de Datos

```python
import pandas as pd

# Crear DataFrame con datos sucios
df = pd.DataFrame({
    'edad': [25, 30, None, 45, 50],
    'salario': [50000, 60000, 70000, None, 90000],
    'ciudad': ['Madrid', 'Barcelona', 'Madrid', 'Sevilla', None]
})

# ========== DETECTAR NULOS ==========
print(df.isnull().sum())
# edad       1
# salario    1
# ciudad     1

# ========== ELIMINAR FILAS CON NULOS ==========
df_clean = df.dropna()  # Elimina filas con cualquier nulo
print(f"Filas despu√©s de dropna: {len(df_clean)}")  # 2

# ========== RELLENAR NULOS ==========
df_filled = df.copy()
df_filled['edad'] = df_filled['edad'].fillna(df_filled['edad'].mean())
df_filled['salario'] = df_filled['salario'].fillna(df_filled['salario'].median())
df_filled['ciudad'] = df_filled['ciudad'].fillna('Desconocido')

print(df_filled)
```

#### Selecci√≥n y Filtrado

```python
import pandas as pd

df = pd.read_csv('data/iris.csv')

# ========== SELECCIONAR COLUMNAS ==========
# Una columna (Serie)
sepal_length = df['sepal_length']

# M√∫ltiples columnas (DataFrame)
features = df[['sepal_length', 'sepal_width']]

# ========== FILTRAR FILAS ==========
# Condici√≥n simple
setosa = df[df['species'] == 'setosa']

# M√∫ltiples condiciones
large_setosa = df[(df['species'] == 'setosa') & (df['sepal_length'] > 5)]

# ========== LOC e ILOC ==========
# loc: por etiquetas
df.loc[0:5, ['sepal_length', 'species']]

# iloc: por posici√≥n (como NumPy)
df.iloc[0:5, 0:2]
```

#### De Pandas a NumPy (D√≠a 6)

```python
import pandas as pd
import numpy as np

df = pd.read_csv('data/iris.csv')

# ========== SEPARAR FEATURES Y TARGET ==========
# Features (X) - todas las columnas num√©ricas
X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].to_numpy()
print(f"X shape: {X.shape}")  # (150, 4)
print(f"X dtype: {X.dtype}")  # float64

# Target (y) - convertir categor√≠as a n√∫meros
y = df['species'].map({'setosa': 0, 'versicolor': 1, 'virginica': 2}).to_numpy()
print(f"y shape: {y.shape}")  # (150,)

# ========== VERIFICAR ==========
print(f"Tipo X: {type(X)}")  # <class 'numpy.ndarray'>
print(f"Tipo y: {type(y)}")  # <class 'numpy.ndarray'>

# Ahora X e y est√°n listos para algoritmos de ML
```

---

### 1. Arrays vs Listas

#### Intuici√≥n: ‚Äúmemoria contigua‚Äù (NumPy) vs ‚Äúcajas dispersas‚Äù (listas)

Piensa en una **lista de Python** como una fila de cajitas que guardan **referencias** a objetos; esos objetos pueden estar **dispersos** por la memoria. NumPy, en cambio, busca representar un `ndarray` como un **bloque contiguo** de n√∫meros del mismo tipo (homog√©neos). Esa decisi√≥n habilita:

- **Vectorizaci√≥n real:** bucles internos en C (muy optimizados).
- **Mejor uso de cach√© CPU:** leer datos contiguos es m√°s r√°pido.
- **Menos overhead:** no hay ‚Äúun objeto por n√∫mero‚Äù.

Mini-diagrama mental:

```
Lista (referencias):  [ * ] -> obj1   [ * ] -> obj2   [ * ] -> obj3   ...
                       |              |              |
                      mem@A          mem@Z          mem@K

NumPy (contiguo):     [ 1.0 ][ 2.0 ][ 3.0 ][ 4.0 ] ...  (mismo dtype)
```

```python
import numpy as np  # Importa NumPy para demostrar c√≥mo axis afecta agregaciones

# Lista de Python
lista = [1, 2, 3, 4, 5]

# Array de NumPy
array = np.array([1, 2, 3, 4, 5])

# Diferencias clave:
# 1. Tipo homog√©neo (todos los elementos del mismo tipo)
# 2. Tama√±o fijo despu√©s de creaci√≥n
# 3. Operaciones vectorizadas
# 4. Almacenamiento contiguo en memoria
```

### 2. Creaci√≥n de Arrays

```python
import numpy as np

# Desde lista
a = np.array([1, 2, 3])

# Arrays especiales
zeros = np.zeros((3, 4))        # Matriz 3x4 de ceros
ones = np.ones((2, 3))          # Matriz 2x3 de unos
identity = np.eye(4)            # Matriz identidad 4x4
random = np.random.randn(3, 3)  # Matriz 3x3 valores normales

# Secuencias
rango = np.arange(0, 10, 2)     # [0, 2, 4, 6, 8]
linspace = np.linspace(0, 1, 5) # [0, 0.25, 0.5, 0.75, 1]

print(f"Shape de zeros: {zeros.shape}")  # (3, 4)
print(f"Dtype de zeros: {zeros.dtype}")  # float64
```

### 3. Indexing y Slicing

```python
import numpy as np

# Crear matriz 2D
matrix = np.array([
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9]
])

# Acceso a elementos
print(matrix[0, 0])      # 1 (fila 0, columna 0)
print(matrix[1, 2])      # 6 (fila 1, columna 2)

# Slicing
print(matrix[0, :])      # [1, 2, 3] (toda la fila 0)
print(matrix[:, 1])      # [2, 5, 8] (toda la columna 1)
print(matrix[0:2, 1:3])  # [[2, 3], [5, 6]] (submatriz)

# Indexing booleano
print(matrix[matrix > 5])  # [6, 7, 8, 9]
```

### 4. Broadcasting

#### Worked Example: `(3, 1) + (1, 3)` paso a paso

Objetivo: entender **por qu√©** funciona sin loops.

1) Define dos arrays con una dimensi√≥n ‚Äúde tama√±o 1‚Äù:

- `A.shape = (3, 1)` (columna)
- `B.shape = (1, 3)` (fila)

2) Regla clave: si en una dimensi√≥n uno de los tama√±os es `1`, NumPy puede **‚Äúestirar‚Äù** esa dimensi√≥n para igualar al otro.

3) Resultado final: ambos se ven como `(3, 3)` y se suman elemento a elemento.

```python
import numpy as np

A = np.array([[1], [2], [3]])        # shape: (3, 1)
B = np.array([[10, 20, 30]])         # shape: (1, 3)

# Broadcasting:
# A se repite horizontalmente 3 veces
# B se repite verticalmente 3 veces
C = A + B                             # shape: (3, 3)

print("A:\n", A)
print("B:\n", B)
print("C = A + B:\n", C)
```

```python
import numpy as np

# Broadcasting: operar arrays de diferentes shapes

# Escalar + Array
a = np.array([1, 2, 3])
print(a + 10)  # [11, 12, 13]

# Vector + Matriz (broadcasting autom√°tico)
matrix = np.array([
    [1, 2, 3],
    [4, 5, 6]
])
vector = np.array([10, 20, 30])

# El vector se "expande" para coincidir con la matriz
print(matrix + vector)
# [[11, 22, 33],
#  [14, 25, 36]]

# Regla de broadcasting:
# Las dimensiones deben ser iguales O una de ellas debe ser 1
```

### 5. Agregaciones y Ejes

#### Visualizaci√≥n: ¬øqu√© ‚Äúcolapsa‚Äù cada eje?

Regla pr√°ctica:

- `axis=0` **colapsa filas** ‚Üí te queda ‚Äúuna salida por columna‚Äù
- `axis=1` **colapsa columnas** ‚Üí te queda ‚Äúuna salida por fila‚Äù

Ejemplo con una matriz `2x3`:

```
X = [[1, 2, 3],
     [4, 5, 6]]

sum(axis=0) = [1+4, 2+5, 3+6] = [5, 7, 9]
sum(axis=1) = [1+2+3, 4+5+6] = [6, 15]
```

```python
import numpy as np

matrix = np.array([
    [1, 2, 3],
    [4, 5, 6]
])

# Agregaciones globales
print(np.sum(matrix))   # 21 (suma de todos)
print(np.mean(matrix))  # 3.5 (promedio de todos)
print(np.std(matrix))   # 1.707... (desviaci√≥n est√°ndar)

# Agregaciones por eje
# axis=0: colapsar filas (operar columnas)
print(np.sum(matrix, axis=0))  # [5, 7, 9]

# axis=1: colapsar columnas (operar filas)
print(np.sum(matrix, axis=1))  # [6, 15]

# Visualizaci√≥n de ejes:
# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
# ‚îÇ axis=0 ‚Üì    ‚îÇ
# ‚îÇ [1, 2, 3]   ‚îÇ ‚Üí axis=1
# ‚îÇ [4, 5, 6]   ‚îÇ ‚Üí axis=1
# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 6. Operaciones Matriciales

```python
import numpy as np

A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])

# Operaciones elemento a elemento
print(A + B)   # Suma
print(A * B)   # Multiplicaci√≥n elemento a elemento (Hadamard)
print(A / B)   # Divisi√≥n elemento a elemento

# Producto matricial (lo que usar√°s en ML)
print(A @ B)           # Operador @ (Python 3.5+)
print(np.matmul(A, B)) # Funci√≥n matmul
print(np.dot(A, B))    # Funci√≥n dot

# Resultado:
# [[19, 22],
#  [43, 50]]

# Transpuesta
print(A.T)
# [[1, 3],
#  [2, 4]]
```

### 7. Vectorizaci√≥n: Eliminar Loops

```python
import numpy as np

# ‚ùå CON LOOP (lento)
def normalize_loop(data: list) -> list:
    """Normalizar datos con loop."""
    mean = sum(data) / len(data)
    std = (sum((x - mean)**2 for x in data) / len(data)) ** 0.5
    return [(x - mean) / std for x in data]

# ‚úÖ VECTORIZADO (r√°pido)
def normalize_vectorized(data: np.ndarray) -> np.ndarray:
    """Normalizar datos vectorizado."""
    return (data - np.mean(data)) / np.std(data)

# Ejemplo
data = np.random.randn(1000000)

# La versi√≥n vectorizada es ~100x m√°s r√°pida
normalized = normalize_vectorized(data)
```

### 8. Funciones Universales (ufuncs)

```python
import numpy as np

x = np.array([1, 2, 3, 4, 5])

# Funciones matem√°ticas (aplicadas elemento a elemento)
print(np.exp(x))      # e^x
print(np.log(x))      # ln(x)
print(np.sqrt(x))     # ‚àöx
print(np.sin(x))      # sin(x)

# Importante para ML:
# Sigmoid: œÉ(x) = 1 / (1 + e^(-x))
def sigmoid(x: np.ndarray) -> np.ndarray:
    return 1 / (1 + np.exp(-x))  # Sigmoid: mapea R -> (0,1) elemento a elemento

# ReLU: max(0, x)
def relu(x: np.ndarray) -> np.ndarray:
    return np.maximum(0, x)  # ReLU: max(0,x) elemento a elemento; anula negativos

print(sigmoid(np.array([-2, -1, 0, 1, 2])))
# [0.119, 0.269, 0.5, 0.731, 0.881]
```

### 9. Reshape y Manipulaci√≥n de Forma

```python
import numpy as np  # Importa NumPy para crear arrays y cambiar su forma (reshape/flatten)

# Crear array 1D
a = np.arange(12)  # Crea un vector 1D con 12 enteros consecutivos (0..11)

# Reshape a 2D
matrix = a.reshape(3, 4)  # Reinterpreta el vector como matriz 2D de shape (3,4); 3*4 debe igualar 12
print(matrix.shape)  # Imprime el shape para verificar que ahora es (3, 4)
# [[ 0,  1,  2,  3],
#  [ 4,  5,  6,  7],
#  [ 8,  9, 10, 11]]

# Reshape a 3D
tensor = a.reshape(2, 2, 3)  # Cambia la forma a 3D (2,2,3); 2*2*3=12 conserva el total de elementos
print(tensor.shape)  # Verifica por pantalla la forma del tensor (2, 2, 3)

# Flatten: volver a 1D
flat = matrix.flatten()  # Aplana la matriz 2D y devuelve una copia 1D con todos los elementos
print(flat.shape)  # Comprueba que vuelve a tener 12 elementos en 1D: shape (12,)

# -1 para inferir dimensi√≥n autom√°ticamente
auto = a.reshape(4, -1)  # Usa -1 para que NumPy infiera la dimensi√≥n faltante: (4, 3)
auto = a.reshape(-1, 6)  # Infiera la primera dimensi√≥n para que el total sea 12: (2, 6)
```

### 9.1 OOP para ML (v5.1): mini-framework `Tensor`

**Objetivo pr√°ctico:** antes de llegar a redes neuronales (donde vas a tener que manejar `self`, estado y operaciones), crea una mini-abstracci√≥n que se comporte como un ‚Äútensor‚Äù simple.

#### Qu√© debes dominar (sin teor√≠a vac√≠a)

- **Clase vs instancia:** la clase define el ‚Äúmolde‚Äù; la instancia es el objeto real en memoria.
- **`self`:** referencia a la instancia actual; ah√≠ vive el estado.
- **Estado:** variables guardadas en el objeto (`self.data`, `self.shape`).
- **Operadores:** `+` llama a `__add__`, `@` llama a `__matmul__`.

#### Entregable (taller)

- Implementar una clase `Tensor` que:
  - acepte lista o `np.ndarray` en `__init__`
  - mantenga un estado interno `self.shape`
  - implemente `__add__` y `__matmul__` usando NumPy por dentro

#### Implementaci√≥n (referencia)

```python
import numpy as np  # NumPy para convertir entrada a ndarray y reutilizar operaciones vectorizadas
from typing import Union  # Union para aceptar m√∫ltiples tipos de entrada en el constructor

ArrayLike = Union[list, np.ndarray]  # Tipo de entrada soportado: lista de Python o ndarray de NumPy

class Tensor:  # Contenedor m√≠nimo para entender OOP aplicado a ML (estado + operadores)
    def __init__(self, data: ArrayLike):  # Constructor: recibe datos y construye el estado interno
        self.data = np.array(data, dtype=float)  # Normaliza a ndarray float para operar consistentemente
        self.shape = self.data.shape  # Guarda shape como parte del estado para inspecci√≥n y debugging

    def __add__(self, other: "Tensor") -> "Tensor":  # Define el operador + (suma elemento a elemento)
        if not isinstance(other, Tensor):  # Si no es Tensor, delega a Python (permite otros tipos)
            return NotImplemented  # Se√±al est√°ndar: operaci√≥n no implementada para ese tipo
        return Tensor(self.data + other.data)  # Suma NumPy y devuelve un nuevo Tensor (no muta self)

    def __matmul__(self, other: "Tensor") -> "Tensor":  # Define el operador @ (producto matricial)
        if not isinstance(other, Tensor):  # Valida tipo para evitar errores silenciosos
            return NotImplemented  # Permite que Python intente la operaci√≥n reflejada si existe
        return Tensor(self.data @ other.data)  # Usa @ de NumPy (matmul) y envuelve el resultado

    def __repr__(self) -> str:  # Representaci√≥n √∫til para ver shape y datos r√°pido al imprimir
        return f"Tensor(shape={self.shape}, data={self.data})"  # String con informaci√≥n m√≠nima de debugging

#### Ejercicios (con `assert`) ‚Äî tu m√≠nimo aceptable

```python
import numpy as np  # NumPy para comparar arrays con allclose y construir datos de prueba

# 1) Estado: shape debe reflejar el ndarray interno
t = Tensor([1, 2, 3])  # Crea Tensor desde lista (se convierte internamente a ndarray)
assert t.shape == (3,)  # Verifica que el shape se guard√≥ correctamente

# 2) Suma: + llama a __add__
a = Tensor([1, 2, 3])  # Tensor A
b = Tensor([10, 20, 30])  # Tensor B
c = a + b  # Ejecuta __add__ y debe devolver un Tensor nuevo
assert isinstance(c, Tensor)  # Debe devolver Tensor
assert np.allclose(c.data, np.array([11.0, 22.0, 33.0]))  # Verifica el resultado num√©rico
assert c.shape == (3,)  # El shape debe permanecer (3,)

# 3) Producto matricial: @ llama a __matmul__
A = Tensor([[1, 2], [3, 4]])  # Matriz 2x2
x = Tensor([1, 1])  # Vector de entrada con shape (2,)
y = A @ x  # Producto matriz-vector -> shape (2,)
assert np.allclose(y.data, np.array([3.0, 7.0]))  # [1,2]¬∑[1,1]=3 y [3,4]¬∑[1,1]=7
assert y.shape == (2,)  # Verifica el shape de salida

# 4) Error de shape: debe fallar si dimensiones no son compatibles
try:  # Captura excepci√≥n esperada de NumPy cuando shapes no son multiplicables
    _ = Tensor([[1, 2, 3], [4, 5, 6]]) @ Tensor([1, 2])  # (2,3) @ (2,) no es v√°lido
    assert False  # Si no fall√≥, el test debe fallar
except ValueError:  # NumPy lanza ValueError ante incompatibilidad de shapes
    pass  # √âxito: esper√°bamos el error
```

### 10. Generaci√≥n de Datos Aleatorios

```python
import numpy as np  # Importa NumPy para generar n√∫meros aleatorios y manipular arrays

# Fijar semilla para reproducibilidad
np.random.seed(42)  # Fija la semilla: hace reproducibles los resultados aleatorios

# Distribuci√≥n uniforme [0, 1)
uniform = np.random.rand(3, 3)  # Genera una matriz 3x3 con valores uniformes en [0,1)

# Distribuci√≥n normal (media=0, std=1)
normal = np.random.randn(3, 3)  # Genera una matriz 3x3 con valores ~ N(0,1)

# Distribuci√≥n normal personalizada
custom_normal = np.random.normal(loc=5, scale=2, size=(100,))  # 100 muestras de N(5,2^2): media 5, std 2

# Enteros aleatorios
integers = np.random.randint(0, 10, size=(3, 3))  # Enteros aleatorios en [0,10) con shape (3,3)

# Shuffle (mezclar)
data = np.arange(10)  # Crea un array 1D [0,1,2,...,9]
np.random.shuffle(data)  # Mezcla el array *in-place* (modifica data directamente)

# Muestreo sin reemplazo
sample = np.random.choice(data, size=5, replace=False)  # Elige 5 elementos distintos de data (sin repetir)
```

---

## üìä Type Hints con NumPy

```python
import numpy as np  # Importa NumPy para operaciones num√©ricas
from numpy.typing import NDArray  # Tipado est√°tico: NDArray permite anotar arrays de NumPy con mypy

# Type hints para arrays
def normalize(data: NDArray[np.float64]) -> NDArray[np.float64]:
    """Normaliza un array de floats."""
    return (data - np.mean(data)) / np.std(data)  # Estandariza: resta la media y divide por la desviaci√≥n est√°ndar

# Type hints gen√©ricos
def dot_product(a: np.ndarray, b: np.ndarray) -> float:
    """Calcula el producto punto de dos vectores."""
    return float(np.dot(a, b))  # np.dot devuelve un escalar NumPy; float() lo convierte a float de Python

# Con mypy
# pip install numpy-stubs
```

---

## ‚ö° Benchmark: Lista vs NumPy

```python
import numpy as np  # NumPy para operaciones vectorizadas y producto punto r√°pido (np.dot)
import time  # time.time() para medir tiempos de ejecuci√≥n (benchmark simple)
from typing import List  # Tipado: lista de floats para la implementaci√≥n ‚Äúcon Python puro‚Äù

def benchmark_dot_product():
    """Compara rendimiento de lista vs NumPy."""
    size = 1_000_000  # Tama√±o del vector: suficientemente grande para notar diferencias de rendimiento

    # Crear datos
    list_a: List[float] = [float(i) for i in range(size)]  # Lista de floats: implementaci√≥n base (no vectorizada)
    list_b: List[float] = [float(i) for i in range(size)]  # Segunda lista de floats
    array_a = np.array(list_a)  # Convierte lista a ndarray: permite operaciones vectorizadas (en C)
    array_b = np.array(list_b)  # Convierte la segunda lista a ndarray

    # Benchmark lista
    start = time.time()  # Marca tiempo inicial
    result_list = sum(a * b for a, b in zip(list_a, list_b))  # Producto punto con generador + zip (Python puro)
    time_list = time.time() - start  # Tiempo total transcurrido para la versi√≥n con listas

    # Benchmark NumPy
    start = time.time()  # Marca tiempo inicial para NumPy
    result_numpy = np.dot(array_a, array_b)  # Producto punto vectorizado: usa implementaci√≥n optimizada (BLAS)
    time_numpy = time.time() - start  # Tiempo total transcurrido para NumPy

    print(f"Lista:  {time_list:.4f}s")  # Reporta tiempo de la implementaci√≥n con listas
    print(f"NumPy:  {time_numpy:.4f}s")  # Reporta tiempo de la implementaci√≥n con NumPy
    print(f"Speedup: {time_list/time_numpy:.1f}x")  # Factor de aceleraci√≥n: cu√°ntas veces NumPy es m√°s r√°pido

    # Verificar resultados iguales
    assert abs(result_list - result_numpy) < 1e-6  # Confirma que ambos m√©todos producen el mismo resultado

if __name__ == "__main__":
    benchmark_dot_product()  # Ejecuta el benchmark solo cuando el archivo se corre como script

# Output t√≠pico:
# Lista:  0.1523s
# NumPy:  0.0015s
# Speedup: 101.5x
```

---

## üéØ Ejercicios por tema (progresivos) + Soluciones

Reglas de uso:

- **Primero intenta** sin ver soluciones.
- **Tiempo l√≠mite sugerido:** 10‚Äì15 min por ejercicio antes de mirar la soluci√≥n.
- **√âxito m√≠nimo:** que tu soluci√≥n pase los `assert` de cada ejercicio.

 ---

 ### Ejercicio 1.1: Pandas - DataFrame y Series

 #### Enunciado

 1) **B√°sico**

 - Crea un `DataFrame` llamado `df` con columnas `edad`, `salario`, `ciudad` (5 filas).
 - Extrae la columna `salario` como `Series` y calcula su media.

 2) **Intermedio**

 - Crea una nueva columna `salario_k` con `salario / 1000`.
 - Ordena el `DataFrame` por `salario` de mayor a menor.

 3) **Avanzado**

 - Calcula, por ciudad, la media de `salario` y el conteo de filas (en una sola tabla).

 #### Soluci√≥n

 ```python
 import pandas as pd  # Importa Pandas: librer√≠a est√°ndar para manipulaci√≥n de datos tabulares

 df = pd.DataFrame(  # Construye un DataFrame (tabla) desde un diccionario de columnas
     {  # Cada clave del diccionario ser√° el nombre de una columna
         "edad": [25, 30, 30, 45, 50],  # Columna num√©rica: lista de edades (5 filas)
         "salario": [50000, 60000, 61000, 80000, 90000],  # Columna num√©rica: salarios (valores enteros)
         "ciudad": ["Madrid", "Barcelona", "Madrid", "Sevilla", "Madrid"],  # Columna categ√≥rica: ciudad por fila
     }  # Cierra el diccionario
 )  # Cierra el constructor del DataFrame

 salario = df["salario"]  # Selecciona una columna: devuelve una Series (vector 1D con √≠ndice)
 media_salario = salario.mean()  # Calcula la media aritm√©tica de la Series (promedio)

 df["salario_k"] = df["salario"] / 1000  # Crea columna nueva: vectoriza la operaci√≥n (sin bucles)
 df_sorted = df.sort_values("salario", ascending=False)  # Ordena el DataFrame por salario (descendente)

 resumen = (  # Crea un resumen agregado por ciudad usando un pipeline encadenado
     df.groupby("ciudad", as_index=False)  # Agrupa por ciudad; as_index=False mantiene 'ciudad' como columna
     .agg(  # Aplica m√∫ltiples agregaciones y asigna nombres a las columnas de salida
         salario_mean=("salario", "mean"),  # Media del salario por ciudad
         n=("salario", "size"),  # Conteo de registros por ciudad (tama√±o del grupo)
     )  # Cierra la agregaci√≥n
     .sort_values("salario_mean", ascending=False)  # Ordena el resumen por salario medio (de mayor a menor)
 )  # Cierra la expresi√≥n multi-l√≠nea

 assert isinstance(media_salario, float)  # Verifica tipo: la media debe ser un float
 assert "salario_k" in df.columns  # Verifica que la columna derivada exista
 assert df_sorted.iloc[0]["salario"] == df["salario"].max()  # La primera fila ordenada debe ser el salario m√°ximo
 assert set(resumen.columns) == {"ciudad", "salario_mean", "n"}  # Verifica el esquema (columnas) del resumen
 ```

 ---

 ### Ejercicio 1.2: Pandas - Limpieza (missing values, dtypes, duplicados)

 #### Enunciado

 1) **B√°sico**

 - Crea un `DataFrame` con valores faltantes en `edad` y `salario`.
 - Cuenta cu√°ntos nulos hay por columna.

 2) **Intermedio**

 - Rellena `edad` con la media.
 - Rellena `salario` con la mediana.

 3) **Avanzado**

 - Agrega una fila duplicada a prop√≥sito.
 - Elimina duplicados.
 - Convierte `edad` a `int` **despu√©s** de imputar.

 #### Soluci√≥n

 ```python
 import pandas as pd  # Pandas para limpieza: nulos, duplicados, casting de tipos
 import numpy as np  # NumPy para utilidades num√©ricas y verificaci√≥n robusta de dtype

 df = pd.DataFrame(  # Crea un DataFrame con missing values (None) para simular datos reales ‚Äúsucios‚Äù
     {  # Diccionario: columnas -> listas
         "edad": [25, None, 30, 45, None],  # 'None' se interpretar√° como NaN (faltante) en una columna num√©rica
         "salario": [50000, 60000, None, 80000, 90000],  # Otro faltante en 'salario'
         "ciudad": ["Madrid", "Barcelona", "Madrid", "Sevilla", "Madrid"],  # Columna categ√≥rica sin nulos
     }  # Cierra diccionario
 )  # Cierra DataFrame

 nulls = df.isnull().sum()  # isnull() marca NaN/None; sum() por columna cuenta True => n√∫mero de nulos

 df2 = df.copy()  # Copia expl√≠cita: evita mutar df (importante si df se reutiliza en otros pasos)
 df2["edad"] = df2["edad"].fillna(df2["edad"].mean())  # Imputa edad con media (supone distribuci√≥n ‚Äúrazonable‚Äù)
 df2["salario"] = df2["salario"].fillna(df2["salario"].median())  # Imputa salario con mediana (robusta a outliers)

 df3 = pd.concat([df2, df2.iloc[[0]]], ignore_index=True)  # A√±ade una fila duplicada (la primera) para probar drop_duplicates
 df3 = df3.drop_duplicates()  # Elimina filas duplicadas exactas (misma combinaci√≥n de valores)
 df3["edad"] = df3["edad"].round().astype(int)  # Convierte a int al final: redondea y castea (sin NaN ya)

 assert nulls["edad"] == 2  # Debe haber 2 nulos originales en edad
 assert nulls["salario"] == 1  # Debe haber 1 nulo original en salario
 assert df2.isnull().sum().sum() == 0  # Tras imputaci√≥n, no deben quedar nulos
 assert len(df3) == len(df2)  # Agregar un duplicado y luego quitarlo deja el mismo tama√±o
 assert df3["edad"].dtype == np.int64 or str(df3["edad"].dtype).startswith("int")  # Verifica tipo entero
 ```

 ---

 ### Ejercicio 1.3: Pandas - Selecci√≥n y filtrado (`loc`, `iloc`, boolean masks)

 #### Enunciado

 Usa este `DataFrame`:

 ```python
 import pandas as pd  # Importa Pandas para construir el DataFrame de ejemplo

 df = pd.DataFrame(  # DataFrame peque√±o (similar a Iris) para practicar selecci√≥n/filtrado
     {  # Diccionario columna -> valores
         "sepal_length": [5.1, 4.9, 5.8, 6.0, 5.4],  # Feature num√©rica: longitud del s√©palo
         "sepal_width": [3.5, 3.0, 2.7, 2.2, 3.9],  # Feature num√©rica: ancho del s√©palo
         "species": ["setosa", "setosa", "versicolor", "virginica", "setosa"],  # Variable categ√≥rica: especie
     }  # Cierra diccionario
 )  # Cierra DataFrame
 ```

 1) **B√°sico**

 - Extrae las columnas `sepal_length` y `species`.

 2) **Intermedio**

 - Filtra solo las filas donde `species == "setosa"` y `sepal_length > 5.0`.

 3) **Avanzado**

 - Calcula el promedio de `sepal_length` por `species`.
 - Devuelve el resultado ordenado de mayor a menor.

 #### Soluci√≥n

 ```python
 import pandas as pd  # Pandas para DataFrames, m√°scaras booleanas y groupby

 df = pd.DataFrame(  # Re-crea el DataFrame del enunciado (datos en memoria)
     {  # Columnas definidas con listas de igual longitud
         "sepal_length": [5.1, 4.9, 5.8, 6.0, 5.4],  # Longitud del s√©palo
         "sepal_width": [3.5, 3.0, 2.7, 2.2, 3.9],  # Ancho del s√©palo
         "species": ["setosa", "setosa", "versicolor", "virginica", "setosa"],  # Clase (string)
     }  # Cierra diccionario
 )  # Cierra DataFrame

 subset = df[["sepal_length", "species"]]  # Selecci√≥n de m√∫ltiples columnas: devuelve DataFrame con 2 columnas

 filtered = df[(df["species"] == "setosa") & (df["sepal_length"] > 5.0)]  # M√°scara booleana: combina condiciones con &

 means = (  # Agregaci√≥n por especie para obtener promedios
     df.groupby("species", as_index=False)  # Agrupa por 'species' y conserva 'species' como columna
     .agg(sepal_length_mean=("sepal_length", "mean"))  # Media por grupo: una fila por especie
     .sort_values("sepal_length_mean", ascending=False)  # Ordena para tener ranking de especies por media
 )  # Cierra pipeline

 assert list(subset.columns) == ["sepal_length", "species"]  # Confirma columnas seleccionadas
 assert (filtered["species"] == "setosa").all()  # Todas las filas filtradas deben ser setosa
 assert (filtered["sepal_length"] > 5.0).all()  # Todas las filas filtradas deben cumplir sepal_length > 5
 assert means.iloc[0]["sepal_length_mean"] >= means.iloc[-1]["sepal_length_mean"]  # Verifica el orden descendente
 ```

 ---

 ### Ejercicio 1.4: NumPy - Arrays y `dtype`

 #### Enunciado

 1) **B√°sico**

 - Crea:
   - un vector de 10 ceros
   - una matriz `3x3` de unos
   - una identidad `4x4`

 2) **Intermedio**

 - Crea un vector `v = np.array([1, 2, 3])`.
 - Convierte `v` a `float64`.
 - Verifica que `v / 2` produce floats.

 3) **Avanzado**

 - Reproduce el caso t√≠pico de bug por `dtype` usando divisi√≥n in-place:
   - crea `a = np.array([1, 2, 3])`
   - aplica `a /= 2`
   - explica el resultado con un `assert` esperado

 #### Soluci√≥n

 ```python
 import numpy as np  # NumPy: base del c√≥mputo num√©rico y estructuras tipo array

 z = np.zeros(10)  # Crea un vector 1D de longitud 10 con ceros (dtype float por defecto)
 ones = np.ones((3, 3))  # Crea una matriz 3x3 llena de unos (shape: (3, 3))
 I = np.eye(4)  # Crea una matriz identidad 4x4 (1 en diagonal, 0 fuera)

 v = np.array([1, 2, 3])  # Crea un array a partir de enteros (dtype t√≠pico: int)
 v_f = v.astype(np.float64)  # Convierte a float64: evita problemas de divisi√≥n/overflow y habilita decimales

 half = v_f / 2  # Divisi√≥n ‚Äúnormal‚Äù: al ser float, el resultado preserva decimales

 a = np.array([1, 2, 3])  # Array entero: aqu√≠ preparamos el caso de bug
 a /= 2  # Divisi√≥n IN-PLACE: si el dtype es int, NumPy trunca/convierte (pierde decimales) para mantener dtype

 assert z.shape == (10,)  # Confirma forma del vector
 assert ones.shape == (3, 3)  # Confirma forma de la matriz
 assert I.shape == (4, 4)  # Confirma forma de la identidad
 assert v_f.dtype == np.float64  # Confirma que la conversi√≥n a float64 ocurri√≥
 assert half.dtype == np.float64  # Confirma que la divisi√≥n produce floats
 assert np.array_equal(a, np.array([0, 1, 1]))  # 1/2->0, 2/2->1, 3/2->1 (truncado por dtype entero)
 ```

 ---

 ### Ejercicio 1.5: NumPy - Indexing y Slicing

#### Enunciado

Dada la matriz:

```python
import numpy as np
X = np.arange(20).reshape(4, 5)
```

1) **B√°sico**

- Extrae el elemento en fila 2, columna 3.

2) **Intermedio**

- Extrae:
  - toda la fila 1
  - toda la columna 4
  - la submatriz filas 1‚Äì2, columnas 2‚Äì4

3) **Avanzado**

- Usa indexing booleano para extraer elementos mayores que 10.
- Verifica que todos los elementos del resultado cumplan `> 10`.

#### Soluci√≥n

```python
import numpy as np  # Importa NumPy: base para trabajar con arrays y hacer slicing/indexing sin bucles

X = np.arange(20).reshape(4, 5)  # Crea 0..19 y lo reorganiza como matriz de 4 filas y 5 columnas

e = X[2, 3]  # Indexado 2D: elemento en fila=2 y columna=3 (√≠ndices empiezan en 0)

row1 = X[1, :]  # Slicing: fila 1 completa; ':' significa ‚Äútodas las columnas‚Äù
col4 = X[:, 4]  # Slicing: columna 4 completa; ':' significa ‚Äútodas las filas‚Äù
sub = X[1:3, 2:5]  # Submatriz: filas 1‚Äì2 y columnas 2‚Äì4 (el extremo final del slice se excluye)

gt10 = X[X > 10]  # Indexado booleano: filtra elementos > 10; el resultado es un vector 1D

assert e == 13  # Verifica el valor esperado en la posici√≥n (2,3)
assert row1.shape == (5,)  # Una fila completa de una matriz (4,5) tiene 5 elementos
assert col4.shape == (4,)  # Una columna completa de una matriz (4,5) tiene 4 elementos
assert sub.shape == (2, 3)  # La submatriz seleccionada tiene 2 filas y 3 columnas
assert (gt10 > 10).all()  # Confirma que todos los elementos filtrados cumplen la condici√≥n
```

---

### Ejercicio 1.6: NumPy - Broadcasting

#### Enunciado

1) **B√°sico**

- Sin loops, suma 100 a cada elemento de una matriz `3x3`.

2) **Intermedio**

- Dada una matriz `A` de shape `(4, 3)` y un vector `v` de shape `(3,)`, suma `v` a cada fila.

3) **Avanzado**

- Dado `X` de shape `(n, d)`, normaliza por columna: `X_norm = (X - mean) / (std + eps)`.
- **Importante:** el resultado debe conservar shape `(n, d)`.

#### Soluci√≥n

```python
import numpy as np  # NumPy: permite operaciones vectorizadas y broadcasting sin bucles

M = np.arange(9).reshape(3, 3)  # Crea una matriz 3x3 con valores 0..8
M2 = M + 100  # Broadcasting con escalar: suma 100 a cada elemento (la forma no cambia)

A = np.arange(12).reshape(4, 3)  # Matriz (4,3) con valores 0..11
v = np.array([10, 20, 30])  # Vector (3,) alineado con las columnas: se sumar√° a cada fila
B = A + v  # Broadcasting: v se ‚Äúexpande‚Äù a (4,3) virtualmente para sumar por filas

X = np.random.randn(100, 5)  # Datos sint√©ticos: 100 muestras (filas) y 5 features (columnas)
eps = 1e-8  # Epsilon: evita divisi√≥n por cero o n√∫meros extremadamente peque√±os
mean = X.mean(axis=0)  # Media por columna (por feature) => shape (5,)
std = X.std(axis=0)  # Desviaci√≥n est√°ndar por columna => shape (5,)
X_norm = (X - mean) / (std + eps)  # Normaliza por feature usando broadcasting; conserva shape (100,5)

assert M2.shape == (3, 3)  # Sumar un escalar no cambia la forma
assert B.shape == (4, 3)  # Sumar un vector alineado a columnas no cambia la forma
assert X_norm.shape == (100, 5)  # La normalizaci√≥n por columnas debe conservar (n,d)
```

---

### Ejercicio 1.7: NumPy - Producto matricial (`@`, `np.dot`, `np.matmul`)

#### Enunciado

1) **B√°sico**

- Calcula `A @ B` con:
  - `A` de shape `(2, 3)`
  - `B` de shape `(3, 2)`

2) **Intermedio**

- Demuestra la diferencia entre:
  - multiplicaci√≥n elemento a elemento `A * B`
  - producto matricial `A @ B`
  usando matrices cuadradas `2x2`.

3) **Avanzado**

- Implementa una predicci√≥n lineal `y_hat = X @ w + b` con:
  - `X` shape `(n, d)`
  - `w` shape `(d,)`
  - `b` escalar
- Verifica el shape de `y_hat`.

#### Soluci√≥n

```python
import numpy as np  # NumPy: operaciones vectorizadas y √°lgebra lineal (producto matricial con @)

A = np.array([[1, 2, 3], [4, 5, 6]])  # Matriz A de shape (2,3)
B = np.array([[1, 0], [0, 1], [1, 1]])  # Matriz B de shape (3,2)
C = A @ B  # Producto matricial: (2,3)@(3,2) -> (2,2)

U = np.array([[1, 2], [3, 4]])  # Matriz 2x2 para contrastar Hadamard vs matmul
V = np.array([[10, 20], [30, 40]])  # Matriz 2x2
hadamard = U * V  # Multiplicaci√≥n elemento a elemento (Hadamard)
matmul = U @ V  # Producto matricial (fila-columna)

X = np.random.randn(50, 3)  # Datos: 50 muestras (n) y 3 features (d)
w = np.array([0.1, -0.2, 0.3])  # Vector de pesos: shape (d,)
b = 0.5  # Bias escalar: se suma a cada predicci√≥n por broadcasting
y_hat = X @ w + b  # Predicci√≥n lineal: (n,d)@(d,) -> (n,)

assert C.shape == (2, 2)  # Verifica shape del producto matricial A@B
assert hadamard.shape == (2, 2)  # Hadamard mantiene shape
assert matmul.shape == (2, 2)  # Matmul entre 2x2 produce 2x2
assert y_hat.shape == (50,)  # Una predicci√≥n por muestra
```

---

### Ejercicio 1.8: NumPy - `reshape`, `flatten`, `transpose`

#### Enunciado

1) **B√°sico**

- Crea `a = np.arange(12)` y convi√©rtelo a una matriz `(3, 4)`.

2) **Intermedio**

- Transpone la matriz anterior y verifica el shape.

3) **Avanzado**

- Convierte la matriz `(3, 4)` a un tensor `(2, 2, 3)`.
- Vuelve a 1D y verifica que recuperas 12 elementos.

#### Soluci√≥n

```python
import numpy as np  # NumPy para manipulaci√≥n de shape y operaciones de reshape/transpose

a = np.arange(12)  # Vector 1D con 12 elementos (0..11)
M = a.reshape(3, 4)  # Reinterpreta como matriz (3,4); 3*4=12 debe coincidir
MT = M.T  # Transpuesta: intercambia ejes (3,4) -> (4,3)

T = a.reshape(2, 2, 3)  # Reinterpreta como tensor 3D (2,2,3); 2*2*3=12
flat = T.reshape(-1)  # Aplana a 1D; -1 indica ‚Äúinfiera el tama√±o‚Äù

assert M.shape == (3, 4)  # Verifica forma de la matriz
assert MT.shape == (4, 3)  # Verifica forma de la transpuesta
assert T.shape == (2, 2, 3)  # Verifica forma del tensor
assert flat.shape == (12,)  # Verifica que el aplanado recupera 12 elementos
assert np.array_equal(flat, a)  # Verifica que el contenido (y el orden) se conserva
```

---

### Ejercicio 1.9: NumPy - Agregaciones y `axis`

#### Enunciado

Sea:

```python
import numpy as np
X = np.array([[1, 2, 3], [4, 5, 6]])
```

1) **B√°sico**

- Calcula `X.sum()` y verifica el resultado.

2) **Intermedio**

- Calcula `X.sum(axis=0)` y `X.sum(axis=1)`.
- Predice los shapes antes de ejecutar.

3) **Avanzado**

- Calcula `mean` por columna con `keepdims=True`.
- Resta esa media a `X` y verifica el shape del resultado.

#### Soluci√≥n

```python
import numpy as np  # NumPy: agregaciones (sum/mean) y control de ejes con axis

X = np.array([[1, 2, 3], [4, 5, 6]])  # Matriz (2,3): 2 filas, 3 columnas

s_all = X.sum()  # Suma total de TODOS los elementos => escalar (sin axis)
s0 = X.sum(axis=0)  # axis=0: reduce filas -> suma por columna => shape (3,)
s1 = X.sum(axis=1)  # axis=1: reduce columnas -> suma por fila => shape (2,)

mu = X.mean(axis=0, keepdims=True)  # Media por columna; keepdims=True deja shape (1,3) para broadcasting expl√≠cito
X_centered = X - mu  # Centrado: resta la media de cada columna a cada fila (broadcasting)

assert s_all == 21  # 1+2+3+4+5+6 = 21
assert s0.shape == (3,)  # Una suma por columna
assert s1.shape == (2,)  # Una suma por fila
assert mu.shape == (1, 3)  # Con keepdims, la media conserva el eje reducido como dimensi√≥n 1
assert X_centered.shape == (2, 3)  # Restar mu no debe cambiar la forma
assert np.allclose(X_centered.mean(axis=0), 0.0)  # Tras centrar, la media por columna debe ser ~0
```

---

### Ejercicio 1.10: NumPy - `random` y datos sint√©ticos

#### Enunciado

1) **B√°sico**

- Fija una semilla y genera 5 n√∫meros con `np.random.randn`.

2) **Intermedio**

- Genera un dataset sint√©tico para regresi√≥n:
  - `X` de shape `(200, 2)`
  - `w_true` de shape `(2,)`
  - `y = X @ w_true + noise`

3) **Avanzado**

- Estandariza `X` por columna (`mean=0`, `std=1` aproximadamente).
- Verifica con `np.allclose` (tolerancia razonable).

#### Soluci√≥n

```python
import numpy as np  # NumPy para aleatoriedad reproducible, datos sint√©ticos y estandarizaci√≥n

np.random.seed(42)  # Semilla fija: garantiza reproducibilidad (mismos n√∫meros aleatorios)
z = np.random.randn(5)  # Genera 5 valores ~ N(0,1) -> vector (5,)

n = 200  # N√∫mero de muestras
X = np.random.randn(n, 2)  # Features: matriz (200,2)
w_true = np.array([1.5, -0.7])  # Pesos verdaderos (ground truth) de la relaci√≥n lineal
noise = 0.1 * np.random.randn(n)  # Ruido gaussiano peque√±o para simular variaci√≥n
y = X @ w_true + noise  # Targets: combinaci√≥n lineal (X@w) + ruido -> vector (200,)

eps = 1e-8  # Epsilon: evita divisi√≥n por cero (estabilidad num√©rica)
X_mean = X.mean(axis=0)  # Media por columna (por feature) -> (2,)
X_std = X.std(axis=0)  # Desviaci√≥n est√°ndar por columna -> (2,)
Xz = (X - X_mean) / (X_std + eps)  # Estandariza por columnas usando broadcasting -> (200,2)

assert z.shape == (5,)  # Confirma 5 valores
assert X.shape == (200, 2)  # Confirma shape del dataset
assert w_true.shape == (2,)  # Confirma shape de pesos
assert y.shape == (200,)  # Confirma un target por muestra
assert np.allclose(Xz.mean(axis=0), np.zeros(2), atol=1e-7)  # Media ~0 por feature
assert np.allclose(Xz.std(axis=0), np.ones(2), atol=1e-6)  # Std ~1 por feature
```

---

### (Bonus) Ejercicio 1.11: Vectorizaci√≥n + funciones de activaci√≥n (dominio)

#### Enunciado

1) **Vectorizaci√≥n**

- Implementa distancia euclidiana sin loops.

2) **Activaciones**

- Implementa:
  - `sigmoid`
  - `relu`
  - `softmax` (estable num√©ricamente)

#### Soluci√≥n

```python
import numpy as np  # NumPy: operaciones vectorizadas y funciones matem√°ticas (exp, sqrt, sum)

def euclidean_distance_vectorized(a: np.ndarray, b: np.ndarray) -> float:
    diff = a - b  # Resta vectorizada: diferencia componente a componente
    return float(np.sqrt(np.sum(diff * diff)))  # Distancia L2: sqrt(sum((a-b)^2)); float() devuelve un escalar nativo

def sigmoid(x: np.ndarray) -> np.ndarray:
    return 1 / (1 + np.exp(-x))  # Sigmoid: 1/(1+exp(-x)), mapea R -> (0,1) elemento a elemento

def relu(x: np.ndarray) -> np.ndarray:
    return np.maximum(0, x)  # ReLU: max(0,x), anula valores negativos y deja positivos

def softmax(x: np.ndarray) -> np.ndarray:
    x = np.asarray(x)  # Asegura np.ndarray (por si llega lista) para operaciones vectorizadas
    x_shift = x - np.max(x)  # Estabilidad num√©rica: resta el m√°ximo para evitar overflow en exp
    exps = np.exp(x_shift)  # Exponencial elemento a elemento (estable tras el shift)
    return exps / np.sum(exps)  # Softmax: normaliza a probabilidades (la suma debe ser 1)

a = np.array([1.0, 2.0, 3.0])  # Vector de prueba
b = np.array([1.0, 1.0, 1.0])  # Segundo vector de prueba
d = euclidean_distance_vectorized(a, b)  # Distancia euclidiana sin loops

assert np.isclose(d, np.sqrt(0**2 + 1**2 + 2**2))  # Chequeo: sqrt((0)^2+(1)^2+(2)^2)
assert np.isclose(sigmoid(np.array([0.0]))[0], 0.5)  # Propiedad clave: sigmoid(0)=0.5
assert relu(np.array([-5.0, 5.0])).tolist() == [0.0, 5.0]  # ReLU anula negativos y deja positivos
assert np.isclose(softmax(np.array([1.0, 2.0, 3.0])).sum(), 1.0)  # Softmax debe sumar 1
```

---

## üì¶ Entregable del M√≥dulo

### Script: `benchmark_vectorization.py`

```python
"""
Benchmark: Operaciones vectoriales Lista vs NumPy

Este script compara el rendimiento de operaciones comunes
usando listas de Python puras vs arrays de NumPy.

Operaciones comparadas:
1. Producto punto
2. Normalizaci√≥n
3. Distancia euclidiana
4. Suma de matrices

Autor: [Tu nombre]
Fecha: [Fecha]
"""

import numpy as np  # NumPy: operaciones vectorizadas (arrays), √°lgebra lineal y c√≥mputo eficiente
import time  # time.time(): medici√≥n simple de tiempo (en segundos) para benchmarks
from typing import List, Tuple, Callable  # Tipos: anotar listas, tuplas de argumentos y funciones ‚Äúcallables‚Äù
from dataclasses import dataclass  # dataclass: genera autom√°ticamente __init__ y facilita structs de resultados


@dataclass  # Marca la clase como dataclass: simplifica almacenamiento de resultados
class BenchmarkResult:  # Estructura para guardar un resultado de benchmark de forma consistente
    """Resultado de un benchmark."""
    operation: str  # Nombre de la operaci√≥n evaluada (p.ej. "Producto Punto")
    time_list: float  # Tiempo promedio por iteraci√≥n usando listas (segundos)
    time_numpy: float  # Tiempo promedio por iteraci√≥n usando NumPy (segundos)
    speedup: float  # Aceleraci√≥n: time_list / time_numpy


def benchmark(
    func_list: Callable,  # Implementaci√≥n ‚Äúcon listas‚Äù (m√°s cercana a Python puro)
    func_numpy: Callable,  # Implementaci√≥n ‚Äúcon NumPy‚Äù (vectorizada/optimizada)
    args_list: Tuple,  # Argumentos posicionales para func_list (se expanden con *)
    args_numpy: Tuple,  # Argumentos posicionales para func_numpy
    operation_name: str,  # Nombre legible para imprimir/reportar
    iterations: int = 100  # Cu√°ntas repeticiones para promediar (reduce ruido)
) -> BenchmarkResult:
    """Ejecuta benchmark comparativo."""

    # Benchmark lista
    start = time.time()  # Tiempo inicial (lista)
    for _ in range(iterations):  # Repite para promediar y obtener una medida m√°s estable
        func_list(*args_list)  # Llama la funci√≥n de listas expandiendo la tupla de argumentos
    time_list = (time.time() - start) / iterations  # Tiempo promedio por iteraci√≥n (lista)

    # Benchmark NumPy
    start = time.time()  # Tiempo inicial (NumPy)
    for _ in range(iterations):  # Misma cantidad de iteraciones para comparar ‚Äújusto‚Äù
        func_numpy(*args_numpy)  # Llama la funci√≥n NumPy expandiendo sus argumentos
    time_numpy = (time.time() - start) / iterations  # Tiempo promedio por iteraci√≥n (NumPy)

    return BenchmarkResult(  # Empaqueta resultados en un objeto con campos con nombre
        operation=operation_name,  # Nombre de la operaci√≥n
        time_list=time_list,  # Tiempo promedio con listas
        time_numpy=time_numpy,  # Tiempo promedio con NumPy
        speedup=time_list / time_numpy  # Speedup: cu√°ntas veces NumPy es m√°s r√°pido que listas
    )


# === IMPLEMENTAR TUS FUNCIONES AQU√ç ===

def dot_product_list(a: List[float], b: List[float]) -> float:
    """Producto punto con listas."""
    # TODO: Implementar el producto punto sum(a_i * b_i) recorriendo ambas listas
    pass


def dot_product_numpy(a: np.ndarray, b: np.ndarray) -> float:
    """Producto punto con NumPy."""
    # TODO: Implementar usando np.dot(a, b) (o a @ b si son 1D)
    pass


def normalize_list(data: List[float]) -> List[float]:
    """Normalizar con listas."""
    # TODO: Implementar (x - mean) / std calculando mean y std manualmente (Python puro)
    pass


def normalize_numpy(data: np.ndarray) -> np.ndarray:
    """Normalizar con NumPy."""
    # TODO: Implementar (data - data.mean()) / data.std() de forma vectorizada
    pass


def euclidean_distance_list(a: List[float], b: List[float]) -> float:
    """Distancia euclidiana con listas."""
    # TODO: Implementar sqrt(sum((a_i - b_i)^2)) recorriendo ambas listas
    pass


def euclidean_distance_numpy(a: np.ndarray, b: np.ndarray) -> float:
    """Distancia euclidiana con NumPy."""
    # TODO: Implementar usando vectorizaci√≥n: np.sqrt(np.sum((a-b)**2)) o np.linalg.norm(a-b)
    pass


def matrix_sum_list(A: List[List[float]], B: List[List[float]]) -> List[List[float]]:
    """Suma de matrices con listas."""
    # TODO: Implementar suma elemento a elemento usando loops (filas/columnas)
    pass


def matrix_sum_numpy(A: np.ndarray, B: np.ndarray) -> np.ndarray:
    """Suma de matrices con NumPy."""
    # TODO: Implementar A + B (broadcasting/operaci√≥n vectorizada)
    pass


def main():
    """Ejecutar todos los benchmarks."""
    size = 10000  # Tama√±o de los vectores para las pruebas (no tan grande para que corra r√°pido)

    # Crear datos de prueba
    list_a = [float(i) for i in range(size)]  # Vector (lista) de floats: 0..size-1
    list_b = [float(i) for i in range(size)]  # Segundo vector (lista) del mismo tama√±o
    array_a = np.array(list_a)  # Versi√≥n NumPy del vector (ndarray)
    array_b = np.array(list_b)  # Versi√≥n NumPy del segundo vector

    matrix_size = 100  # Tama√±o de matrices cuadradas (100x100) para prueba de suma de matrices
    list_matrix_a = [[float(i*j) for j in range(matrix_size)]  # Construye matriz A con listas (filas)
                     for i in range(matrix_size)]  # Cada fila i contiene productos i*j
    list_matrix_b = [[float(i+j) for j in range(matrix_size)]  # Construye matriz B con listas
                     for i in range(matrix_size)]  # Cada fila i contiene sumas i+j
    array_matrix_a = np.array(list_matrix_a)  # Convierte matriz A a ndarray (vectorizado)
    array_matrix_b = np.array(list_matrix_b)  # Convierte matriz B a ndarray

    # Ejecutar benchmarks
    results = []  # Acumulador de BenchmarkResult (uno por operaci√≥n)

    results.append(benchmark(  # Ejecuta y guarda benchmark del producto punto
        dot_product_list, dot_product_numpy,
        (list_a, list_b), (array_a, array_b),
        "Producto Punto"
    ))

    results.append(benchmark(  # Ejecuta y guarda benchmark de normalizaci√≥n
        normalize_list, normalize_numpy,
        (list_a,), (array_a,),
        "Normalizaci√≥n"
    ))

    results.append(benchmark(  # Ejecuta y guarda benchmark de distancia euclidiana
        euclidean_distance_list, euclidean_distance_numpy,
        (list_a, list_b), (array_a, array_b),
        "Distancia Euclidiana"
    ))

    results.append(benchmark(  # Ejecuta y guarda benchmark de suma de matrices
        matrix_sum_list, matrix_sum_numpy,
        (list_matrix_a, list_matrix_b), (array_matrix_a, array_matrix_b),
        "Suma de Matrices"
    ))

    # Mostrar resultados
    print("\n" + "="*60)  # Separador visual
    print("BENCHMARK: Lista vs NumPy")  # T√≠tulo del reporte
    print("="*60)  # Separador visual
    print(f"{'Operaci√≥n':<25} {'Lista (ms)':<12} {'NumPy (ms)':<12} {'Speedup':<10}")  # Encabezado de tabla
    print("-"*60)  # Separador para la tabla

    for r in results:  # Itera sobre resultados de cada operaci√≥n
        print(f"{r.operation:<25} {r.time_list*1000:<12.4f} {r.time_numpy*1000:<12.4f} {r.speedup:<10.1f}x")  # Convierte s->ms

    print("="*60)  # Cierre de la tabla
    print(f"\nSpeedup promedio: {sum(r.speedup for r in results)/len(results):.1f}x")  # Promedio de speedups


if __name__ == "__main__":
    main()  # Punto de entrada: ejecuta benchmarks al correr el script
```

---

## üêõ Debugging NumPy: Errores que te Har√°n Perder el Tiempo (v3.2)

> ‚ö†Ô∏è **CR√çTICO:** Estos 5 errores son los m√°s frecuentes en las Fases 1 y 2. Resolverlos ahora previene horas de frustraci√≥n.

### Error 1: Shape Mismatch - `(5,)` vs `(5,1)`

```python
import numpy as np  # Importa NumPy para crear arrays y analizar shapes (dimensiones)

# PROBLEMA: Vector 1D vs Vector Columna
v1 = np.array([1, 2, 3, 4, 5])      # Shape: (5,) - Vector 1D (una sola dimensi√≥n)
v2 = np.array([[1], [2], [3], [4], [5]])  # Shape: (5, 1) - Vector columna (matriz de 5 filas y 1 columna)

print(f"v1.shape: {v1.shape}")  # Imprime el shape real de v1 para confirmar que es (5,)
print(f"v2.shape: {v2.shape}")  # Imprime el shape real de v2 para confirmar que es (5, 1)

# ESTO FALLA en Regresi√≥n Lineal:
# Si X tiene shape (100, 5) y theta tiene shape (5,), el resultado es (100,)
# Si theta tiene shape (5, 1), el resultado es (100, 1)

# SOLUCI√ìN: Usar reshape o keepdims
v1_columna = v1.reshape(-1, 1)  # Convierte (5,) ‚Üí (5,1); -1 infiere autom√°ticamente el n√∫mero de filas
v1_columna_alt = v1[:, np.newaxis]  # Alternativa: inserta un eje nuevo para obtener un vector columna

# REGLA: Para ML, los vectores de features deben ser (n, 1), no (n,)
```

### Error 2: Broadcasting Silencioso Incorrecto

```python
import numpy as np  # Importa NumPy para generar datos y demostrar c√≥mo axis afecta agregaciones/broadcasting

# PROBLEMA: Broadcasting no falla, pero da resultados incorrectos
X = np.random.randn(100, 5)  # 100 samples, 5 features
mean_wrong = np.mean(X)      # ¬°INCORRECTO! Media global: colapsa todos los ejes y devuelve un escalar
mean_correct = np.mean(X, axis=0)  # Correcto: media por feature (columna) => shape (5,)

print(f"mean_wrong shape: {np.array(mean_wrong).shape}")  # () - escalar (sin dimensiones)
print(f"mean_correct shape: {mean_correct.shape}")  # (5,) - un valor por columna

# REGLA: Siempre especifica axis= en agregaciones
# axis=0: opera sobre filas (resultado por columna)
# axis=1: opera sobre columnas (resultado por fila)
```

### Error 3: Modificaci√≥n In-Place Inesperada

```python
import numpy as np  # Importa NumPy para mostrar la diferencia entre vistas (views) y copias (.copy())

# PROBLEMA: Los slices de NumPy son VISTAS, no copias
original = np.array([1, 2, 3, 4, 5])  # Array original
slice_view = original[1:4]  # Slice: por defecto es una vista al mismo buffer de memoria
slice_view[0] = 999  # Modifica la vista; por ser vista, tambi√©n modifica el array original

print(original)  # [1, 999, 3, 4, 5] - ¬°ORIGINAL MODIFICADO! porque slice_view comparte memoria

# SOLUCI√ìN: Usar .copy() expl√≠citamente
original = np.array([1, 2, 3, 4, 5])  # Reinicia el array original
slice_copy = original[1:4].copy()  # copy(): crea un nuevo buffer independiente
slice_copy[0] = 999  # Modifica la copia; NO afecta el original

print(original)  # [1, 2, 3, 4, 5] - Original intacto porque slice_copy no comparte memoria
```

### Error 4: Divisi√≥n por Cero en Normalizaci√≥n

```python
import numpy as np  # Importa NumPy para ejemplificar el caso std=0 y c√≥mo estabilizar divisiones con epsilon

# PROBLEMA: Divisi√≥n por cero cuando std = 0
data = np.array([5, 5, 5, 5, 5])
std = np.std(data)  # 0.0 porque todos los valores son id√©nticos (varianza cero)
normalized = (data - np.mean(data)) / std  # RuntimeWarning: divide by zero (divisi√≥n por 0)

# SOLUCI√ìN: A√±adir epsilon
epsilon = 1e-8
normalized_safe = (data - np.mean(data)) / (std + epsilon)  # Evita divisi√≥n por cero y estabiliza el c√°lculo

# REGLA: Siempre usar epsilon en divisiones (especialmente en softmax, normalizaciones)
```

### Error 5: Tipos de Datos Incorrectos

```python
import numpy as np  # Importa NumPy para demostrar problemas de dtype (int vs float) en operaciones in-place

# PROBLEMA: Operaciones con int cuando necesitas float
a = np.array([1, 2, 3])  # dtype: int64 (enteros)
b = a / 2  # dtype: float64 (OK): en Python 3 la divisi√≥n / produce float

# PERO en operaciones in-place:
a = np.array([1, 2, 3])
a /= 2  # In-place: intenta guardar floats en int64 => trunca (pierde decimales)
print(a)  # [0, 1, 1] - ¬°TRUNCADO! por conversi√≥n impl√≠cita a entero

# SOLUCI√ìN: Especificar dtype al crear
a = np.array([1, 2, 3], dtype=np.float64)
a /= 2  # Ahora s√≠: al ser float64, conserva decimales en la operaci√≥n in-place
print(a)  # [0.5, 1.0, 1.5] - Correcto (sin truncamiento)

# REGLA: Para ML, siempre usar dtype=np.float64 o np.float32
```

---

## üõ†Ô∏è Est√°ndares de C√≥digo Profesional (v3.2)

> üíé **Filosof√≠a v3.2:** El c√≥digo no se considera terminado hasta que pase `mypy`, `ruff` y `pytest`.

### Configuraci√≥n del Entorno Profesional

```bash
# Crear entorno virtual
python -m venv .venv  # Crea un entorno virtual local (aislado) en la carpeta .venv
source .venv/bin/activate  # Activa el entorno virtual en Linux/Mac (usa el Python y pip de .venv)
# .venv\Scripts\activate   # Alternativa en Windows para activar el entorno virtual

# Instalar herramientas de calidad
pip install numpy pandas matplotlib  # Instala dependencias principales de ciencia de datos
pip install mypy ruff pytest  # Instala herramientas de calidad: tipos, lint/format y tests

# Archivo pyproject.toml (crear en la ra√≠z del proyecto)
```

```toml
# pyproject.toml
[tool.mypy]
python_version = "3.11"  # Versi√≥n de Python objetivo para el an√°lisis de tipos
warn_return_any = true  # Advierte cuando una funci√≥n retorna Any (p√©rdida de precisi√≥n de tipos)
warn_unused_ignores = true  # Advierte si hay "# type: ignore" que no son necesarios
disallow_untyped_defs = true  # Exige anotaciones de tipo en funciones (evita defs sin typing)

[tool.ruff]
line-length = 100  # Longitud m√°xima de l√≠nea para lint/format
select = ["E", "F", "W", "I", "UP"]  # Conjunto de reglas: estilo, errores, imports, modernizaci√≥n

[tool.pytest.ini_options]
testpaths = ["tests"]  # Carpeta donde pytest buscar√° tests por defecto
python_files = "test_*.py"  # Patr√≥n de archivos que pytest considera como tests
```

### Ejemplo: C√≥digo con Type Hints

```python
# src/linear_algebra.py
"""Operaciones de √°lgebra lineal desde cero."""
import numpy as np  # NumPy para operaciones vectorizadas (sum, sqrt) sobre arrays
from numpy.typing import NDArray  # Tipado: NDArray permite anotar ndarrays con dtype para mypy


def dot_product(a: NDArray[np.float64], b: NDArray[np.float64]) -> float:
    """
    Calcula el producto punto de dos vectores.

    Args:
        a: Primer vector (n,)
        b: Segundo vector (n,)

    Returns:
        El producto punto (escalar)

    Raises:
        ValueError: Si los vectores tienen shapes diferentes
    """
    if a.shape != b.shape:  # Validaci√≥n: el producto punto requiere vectores del mismo tama√±o
        raise ValueError(f"Shapes incompatibles: {a.shape} vs {b.shape}")  # Falla expl√≠citamente con mensaje √∫til
    return float(np.sum(a * b))  # Multiplica elemento a elemento y suma; float() convierte escalar NumPy a float nativo


def norm_l2(v: NDArray[np.float64]) -> float:
    """Calcula la norma L2 (euclidiana) de un vector."""
    return float(np.sqrt(np.sum(v ** 2)))  # sqrt(sum(v^2)): definici√≥n de norma L2
```

### Ejemplo: Tests con pytest

```python
# tests/test_linear_algebra.py
"""Tests unitarios para linear_algebra.py"""
import numpy as np  # NumPy para construir vectores de prueba
import pytest  # pytest para asserts avanzados y verificaci√≥n de excepciones
from src.linear_algebra import dot_product, norm_l2  # Funciones bajo prueba


class TestDotProduct:
    """Tests para la funci√≥n dot_product."""

    def test_dot_product_basic(self) -> None:
        """Test b√°sico: [1,2,3] ¬∑ [4,5,6] = 32"""
        a = np.array([1.0, 2.0, 3.0])  # Primer vector
        b = np.array([4.0, 5.0, 6.0])  # Segundo vector
        assert dot_product(a, b) == 32.0  # Verifica 1*4 + 2*5 + 3*6

    def test_dot_product_orthogonal(self) -> None:
        """Vectores ortogonales tienen producto punto = 0"""
        a = np.array([1.0, 0.0])  # Vector unitario en x
        b = np.array([0.0, 1.0])  # Vector unitario en y
        assert dot_product(a, b) == 0.0  # Ortogonales => producto punto 0

    def test_dot_product_shape_mismatch(self) -> None:
        """Debe lanzar ValueError si shapes no coinciden"""
        a = np.array([1.0, 2.0])  # Shape (2,)
        b = np.array([1.0, 2.0, 3.0])  # Shape (3,)
        with pytest.raises(ValueError):  # Espera una excepci√≥n por shapes incompatibles
            dot_product(a, b)  # Debe fallar (validaci√≥n de shapes)


class TestNormL2:
    """Tests para la funci√≥n norm_l2."""

    def test_norm_unit_vector(self) -> None:
        """Vector unitario tiene norma 1"""
        v = np.array([1.0, 0.0, 0.0])  # Vector unitario en 3D
        assert norm_l2(v) == 1.0  # Norma de un vector unitario es 1

    def test_norm_345(self) -> None:
        """Tri√°ngulo 3-4-5: norma de [3,4] = 5"""
        v = np.array([3.0, 4.0])  # Vector (3,4)
        assert norm_l2(v) == 5.0  # sqrt(3^2 + 4^2) = 5
```

### Comandos de Verificaci√≥n

```bash
# Ejecutar en la ra√≠z del proyecto:

# 1. Verificar tipos (mypy)
mypy src/  # Revisa anotaciones de tipo y detecta inconsistencias en src/

# 2. Verificar estilo (ruff)
ruff check src/  # Lint: encuentra errores comunes (imports, variables no usadas, estilo)
ruff format src/  # Auto-formatea el c√≥digo seg√∫n reglas de estilo

# 3. Ejecutar tests (pytest)
pytest tests/ -v  # Ejecuta los tests en modo verboso

# 4. Todo junto (antes de cada commit)
mypy src/ && ruff check src/ && pytest tests/ -v  # Pipeline m√≠nimo de calidad antes de commitear
```

---

## üéØ El Reto del Tablero Blanco (Metodolog√≠a Feynman)

> üìù **Instrucci√≥n:** Despu√©s de implementar c√≥digo, debes poder explicar el algoritmo en **m√°ximo 5 l√≠neas** sin usar jerga t√©cnica. Si no puedes, vuelve a la teor√≠a.

### Ejemplo: Broadcasting

**‚ùå Explicaci√≥n t√©cnica (mala):**
"Broadcasting es la capacidad de NumPy de realizar operaciones elemento a elemento entre arrays de diferentes shapes mediante la expansi√≥n impl√≠cita de dimensiones seg√∫n reglas de compatibilidad."

**‚úÖ Explicaci√≥n Feynman (buena):**
"Cuando sumas un n√∫mero a una lista, NumPy autom√°ticamente suma ese n√∫mero a CADA elemento. Es como si el n√∫mero se 'copiara' para que tenga el mismo tama√±o que la lista. Lo mismo pasa entre listas de diferentes tama√±os, siempre que una de ellas tenga tama√±o 1 en alguna dimensi√≥n."

### Tu Reto para el M√≥dulo 01:

Explica en 5 l√≠neas o menos:
1. ¬øPor qu√© NumPy es m√°s r√°pido que listas de Python?
2. ¬øQu√© significa `axis=0` vs `axis=1`?
3. ¬øPor qu√© `.copy()` es importante?

---

## ‚úÖ Checklist de Finalizaci√≥n (v3.2)

### Conocimiento
- [ ] Puedo crear arrays 1D, 2D y 3D con NumPy
- [ ] Entiendo indexing y slicing de arrays
- [ ] Puedo explicar broadcasting y usarlo
- [ ] S√© calcular agregaciones por eje (axis)
- [ ] Puedo reescribir loops como operaciones vectorizadas
- [ ] Conozco las diferencias entre `@`, `np.dot`, `np.matmul`
- [ ] Conozco los 5 errores comunes de NumPy y sus soluciones

### Entregables de C√≥digo
- [ ] `benchmark_vectorization.py` implementado
- [ ] El speedup de NumPy vs lista es >50x en mis pruebas
- [ ] `mypy src/` pasa sin errores
- [ ] `ruff check src/` pasa sin errores
- [ ] Al menos 3 tests con `pytest` pasando

### Metodolog√≠a Feynman
- [ ] Puedo explicar broadcasting en 5 l√≠neas sin jerga
- [ ] Puedo explicar axis=0 vs axis=1 en 5 l√≠neas sin jerga
- [ ] Puedo explicar por qu√© .copy() es importante

---

## üîó Navegaci√≥n

| Anterior | √çndice | Siguiente |
|----------|--------|-----------|
| - | [00_INDICE](00_INDICE.md) | [02_ALGEBRA_LINEAL_ML](02_ALGEBRA_LINEAL_ML.md) |
