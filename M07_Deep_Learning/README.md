# M√≥dulo 07: Deep Learning

> **Semanas:** 16-20 | **Fase:** ML Core ‚≠ê | **Curso Alineado:** CSCA 5642

---

## ‚ö†Ô∏è Stack Tecnol√≥gico: Keras/TensorFlow (Principal)

> **IMPORTANTE:** El curso CSCA 5642 utiliza **Keras/TensorFlow** como framework principal.
> Este m√≥dulo prioriza Keras para m√°xima alineaci√≥n con el pathway.
> PyTorch se ofrece como track avanzado opcional.

---

## üìÅ Estructura

```
M07_Deep_Learning/
‚îú‚îÄ‚îÄ Teoria/
‚îÇ   ‚îú‚îÄ‚îÄ 01_perceptron_mlp.md
‚îÇ   ‚îú‚îÄ‚îÄ 02_backpropagation.md
‚îÇ   ‚îú‚îÄ‚îÄ 03_cnns.md
‚îÇ   ‚îú‚îÄ‚îÄ 04_rnns_lstm.md
‚îÇ   ‚îî‚îÄ‚îÄ 05_regularizacion_dl.md
‚îú‚îÄ‚îÄ Notebooks_Keras/                        # RUTA PRINCIPAL (tf.keras)
‚îÇ   ‚îú‚îÄ‚îÄ 01_perceptron_scratch.ipynb        # Implementaci√≥n matem√°tica
‚îÇ   ‚îú‚îÄ‚îÄ 02_mlp_keras_sequential.ipynb      # API Sequential
‚îÇ   ‚îú‚îÄ‚îÄ 03_mlp_keras_functional.ipynb      # API Funcional (CR√çTICO)
‚îÇ   ‚îú‚îÄ‚îÄ 04_backprop_manual.ipynb           # Gradientes a mano
‚îÇ   ‚îú‚îÄ‚îÄ 05_cnn_keras.ipynb                 # Conv2D, MaxPooling2D
‚îÇ   ‚îú‚îÄ‚îÄ 06_rnn_lstm_keras.ipynb            # LSTM, GRU
‚îÇ   ‚îú‚îÄ‚îÄ 07_regularizacion_callbacks.ipynb  # Dropout, EarlyStopping, ModelCheckpoint
‚îÇ   ‚îî‚îÄ‚îÄ 08_transfer_learning_keras.ipynb   # Fine-tuning modelos preentrenados
‚îú‚îÄ‚îÄ Advanced_Track_PyTorch/                 # OPCIONAL
‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ 01_tensors_autograd.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_mlp_pytorch.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_cnn_pytorch.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 04_rnn_pytorch.ipynb
‚îú‚îÄ‚îÄ Laboratorios_Interactivos/
‚îÇ   ‚îú‚îÄ‚îÄ keras_training_playground_app.py
‚îÇ   ‚îú‚îÄ‚îÄ cnn_filter_visualization_app.py
‚îÇ   ‚îî‚îÄ‚îÄ lstm_sequence_app.py
‚îî‚îÄ‚îÄ assets/
```

---

## üéØ Objetivos de Aprendizaje

### Semana 16: Fundamentos de Redes Neuronales

| Objetivo | Criterio de √âxito |
|----------|-------------------|
| Implementar perceptr√≥n desde cero | Forward pass + update rule funcionando |
| Implementar MLP desde cero | Backpropagation manual con derivadas |
| Overfit en problema XOR | Demostrar no-linealidad aprendida |

### Semana 17: Keras - APIs Sequential y Funcional

| Objetivo | Criterio de √âxito |
|----------|-------------------|
| Dominar `tf.keras.Sequential` | Construir MLP para clasificaci√≥n |
| **Dominar API Funcional de Keras** | `inputs = Input(...)`, `x = Dense(...)(x)` |
| Compilar y entrenar modelos | `model.compile()`, `model.fit()`, `model.evaluate()` |
| Visualizar entrenamiento | `history` plots, TensorBoard b√°sico |

### Semana 18: CNNs (Redes Convolucionales)

| Objetivo | Criterio de √âxito |
|----------|-------------------|
| Entender convoluci√≥n y pooling | Implementar Conv2D desde cero (conceptual) |
| Construir CNN en Keras | `Conv2D`, `MaxPooling2D`, `Flatten` |
| Clasificar MNIST/CIFAR-10 | >98% accuracy en MNIST, >70% en CIFAR-10 |
| Visualizar filtros aprendidos | Feature maps de capas convolucionales |

### Semana 19: RNNs y LSTMs

| Objetivo | Criterio de √âxito |
|----------|-------------------|
| Entender secuencias y estados | Vanishing gradient problem |
| Implementar LSTM/GRU en Keras | `LSTM`, `GRU`, `Bidirectional` |
| Procesamiento de texto b√°sico | Clasificaci√≥n de sentimientos |
| Entender embeddings | `Embedding` layer en Keras |

### Semana 20: Regularizaci√≥n y Buenas Pr√°cticas

| Objetivo | Criterio de √âxito |
|----------|-------------------|
| Implementar Dropout | Prevenir overfitting |
| Usar Callbacks de Keras | `EarlyStopping`, `ModelCheckpoint`, `ReduceLROnPlateau` |
| Batch Normalization | Entender y aplicar `BatchNormalization` |
| Transfer Learning | Fine-tuning de modelo preentrenado (VGG16/ResNet) |

---

## üîë API Funcional de Keras (CR√çTICO para CSCA 5642)

```python
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.models import Model

# Definir arquitectura con API Funcional
inputs = Input(shape=(784,))
x = Dense(256, activation='relu')(inputs)
x = Dropout(0.3)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.3)(x)
outputs = Dense(10, activation='softmax')(x)

# Crear modelo
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Entrenar con callbacks
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

callbacks = [
    EarlyStopping(patience=5, restore_best_weights=True),
    ModelCheckpoint('best_model.h5', save_best_only=True)
]

history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, callbacks=callbacks)
```

---

## ‚ö° Inicio R√°pido

```bash
# Semana 16: Fundamentos
jupyter notebook Notebooks_Keras/01_perceptron_scratch.ipynb
jupyter notebook Notebooks_Keras/04_backprop_manual.ipynb

# Semana 17: Keras APIs (CR√çTICO)
jupyter notebook Notebooks_Keras/02_mlp_keras_sequential.ipynb
jupyter notebook Notebooks_Keras/03_mlp_keras_functional.ipynb  # PRIORITARIO

# Semana 18: CNNs
jupyter notebook Notebooks_Keras/05_cnn_keras.ipynb
streamlit run Laboratorios_Interactivos/cnn_filter_visualization_app.py

# Semana 19: RNNs
jupyter notebook Notebooks_Keras/06_rnn_lstm_keras.ipynb

# Semana 20: Regularizaci√≥n y Transfer Learning
jupyter notebook Notebooks_Keras/07_regularizacion_callbacks.ipynb
jupyter notebook Notebooks_Keras/08_transfer_learning_keras.ipynb

# OPCIONAL: Track PyTorch Avanzado
jupyter notebook Advanced_Track_PyTorch/01_tensors_autograd.ipynb
```

---

## ‚úÖ Entregables del M√≥dulo

- [ ] `neural_network.py` con backprop manual (from scratch)
- [ ] MLP en Keras usando API Funcional
- [ ] CNN para MNIST con >98% accuracy (Keras)
- [ ] LSTM para clasificaci√≥n de texto (Keras)
- [ ] Modelo con EarlyStopping y ModelCheckpoint
- [ ] Experimento de Transfer Learning documentado

---

## üìö Recursos

### Documentaci√≥n Oficial
- **Keras Documentation**: https://keras.io/
- **TensorFlow Tutorials**: https://www.tensorflow.org/tutorials

### Lecturas Recomendadas
1. **Deep Learning with Python** (Fran√ßois Chollet) - Autor de Keras
2. **CS231n Stanford** - CNNs for Visual Recognition
3. **CS224n Stanford** - NLP with Deep Learning

---

## üîó Navegaci√≥n

| Anterior | √çndice | Siguiente |
|----------|--------|-----------|
| [M06 No Supervisado](../M06_Aprendizaje_No_Supervisado/) | [README](../README.md) | [M08 Proyecto Final ‚Üí](../M08_Proyecto_Integrador/) |
