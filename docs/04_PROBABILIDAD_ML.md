# M√≥dulo 04: Probabilidad Esencial para Machine Learning

> **Semana 8 | Prerequisito para entender Loss Functions y GMM**
> **Filosof√≠a: Solo la probabilidad que necesitas para la L√≠nea 1**

---

## üéØ Objetivo del M√≥dulo

Dominar los **conceptos m√≠nimos de probabilidad** necesarios para:

1. Entender **Logistic Regression** como modelo probabil√≠stico
2. Comprender **Cross-Entropy Loss** y por qu√© funciona
3. Prepararte para **Gaussian Mixture Models (GMM)** en Unsupervised
4. Entender **Softmax** como distribuci√≥n de probabilidad

> ‚ö†Ô∏è **Nota:** Este NO es el curso completo de Probabilidad (L√≠nea 2). Es solo lo esencial para ML.

---

<a id="m04-0"></a>

## üß≠ C√≥mo usar este m√≥dulo (modo 0‚Üí100)

**Prop√≥sito:** conectar probabilidad con lo que realmente usar√°s en el Pathway:

- p√©rdidas (cross-entropy) como *negative log-likelihood*
- clasificaci√≥n probabil√≠stica (logistic/softmax)
- gaussianas como base de modelos generativos (GMM)
- estabilidad num√©rica (evitar `NaN`)

### Objetivos de aprendizaje (medibles)

Al terminar el m√≥dulo podr√°s:

- **Explicar** `P(A|B)` y el teorema de Bayes con un ejemplo de clasificaci√≥n.
- **Aplicar** el punto de vista de MLE: ‚Äúelegir par√°metros que hacen los datos m√°s probables‚Äù.
- **Derivar** por qu√© minimizar cross-entropy equivale a maximizar log-likelihood (binaria y multiclase).
- **Implementar** softmax y log-softmax de forma num√©ricamente estable (log-sum-exp).
- **Diagnosticar** fallos t√≠picos: `log(0)`, overflow/underflow, probabilidades que no suman 1.

### Prerrequisitos

- De `M√≥dulo 01`: NumPy (vectorizaci√≥n, `axis`, broadcasting).
- De `M√≥dulo 03`: Chain Rule y gradiente (para entender el salto a `M√≥dulo 05/07`).

Enlaces r√°pidos:

- [RECURSOS.md](RECURSOS.md)
- [GLOSARIO: Binary Cross-Entropy](GLOSARIO.md#binary-cross-entropy)
- [GLOSARIO: Softmax](GLOSARIO.md#softmax)
- [GLOSARIO: Chain Rule](GLOSARIO.md#chain-rule)

### Integraci√≥n con Plan v4/v5

- [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md)
- [PLAN_V5_ESTRATEGICO.md](PLAN_V5_ESTRATEGICO.md)
- Registro de errores: `study_tools/DIARIO_ERRORES.md`
- Evaluaci√≥n (r√∫brica): [study_tools/RUBRICA_v1.md](../study_tools/RUBRICA_v1.md) (scope `M04` en `rubrica.csv`; incluye PB-8)

### Recursos (cu√°ndo usarlos)

| Prioridad | Recurso | Cu√°ndo usarlo en este m√≥dulo | Para qu√© |
|----------|---------|------------------------------|----------|
| **Obligatorio** | `study_tools/DIARIO_ERRORES.md` | Cada vez que aparezca `NaN`, `inf`, `log(0)` u overflow/underflow | Registrar el caso y crear un ‚Äúfix‚Äù reproducible |
| **Obligatorio** | [StatQuest - Maximum Likelihood](https://www.youtube.com/watch?v=XepXtl9YKwc) | Antes (o durante) la secci√≥n de MLE y cross-entropy | Alinear intuici√≥n de ‚Äúmaximizar verosimilitud‚Äù |
| **Complementario** | [3Blue1Brown - Bayes Theorem](https://www.youtube.com/watch?v=HZGCoVF3YvM) | Cuando Bayes se sienta ‚Äúf√≥rmula sin sentido‚Äù (d√≠a 3-4) | Visualizar prior/likelihood/posterior |
| **Complementario** | [Mathematics for ML (book)](https://mml-book.github.io/) | Al implementar Gaussiana multivariada y covarianza | Refuerzo de notaci√≥n y derivaciones |
| **Opcional** | [RECURSOS.md](RECURSOS.md) | Al terminar el m√≥dulo (para planificar L√≠nea 2 o profundizar) | Elegir rutas de estudio sin romper el foco de L√≠nea 1 |

### Mapa conceptual (qu√© conecta con qu√©)

- **MLE ‚Üí Cross-Entropy:** sustenta Logistic Regression (M√≥dulo 05) y BCE/CCE en Deep Learning (M√≥dulo 07).
- **Gaussiana multivariada:** es el ‚Äú√°tomo‚Äù de GMM (M√≥dulo 06).
- **Softmax + Log-Sum-Exp:** evita inestabilidad num√©rica en clasificaci√≥n multiclase (M√≥dulo 05/07).

---

## üìö Contenido

### D√≠a 1-2: Fundamentos de Probabilidad

#### 1.1 Probabilidad B√°sica

```text
P(A) = casos favorables / casos totales

Propiedades:
- 0 ‚â§ P(A) ‚â§ 1
- P(Œ©) = 1 (espacio muestral)
- P(‚àÖ) = 0 (evento imposible)
```

#### 1.2 Probabilidad Condicional

```text
P(A|B) = P(A ‚à© B) / P(B)

"Probabilidad de A dado que B ocurri√≥"
```

**Ejemplo en ML:**
- P(spam | contiene "gratis") = ¬øQu√© tan probable es spam si el email dice "gratis"?

#### 1.3 Independencia

```text
A y B son independientes si:
P(A ‚à© B) = P(A) ¬∑ P(B)

Equivalente a:
P(A|B) = P(A)
```

---

### D√≠a 3-4: Teorema de Bayes (Cr√≠tico para ML)

#### 2.1 La F√≥rmula

```text
            P(B|A) ¬∑ P(A)
P(A|B) = ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
               P(B)

Donde:
- P(A|B) = Posterior (lo que queremos calcular)
- P(B|A) = Likelihood (verosimilitud)
- P(A)   = Prior (conocimiento previo)
- P(B)   = Evidence (normalizador)
```

#### 2.2 Interpretaci√≥n para ML

```text
              P(datos|clase) ¬∑ P(clase)
P(clase|datos) = ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                      P(datos)

Ejemplo: Clasificaci√≥n de spam
- P(spam|palabras) = P(palabras|spam) ¬∑ P(spam) / P(palabras)
```

#### 2.3 Implementaci√≥n en Python

```python
import numpy as np

def bayes_classifier(x: np.ndarray,
                     likelihood_spam: float,
                     likelihood_ham: float,
                     prior_spam: float = 0.3) -> str:
    """
    Clasificador Bayesiano simple.

    Args:
        x: Caracter√≠sticas del email (simplificado)
        likelihood_spam: P(x|spam)
        likelihood_ham: P(x|ham)
        prior_spam: P(spam) - conocimiento previo

    Returns:
        'spam' o 'ham'
    """
    prior_ham = 1 - prior_spam

    # Posterior (sin normalizar, solo comparamos)
    posterior_spam = likelihood_spam * prior_spam
    posterior_ham = likelihood_ham * prior_ham

    return 'spam' if posterior_spam > posterior_ham else 'ham'


# Ejemplo: Email con palabra "gratis"
# P("gratis"|spam) = 0.8, P("gratis"|ham) = 0.1
result = bayes_classifier(
    x=None,  # simplificado
    likelihood_spam=0.8,
    likelihood_ham=0.1,
    prior_spam=0.3
)
print(f"Clasificaci√≥n: {result}")  # spam
```

#### 2.4 Naive Bayes (Conexi√≥n con Supervised Learning)

```python
def naive_bayes_predict(X: np.ndarray,
                        class_priors: np.ndarray,
                        feature_probs: dict) -> np.ndarray:
    """
    Naive Bayes asume independencia entre features:
    P(x1, x2, ..., xn | clase) = P(x1|clase) ¬∑ P(x2|clase) ¬∑ ... ¬∑ P(xn|clase)

    Esta "ingenuidad" simplifica mucho el c√°lculo.
    """
    n_samples = X.shape[0]
    n_classes = len(class_priors)

    log_posteriors = np.zeros((n_samples, n_classes))

    for c in range(n_classes):
        # Log para evitar underflow con muchas features
        log_prior = np.log(class_priors[c])
        log_likelihood = np.sum(np.log(feature_probs[c][X]), axis=1)
        log_posteriors[:, c] = log_prior + log_likelihood

    return np.argmax(log_posteriors, axis=1)
```

---

## üß© Micro-Cap√≠tulo Maestro: Maximum Likelihood Estimation (MLE) ‚Äî Nivel: Avanzado

### 1) Intuici√≥n (la met√°fora del detective)

Imagina que eres un detective que llega a una escena del crimen (tus **datos** `X`).

- Tienes una lista de sospechosos (tus **modelos**).
- Cada sospechoso tiene un comportamiento ajustable por perillas (tus **par√°metros** `Œ∏`).

MLE pregunta:

> **¬øQu√© valores de `Œ∏` hacen M√ÅS PROBABLE que estos datos espec√≠ficos hayan ocurrido?**

Importante:

- No estamos diciendo ‚Äúqu√© par√°metro es m√°s probable‚Äù (eso ser√≠a un enfoque Bayesiano).
- Estamos diciendo ‚Äúqu√© par√°metro le da la mayor probabilidad a los datos que YA vimos‚Äù.

### 2) Formalizaci√≥n (likelihood y log-likelihood)

Sea `X = {x1, x2, ..., xn}` un conjunto de datos i.i.d.

La **likelihood** es:

`L(Œ∏ | X) = P(X | Œ∏) = Œ†_{i=1}^{n} P(x_i | Œ∏)`

Como multiplicar muchos n√∫meros peque√±os causa underflow, usamos log:

`‚Ñì(Œ∏) = log L(Œ∏|X) = Œ£_{i=1}^{n} log P(x_i | Œ∏)`

Como `log` es mon√≥tona creciente, maximizar `L` y maximizar `‚Ñì` es equivalente:

`Œ∏_MLE = argmax_Œ∏ ‚Ñì(Œ∏)`

### 3) Derivaci√≥n clave: de MLE a MSE (Regresi√≥n Lineal)

La idea conceptual: cuando usas **MSE**, est√°s asumiendo impl√≠citamente un modelo de ruido.

Sup√≥n que tu regresi√≥n lineal es:

`y = XŒ≤ + Œµ` con `Œµ ~ N(0, œÉ¬≤ I)`

Entonces la probabilidad de observar `y` dado `Œ≤` es Gaussiana:

`P(y | X, Œ≤) ‚àù exp( - (1/(2œÉ¬≤)) ||y - XŒ≤||¬≤ )`

Tomando log-likelihood y tirando constantes que no dependen de `Œ≤`:

`‚Ñì(Œ≤) = const - (1/(2œÉ¬≤)) ||y - XŒ≤||¬≤`

Maximizar `‚Ñì(Œ≤)` equivale a minimizar `||y - XŒ≤||¬≤`.

Conclusi√≥n:

- Minimizar **SSE/MSE** es exactamente hacer **MLE** bajo ruido Gaussiano.
- Esta conexi√≥n es el puente directo hacia **Statistical Estimation** (L√≠nea 2).

### 4) Conexi√≥n L√≠nea 2: estimadores, sesgo y varianza (intuici√≥n)

En L√≠nea 2, la palabra clave es **estimador**: una regla que convierte datos en un par√°metro.

- Un **estimador** es una funci√≥n: `\hat{Œ∏} = g(X)`.
- **Sesgo (bias):** si `E[\hat{Œ∏}]` no coincide con el valor real `Œ∏`.
- **Varianza:** cu√°nto cambia `\hat{Œ∏}` si repites el muestreo.

Regla mental:

- **M√°s bias** suele dar **menos varianza**.
- **Menos bias** suele dar **m√°s varianza**.

Esto reaparece en ML como *bias-variance tradeoff*.

### 5) Teor√≠a de Estimadores (lo que te eval√∫an en proyectos/examen)

Aqu√≠ pasamos de la intuici√≥n a una formalizaci√≥n que aparece mucho en evaluaci√≥n.

#### 5.1 Sesgo, varianza y MSE (descomposici√≥n clave)

Si quieres estimar un par√°metro real `Œ∏` con un estimador `\hat{Œ∏}`, el error cuadr√°tico medio es:

`MSE(\hat{Œ∏}) = E[(\hat{Œ∏} - Œ∏)^2]`

La identidad importante es:

`MSE(\hat{Œ∏}) = Var(\hat{Œ∏}) + Bias(\hat{Œ∏})^2`

Donde:

- `Bias(\hat{Œ∏}) = E[\hat{Œ∏}] - Œ∏`
- `Var(\hat{Œ∏}) = E[(\hat{Œ∏} - E[\hat{Œ∏}])^2]`

Lectura mental:

- Puedes reducir MSE bajando varianza, aunque suba un poco el sesgo.
- O puedes ‚Äúperseguir cero sesgo‚Äù y pagar con alta varianza.

Esto es exactamente el *bias-variance trade-off* en ML (por ejemplo, regularizar o simplificar modelos).

#### 5.2 Unbiased vs consistente (2 propiedades distintas)

- **Unbiased (insesgado):** `E[\hat{Œ∏}] = Œ∏`.
- **Consistente:** cuando `n ‚Üí ‚àû`, `\hat{Œ∏} ‚Üí Œ∏` (en un sentido probabil√≠stico).

Un estimador puede ser sesgado y aun as√≠ consistente (y a veces es preferible si reduce varianza para `n` finito).

#### 5.3 Conexi√≥n directa con regularizaci√≥n (puente a ML)

Ejemplo mental:

- **Ridge / L2** introduce sesgo (empuja coeficientes hacia 0).
- A cambio suele reducir varianza (soluci√≥n m√°s estable ante ruido y colinealidad).

En t√©rminos de la descomposici√≥n:

- sube `Bias^2`
- baja `Var`

Si el total baja, mejora el `MSE` esperado fuera de muestra.

## üß© Micro-Cap√≠tulo Maestro: Introducci√≥n a Markov Chains ‚Äî Nivel: Intermedio

### 1) Concepto

Una cadena de Markov es un sistema que salta entre estados.

Propiedad de Markov (‚Äúfalta de memoria‚Äù):

`P(S_{t+1} | S_t, S_{t-1}, ...) = P(S_{t+1} | S_t)`

### 2) Representaci√≥n matricial (puente con √Ålgebra Lineal)

Si tienes 3 estados (Sol, Nube, Lluvia), defines una matriz de transici√≥n `P` (3√ó3) donde cada fila suma 1.

Si `œÄ_t` es un vector fila (1√ó3) con la distribuci√≥n ‚Äúhoy‚Äù, entonces:

`œÄ_{t+1} = œÄ_t P`

Y en `k` pasos:

`œÄ_{t+k} = œÄ_t P^k`

### 3) Reto mental: estacionariedad = eigenvector

Si repites multiplicaciones, muchas cadenas convergen a una distribuci√≥n estacionaria `œÄ*` tal que:

`œÄ* = œÄ* P`

Eso significa (en la perspectiva correcta) que `œÄ*` es un **eigenvector** asociado al **eigenvalue 1**.

---

### D√≠a 5: Distribuci√≥n Gaussiana (Normal)

#### 3.1 La Distribuci√≥n M√°s Importante en ML

```text
                    1              (x - Œº)¬≤
f(x) = ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ¬∑ exp(- ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ)
       œÉ ¬∑ ‚àö(2œÄ)                   2œÉ¬≤

Par√°metros:
- Œº (mu): Media (centro de la campana)
- œÉ (sigma): Desviaci√≥n est√°ndar (ancho)
- œÉ¬≤ (sigma¬≤): Varianza
```

#### 3.2 Por Qu√© es Importante

1. **Muchos fen√≥menos naturales** siguen esta distribuci√≥n
2. **Teorema del L√≠mite Central:** promedios de cualquier distribuci√≥n ‚Üí Normal
3. **GMM usa Gaussianas** para modelar clusters
4. **Inicializaci√≥n de pesos** en redes neuronales

#### 3.3 Implementaci√≥n

```python
import numpy as np

def gaussian_pdf(x: np.ndarray, mu: float, sigma: float) -> np.ndarray:
    """
    Probability Density Function de la Gaussiana.

    Args:
        x: Puntos donde evaluar
        mu: Media
        sigma: Desviaci√≥n est√°ndar

    Returns:
        Densidad de probabilidad en cada punto
    """
    coefficient = 1 / (sigma * np.sqrt(2 * np.pi))
    exponent = -((x - mu) ** 2) / (2 * sigma ** 2)
    return coefficient * np.exp(exponent)


# Visualizaci√≥n
import matplotlib.pyplot as plt

x = np.linspace(-5, 5, 1000)

# Diferentes Gaussianas
plt.figure(figsize=(10, 6))
plt.plot(x, gaussian_pdf(x, mu=0, sigma=1), label='Œº=0, œÉ=1 (est√°ndar)')
plt.plot(x, gaussian_pdf(x, mu=0, sigma=2), label='Œº=0, œÉ=2 (m√°s ancha)')
plt.plot(x, gaussian_pdf(x, mu=2, sigma=1), label='Œº=2, œÉ=1 (desplazada)')
plt.legend()
plt.title('Distribuciones Gaussianas')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.grid(True)
plt.savefig('gaussian_distributions.png')
```

#### 3.4 Gaussiana Multivariada (Para GMM)

```python
def multivariate_gaussian_pdf(x: np.ndarray,
                               mu: np.ndarray,
                               cov: np.ndarray) -> float:
    """
    Gaussiana multivariada para vectores.

    Args:
        x: Vector de caracter√≠sticas (d,)
        mu: Vector de medias (d,)
        cov: Matriz de covarianza (d, d)

    Returns:
        Densidad de probabilidad
    """
    d = len(mu)
    diff = x - mu

    # Determinante e inversa de la covarianza
    det_cov = np.linalg.det(cov)
    inv_cov = np.linalg.inv(cov)

    # Coeficiente de normalizaci√≥n
    coefficient = 1 / (np.sqrt((2 * np.pi) ** d * det_cov))

    # Exponente (forma cuadr√°tica)
    exponent = -0.5 * diff.T @ inv_cov @ diff

    return coefficient * np.exp(exponent)


# Ejemplo 2D
mu = np.array([0, 0])
cov = np.array([[1, 0.5],
                [0.5, 1]])  # Correlaci√≥n positiva

x = np.array([0.5, 0.5])
prob = multivariate_gaussian_pdf(x, mu, cov)
print(f"P(x=[0.5, 0.5]) = {prob:.4f}")
```

---

### D√≠a 6: Maximum Likelihood Estimation (MLE)

#### 4.0 MLE ‚Üí Cross-Entropy (la conexi√≥n que te piden en ex√°menes)

**Idea:** si un modelo produce probabilidades `P(y|x, Œ∏)`, entrenar por MLE significa:

- maximizar `Œ†·µ¢ P(y·µ¢|x·µ¢, Œ∏)`

Por estabilidad num√©rica y conveniencia, trabajamos con log:

- maximizar `Œ£·µ¢ log P(y·µ¢|x·µ¢, Œ∏)`

Y como optimizadores minimizan, entrenamos minimizando:

- `-Œ£·µ¢ log P(y·µ¢|x·µ¢, Œ∏)`  (negative log-likelihood)

Ese t√©rmino es exactamente la **cross-entropy** que usas en:

- Logistic Regression (BCE) en `M√≥dulo 05`
- clasificaci√≥n multiclase (CCE) en `M√≥dulo 07`

**Cheat sheet:**

- **MLE:** maximizar likelihood
- **Entrenamiento:** minimizar negative log-likelihood
- **En clasificaci√≥n:** eso se llama cross-entropy

---

### Extensi√≥n Estrat√©gica (L√≠nea 2): Statistical Estimation

#### MLE como filosof√≠a: ‚Äúajustar perillas‚Äù

MLE no es solo una f√≥rmula: es una forma de pensar.

- Tienes un modelo con par√°metros `Œ∏` (las ‚Äúperillas‚Äù).
- Ya viste datos `D`.
- Pregunta: ¬øqu√© valores de `Œ∏` hacen que `D` sea lo m√°s probable posible?

Formalmente:

```text
Œ∏_MLE = argmax_Œ∏ P(D | Œ∏)
```

Como `P(D|Œ∏)` suele ser un producto grande, usamos log:

```text
Œ∏_MLE = argmax_Œ∏ log P(D | Œ∏)
```

Esto es el puente directo a **Statistical Estimation** (L√≠nea 2): estimadores, sesgo, varianza, y por qu√© ‚Äúpromedio‚Äù aparece en tantos lados.

#### Worked example: Moneda (Bernoulli) ‚Üí estimador MLE

Modelo:

- `X_i ~ Bernoulli(p)` donde `p = P(cara)`.

Datos:

- `D = {x_1, ..., x_n}` con `x_i ‚àà {0,1}`.

Likelihood:

```text
P(D | p) = Œ†_i p^{x_i} (1-p)^{(1-x_i)}
```

Log-likelihood:

```text
‚Ñì(p) = Œ£_i [x_i log p + (1-x_i) log(1-p)]
```

Derivar y hacer 0 (intuici√≥n: el m√°ximo ocurre cuando la ‚Äúprobabilidad del modelo‚Äù coincide con la frecuencia observada):

```text
d‚Ñì/dp = Œ£_i [x_i/p - (1-x_i)/(1-p)] = 0
```

Soluci√≥n:

```text
p_MLE = (1/n) Œ£_i x_i
```

Interpretaci√≥n: el MLE de `p` es simplemente la **proporci√≥n de caras**. Este patr√≥n (media muestral) reaparece en gaussianas y en muchos estimadores.

#### 4.1 La Idea Central

```text
MLE: Encontrar los par√°metros Œ∏ que maximizan la probabilidad
     de observar los datos que tenemos.

Œ∏_MLE = argmax P(datos | Œ∏)
            Œ∏
```

#### 4.2 Por Qu√© es Fundamental

- **Logistic Regression** usa MLE para encontrar los pesos
- **Cross-Entropy Loss** viene de maximizar likelihood
- **GMM** usa MLE (via EM algorithm)

#### 4.3 MLE para Gaussiana

```python
def mle_gaussian(data: np.ndarray) -> tuple[float, float]:
    """
    Estimar par√°metros de Gaussiana con MLE.

    Para una Gaussiana, los estimadores MLE son:
    - Œº_MLE = media muestral
    - œÉ¬≤_MLE = varianza muestral (con n, no n-1)

    Args:
        data: Muestras observadas

    Returns:
        (mu_mle, sigma_mle)
    """
    n = len(data)

    # MLE de la media
    mu_mle = np.mean(data)

    # MLE de la varianza (dividir por n, no n-1)
    sigma_squared_mle = np.sum((data - mu_mle) ** 2) / n
    sigma_mle = np.sqrt(sigma_squared_mle)

    return mu_mle, sigma_mle


# Ejemplo: Generar datos y estimar
np.random.seed(42)
true_mu, true_sigma = 5.0, 2.0
samples = np.random.normal(true_mu, true_sigma, size=1000)

estimated_mu, estimated_sigma = mle_gaussian(samples)
print(f"Par√°metros reales: Œº={true_mu}, œÉ={true_sigma}")
print(f"MLE estimados:     Œº={estimated_mu:.3f}, œÉ={estimated_sigma:.3f}")
```

#### 4.4 Conexi√≥n con Cross-Entropy Loss

#### 4.5 MLE para multiclase (Softmax + Categorical Cross-Entropy)

Para `K` clases, `y` es one-hot y el modelo produce probabilidades con softmax:

- `p = softmax(z)` donde `z = XW` son logits

Likelihood (por muestra):

- `P(y|x) = Œ†_k p_k^{y_k}`

Log-likelihood:

- `log P(y|x) = Œ£_k y_k log(p_k)`

Negative log-likelihood promedio:

- `L = -(1/m) Œ£·µ¢ Œ£_k y_{ik} log(p_{ik})`

Eso es exactamente **Categorical Cross-Entropy**.

```python
def cross_entropy_from_mle():
    """
    Demostraci√≥n de que Cross-Entropy viene de MLE.

    Para clasificaci√≥n binaria con Bernoulli:
    P(y|x, Œ∏) = p^y ¬∑ (1-p)^(1-y)

    Donde p = œÉ(Œ∏·µÄx) (predicci√≥n del modelo)

    Log-likelihood:
    log P(y|x, Œ∏) = y¬∑log(p) + (1-y)¬∑log(1-p)

    Maximizar likelihood = Minimizar negative log-likelihood
    = Minimizar Cross-Entropy!
    """
    # Ejemplo num√©rico
    y_true = np.array([1, 0, 1, 1, 0])
    y_pred = np.array([0.9, 0.1, 0.8, 0.7, 0.2])  # Probabilidades

    # Cross-Entropy (negative log-likelihood promedio)
    epsilon = 1e-15  # Para evitar log(0)
    ce = -np.mean(
        y_true * np.log(y_pred + epsilon) +
        (1 - y_true) * np.log(1 - y_pred + epsilon)
    )

    print(f"Cross-Entropy Loss: {ce:.4f}")
    return ce

cross_entropy_from_mle()
```

---

## üå± Extensi√≥n Estrat√©gica (L√≠nea 2): Markov Chains (intro conceptual)

> Esta secci√≥n es conceptual: no vas a implementar Markov Chains en L√≠nea 1, pero s√≠ necesitas que la idea te resulte familiar cuando entres al curso de **Discrete-Time Markov Chains and Monte Carlo Methods**.

### Idea central: estados y transiciones

Una cadena de Markov modela un sistema que ‚Äúsalta‚Äù entre **estados**.

- Hoy est√°s en un estado `S_t`.
- Ma√±ana est√°s en `S_{t+1}`.
- Lo importante: `P(S_{t+1} | S_t)` depende solo del estado actual (memoria de 1 paso).

### Matriz de transici√≥n (conexi√≥n con √Ålgebra Lineal)

Definimos una matriz `P` donde:

- `P[i, j] = P(estado j | estado i)`
- Cada fila suma 1 (matriz estoc√°stica por filas)

Si `œÄ_t` es un vector fila con la distribuci√≥n de probabilidad sobre estados en el tiempo `t`, entonces:

```text
œÄ_{t+1} = œÄ_t P
```

Esto conecta directamente con `M√≥dulo 02`: es **multiplicaci√≥n de matrices** aplicada a probabilidades.

### Ejemplo m√≠nimo (2 estados)

Estados: `A` y `B`.

```text
P = [[0.9, 0.1],
     [0.2, 0.8]]
```

Interpretaci√≥n:

- Si est√°s en `A`, te quedas en `A` con 0.9, pasas a `B` con 0.1.
- Si est√°s en `B`, pasas a `A` con 0.2, te quedas en `B` con 0.8.

### Estacionariedad (semilla para L√≠nea 2)

Una distribuci√≥n estacionaria `œÄ*` satisface:

```text
œÄ* = œÄ* P
```

En otras palabras: es un **autovector** (eigenvector) asociado al eigenvalue `1` (visto desde la perspectiva correcta). Esto vuelve a conectar Markov Chains con eigenvalues/eigenvectors.

---

### D√≠a 7: Softmax como Distribuci√≥n de Probabilidad

#### 5.1 De Logits a Probabilidades

```text
                    exp(z·µ¢)
softmax(z)·µ¢ = ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
              Œ£‚±º exp(z‚±º)

Propiedades:
- Cada salida ‚àà (0, 1)
- Suma de salidas = 1 (distribuci√≥n v√°lida)
- Preserva el orden (mayor logit ‚Üí mayor probabilidad)
```

#### 5.2 El Problema de Estabilidad Num√©rica (v3.3)

```text
‚ö†Ô∏è PROBLEMA: exp() puede causar overflow/underflow

Ejemplo peligroso:
    z = [1000, 1001, 1002]
    exp(z) = [inf, inf, inf]  ‚Üí NaN en softmax!

Ejemplo underflow:
    z = [-1000, -1001, -1002]
    exp(z) = [0, 0, 0]  ‚Üí 0/0 = NaN!
```

#### 5.3 Log-Sum-Exp Trick (Estabilidad Num√©rica)

```text
TRUCO: softmax(z) = softmax(z - max(z))

Demostraci√≥n:
    softmax(z - c)·µ¢ = exp(z·µ¢ - c) / Œ£‚±º exp(z‚±º - c)
                    = exp(z·µ¢)¬∑exp(-c) / Œ£‚±º exp(z‚±º)¬∑exp(-c)
                    = exp(z·µ¢) / Œ£‚±º exp(z‚±º)
                    = softmax(z)·µ¢

Al restar max(z), todos los exponentes son ‚â§ 0, evitando overflow.
```

#### 5.4 Implementaci√≥n Num√©ricamente Estable

> Regla pr√°ctica: si vas a calcular cross-entropy, prefiere **log-softmax** estable en vez de `np.log(softmax(z))`.

```python
def softmax(z: np.ndarray) -> np.ndarray:
    """
    Softmax num√©ricamente estable usando Log-Sum-Exp trick.

    Truco: Restar el m√°ximo para evitar overflow en exp()
    softmax(z) = softmax(z - max(z))

    Args:
        z: Logits (scores antes de activaci√≥n)

    Returns:
        Probabilidades que suman 1
    """
    # Log-Sum-Exp trick: restar el m√°ximo
    z_stable = z - np.max(z, axis=-1, keepdims=True)

    exp_z = np.exp(z_stable)
    return exp_z / np.sum(exp_z, axis=-1, keepdims=True)


def log_softmax(z: np.ndarray) -> np.ndarray:
    """
    Log-Softmax estable (√∫til para Cross-Entropy).

    log(softmax(z)) calculado de forma estable.
    Evita calcular softmax primero y luego log (pierde precisi√≥n).
    """
    z_stable = z - np.max(z, axis=-1, keepdims=True)
    log_sum_exp = np.log(np.sum(np.exp(z_stable), axis=-1, keepdims=True))
    return z_stable - log_sum_exp


def categorical_cross_entropy_from_logits(y_true: np.ndarray, logits: np.ndarray) -> float:
    """
    Cross-entropy estable usando logits directamente.

    Evita calcular softmax expl√≠cito.
    √ötil cuando entrenas modelos y quieres estabilidad.
    """
    log_probs = log_softmax(logits)
    return -np.mean(np.sum(y_true * log_probs, axis=1))


# ============================================================
# DEMOSTRACI√ìN: Por qu√© el trick es necesario
# ============================================================

def demo_numerical_stability():
    """Muestra por qu√© necesitamos el Log-Sum-Exp trick."""

    # Caso peligroso: logits muy grandes
    z_dangerous = np.array([1000.0, 1001.0, 1002.0])

    # Sin el trick (INCORRECTO)
    def softmax_naive(z):
        exp_z = np.exp(z)  # ¬°Overflow!
        return exp_z / np.sum(exp_z)

    # Con el trick (CORRECTO)
    def softmax_stable(z):
        z_stable = z - np.max(z)
        exp_z = np.exp(z_stable)
        return exp_z / np.sum(exp_z)

    print("Logits peligrosos:", z_dangerous)
    print()

    # Naive (falla)
    import warnings
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        result_naive = softmax_naive(z_dangerous)
        print(f"Softmax NAIVE: {result_naive}")
        print(f"  ‚Üí Suma: {np.sum(result_naive)} (deber√≠a ser 1.0)")

    # Estable (funciona)
    result_stable = softmax_stable(z_dangerous)
    print(f"\nSoftmax ESTABLE: {result_stable}")
    print(f"  ‚Üí Suma: {np.sum(result_stable):.6f} ‚úì")

demo_numerical_stability()


# Ejemplo: Clasificaci√≥n multiclase (d√≠gitos 0-9)
logits = np.array([2.0, 1.0, 0.1, -1.0, 3.0, 0.5, -0.5, 1.5, 0.0, -2.0])
probs = softmax(logits)

print("\nLogits ‚Üí Probabilidades:")
for i, (l, p) in enumerate(zip(logits, probs)):
    print(f"  Clase {i}: logit={l:+.1f} ‚Üí prob={p:.3f}")
print(f"\nSuma de probabilidades: {np.sum(probs):.6f}")
print(f"Clase predicha: {np.argmax(probs)}")
```

#### 5.3 Categorical Cross-Entropy (Multiclase)

```python
def categorical_cross_entropy(y_true: np.ndarray,
                               y_pred: np.ndarray) -> float:
    """
    Loss para clasificaci√≥n multiclase.

    Args:
        y_true: One-hot encoded labels (n_samples, n_classes)
        y_pred: Probabilidades softmax (n_samples, n_classes)

    Returns:
        Loss promedio
    """
    epsilon = 1e-15
    # Solo cuenta la clase correcta (donde y_true=1)
    return -np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=1))


# Ejemplo
y_true = np.array([
    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],  # Clase 4
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # Clase 0
])

y_pred = np.array([
    softmax(np.array([0, 0, 0, 0, 5, 0, 0, 0, 0, 0])),  # Confiado en 4
    softmax(np.array([3, 1, 0, 0, 0, 0, 0, 0, 0, 0])),  # Confiado en 0
])

loss = categorical_cross_entropy(y_true, y_pred)
print(f"Categorical Cross-Entropy: {loss:.4f}")
```

---

## üéØ Ejercicios por tema (progresivos) + Soluciones

Reglas:

- **Intenta primero** sin mirar la soluci√≥n.
- **Timebox sugerido:** 15‚Äì30 min por ejercicio.
- **√âxito m√≠nimo:** tu soluci√≥n debe pasar los `assert`.

---

### Ejercicio 4.1: Probabilidad condicional (P(A|B)) y consistencia

#### Enunciado

1) **B√°sico**

- Dado un conjunto de conteos de eventos, calcula `P(A)`, `P(B)` y `P(A ‚à© B)`.

2) **Intermedio**

- Calcula `P(A|B) = P(A‚à©B)/P(B)` y verifica que est√° en `[0,1]`.

3) **Avanzado**

- Verifica que `P(A‚à©B) = P(A|B)¬∑P(B)`.

#### Soluci√≥n

```python
import numpy as np

# Simulaci√≥n con conteos (dataset peque√±o)
n = 100
count_A = 40
count_B = 50
count_A_and_B = 20

P_A = count_A / n
P_B = count_B / n
P_A_and_B = count_A_and_B / n

P_A_given_B = P_A_and_B / P_B

assert 0.0 <= P_A <= 1.0
assert 0.0 <= P_B <= 1.0
assert 0.0 <= P_A_given_B <= 1.0
assert np.isclose(P_A_and_B, P_A_given_B * P_B)
```

---

### Ejercicio 4.2: Bayes en modo clasificador (posterior sin normalizar)

#### Enunciado

1) **B√°sico**

- Implementa el c√°lculo de posterior sin normalizar:
  - `score_spam = P(x|spam)¬∑P(spam)`
  - `score_ham = P(x|ham)¬∑P(ham)`

2) **Intermedio**

- Normaliza y obt√©n `P(spam|x)` y `P(ham|x)`.

3) **Avanzado**

- Verifica que las probabilidades normalizadas suman 1.

#### Soluci√≥n

```python
import numpy as np

P_spam = 0.3
P_ham = 1.0 - P_spam

P_x_given_spam = 0.8
P_x_given_ham = 0.1

score_spam = P_x_given_spam * P_spam
score_ham = P_x_given_ham * P_ham

Z = score_spam + score_ham
P_spam_given_x = score_spam / Z
P_ham_given_x = score_ham / Z

assert np.isclose(P_spam_given_x + P_ham_given_x, 1.0)
assert P_spam_given_x > P_ham_given_x
```

---

### Ejercicio 4.3: Independencia (test emp√≠rico)

#### Enunciado

1) **B√°sico**

- Simula dos variables binarias independientes `A` y `B`.

2) **Intermedio**

- Estima `P(A)`, `P(B)`, `P(A‚à©B)` y verifica `P(A‚à©B) ‚âà P(A)P(B)`.

3) **Avanzado**

- Simula un caso dependiente y verifica que la igualdad se rompe.

#### Soluci√≥n

```python
import numpy as np

np.random.seed(0)
n = 20000

# Independientes
A = (np.random.rand(n) < 0.4)
B = (np.random.rand(n) < 0.5)

P_A = A.mean()
P_B = B.mean()
P_A_and_B = (A & B).mean()

assert abs(P_A_and_B - (P_A * P_B)) < 0.01

# Dependientes: B es casi A
B_dep = (A | (np.random.rand(n) < 0.05))
P_B_dep = B_dep.mean()
P_A_and_B_dep = (A & B_dep).mean()

assert abs(P_A_and_B_dep - (P_A * P_B_dep)) > 0.02
```

---

### Ejercicio 4.4: MLE de Bernoulli ("fracci√≥n de heads")

#### Enunciado

1) **B√°sico**

- Genera muestras Bernoulli con `p_true`.

2) **Intermedio**

- Implementa el estimador MLE `p_hat = mean(x)`.

3) **Avanzado**

- Verifica que `p_hat` se aproxima a `p_true` con suficientes muestras.

#### Soluci√≥n

```python
import numpy as np

np.random.seed(1)
p_true = 0.7
n = 5000
x = (np.random.rand(n) < p_true).astype(float)

p_hat = float(np.mean(x))
assert abs(p_hat - p_true) < 0.02
```

---

### Ejercicio 4.5: PDF Gaussiana univariada (sanity check)

#### Enunciado

1) **B√°sico**

- Implementa la PDF de una normal `N(Œº,œÉ¬≤)`.

2) **Intermedio**

- Verifica que para `N(0,1)` en `x=0` la densidad ‚âà `0.39894228`.

3) **Avanzado**

- Verifica que `pdf(x)` es sim√©trica: `pdf(a) == pdf(-a)` cuando `Œº=0`.

#### Soluci√≥n

```python
import numpy as np

def gaussian_pdf(x: np.ndarray, mu: float, sigma: float) -> np.ndarray:
    x = np.asarray(x, dtype=float)
    sigma = float(sigma)
    assert sigma > 0
    z = (x - mu) / sigma
    return (1.0 / (np.sqrt(2.0 * np.pi) * sigma)) * np.exp(-0.5 * z**2)


val0 = gaussian_pdf(np.array([0.0]), mu=0.0, sigma=1.0)[0]
assert np.isclose(val0, 0.39894228, atol=1e-4)

a = 1.7
assert np.isclose(
    gaussian_pdf(np.array([a]), 0.0, 1.0)[0],
    gaussian_pdf(np.array([-a]), 0.0, 1.0)[0],
    rtol=1e-12,
    atol=1e-12,
)
```

---

### Ejercicio 4.6: Gaussiana multivariada (2D) + covarianza v√°lida

#### Enunciado

1) **B√°sico**

- Implementa la densidad `N(Œº, Œ£)` en 2D.

2) **Intermedio**

- Para `Œº=0` y `Œ£=I`, verifica que `pdf(0) = 1/(2œÄ)`.

3) **Avanzado**

- Verifica que `Œ£` es definida positiva (eigenvalores > 0) antes de invertir.

#### Soluci√≥n

```python
import numpy as np

def multivariate_gaussian_pdf(x: np.ndarray, mu: np.ndarray, cov: np.ndarray) -> float:
    x = np.asarray(x, dtype=float)
    mu = np.asarray(mu, dtype=float)
    cov = np.asarray(cov, dtype=float)
    d = x.shape[0]

    assert mu.shape == (d,)
    assert cov.shape == (d, d)
    assert np.allclose(cov, cov.T)
    eigvals = np.linalg.eigvals(cov)
    assert np.all(eigvals > 0)

    diff = x - mu
    inv = np.linalg.inv(cov)
    det = np.linalg.det(cov)
    norm = 1.0 / (np.sqrt(((2.0 * np.pi) ** d) * det))
    expo = -0.5 * float(diff.T @ inv @ diff)
    return float(norm * np.exp(expo))


mu = np.array([0.0, 0.0])
cov = np.eye(2)
pdf0 = multivariate_gaussian_pdf(np.array([0.0, 0.0]), mu, cov)
assert np.isclose(pdf0, 1.0 / (2.0 * np.pi), atol=1e-6)
assert pdf0 > 0.0
```

---

### Ejercicio 4.7: Log-Sum-Exp y log-softmax estable

#### Enunciado

1) **B√°sico**

- Implementa `logsumexp(z)` de forma estable (restando `max(z)`).

2) **Intermedio**

- Implementa `log_softmax(z) = z - logsumexp(z)`.

3) **Avanzado**

- Verifica que `sum(exp(log_softmax(z))) == 1` y que no hay `inf` con logits grandes.

#### Soluci√≥n

```python
import numpy as np

def logsumexp(z: np.ndarray) -> float:
    z = np.asarray(z, dtype=float)
    m = np.max(z)
    return float(m + np.log(np.sum(np.exp(z - m))))


def log_softmax(z: np.ndarray) -> np.ndarray:
    z = np.asarray(z, dtype=float)
    return z - logsumexp(z)


z = np.array([1000.0, 0.0, -1000.0])
lsm = log_softmax(z)
probs = np.exp(lsm)
assert np.isfinite(lsm).all()
assert np.isfinite(probs).all()
assert np.isclose(np.sum(probs), 1.0)
```

---

### Ejercicio 4.8: Softmax estable (invariancia a constantes)

#### Enunciado

1) **B√°sico**

- Implementa softmax estable: `exp(z-max)/sum(exp(z-max))`.

2) **Intermedio**

- Verifica que suma 1.

3) **Avanzado**

- Verifica invariancia: `softmax(z) == softmax(z + c)`.

#### Soluci√≥n

```python
import numpy as np

def softmax(z: np.ndarray) -> np.ndarray:
    z = np.asarray(z, dtype=float)
    z_shift = z - np.max(z)
    expz = np.exp(z_shift)
    return expz / np.sum(expz)


z = np.array([2.0, 1.0, 0.0])
p = softmax(z)
assert np.isclose(np.sum(p), 1.0)

c = 100.0
p2 = softmax(z + c)
assert np.allclose(p, p2)
assert np.argmax(p) == np.argmax(z)
```

---

### Ejercicio 4.9: Binary Cross-Entropy estable (evitar log(0))

#### Enunciado

1) **B√°sico**

- Implementa BCE: `-mean(y log(p) + (1-y) log(1-p))`.

2) **Intermedio**

- Usa `clip`/`epsilon` para evitar `log(0)`.

3) **Avanzado**

- Verifica:
  - BCE cerca de 0 para predicciones casi perfectas.
  - BCE ‚âà `-log(0.9)` cuando `y=1` y `p=0.9`.

#### Soluci√≥n

```python
import numpy as np

def binary_cross_entropy(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-15) -> float:
    y_true = np.asarray(y_true, dtype=float)
    y_pred = np.asarray(y_pred, dtype=float)
    y_pred = np.clip(y_pred, eps, 1.0 - eps)
    return float(-np.mean(y_true * np.log(y_pred) + (1.0 - y_true) * np.log(1.0 - y_pred)))


y_true = np.array([1.0, 0.0, 1.0, 0.0])
y_pred_good = np.array([0.999, 0.001, 0.999, 0.001])
assert binary_cross_entropy(y_true, y_pred_good) < 0.01

assert np.isclose(binary_cross_entropy(np.array([1.0]), np.array([0.9])), -np.log(0.9), atol=1e-12)
```

---

### Ejercicio 4.10: Categorical Cross-Entropy (multiclase) + one-hot

#### Enunciado

1) **B√°sico**

- Implementa CCE: `-mean(sum(y_true * log(y_pred)))`.

2) **Intermedio**

- Asegura que `y_pred` no contiene ceros (epsilon).

3) **Avanzado**

- Verifica que el loss baja cuando aumenta la probabilidad de la clase correcta.

#### Soluci√≥n

```python
import numpy as np

def categorical_cross_entropy(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-15) -> float:
    y_true = np.asarray(y_true, dtype=float)
    y_pred = np.asarray(y_pred, dtype=float)
    y_pred = np.clip(y_pred, eps, 1.0)
    return float(-np.mean(np.sum(y_true * np.log(y_pred), axis=1)))


y_true = np.array([[0, 1, 0], [1, 0, 0]], dtype=float)
y_pred_bad = np.array([[0.34, 0.33, 0.33], [0.34, 0.33, 0.33]], dtype=float)
y_pred_good = np.array([[0.05, 0.90, 0.05], [0.90, 0.05, 0.05]], dtype=float)

loss_bad = categorical_cross_entropy(y_true, y_pred_bad)
loss_good = categorical_cross_entropy(y_true, y_pred_good)
assert loss_good < loss_bad
```

---

### (Bonus) Ejercicio 4.11: Cadena de Markov (matriz de transici√≥n)

#### Enunciado

1) **B√°sico**

- Define una matriz de transici√≥n `P` (filas suman 1).

2) **Intermedio**

- Propaga una distribuci√≥n `œÄ_{t+1} = œÄ_t P` y verifica que sigue siendo distribuci√≥n.

3) **Avanzado**

- Encuentra una distribuci√≥n estacionaria aproximada iterando muchas veces y verifica `œÄ ‚âà œÄP`.

#### Soluci√≥n

```python
import numpy as np

P = np.array([
    [0.9, 0.1],
    [0.2, 0.8],
], dtype=float)
assert np.allclose(P.sum(axis=1), 1.0)

pi = np.array([1.0, 0.0])
for _ in range(50):
    pi = pi @ P
    assert np.isclose(np.sum(pi), 1.0)
    assert np.all(pi >= 0)

pi_star = pi.copy()
assert np.allclose(pi_star, pi_star @ P, atol=1e-6)
```

## üî® Entregables del M√≥dulo

### E1: `probability.py`

```python
"""
M√≥dulo de probabilidad esencial para ML.
Implementaciones desde cero con NumPy.
"""

import numpy as np
from typing import Tuple

def gaussian_pdf(x: np.ndarray, mu: float, sigma: float) -> np.ndarray:
    """Densidad de probabilidad Gaussiana univariada."""
    pass

def multivariate_gaussian_pdf(x: np.ndarray,
                               mu: np.ndarray,
                               cov: np.ndarray) -> float:
    """Densidad de probabilidad Gaussiana multivariada."""
    pass

def mle_gaussian(data: np.ndarray) -> Tuple[float, float]:
    """Estimaci√≥n MLE de par√°metros de Gaussiana."""
    pass

def softmax(z: np.ndarray) -> np.ndarray:
    """Funci√≥n softmax num√©ricamente estable."""
    pass

def cross_entropy(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """Binary cross-entropy loss."""
    pass

def categorical_cross_entropy(y_true: np.ndarray,
                               y_pred: np.ndarray) -> float:
    """Categorical cross-entropy loss para multiclase."""
    pass
```

### E2: Tests

```python
# tests/test_probability.py
import numpy as np
import pytest
from src.probability import (
    gaussian_pdf, mle_gaussian, softmax,
    cross_entropy, categorical_cross_entropy
)

def test_gaussian_pdf_standard():
    """PDF de Gaussiana est√°ndar en x=0 debe ser ~0.3989."""
    result = gaussian_pdf(np.array([0.0]), mu=0, sigma=1)
    expected = 1 / np.sqrt(2 * np.pi)  # ~0.3989
    assert np.isclose(result[0], expected, rtol=1e-5)

def test_softmax_sums_to_one():
    """Softmax debe sumar 1."""
    z = np.random.randn(10)
    probs = softmax(z)
    assert np.isclose(np.sum(probs), 1.0)

def test_softmax_preserves_order():
    """Mayor logit ‚Üí mayor probabilidad."""
    z = np.array([1.0, 2.0, 3.0])
    probs = softmax(z)
    assert probs[2] > probs[1] > probs[0]

def test_mle_gaussian_accuracy():
    """MLE debe recuperar par√°metros con suficientes datos."""
    np.random.seed(42)
    true_mu, true_sigma = 10.0, 3.0
    data = np.random.normal(true_mu, true_sigma, size=10000)

    est_mu, est_sigma = mle_gaussian(data)

    assert np.isclose(est_mu, true_mu, rtol=0.05)
    assert np.isclose(est_sigma, true_sigma, rtol=0.05)

def test_cross_entropy_perfect_prediction():
    """CE debe ser ~0 para predicciones perfectas."""
    y_true = np.array([1, 0, 1])
    y_pred = np.array([0.999, 0.001, 0.999])

    loss = cross_entropy(y_true, y_pred)
    assert loss < 0.01
```

---

## üìä Resumen Visual

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PROBABILIDAD PARA ML - MAPA CONCEPTUAL                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  TEOREMA DE BAYES                                               ‚îÇ
‚îÇ       ‚îÇ                                                         ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ Naive Bayes Classifier (M√≥dulo 05)                   ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚ñ∫ Intuici√≥n de posterior vs prior                      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  DISTRIBUCI√ìN GAUSSIANA                                         ‚îÇ
‚îÇ       ‚îÇ                                                         ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ GMM en Unsupervised (M√≥dulo 06)                      ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ Inicializaci√≥n de pesos en DL (M√≥dulo 07)            ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚ñ∫ Normalizaci√≥n de datos                               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  MAXIMUM LIKELIHOOD (MLE)                                       ‚îÇ
‚îÇ       ‚îÇ                                                         ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ Cross-Entropy Loss (Logistic Regression)             ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ Categorical CE (Softmax + Multiclase)                ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚ñ∫ EM Algorithm en GMM                                  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  SOFTMAX                                                        ‚îÇ
‚îÇ       ‚îÇ                                                         ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚ñ∫ Capa de salida en clasificaci√≥n multiclase           ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîó Conexiones con Otros M√≥dulos

| Concepto | D√≥nde se usa |
|----------|--------------|
| Teorema de Bayes | Naive Bayes en M√≥dulo 05 |
| Gaussiana | GMM en M√≥dulo 06, inicializaci√≥n en M√≥dulo 07 |
| MLE | Derivaci√≥n de Cross-Entropy en M√≥dulo 05 |
| Softmax | Capa de salida en M√≥dulo 07 |
| Cross-Entropy | Loss function principal en M√≥dulo 05 y 07 |

---

## üß© Consolidaci√≥n (errores comunes + debugging v5 + reto Feynman)

### Errores comunes

- **Confundir PDF con probabilidad:** en continuas, `f(x)` es densidad; la probabilidad requiere integrar en un intervalo.
- **`log(0)` en cross-entropy:** siempre usa `epsilon` o `np.clip`.
- **Overflow/underflow en `exp`:** aplica log-sum-exp / log-softmax.
- **MLE ‚Äúm√°gico‚Äù:** si no puedes explicar por qu√© aparece la media, repite el worked example Bernoulli.

### Debugging / validaci√≥n (v5)

- Cuando algo explote con `nan/inf`, revisa:
  - `np.log` sobre valores 0
  - `np.exp` sobre logits grandes
  - normalizaci√≥n incorrecta en probabilidades (que no suman 1)
- Registra hallazgos en `study_tools/DIARIO_ERRORES.md`.
- Protocolos completos:
  - [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md)
  - [PLAN_V5_ESTRATEGICO.md](PLAN_V5_ESTRATEGICO.md)

### Reto Feynman (tablero blanco)

Explica en 5 l√≠neas o menos:

1) ¬øPor qu√© maximizar likelihood es equivalente a minimizar negative log-likelihood?
2) ¬øPor qu√© el MLE de una moneda es ‚Äúproporci√≥n de caras‚Äù?
3) ¬øQu√© significa `œÄ_{t+1} = œÄ_t P` y por qu√© es √°lgebra lineal?

## ‚úÖ Checklist del M√≥dulo

- [ ] Puedo explicar el Teorema de Bayes con un ejemplo
- [ ] S√© calcular la PDF de una Gaussiana a mano
- [ ] Entiendo por qu√© MLE da Cross-Entropy como loss
- [ ] Implement√© softmax num√©ricamente estable
- [ ] Puedo derivar el MLE de una Bernoulli (moneda) y explicarlo
- [ ] Puedo explicar qu√© es una Markov Chain y qu√© representa una matriz de transici√≥n
- [ ] Los tests de `probability.py` pasan

---

## üìñ Recursos Adicionales

### Videos
- [3Blue1Brown - Bayes Theorem](https://www.youtube.com/watch?v=HZGCoVF3YvM)
- [StatQuest - Maximum Likelihood](https://www.youtube.com/watch?v=XepXtl9YKwc)
- [StatQuest - Gaussian Distribution](https://www.youtube.com/watch?v=rzFX5NWojp0)

### Lecturas
- Mathematics for ML, Cap. 6 (Probability)
- Pattern Recognition and ML (Bishop), Cap. 1-2

---

> üí° **Nota Final:** Este m√≥dulo sigue siendo compacto comparado con un curso completo de probabilidad/estad√≠stica, pero aqu√≠ ya tienes el n√∫cleo de L√≠nea 1 y una ‚Äúsemilla‚Äù intencional para L√≠nea 2 (estimaci√≥n y Markov Chains).

---

**[‚Üê M√≥dulo 03: C√°lculo](03_CALCULO_MULTIVARIANTE.md)** | **[M√≥dulo 05: Supervised Learning ‚Üí](05_SUPERVISED_LEARNING.md)**
