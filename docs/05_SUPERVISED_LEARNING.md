# M√≥dulo 05 - Supervised Learning

> **üéØ Objetivo:** Dominar regresi√≥n lineal, log√≠stica y m√©tricas de evaluaci√≥n
> **Fase:** 2 - N√∫cleo de ML | **Semanas 9-12**
> **Curso del Pathway:** Introduction to Machine Learning: Supervised Learning

---

<a id="m05-0"></a>

## üß≠ C√≥mo usar este m√≥dulo (modo 0‚Üí100)

**Prop√≥sito:** que puedas construir un pipeline supervisado ‚Äúde examen‚Äù:

- entrenar (regresi√≥n lineal/log√≠stica)
- evaluar (m√©tricas)
- validar (train/test, K-fold)
- controlar overfitting (regularizaci√≥n)

### Objetivos de aprendizaje (medibles)

Al terminar este m√≥dulo podr√°s:

- **Implementar** regresi√≥n lineal y regresi√≥n log√≠stica desde cero.
- **Derivar** el gradiente de MSE y de cross-entropy (con la forma `X·µÄ(≈∑ - y)`).
- **Elegir** m√©tricas correctas seg√∫n el costo de FP/FN.
- **Aplicar** validaci√≥n (split y K-fold) evitando leakage.
- **Validar** tu implementaci√≥n con Shadow Mode (sklearn) como ground truth.
- **Explicar** Entrop√≠a/Gini, Information Gain y el contraste **Bagging vs Boosting** (Random Forest vs Gradient Boosting) a nivel conceptual.

### C√°psula (obligatoria): Vectorizaci√≥n extrema (prohibido usar loops)

Regla pr√°ctica para todo el m√≥dulo:

- **Prohibido** iterar con `for` sobre muestras (`N`) o features (`D`) para computar predicciones, p√©rdidas o gradientes.
- **Permitido** iterar sobre iteraciones de entrenamiento (`for step in range(...)`) o √©pocas.

Objetivo: que el *core* de ML sea una composici√≥n de operaciones tipo:

- `logits = X @ W`
- `grad = X.T @ something`

Ejemplos can√≥nicos (con **disciplina de shapes** y sin loops):

```python
import numpy as np  # NumPy: √°lgebra lineal y vectorizaci√≥n


# ============================================================
# 1) Forward multiclase: logits = X @ W
# ============================================================
N = 5  # N: n√∫mero de muestras
D = 4  # D: n√∫mero de features
K = 3  # K: n√∫mero de clases

X = np.random.randn(N, D).astype(float)  # X:(N,D) batch de entrada
assert X.shape == (N, D)  # Contrato de shape para X

W = np.random.randn(D, K).astype(float)  # W:(D,K) pesos por clase
assert W.shape == (D, K)  # Contrato de shape para W

logits = X @ W  # logits:(N,K) porque (N,D)@(D,K)=(N,K)
assert logits.shape == (N, K)  # Contrato: logits debe ser 2D (batch x clases)


# ============================================================
# 2) Log√≠stica binaria: gradiente vectorizado ‚àáw = (1/N) X^T(≈∑ - y)
# ============================================================
w = np.random.randn(D).astype(float)  # w:(D,) pesos binarios (una clase)
assert w.shape == (D,)  # Contrato de shape para w

y = (np.random.rand(N) > 0.5).astype(float)  # y:(N,) etiquetas binarias en {0,1}
assert y.shape == (N,)  # Contrato de shape para y

z = X @ w  # z:(N,) logits binarios
assert z.shape == (N,)  # Contrato de shape para z

y_hat = 1.0 / (1.0 + np.exp(-z))  # sigmoid(z) vectorizada (sin loops)
assert y_hat.shape == (N,)  # Contrato de shape para ≈∑

grad_w = (X.T @ (y_hat - y)) / N  # (D,N)@(N,)=(D,) (forma de examen)
assert grad_w.shape == (D,)  # Contrato: gradiente debe tener el shape de w
# ============================================================
# 3) Distancias pairwise sin loops (kNN / clustering):
#    dist2[i,j] = ||X_query[i] - X_train[j]||^2
# ============================================================
M = 6  # M: n√∫mero de queries
X_train = np.random.randn(N, D).astype(float)  # X_train:(N,D)
X_query = np.random.randn(M, D).astype(float)  # X_query:(M,D)
assert X_train.shape == (N, D)  # Shape correcto para broadcasting
assert X_query.shape == (M, D)  # Shape correcto para broadcasting

# Trick algebraico: ||a-b||^2 = ||a||^2 + ||b||^2 - 2 a¬∑b
q_norm2 = np.sum(X_query ** 2, axis=1, keepdims=True)  # (M,1) ||q_i||^2
t_norm2 = np.sum(X_train ** 2, axis=1, keepdims=True).T  # (1,N) ||t_j||^2
cross = X_query @ X_train.T  # (M,N) producto punto entre cada par (q_i, t_j)

dist2 = q_norm2 + t_norm2 - 2.0 * cross  # (M,N) distancias cuadradas
dist2 = np.maximum(dist2, 0.0)  # Evita negativos por error num√©rico (float)
assert dist2.shape == (M, N)  # Shape correcto de matriz de distancias
```

Enlaces r√°pidos:

- [04_PROBABILIDAD_ML.md](04_PROBABILIDAD_ML.md) (MLE ‚Üí cross-entropy)
- [GLOSARIO.md](GLOSARIO.md)
- [RECURSOS.md](RECURSOS.md)
- [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md)
- [PLAN_V5_ESTRATEGICO.md](PLAN_V5_ESTRATEGICO.md)
- Evaluaci√≥n (r√∫brica): [study_tools/RUBRICA_v1.md](../study_tools/RUBRICA_v1.md) (scope `M05` en `rubrica.csv`)

### Recursos (cu√°ndo usarlos)

| Prioridad | Recurso | Cu√°ndo usarlo en este m√≥dulo | Para qu√© |
|----------|---------|------------------------------|----------|
| **Obligatorio** | [04_PROBABILIDAD_ML.md](04_PROBABILIDAD_ML.md) | Antes de implementar `log-loss`/cross-entropy y el gradiente de log√≠stica | Conectar MLE ‚Üí cross-entropy y evitar derivaciones ‚Äúde memoria‚Äù |
| **Obligatorio** | `study_tools/DIRTY_DATA_CHECK.md` | Antes del primer entrenamiento real (Semana 9‚Äì10), al preparar datasets | Evitar que el modelo ‚Äúaprenda basura‚Äù por fallas de datos |
| **Obligatorio** | `study_tools/DIARIO_ERRORES.md` | Cada vez que veas m√©tricas incoherentes, accuracy ‚Äúm√°gico‚Äù o divergencia | Registrar bugs, causas y fixes reproducibles |
| **Complementario** | [StatQuest ML (playlist)](https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF) | Semana 10‚Äì12 (log√≠stica, m√©tricas, regularizaci√≥n) | Refuerzo conceptual r√°pido + ejemplos |
| **Complementario** | [Stanford CS229](https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU) | Despu√©s de implementar regresi√≥n lineal/log√≠stica (para profundizar) | Profundizar en teor√≠a y derivaciones est√°ndar |
| **Opcional** | [RECURSOS.md](RECURSOS.md) | Al finalizar el m√≥dulo (para escoger pr√°ctica extra) | Expandir sin perder el foco del Pathway |

---

## üß† ¬øQu√© es Supervised Learning?

```text
APRENDIZAJE SUPERVISADO

Tenemos:
- Datos de entrada X (features)
- Etiquetas Y (targets/labels)

Objetivo: Aprender una funci√≥n f tal que f(X) ‚âà Y

Tipos principales:
‚îú‚îÄ‚îÄ REGRESI√ìN: Y es continuo (precio, temperatura)
‚îÇ   ‚îî‚îÄ‚îÄ Output: n√∫mero real
‚îî‚îÄ‚îÄ CLASIFICACI√ìN: Y es discreto (spam/no spam, d√≠gito 0-9)
    ‚îî‚îÄ‚îÄ Output: clase o probabilidad
```

---

## üìö Contenido del M√≥dulo

| Semana | Tema | Entregable |
|--------|------|------------|
| 9 | Regresi√≥n Lineal | `linear_regression.py` |
| 10 | Regresi√≥n Log√≠stica | `logistic_regression.py` |
| 11 | M√©tricas de Evaluaci√≥n | `metrics.py` |
| 12 | Validaci√≥n + Regularizaci√≥n + √Årboles | Cross-validation, L1/L2 + Tree-Based Models |

---

## üíª Parte 1: Regresi√≥n Lineal

### 1.1 Modelo

```python
import numpy as np

"""
REGRESI√ìN LINEAL

Hip√≥tesis: h(x) = Œ∏‚ÇÄ + Œ∏‚ÇÅx‚ÇÅ + Œ∏‚ÇÇx‚ÇÇ + ... + Œ∏‚Çôx‚Çô
         = Œ∏·µÄx (forma matricial)

Donde:
- Œ∏ (theta): par√°metros/pesos del modelo
- x: vector de features (con x‚ÇÄ = 1 para el bias)

En forma matricial para m√∫ltiples muestras:
    ≈∑ = XŒ∏

Donde:
- X: matriz (m √ó n+1) con m muestras y n features + columna de 1s
- Œ∏: vector (n+1 √ó 1) de par√°metros
- ≈∑: vector (m √ó 1) de predicciones
"""

def add_bias_term(X: np.ndarray) -> np.ndarray:
    """A√±ade columna de 1s para el t√©rmino de bias."""
    m = X.shape[0]
    return np.column_stack([np.ones(m), X])

def predict_linear(X: np.ndarray, theta: np.ndarray) -> np.ndarray:
    """Predicci√≥n lineal: ≈∑ = XŒ∏"""
    return X @ theta
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 1.1: Modelo (Regresi√≥n Lineal)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** De la hip√≥tesis `≈∑=XŒ∏` a un contrato de shapes (y por qu√© el bias es ‚Äúfeature 0‚Äù)
- **ID (opcional):** `M05-T01_1`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** B√°sico‚ÄìIntermedio
- **Dependencias:** √Ålgebra lineal m√≠nima (producto matriz-vector), noci√≥n de dataset tabular

#### 2) Objetivos
- Escribir la hip√≥tesis en forma escalar y matricial y explicar qu√© representa cada s√≠mbolo.
- Usar una convenci√≥n de shapes sin ambig√ºedad: `X:(m,n)` y `Œ∏:(n+1,)` tras agregar bias.
- Verificar r√°pidamente si una implementaci√≥n est√° ‚Äúbien cableada‚Äù (shape checks).

#### 3) Relevancia
- Todo el resto del m√≥dulo (log√≠stica, m√©tricas, regularizaci√≥n) depende de tener claro el *forward* `X @ Œ∏`.
- La mayor√≠a de bugs ‚Äúmisteriosos‚Äù en ML-from-scratch son bugs de shapes, no de matem√°ticas.

#### 4) Mapa conceptual m√≠nimo
- **Datos** `X` (features) + **par√°metros** `Œ∏` ‚Üí **predicci√≥n** `≈∑`.
- **Bias** ‚Üí se implementa como `x‚ÇÄ=1` y `Œ∏‚ÇÄ`.

#### 5) Definiciones esenciales
- `m`: n√∫mero de muestras.
- `n`: n√∫mero de features (sin bias).
- `Œ∏‚ÇÄ`: intercepto/bias.

#### 6) Explicaci√≥n did√°ctica
- Tr√°talo como ‚Äúcontrato‚Äù: si `add_bias_term(X)` devuelve `(m,n+1)`, entonces `Œ∏` debe tener longitud `n+1`.

#### 7) Ejemplo modelado
- Dataset 1D (`n=1`): `X:(m,1)` ‚Üí con bias `X_b:(m,2)` y `Œ∏:(2,)`.

#### 8) Pr√°ctica guiada
- Escribe 3 asserts: shapes de `X_b`, `Œ∏`, `X_b @ Œ∏`.

#### 9) Pr√°ctica independiente
- Convierte un dataset con 3 features a `X_b` y verifica que el forward funciona sin loops.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© `x‚ÇÄ=1` hace que el intercepto sea un peso m√°s?

#### 11) Errores comunes
- Duplicar bias (agregar columna de 1s dos veces).
- Usar `Œ∏` como columna `(n+1,1)` y luego mezclar con `(n+1,)` sin querer.

#### 12) Retenci√≥n
- Mantra: `≈∑ = X_b @ Œ∏` y el bias es `x‚ÇÄ=1`.

#### 13) Diferenciaci√≥n
- Avanzado: generaliza a multiclase `logits = X @ W`.

#### 14) Recursos
- Cheatsheet de shapes y producto matricial.

#### 15) Nota docente
- Pide que el alumno ‚Äúdebuggee en voz alta‚Äù un error de shape t√≠pico (ej. `(m,n)@(n+1,)`).
</details>

### 1.2 Funci√≥n de Costo (MSE)

```python
import numpy as np

def mse_cost(X: np.ndarray, y: np.ndarray, theta: np.ndarray) -> float:
    """
    Mean Squared Error Cost Function.

    J(Œ∏) = (1/2m) Œ£·µ¢ (h(x·µ¢) - y·µ¢)¬≤
         = (1/2m) ||XŒ∏ - y||¬≤

    El factor 1/2 es por conveniencia (cancela con la derivada).
    """
    m = len(y)
    predictions = X @ theta
    errors = predictions - y
    return (1 / (2 * m)) * np.sum(errors ** 2)

def mse_gradient(X: np.ndarray, y: np.ndarray, theta: np.ndarray) -> np.ndarray:
    """
    Gradiente del MSE respecto a Œ∏.

    ‚àÇJ/‚àÇŒ∏ = (1/m) X·µÄ(XŒ∏ - y)
    """
    m = len(y)
    predictions = X @ theta
    errors = predictions - y
    return (1 / m) * X.T @ errors
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 1.2: Funci√≥n de Costo (MSE)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** MSE como ‚Äúpenalizaci√≥n cuadr√°tica‚Äù y como `||XŒ∏-y||¬≤` (con lectura geom√©trica)
- **ID (opcional):** `M05-T01_2`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** B√°sico‚ÄìIntermedio
- **Dependencias:** 1.1, suma de cuadrados, producto `X.T @ v`

#### 2) Objetivos
- Explicar el MSE en lenguaje natural (errores grandes se penalizan m√°s).
- Reconocer la forma vectorizada del gradiente `‚àáŒ∏ = (1/m) X·µÄ(XŒ∏ - y)`.
- Entender por qu√© aparece `X·µÄ` (proyecci√≥n del error hacia par√°metros).

#### 3) Relevancia
- Este patr√≥n de gradiente `X·µÄ(≈∑-y)` reaparece en log√≠stica (BCE) y en softmax (CCE).

#### 4) Mapa conceptual m√≠nimo
- **Predicci√≥n** `≈∑` ‚Üí **residuo** `(≈∑-y)` ‚Üí **gradiente** `X·µÄ(residuo)`.

#### 5) Definiciones esenciales
- **Residuo**: `r = ≈∑ - y`.
- **Costo**: promedio (o suma) de `r¬≤`.

#### 6) Explicaci√≥n did√°ctica
- El factor `1/2` en el costo suele usarse para simplificar derivadas; el m√≠nimo no cambia.

#### 7) Ejemplo modelado
- Si duplicas un error (de 2 a 4), la contribuci√≥n al costo se cuadruplica (4‚Üí16).

#### 8) Pr√°ctica guiada
- Implementa un test: si `theta` es perfecto (`X@theta==y`), entonces `mse_cost==0` y `mse_gradient==0`.

#### 9) Pr√°ctica independiente
- Compara `mse_cost` con `np.mean((X@theta - y)**2)` y explica la diferencia del `1/2`.

#### 10) Autoevaluaci√≥n
- ¬øQu√© significa que el gradiente apunte hacia donde el costo sube m√°s r√°pido?

#### 11) Errores comunes
- Confundir shapes: `y` como `(m,1)` vs `(m,)`.
- Olvidar el promedio por `m` (magnitud del gradiente depende del batch size).

#### 12) Retenci√≥n
- F√≥rmula clave: `‚àáŒ∏ MSE = (1/m) X·µÄ(XŒ∏-y)`.

#### 13) Diferenciaci√≥n
- Avanzado: conecta con m√≠nimos cuadrados y proyecciones (subespacios).

#### 14) Recursos
- Notas de least squares, interpretaci√≥n geom√©trica.

#### 15) Nota docente
- Pide que el alumno derive la forma vectorizada desde la forma sumatoria (una vez, con calma).
</details>

### 1.3 Soluci√≥n Cerrada (Normal Equation)

```python
import numpy as np

def normal_equation(X: np.ndarray, y: np.ndarray) -> np.ndarray:
    """
    Soluci√≥n cerrada para regresi√≥n lineal.

    Œ∏ = (X·µÄX)‚Åª¬π X·µÄy

    Ventajas:
    - No requiere iteraciones
    - No hay hiperpar√°metros (learning rate)

    Desventajas:
    - O(n¬≥) por la inversi√≥n de matriz
    - No funciona si X·µÄX es singular
    - No escala bien para n grande (>10,000 features)
    """
    XtX = X.T @ X
    Xty = X.T @ y

    # Usar solve en lugar de inv para estabilidad num√©rica
    theta = np.linalg.solve(XtX, Xty)
    return theta
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 1.3: Soluci√≥n Cerrada (Normal Equation)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Normal Equation: cu√°ndo sirve, cu√°ndo falla y por qu√© `solve` es mejor que `inv`
- **ID (opcional):** `M05-T01_3`
- **Duraci√≥n estimada:** 45‚Äì90 min
- **Nivel:** Intermedio
- **Dependencias:** 1.1‚Äì1.2, noci√≥n de matriz singular/condicionamiento

#### 2) Objetivos
- Implementar `Œ∏ = argmin ||XŒ∏-y||¬≤` v√≠a ecuaciones normales.
- Explicar por qu√© `X·µÄX` puede ser singular o mal condicionada.
- Preferir `np.linalg.solve` sobre `inv` por estabilidad.

#### 3) Relevancia
- Te da un ‚Äúbaseline‚Äù para validar GD: si ambos dan resultados parecidos (cuando aplica), tu GD est√° bien.

#### 4) Mapa conceptual m√≠nimo
- Minimizar SSE ‚Üí derivada = 0 ‚Üí `X·µÄXŒ∏ = X·µÄy`.

#### 5) Definiciones esenciales
- **Singular**: no invertible.
- **Condicionamiento**: sensibilidad num√©rica a perturbaciones.

#### 6) Explicaci√≥n did√°ctica
- En alta dimensi√≥n o con colinealidad fuerte, `X·µÄX` puede ‚Äúromperse‚Äù num√©ricamente.

#### 7) Ejemplo modelado
- Si una feature es combinaci√≥n lineal de otra (duplicada), `X·µÄX` tiende a singular.

#### 8) Pr√°ctica guiada
- Crea una feature duplicada en `X` y observa qu√© ocurre con `np.linalg.solve`.

#### 9) Pr√°ctica independiente
- Implementa Ridge cerrada: `Œ∏=(X·µÄX+ŒªI)^{-1}X·µÄy` (solo conceptual aqu√≠).

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© la complejidad crece como `O(n¬≥)`?

#### 11) Errores comunes
- Usar `inv` por costumbre.
- Olvidar agregar bias antes de la ecuaci√≥n normal.

#### 12) Retenci√≥n
- Regla: si puedes usar closed-form, √∫sala para validar GD (no necesariamente para producci√≥n).

#### 13) Diferenciaci√≥n
- Avanzado: `np.linalg.lstsq` y pseudo-inversa (SVD) como alternativa estable.

#### 14) Recursos
- Documentaci√≥n NumPy: `solve`, `lstsq`, conceptos de singularidad.

#### 15) Nota docente
- Pedir un ‚Äúdiagn√≥stico‚Äù cuando falla: ¬øsingularidad real o num√©rica?
</details>

### 1.4 Gradient Descent para Regresi√≥n

```python
import numpy as np  # Importa NumPy para operaciones matem√°ticas
from typing import List, Tuple  # Importa tipos para anotaciones

class LinearRegression:
    """Regresi√≥n Lineal implementada desde cero."""

    def __init__(self):
        self.theta = None  # Par√°metros del modelo (pesos + bias)
        self.cost_history = []  # Historial de costos para monitoreo

    def fit(
        self,
        X: np.ndarray,
        y: np.ndarray,
        method: str = 'gradient_descent',
        learning_rate: float = 0.01,
        n_iterations: int = 1000
    ) -> 'LinearRegression':
        """
        Entrena el modelo.

        Args:
            X: features (m, n)
            y: targets (m,)
            method: 'gradient_descent' o 'normal_equation'
            learning_rate: tasa de aprendizaje (solo para GD)
            n_iterations: n√∫mero de iteraciones (solo para GD)
        """
        # A√±adir bias a las features
        X_b = add_bias_term(X)
        m, n = X_b.shape  # m: muestras, n: features + bias

        if method == 'normal_equation':
            self.theta = normal_equation(X_b, y)  # Soluci√≥n anal√≠tica directa
        else:
            # Inicializar theta con ceros o valores peque√±os
            self.theta = np.zeros(n)

            for i in range(n_iterations):
                # Calcular gradiente del MSE
                gradient = mse_gradient(X_b, y, self.theta)

                # Actualizar theta usando gradient descent
                self.theta = self.theta - learning_rate * gradient

                # Guardar costo para monitoreo de convergencia
                cost = mse_cost(X_b, y, self.theta)
                self.cost_history.append(cost)

        return self

    def predict(self, X: np.ndarray) -> np.ndarray:
        """Predice valores."""
        X_b = add_bias_term(X)  # A√±ade bias para predicci√≥n
        return X_b @ self.theta  # Predicci√≥n lineal: y = X¬∑Œ∏

    def score(self, X: np.ndarray, y: np.ndarray) -> float:
        """R¬≤ score."""
        y_pred = self.predict(X)  # Predicciones del modelo
        ss_res = np.sum((y - y_pred) ** 2)  # Suma de residuos al cuadrado
        ss_tot = np.sum((y - np.mean(y)) ** 2)  # Suma total de cuadrados
        return 1 - (ss_res / ss_tot)  # R¬≤ = 1 - (residuos/total)


# Demo de regresi√≥n lineal
np.random.seed(42)  # Fija semilla para reproducibilidad
X = 2 * np.random.rand(100, 1)  # 100 puntos entre 0 y 2
y = 4 + 3 * X.flatten() + np.random.randn(100) * 0.5  # y = 4 + 3x + ruido gaussiano

model = LinearRegression()  # Crea instancia del modelo
model.fit(X, y, method='gradient_descent', learning_rate=0.1, n_iterations=1000)  # Entrena

print(f"Par√°metros aprendidos: {model.theta}")  # Muestra Œ∏ aprendido
print(f"Esperados: [4, 3]")  # Valores te√≥ricos (bias=4, pendiente=3)
print(f"R¬≤ score: {model.score(X, y):.4f}")  # Calidad del ajuste
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 1.4: Gradient Descent para Regresi√≥n</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Gradient Descent ‚Äúde examen‚Äù: convergence, learning rate, y checks de sanidad
- **ID (opcional):** `M05-T01_4`
- **Duraci√≥n estimada:** 90‚Äì150 min
- **Nivel:** Intermedio
- **Dependencias:** 1.1‚Äì1.3, gradiente MSE, noci√≥n de iteraci√≥n/√©pocas

#### 2) Objetivos
- Entrenar regresi√≥n lineal por GD con un `learning_rate` razonable.
- Leer el `cost_history` y detectar divergencia o estancamiento.
- Entender por qu√© la vectorizaci√≥n es obligatoria (performance + claridad).

#### 3) Relevancia
- GD es la base del entrenamiento de modelos m√°s grandes (log√≠stica, MLP). Aqu√≠ practicas el ciclo ‚Äúforward ‚Üí loss ‚Üí grad ‚Üí update‚Äù.

#### 4) Mapa conceptual m√≠nimo
- Inicializar `Œ∏` ‚Üí repetir: `grad = X·µÄ(≈∑-y)/m` ‚Üí `Œ∏ ‚Üê Œ∏ - Œ± grad`.

#### 5) Definiciones esenciales
- **Learning rate (Œ±)**: tama√±o del paso.
- **Divergencia**: el costo sube o se vuelve NaN/inf.
- **Convergencia**: el costo baja y se estabiliza.

#### 6) Explicaci√≥n did√°ctica
- Si `Œ±` es muy grande: saltas el m√≠nimo y explota.
- Si `Œ±` es muy peque√±o: entrenas ‚Äúpara siempre‚Äù.

#### 7) Ejemplo modelado
- En el demo, la soluci√≥n esperada es ~`[4,3]` (con ruido). Si sale lej√≠simos, revisa shapes, bias y `Œ±`.

#### 8) Pr√°ctica guiada
- Imprime cada 100 iteraciones: costo actual. Debe decrecer (aprox).

#### 9) Pr√°ctica independiente
- Implementa early stopping: si la mejora del costo < `tol` por varias iteraciones, det√©n.

#### 10) Autoevaluaci√≥n
- ¬øQu√© pasa si omites el bias? ¬øC√≥mo cambia la recta aprendida?

#### 11) Errores comunes
- No normalizar features ‚Üí GD lento o inestable.
- Mezclar `X` con `X_b` en gradiente/predicci√≥n.
- Reportar R¬≤ en train y creer que generaliza (falta split).

#### 12) Retenci√≥n
- Checklist: bias, shapes, costo decrece, no NaNs, params razonables.

#### 13) Diferenciaci√≥n
- Avanzado: batch vs mini-batch vs SGD (conceptual) y efecto en el ruido del gradiente.

#### 14) Recursos
- Notas de optimizaci√≥n b√°sica, escalado de features.

#### 15) Nota docente
- Pide un ‚Äúprotocolo de debugging‚Äù: 1) overfit test en dataset peque√±o, 2) comparar con normal equation.
</details>

---

## üíª Parte 2: Regresi√≥n Log√≠stica

### 2.0 Regresi√≥n Log√≠stica ‚Äî Nivel: intermedio (core del Pathway)

**Prop√≥sito:** pasar de ‚Äús√© aplicar sigmoid‚Äù a **poder entrenar, derivar y validar** un clasificador binario (y extenderlo a multiclase con One-vs-All).

#### Objetivos de aprendizaje (medibles)

Al terminar esta parte podr√°s:

- **Explicar** por qu√© regresi√≥n log√≠stica es un modelo lineal *sobre el log-odds* (aunque la salida sea una probabilidad).
- **Derivar** (a mano) el gradiente de la p√©rdida *Binary Cross-Entropy* y reconocer la forma `X·µÄ(≈∑ - y)`.
- **Implementar** `fit()` con gradient descent estable (con `clip`/`eps`) y verificar convergencia.
- **Diagnosticar** errores t√≠picos: shapes, overflow en `exp`, signos invertidos, saturaci√≥n de sigmoid.
- **Validar** tu implementaci√≥n con **Shadow Mode** (comparaci√≥n con sklearn) y con un *overfit test* en dataset peque√±o.

#### Prerrequisitos

- De `M√≥dulo 03`: Chain Rule y gradiente.
- De `M√≥dulo 04`: interpretaci√≥n de MLE (conexi√≥n con cross-entropy).

Enlaces r√°pidos:

- [GLOSARIO: Logistic Regression](GLOSARIO.md#logistic-regression)
- [GLOSARIO: Sigmoid](GLOSARIO.md#sigmoid)
- [GLOSARIO: Binary Cross-Entropy](GLOSARIO.md#binary-cross-entropy)
- [GLOSARIO: Gradient Descent](GLOSARIO.md#gradient-descent)
- [RECURSOS.md](RECURSOS.md)

#### Explicaci√≥n progresiva (intuici√≥n ‚Üí formalizaci√≥n ‚Üí implementaci√≥n)

##### a) Intuici√≥n

Quieres un modelo que devuelva:

- un **score lineal** `z = Œ∏·µÄx` (como en regresi√≥n lineal), y
- lo convierta en una **probabilidad** en `(0, 1)`.

Eso lo hace `œÉ(z)`.

##### a.1 Odds, log-odds y por qu√© esto ‚Äúsigue siendo lineal‚Äù

Si el modelo produce `p = P(y=1|x)`, define:

```
odds = p / (1 - p)
logit(p) = log(odds)
```

La regresi√≥n log√≠stica asume que **el log-odds es lineal**:

```
logit(p) = Œ∏·µÄx
```

Y la sigmoide es simplemente la funci√≥n que vuelve de logit a probabilidad:

```
p = œÉ(Œ∏·µÄx) = 1 / (1 + exp(-Œ∏·µÄx))
```

Esto importa porque te permite interpretar el modelo:

- subir `Œ∏·µÄx` en +1 incrementa el **log-odds** en +1 (cambio multiplicativo en odds).

##### a.2 Por qu√© NO usar MSE para clasificaci√≥n

Podr√≠as intentar usar MSE con `≈∑ = œÉ(z)`, pero en pr√°ctica es mala idea:

- **La geometr√≠a del entrenamiento empeora:** el gradiente se vuelve poco informativo cuando `œÉ(z)` se satura (cerca de 0 o 1).
- **La funci√≥n objetivo deja de ser convexa** (puede tener m√≠nimos locales / mesetas), haciendo el descenso de gradiente menos confiable.
- **No penaliza bien el caso ‚Äúseguro y equivocado‚Äù:** si `y=1` pero `≈∑‚âà0`, quieres un castigo enorme; eso lo da `-log(≈∑)`.

Por eso usamos **Log-Loss / Binary Cross-Entropy**, que viene de MLE y es convexa para este modelo.

##### a.3 Visual: frontera de decisi√≥n

La frontera de decisi√≥n es el conjunto de puntos donde `p = 0.5`:

```
œÉ(Œ∏·µÄx) = 0.5  ‚áî  Œ∏·µÄx = 0
```

##### a.3.1 Intuici√≥n geom√©trica: el ‚Äúplano de corte‚Äù

Piensa en tus datos como puntos en un espacio.

- En 2D, `Œ∏·µÄx + b = 0` es una **l√≠nea**.
- En 3D, es un **plano**.
- En `n` dimensiones, es un **hiperplano**.

La cantidad `z = Œ∏·µÄx + b` es un **score con signo**:

- `z > 0` ‚Üí est√°s del lado ‚Äúpositivo‚Äù del plano
- `z < 0` ‚Üí est√°s del lado ‚Äúnegativo‚Äù

La sigmoide `œÉ(z)` convierte ese score (relacionado con la distancia al plano) en probabilidad:

- puntos muy lejos del plano (|z| grande) ‚Üí probabilidad cerca de 0 o 1
- puntos cerca del plano (`z ‚âà 0`) ‚Üí probabilidad cerca de 0.5

Visualizaci√≥n sugerida (dib√∫jalo): una nube roja/azul y una l√≠nea que la corta; marca puntos a distinta distancia y escribe su `z` y `œÉ(z)`.

##### a.3.2 Conexi√≥n conceptual: SVM y la idea de ‚Äúmargen‚Äù (sin implementar)

Aunque no implementes SVM aqu√≠, su intuici√≥n te mejora la comprensi√≥n de regularizaci√≥n.

Idea:

- En clasificaci√≥n lineal, hay muchas l√≠neas/planos que separan (si los datos lo permiten).
- SVM busca el separador que deja la ‚Äúcarretera‚Äù m√°s ancha entre clases: **m√°ximo margen**.

Conexi√≥n con lo que s√≠ implementas:

- La **regularizaci√≥n** (L2/L1) controla complejidad efectiva.
- En problemas separables o casi separables, regularizar suele empujar a soluciones m√°s estables, con fronteras menos extremas.

Visualizaci√≥n sugerida: dos l√≠neas separadoras posibles y dibujar cu√°l deja m√°s espacio m√≠nimo a los puntos m√°s cercanos (support vectors).

En 2D, `Œ∏·µÄx = 0` es una **l√≠nea**.

```
clase 1:   o o o o o
           o o o o o

frontera:  ---------

clase 0:   x x x x x
           x x x x x
```

##### a.4 Worked example (num√©rico) de BCE

Datos: `x=2`, `y=1`.

- `w=0.5`, `b=0`
- `z = wx + b = 1`
- `≈∑ = œÉ(1) ‚âà 0.731`

Como `y=1`, la loss por muestra es:

```
L = -log(≈∑) ‚âà -log(0.731) ‚âà 0.313
```

Interpretaci√≥n: la predicci√≥n es ‚Äúbastante‚Äù correcta, por eso la loss es peque√±a. Si `≈∑` fuera 0.01, la loss ser√≠a enorme.

##### a.5 C√≥digo generador de intuici√≥n (Protocolo D): frontera de decisi√≥n en 2D

Objetivo: ver que la **frontera de decisi√≥n** (`p=0.5`) es lineal, aunque la salida `œÉ(z)` sea curva (curva en *probabilidad*, no en geometr√≠a de la frontera).

```python
import numpy as np
import matplotlib.pyplot as plt


def make_blobs_2d(n=200, seed=42):
    rng = np.random.default_rng(seed)
    c0 = rng.normal(loc=(-2.0, -1.5), scale=0.8, size=(n // 2, 2))
    c1 = rng.normal(loc=(2.0, 1.5), scale=0.8, size=(n // 2, 2))
    X = np.vstack([c0, c1])
    y = np.array([0] * (n // 2) + [1] * (n // 2))
    return X, y


def sigmoid(z):
    z = np.clip(z, -500, 500)
    return 1 / (1 + np.exp(-z))


def add_bias(X):
    return np.column_stack([np.ones(len(X)), X])


def plot_decision_boundary(model, X, y, title="Decision boundary"):
    x_min, x_max = X[:, 0].min() - 1.0, X[:, 0].max() + 1.0
    y_min, y_max = X[:, 1].min() - 1.0, X[:, 1].max() + 1.0

    xx, yy = np.meshgrid(
        np.linspace(x_min, x_max, 250),
        np.linspace(y_min, y_max, 250),
    )

    grid = np.column_stack([xx.ravel(), yy.ravel()])
    proba = model.predict_proba(grid).reshape(xx.shape)

    plt.figure(figsize=(7, 6))
    plt.contourf(xx, yy, proba, levels=20, cmap="RdBu", alpha=0.35)
    plt.contour(xx, yy, proba, levels=[0.5], colors="black", linewidths=2)

    plt.scatter(X[y == 0, 0], X[y == 0, 1], s=18, label="Clase 0")
    plt.scatter(X[y == 1, 0], X[y == 1, 1], s=18, label="Clase 1")

    plt.title(title)
    plt.legend()
    plt.grid(True, alpha=0.2)
    plt.show()


# Usa TU LogisticRegression del m√≥dulo (la clase ya existe m√°s abajo)
# X, y = make_blobs_2d(n=300)
# model = LogisticRegression()
# model.fit(X, y, learning_rate=0.1, n_iterations=2000)
# plot_decision_boundary(model, X, y)
```

Reto visual (opcional, si usas sklearn solo para generar datos):

- genera `make_moons` y grafica la frontera
- ver√°s por qu√© log√≠stica falla (frontera lineal)
- luego entrena tu MLP (M07) y observa c√≥mo la frontera se curva

##### b) Formalizaci√≥n m√≠nima

- **Modelo:** `≈∑ = œÉ(XŒ∏)`
- **Decisi√≥n:** `≈∑ ‚â• 0.5 ‚Üí clase 1` (umbral configurable)
- **Loss (BCE):** penaliza fuerte cuando est√°s ‚Äúseguro y equivocado‚Äù (ej. `≈∑‚âà0` pero `y=1`).

##### c) Regla de oro de shapes

Evita bugs silenciosos usando una convenci√≥n consistente:

- `X`: `(m, n)`
- `Œ∏`: `(n,)` (o `(n, 1)` si prefieres columnas)
- `y`: `(m,)`

Y verifica que `X @ Œ∏` te da `(m,)`.

#### Actividades activas (para convertir teor√≠a en habilidad)

- **Retrieval practice (5 min):** escribe sin mirar:
  - la ecuaci√≥n de BCE,
  - el gradiente `‚àáŒ∏`.
- **Ejercicio de calibraci√≥n:** cambia el `threshold` de 0.5 a 0.3 y explica qu√© pasa con precision/recall.
- **Sanity check obligatorio:** entrena con 20 ejemplos hasta obtener accuracy ~100% (si no, hay bug).

#### Evaluaci√≥n (criterios de ‚Äúdominio‚Äù)

- **Dominio matem√°tico:** puedes explicar por qu√© aparece `(≈∑ - y)` en el gradiente.
- **Dominio de implementaci√≥n:** tu `fit()` reduce BCE de forma monot√≥nica (o casi) en un dataset simple.
- **Dominio de validaci√≥n:** tu accuracy difiere <5% de sklearn en Shadow Mode.

#### Errores comunes (los que m√°s queman tiempo)

- **Overflow/NaN:** `exp(500)` revienta. Soluci√≥n: `clip(z)` y `eps` en logs.
- **Saturaci√≥n:** si `|z|` crece, `œÉ(z)` se pega a 0/1 y el gradiente se hace peque√±o.
- **Signo invertido:** si actualizas en la direcci√≥n equivocada, la loss sube.
- **Sin normalizaci√≥n:** features en escalas muy distintas hacen que GD sea inestable.

#### Integraci√≥n con Plan v4/v5

- **v4.0:** usa `study_tools/SIMULACRO_EXAMEN_TEORICO.md` para preguntas tipo examen (sigmoid vs softmax, BCE vs MSE).
- **v5.0:** ejecuta **Shadow Mode** como verificaci√≥n externa antes de dar por terminado el m√≥dulo.

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 2.0: Regresi√≥n Log√≠stica (marco mental completo)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Qu√© est√°s construyendo realmente: probabilidades, decisi√≥n, loss y gradiente (una sola historia)
- **ID (opcional):** `M05-T02_0`
- **Duraci√≥n estimada:** 90‚Äì150 min
- **Nivel:** Intermedio (core)
- **Dependencias:** M03 (chain rule), M04 (MLE ‚Üí cross-entropy)

#### 2) Objetivos
- Unificar en una frase el pipeline: `z = XŒ∏` ‚Üí `p = œÉ(z)` ‚Üí `loss = BCE(p,y)` ‚Üí `grad = X·µÄ(p-y)/m` ‚Üí update.
- Explicar por qu√© log√≠stica es ‚Äúlineal‚Äù en la frontera, aunque `œÉ` sea no lineal.
- Saber qu√© debes observar cuando algo falla (NaNs, saturaci√≥n, signos, shapes).

#### 3) Relevancia
- Esta secci√≥n es el puente directo a MLP/softmax (M07): cambia `œÉ` por softmax y `BCE` por CCE, pero el esqueleto es el mismo.

#### 4) Mapa conceptual m√≠nimo
- **Modelo:** `p(y=1|x) = œÉ(Œ∏·µÄx)`.
- **Decisi√≥n:** `p ‚â• threshold`.
- **Entrenamiento (MLE):** minimizar NLL = BCE.
- **Gradiente vectorizado:** siempre termina en `X·µÄ(something)`.

#### 5) Definiciones esenciales
- **Logit:** `z = Œ∏·µÄx` (score sin acotar).
- **Probabilidad:** `p = œÉ(z)`.
- **Loss BCE:** castiga fuerte ‚Äúseguro y equivocado‚Äù.

#### 6) Explicaci√≥n did√°ctica
- Lo m√°s importante no es memorizar f√≥rmulas, sino saber qu√© variable inspeccionar:
  - si `p` es 0/1 exacto ‚Üí `log(0)` rompe ‚Üí `eps`.
  - si `|z|` es enorme ‚Üí saturaci√≥n ‚Üí gradiente peque√±o.

#### 7) Ejemplo modelado
- Si tu modelo predice `p=0.01` cuando `y=1`, BCE es grande; eso fuerza una correcci√≥n fuerte del gradiente.

#### 8) Pr√°ctica guiada
- Haz un ‚Äúoverfit test‚Äù con 20 ejemplos y confirma que BCE cae y accuracy sube.

#### 9) Pr√°ctica independiente
- Cambia `threshold` y observa el tradeoff precision/recall (lo conectar√°s con m√©tricas en Parte 3).

#### 10) Autoevaluaci√≥n
- ¬øCu√°l es la √∫nica pieza que convierte un score lineal en probabilidad? (respuesta: `œÉ`).

#### 11) Errores comunes
- Entrenar con `y‚àà{-1,1}` usando BCE est√°ndar.
- Olvidar bias.
- Mezclar `X` con `X_b` (con bias) en distintas funciones.

#### 12) Retenci√≥n
- Recita el mantra: `z‚ÜíœÉ(z)‚ÜíBCE‚ÜíX·µÄ(p-y)`.

#### 13) Diferenciaci√≥n
- Avanzado: interpreta `Œ∏` como direcci√≥n normal al hiperplano; magnitud controla ‚Äúconfianza‚Äù.

#### 14) Recursos
- M04 (MLE/cross-entropy) y glosario de sigmoid/logistic regression.

#### 15) Nota docente
- Pide al alumno un diagrama de flujo con shapes: `X:(m,n)`, `Œ∏:(n,)`, `z:(m,)`, `p:(m,)`, `grad:(n,)`.
</details>

### 2.1 Funci√≥n Sigmoid

```python
import numpy as np  # Importa NumPy para operaciones matem√°ticas

def sigmoid(z: np.ndarray) -> np.ndarray:
    """
    Funci√≥n sigmoid/log√≠stica.

    œÉ(z) = 1 / (1 + e^(-z))

    Propiedades:
    - Rango: (0, 1) - perfecto para probabilidades
    - œÉ(0) = 0.5
    - œÉ'(z) = œÉ(z)(1 - œÉ(z))
    """
    # Clip para evitar overflow en exp() con valores extremos
    z = np.clip(z, -500, 500)
    return 1 / (1 + np.exp(-z))  # F√≥rmula matem√°tica de la sigmoide

# Visualizar la funci√≥n sigmoid
import matplotlib.pyplot as plt  # Importa matplotlib para gr√°ficos

z = np.linspace(-10, 10, 100)  # Valores de prueba de -10 a 10
plt.figure(figsize=(8, 4))  # Crea figura de 8x4 pulgadas
plt.plot(z, sigmoid(z))  # Grafica sigmoid(z)
plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5)  # L√≠nea horizontal en y=0.5
plt.axvline(x=0, color='r', linestyle='--', alpha=0.5)  # L√≠nea vertical en x=0
plt.xlabel('z')  # Etiqueta eje x
plt.ylabel('œÉ(z)')  # Etiqueta eje y
plt.title('Funci√≥n Sigmoid')  # T√≠tulo del gr√°fico
plt.grid(True)  # Activa cuadr√≠cula
# plt.show()  # Descomentar para mostrar gr√°fico
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 2.1: Sigmoid (intuici√≥n + estabilidad num√©rica)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Sigmoid como ‚Äúpuerta‚Äù a probabilidades y por qu√© hay que hacer `clip`
- **ID (opcional):** `M05-T02_1`
- **Duraci√≥n estimada:** 45‚Äì90 min
- **Nivel:** B√°sico‚ÄìIntermedio
- **Dependencias:** Exponencial/log, overflow/underflow

#### 2) Objetivos
- Entender que `œÉ(z)` solo reescala el score a `(0,1)`; no hace la frontera no lineal.
- Reconocer saturaci√≥n: `z>>0 ‚Üí œÉ‚âà1` y `z<<0 ‚Üí œÉ‚âà0`.
- Justificar `clip(z)` como protecci√≥n num√©rica.

#### 3) Relevancia
- Si no controlas overflow/saturaci√≥n, tu BCE se vuelve NaN y el entrenamiento colapsa.

#### 4) Mapa conceptual m√≠nimo
- `z` crece ‚Üí `exp(-z)` puede underflow; `z` muy negativo ‚Üí `exp(-z)` overflow.

#### 5) Definiciones esenciales
- `œÉ(0)=0.5`.
- `œÉ'(z)=œÉ(z)(1-œÉ(z))` (m√°xima en 0, m√≠nima en extremos).

#### 6) Explicaci√≥n did√°ctica
- Cuando `œÉ` se satura, el gradiente se vuelve peque√±o: puede ‚Äúaprender lento‚Äù aunque el error sea real.

#### 7) Ejemplo modelado
- Prueba `z=[-1000,0,1000]` y observa que sin `clip` puedes romper `exp`.

#### 8) Pr√°ctica guiada
- Escribe un test: `sigmoid(np.array([0.0]))==0.5` (aprox).

#### 9) Pr√°ctica independiente
- Implementa una sigmoid estable alternativa (log-sum-exp) y compara.

#### 10) Autoevaluaci√≥n
- ¬øQu√© pasa con `œÉ'(z)` cuando `z` es muy grande en valor absoluto?

#### 11) Errores comunes
- Creer que sigmoid ‚Äúhace no lineal‚Äù la frontera.

#### 12) Retenci√≥n
- ‚ÄúSigmoid curva la probabilidad, no la geometr√≠a del plano‚Äù.

#### 13) Diferenciaci√≥n
- Avanzado: relaci√≥n entre sigmoid y logit.

#### 14) Recursos
- Material de estabilidad num√©rica (overflow/underflow).

#### 15) Nota docente
- Pedir al alumno que explique por qu√© `clip` es un *guardrail* y no un ‚Äúhack‚Äù.
</details>

### 2.2 Hip√≥tesis Log√≠stica

```python
"""
REGRESI√ìN LOG√çSTICA

No predice un valor continuo, sino la PROBABILIDAD de pertenecer a la clase 1.

h(x) = P(y=1|x; Œ∏) = œÉ(Œ∏·µÄx)

Decisi√≥n:
- Si h(x) ‚â• 0.5 ‚Üí predicir clase 1
- Si h(x) < 0.5 ‚Üí predicir clase 0

Equivalente a:
- Si Œ∏·µÄx ‚â• 0 ‚Üí clase 1
- Si Œ∏·µÄx < 0 ‚Üí clase 0

El "decision boundary" est√° en Œ∏·µÄx = 0
"""

def predict_proba(X: np.ndarray, theta: np.ndarray) -> np.ndarray:
    """Predice probabilidad de clase 1."""
    return sigmoid(X @ theta)

def predict_class(X: np.ndarray, theta: np.ndarray, threshold: float = 0.5) -> np.ndarray:
    """Predice clase (0 o 1)."""
    return (predict_proba(X, theta) >= threshold).astype(int)
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 2.2: Hip√≥tesis + umbral (qu√© significa predecir)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Probabilidad vs clase: `predict_proba` y `predict_class` no son lo mismo
- **ID (opcional):** `M05-T02_2`
- **Duraci√≥n estimada:** 45‚Äì90 min
- **Nivel:** Intermedio
- **Dependencias:** 2.1

#### 2) Objetivos
- Separar claramente: score `z`, probabilidad `p`, decisi√≥n `≈∑`.
- Entender el papel del `threshold` como decisi√≥n de negocio (no matem√°tica fija).

#### 3) Relevancia
- Cambiar `threshold` es una de las maneras m√°s simples y potentes de controlar FP vs FN (ver√°s esto en m√©tricas).

#### 4) Mapa conceptual m√≠nimo
- `predict_proba` te da un ranking de ‚Äúconfianza‚Äù.
- `predict_class` es una pol√≠tica: ‚Äúsi p‚â•t, digo 1‚Äù.

#### 5) Definiciones esenciales
- **Frontera:** `Œ∏·µÄx=0` si `t=0.5`.

#### 6) Explicaci√≥n did√°ctica
- `t=0.5` es convencional; si el costo de FN es alto, baja el umbral.

#### 7) Ejemplo modelado
- En spam: prefieres recall alto ‚Üí `threshold` m√°s bajo (aceptas m√°s FP).

#### 8) Pr√°ctica guiada
- Eval√∫a el mismo modelo con `t=0.3,0.5,0.7` y registra cambios de precision/recall.

#### 9) Pr√°ctica independiente
- Encuentra un `threshold` que maximice F1 en un dataset de validaci√≥n.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© dos modelos con igual accuracy pueden ser muy distintos cuando cambias `threshold`?

#### 11) Errores comunes
- Calcular m√©tricas usando probabilidades como si fueran clases.

#### 12) Retenci√≥n
- ‚ÄúPrimero calibro y eval√∫o probabilidades; luego decido clases con un umbral‚Äù.

#### 13) Diferenciaci√≥n
- Avanzado: curva ROC/PR (conceptual) como barrido de thresholds.

#### 14) Recursos
- Glosario: precision/recall y confusion matrix.

#### 15) Nota docente
- Pide que el alumno explique verbalmente qu√© significa: ‚Äúpredigo 1 si p‚â•0.3‚Äù.
</details>

### 2.3 Binary Cross-Entropy Loss

```python
import numpy as np

def binary_cross_entropy(
    X: np.ndarray,
    y: np.ndarray,
    theta: np.ndarray,
    eps: float = 1e-15
) -> float:
    """
    Binary Cross-Entropy (Log Loss).

    J(Œ∏) = -(1/m) Œ£·µ¢ [y·µ¢ log(h·µ¢) + (1-y·µ¢) log(1-h·µ¢)]

    Donde h·µ¢ = œÉ(Œ∏·µÄx·µ¢)

    Por qu√© esta funci√≥n de costo:
    - Es convexa (tiene un √∫nico m√≠nimo global)
    - Penaliza mucho las predicciones muy incorrectas
    - Es la derivaci√≥n de Maximum Likelihood Estimation
    """
    m = len(y)
    h = sigmoid(X @ theta)

    # Clip para evitar log(0)
    h = np.clip(h, eps, 1 - eps)

    cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))
    return cost

def bce_gradient(X: np.ndarray, y: np.ndarray, theta: np.ndarray) -> np.ndarray:
    """
    Gradiente de Binary Cross-Entropy.

    ‚àÇJ/‚àÇŒ∏ = (1/m) X·µÄ(h - y)

    ¬°Tiene la misma forma que el gradiente del MSE!
    Esto es porque derivamos œÉ(z) y la derivada œÉ'(z) = œÉ(z)(1-œÉ(z))
    cancela parte de la expresi√≥n.
    """
    m = len(y)
    h = sigmoid(X @ theta)
    return (1/m) * X.T @ (h - y)
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 2.3: BCE + gradiente (lo que debes saber de memoria)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** BCE como NLL (MLE) y por qu√© el gradiente termina en `X·µÄ(p-y)`
- **ID (opcional):** `M05-T02_3`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 2.1‚Äì2.2, logaritmos

#### 2) Objetivos
- Entender BCE como ‚Äúcastigo logar√≠tmico‚Äù a la probabilidad asignada a la clase correcta.
- Memorizar la forma del gradiente vectorizado.
- Entender por qu√© `eps` evita `log(0)` sin cambiar el objetivo conceptual.

#### 3) Relevancia
- Esta es la p√©rdida est√°ndar para binario y base de softmax cross-entropy en multiclase.

#### 4) Mapa conceptual m√≠nimo
- Si `y=1`: loss = `-log(p)`.
- Si `y=0`: loss = `-log(1-p)`.

#### 5) Definiciones esenciales
- `p = œÉ(XŒ∏)`.
- `‚àáŒ∏ = (1/m) X·µÄ(p-y)`.

#### 6) Explicaci√≥n did√°ctica
- El gradiente ‚Äúmide error en probabilidad‚Äù: si `p>y`, empuja hacia abajo; si `p<y`, empuja hacia arriba.

#### 7) Ejemplo modelado
- Una sola muestra: si `y=1` y `p=0.1`, el error `(p-y)` es negativo y el update mueve `Œ∏` para subir `z`.

#### 8) Pr√°ctica guiada
- Haz un gradient check num√©rico en 1 coordenada (diferencias centrales) con dataset peque√±o.

#### 9) Pr√°ctica independiente
- Grafica BCE vs `p` para `y=1` y `y=0` y explica la asimetr√≠a.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© BCE penaliza m√°s el caso ‚Äúseguro y equivocado‚Äù que MSE?

#### 11) Errores comunes
- Usar `y` como int pero con shape `(m,1)` y romper broadcasting.
- No hacer `clip` en `p` antes del log.

#### 12) Retenci√≥n
- F√≥rmula clave: `grad = X·µÄ(p-y)/m`.

#### 13) Diferenciaci√≥n
- Avanzado: relaci√≥n con la entrop√≠a cruzada y KL-divergence.

#### 14) Recursos
- M04 (MLE‚Üícross-entropy), glosario BCE.

#### 15) Nota docente
- Pide que el alumno derive el gradiente una vez y luego lo trate como ‚Äúpatr√≥n‚Äù reusable.
</details>

### 2.4 Implementaci√≥n Completa

```python
import numpy as np
from typing import List

class LogisticRegression:
    """Regresi√≥n Log√≠stica implementada desde cero."""

    def __init__(self):
        self.theta = None
        self.cost_history = []

    def fit(
        self,
        X: np.ndarray,
        y: np.ndarray,
        learning_rate: float = 0.1,
        n_iterations: int = 1000
    ) -> 'LogisticRegression':
        """Entrena con gradient descent."""
        # A√±adir bias
        X_b = np.column_stack([np.ones(len(X)), X])
        m, n = X_b.shape

        # Inicializar
        self.theta = np.zeros(n)

        for i in range(n_iterations):
            # Gradiente
            gradient = bce_gradient(X_b, y, self.theta)

            # Actualizar
            self.theta = self.theta - learning_rate * gradient

            # Guardar costo
            cost = binary_cross_entropy(X_b, y, self.theta)
            self.cost_history.append(cost)

        return self

    def predict_proba(self, X: np.ndarray) -> np.ndarray:
        """Predice probabilidades."""
        X_b = np.column_stack([np.ones(len(X)), X])
        return sigmoid(X_b @ self.theta)

    def predict(self, X: np.ndarray, threshold: float = 0.5) -> np.ndarray:
        """Predice clases."""
        return (self.predict_proba(X) >= threshold).astype(int)

    def score(self, X: np.ndarray, y: np.ndarray) -> float:
        """Accuracy."""
        return np.mean(self.predict(X) == y)


# Demo con datos sint√©ticos
np.random.seed(42)

# Generar datos de dos clases
n_samples = 200
X_class0 = np.random.randn(n_samples // 2, 2) + np.array([-2, -2])
X_class1 = np.random.randn(n_samples // 2, 2) + np.array([2, 2])
X = np.vstack([X_class0, X_class1])
y = np.array([0] * (n_samples // 2) + [1] * (n_samples // 2))

# Entrenar
model = LogisticRegression()
model.fit(X, y, learning_rate=0.1, n_iterations=1000)

print(f"Accuracy: {model.score(X, y):.2%}")
print(f"Par√°metros: {model.theta}")
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 2.4: Implementaci√≥n completa (checklist de robustez)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** C√≥mo saber que tu LogReg ‚Äúfunciona‚Äù: contratos, overfit test y Shadow Mode
- **ID (opcional):** `M05-T02_4`
- **Duraci√≥n estimada:** 90‚Äì150 min
- **Nivel:** Intermedio
- **Dependencias:** 2.1‚Äì2.3

#### 2) Objetivos
- Establecer invariantes: `theta` tama√±o correcto, `cost_history` finito, `predict_proba` en `(0,1)`.
- Detectar r√°pido si GD diverge (cost sube/NaN).
- Ejecutar ‚Äúoverfit test‚Äù como prueba unitaria del entrenamiento.

#### 3) Relevancia
- Un modelo que ‚Äúcorre‚Äù no necesariamente aprende. Necesitas una bater√≠a m√≠nima de checks.

#### 4) Mapa conceptual m√≠nimo
- **Datos** ‚Üí **bias** ‚Üí **sigmoid** ‚Üí **BCE** ‚Üí **grad** ‚Üí **update**.

#### 5) Definiciones esenciales
- `X_b = [1, X]`.
- `theta[0]` es bias.

#### 6) Explicaci√≥n did√°ctica
- Si el costo no baja en un dataset f√°cil, asume bug antes de ‚Äútocar hiperpar√°metros‚Äù.

#### 7) Ejemplo modelado
- Con datos separables (dos gaussianas separadas), deber√≠as obtener accuracy alta.

#### 8) Pr√°ctica guiada
- Imprime cada 100 iteraciones: `cost`. Debe caer en promedio.

#### 9) Pr√°ctica independiente
- A√±ade early stopping y guarda el mejor `theta` por costo.

#### 10) Autoevaluaci√≥n
- ¬øQu√© s√≠ntoma te indica signo invertido en el update? (costo sube sistem√°ticamente).

#### 11) Errores comunes
- No escalar features.
- Confundir `predict_proba` con `predict` en m√©tricas.

#### 12) Retenci√≥n
- Checklist m√≠nimo: `finite`, `monotonic-ish`, `overfit test`, `shadow mode`.

#### 13) Diferenciaci√≥n
- Avanzado: regularizaci√≥n L2 (MAP) y su efecto en estabilidad.

#### 14) Recursos
- Plan v5: validaci√≥n externa y rutina de checks.

#### 15) Nota docente
- Pide evidencia: captura de `cost_history` (inicio vs final) + comparaci√≥n con sklearn.
</details>

---

## üß© Consolidaci√≥n (Regresi√≥n Log√≠stica)

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Consolidaci√≥n LogReg: interpretaci√≥n y criterio de dominio</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** De ‚Äúentrenar un modelo‚Äù a ‚Äúentender qu√© aprendi√≥‚Äù (pesos como explicaci√≥n)
- **ID (opcional):** `M05-CONS-LOGREG`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 2.4

#### 2) Objetivos
- Interpretar el vector de pesos como ‚Äúdirecci√≥n‚Äù que favorece una clase.
- En im√°genes (MNIST), mapear `theta[1:]` a 28√ó28 y explicar regiones importantes.

#### 3) Relevancia
- Esto te entrena para hacer informes: no solo reportar accuracy, sino justificar el comportamiento del modelo.

#### 4) Mapa conceptual m√≠nimo
- Pesos positivos aumentan `z` ‚Üí suben probabilidad de clase 1.
- Pesos negativos disminuyen `z` ‚Üí bajan probabilidad.

#### 5) Definiciones esenciales
- `theta[0]`: bias.
- `theta[1:]`: pesos por feature.

#### 6) Explicaci√≥n did√°ctica
- Interpretaci√≥n correcta es ‚Äúsi sube esta feature, sube/baja el logit‚Äù, no ‚Äúcausa‚Äù.

#### 7) Ejemplo modelado
- Para 0 vs 1, pesos en trazos t√≠picos del ‚Äú1‚Äù deber√≠an ser positivos (seg√∫n c√≥mo codifiques la clase).

#### 8) Pr√°ctica guiada
- Guarda el mapa de pesos y escribe 5 l√≠neas de interpretaci√≥n con hip√≥tesis verificables.

#### 9) Pr√°ctica independiente
- Repite con otra pareja (3 vs 8) y discute por qu√© es m√°s dif√≠cil.

#### 10) Autoevaluaci√≥n
- ¬øC√≥mo cambia la interpretaci√≥n si inviertes qu√© clase es 1 y cu√°l es 0?

#### 11) Errores comunes
- Olvidar remover el bias antes del reshape.
- Interpretar magnitudes sin normalizar features.

#### 12) Retenci√≥n
- ‚ÄúPesos ‚Üí logit ‚Üí probabilidad‚Äù: siempre explica primero qu√© clase corresponde a `y=1`.

#### 13) Diferenciaci√≥n
- Avanzado: inspeccionar errores (top confusiones) y correlacionarlos con regiones de peso.

#### 14) Recursos
- Herramientas de visualizaci√≥n y notas de interpretabilidad lineal.

#### 15) Nota docente
- Pide consistencia: la explicaci√≥n debe predecir qu√© p√≠xeles cambiar√≠an la predicci√≥n.
</details>

### Entregable conceptual (v3.3): Interpretaci√≥n de pesos (LogReg)

Objetivo: conectar el vector de pesos con ‚Äúqu√© est√° mirando‚Äù el modelo.

- Dataset recomendado: MNIST (28x28) en binario (p. ej. 0 vs 1) usando `sklearn.datasets.fetch_openml("mnist_784", as_frame=False)`.
- Entrena tu regresi√≥n log√≠stica sobre im√°genes aplanadas (`784` features).
- Visualiza:
  - toma `theta[1:]` (sin bias), reshapea a `(28, 28)` y grafica con `imshow`.
  - usa un mapa de color divergente (p. ej. centrado en 0) y guarda una imagen.
- Interpreta en 5‚Äì10 l√≠neas:
  - ¬øqu√© regiones tienen peso positivo/negativo?
  - ¬øpor qu√© eso tiene sentido para el d√≠gito?

### Errores comunes

- **Etiquetas incorrectas:** BCE asume `y ‚àà {0,1}` (no `{-1,1}`) si usas la f√≥rmula est√°ndar.
- **Olvidar el bias:** si no agregas columna de 1s, la frontera se forza a pasar por el origen.
- **`exp` overflow:** si `z` crece, `exp(-z)` puede overflow/underflow ‚Üí usa `clip`.
- **`log(0)`:** si `h` llega a 0 o 1 exactos, `log` revienta ‚Üí usa `eps`.
- **Sin escalado:** features con escalas distintas hacen el GD inestable.

### Debugging / validaci√≥n (v5)

- **Overfit test:** entrena con 20 ejemplos hasta casi 100% accuracy. Si no, asume bug.
- **Shadow Mode:** compara con sklearn para la misma semilla/dataset.
- Registra hallazgos en `study_tools/DIARIO_ERRORES.md`.
- Protocolos completos:
  - [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md)
  - [PLAN_V5_ESTRATEGICO.md](PLAN_V5_ESTRATEGICO.md)

### Reto Feynman (tablero blanco)

Explica en 5 l√≠neas o menos:

1) ¬øQu√© es el logit y por qu√© log√≠stica es lineal ‚Äúen el espacio de log-odds‚Äù?
2) ¬øPor qu√© `-log(≈∑)` explota cuando est√°s seguro y equivocado?
3) ¬øQu√© significa `X·µÄ(≈∑ - y)` y por qu√© aparece en el gradiente?

---

## üíª Parte 3: M√©tricas de Evaluaci√≥n

### 3.0 M√©tricas ‚Äî Nivel: intermedio (de ‚Äúcalcular‚Äù a ‚Äútomar decisiones‚Äù)

**Prop√≥sito:** que no te quedes en ‚Äús√© calcular accuracy‚Äù, sino que puedas **elegir la m√©trica correcta seg√∫n el riesgo** (FP vs FN), detectar desbalance de clases y justificar tus decisiones como en un informe.

#### Objetivos de aprendizaje (medibles)

Al terminar esta parte podr√°s:

- **Explicar** la matriz de confusi√≥n y derivar TP/TN/FP/FN sin mirar apuntes.
- **Aplicar** accuracy/precision/recall/F1/specificity y explicar cu√°ndo cada una es adecuada.
- **Analizar** el impacto del umbral (`threshold`) en precision/recall.
- **Diagnosticar** trampas comunes: accuracy alta con clases desbalanceadas, leakage, evaluar sobre train.

#### Prerrequisitos y conexiones

- Conexi√≥n directa con probabilidad/loss:
  - [04_PROBABILIDAD_ML.md](04_PROBABILIDAD_ML.md) (MLE ‚Üí cross-entropy)
- Glosario:
  - [GLOSARIO: Confusion Matrix](GLOSARIO.md#confusion-matrix)
  - [GLOSARIO: Accuracy](GLOSARIO.md#accuracy)
  - [GLOSARIO: Precision](GLOSARIO.md#precision)
  - [GLOSARIO: Recall](GLOSARIO.md#recall)
  - [GLOSARIO: F1 Score](GLOSARIO.md#f1-score)

#### Resumen ejecutivo (big idea)

La m√©trica es una traducci√≥n expl√≠cita de ‚Äúqu√© error es m√°s caro‚Äù:

- Si te preocupa **no perder positivos reales** ‚Üí prioriza **recall**.
- Si te preocupa **no disparar falsas alarmas** ‚Üí prioriza **precision**.
- Si necesitas balance ‚Üí **F1**.
- Si tu dataset est√° balanceado y el costo es sim√©trico ‚Üí **accuracy** puede servir.

#### Actividades activas (obligatorias)

- **Retrieval practice (5 min):** escribe la matriz 2x2 y define TP/TN/FP/FN.
- **Experimento de umbral:** eval√∫a con `threshold = 0.3, 0.5, 0.7` y anota c√≥mo cambian precision/recall.
- **Caso desbalanceado:** crea un dataset donde 95% sea clase 0 y muestra por qu√© accuracy enga√±a.

#### Errores comunes (los que m√°s da√±an resultados)
- **Evaluar en training:** te da una ‚Äúm√©trica falsa‚Äù por overfitting.
- **Leakage:** normalizar/seleccionar features usando todo el dataset antes del split.
- **No fijar semilla:** resultados no reproducibles.

Integraci√≥n con Plan v4/v5:

- [PLAN_V4_ESTRATEGICO.md](PLAN_V4_ESTRATEGICO.md) (rutina + simulacros)
- [PLAN_V5_ESTRATEGICO.md](PLAN_V5_ESTRATEGICO.md) (validaci√≥n externa / rigor)
- Diario: `study_tools/DIARIO_ERRORES.md`

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 3.0: M√©tricas (c√≥mo elegir y no autoenga√±arte)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** M√©tricas como decisi√≥n: qu√© optimizas depende del costo (FP vs FN) y del umbral
- **ID (opcional):** `M05-T03_0`
- **Duraci√≥n estimada:** 90‚Äì150 min
- **Nivel:** Intermedio
- **Dependencias:** LogReg (probabilidades + threshold), matriz de confusi√≥n

#### 2) Objetivos
- Pasar de ‚Äús√© calcular‚Äù a ‚Äús√© elegir‚Äù la m√©trica correcta seg√∫n el problema.
- Entender c√≥mo el `threshold` cambia precision/recall sin re-entrenar el modelo.
- Detectar el caso cl√°sico de autoenga√±o: accuracy alta con dataset desbalanceado.

#### 3) Relevancia
- En proyectos reales, la m√©trica es parte del producto: define qu√© errores toleras.
- M√©tricas conectan directamente con tu pol√≠tica de decisi√≥n (umbral) y con el tipo de informe.

#### 4) Mapa conceptual m√≠nimo
- **Modelo** produce `p(y=1|x)`.
- **Threshold** produce `≈∑`.
- `≈∑` + `y` ‚Üí **confusion matrix** ‚Üí m√©tricas.

#### 5) Definiciones esenciales
- **TP/TN/FP/FN:** conteos base.
- **Precision:** de lo que dije ‚Äúpositivo‚Äù, cu√°nto era positivo.
- **Recall:** de lo positivo real, cu√°nto captur√©.

#### 6) Explicaci√≥n did√°ctica
- Si tu modelo solo da clases, ya tomaste una decisi√≥n de threshold (impl√≠cita). Mejor separar: proba ‚Üí threshold ‚Üí m√©tricas.

#### 7) Ejemplo modelado
- Detecci√≥n de c√°ncer: FN es caro ‚Üí prioriza recall.
- Filtro de spam: FP es caro ‚Üí prioriza precision.

#### 8) Pr√°ctica guiada
- Para un mismo modelo, eval√∫a `threshold` en `{0.3, 0.5, 0.7}` y anota c√≥mo cambian precision/recall.

#### 9) Pr√°ctica independiente
- Crea un dataset con 95% clase 0 y muestra:
  - baseline ‚Äúsiempre 0‚Äù ‚Üí accuracy alta, pero recall para clase 1 = 0.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© no puedes comparar modelos con thresholds distintos sin decir el threshold?

#### 11) Errores comunes
- Reportar solo accuracy.
- Evaluar sobre train y reportar m√©tricas ‚Äúperfectas‚Äù.

#### 12) Retenci√≥n
- Regla: ‚Äúm√©trica = costo impl√≠cito‚Äù (si no lo defines, el modelo decide por ti).

#### 13) Diferenciaci√≥n
- Avanzado: curva PR/ROC como barrido de thresholds (sin cambiar el modelo).

#### 14) Recursos
- Glosario de confusion matrix/precision/recall/F1.

#### 15) Nota docente
- Pide que el alumno justifique una m√©trica con una frase de costo (‚ÄúFN cuesta m√°s que FP‚Äù).
</details>

### 3.1 Matriz de Confusi√≥n

```python
import numpy as np

def confusion_matrix(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:
    """
    Calcula la matriz de confusi√≥n.

    Para clasificaci√≥n binaria:

                    Predicho
                    0       1
    Real    0      TN      FP
            1      FN      TP

    - TP (True Positive): Predijo 1, era 1
    - TN (True Negative): Predijo 0, era 0
    - FP (False Positive): Predijo 1, era 0 (Error Tipo I)
    - FN (False Negative): Predijo 0, era 1 (Error Tipo II)
    """
    classes = np.unique(np.concatenate([y_true, y_pred]))
    n_classes = len(classes)
    cm = np.zeros((n_classes, n_classes), dtype=int)

    for i, true_class in enumerate(classes):
        for j, pred_class in enumerate(classes):
            cm[i, j] = np.sum((y_true == true_class) & (y_pred == pred_class))

    return cm

def extract_tp_tn_fp_fn(y_true: np.ndarray, y_pred: np.ndarray):
    """Extrae TP, TN, FP, FN para clasificaci√≥n binaria."""
    tp = np.sum((y_true == 1) & (y_pred == 1))
    tn = np.sum((y_true == 0) & (y_pred == 0))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == 0))
    return tp, tn, fp, fn
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 3.1: Matriz de Confusi√≥n (la base de todo)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** TP/TN/FP/FN como diagn√≥stico (no como tabla)
- **ID (opcional):** `M05-T03_1`
- **Duraci√≥n estimada:** 45‚Äì90 min
- **Nivel:** Intermedio
- **Dependencias:** Definir expl√≠citamente cu√°l es la clase positiva

#### 2) Objetivos
- Leer la matriz 2√ó2 sin confundirte entre FP y FN.
- Traducir el problema (spam, fraude, c√°ncer, etc.) a ‚Äúqu√© error es m√°s caro‚Äù.
- Usar la matriz para explicar cambios de precision/recall al mover el threshold.

#### 3) Relevancia
- Todas las m√©tricas son funciones de estos cuatro n√∫meros.
- Si FP/FN est√°n invertidos, todo el an√°lisis posterior queda inv√°lido.

#### 4) Mapa conceptual m√≠nimo
- `y_true` vs `y_pred` ‚Üí conteos ‚Üí m√©tricas.
- Cambiar `threshold` mueve masa entre celdas (no crea magia).

#### 5) Definiciones esenciales
- **FP:** predije 1 pero era 0 (alarma falsa).
- **FN:** predije 0 pero era 1 (caso perdido).

#### 6) Explicaci√≥n did√°ctica
- Subir threshold suele:
  - bajar FP (menos alarmas)
  - subir FN (pierdes positivos)

#### 7) Ejemplo modelado
- Si ‚Äúpositivo‚Äù = c√°ncer, FN suele ser m√°s grave que FP.

#### 8) Pr√°ctica guiada
- Crea 10 pares (true,pred) y llena la matriz a mano.

#### 9) Pr√°ctica independiente
- Repite con una definici√≥n distinta de ‚Äúpositivo‚Äù y observa c√≥mo cambia la interpretaci√≥n.

#### 10) Autoevaluaci√≥n
- ¬øQu√© celda corresponde a ‚Äúdije 0 pero era 1‚Äù?

#### 11) Errores comunes
- No declarar clase positiva.
- Intercambiar FP/FN.

#### 12) Retenci√≥n
- Atajo: FP = (pred 1, true 0), FN = (pred 0, true 1).

#### 13) Diferenciaci√≥n
- Multiclase: matriz K√óK, y cada clase se puede analizar como one-vs-rest.

#### 14) Recursos
- Glosario: Confusion Matrix.

#### 15) Nota docente
- Exige que el alumno explique un FP y un FN con un ejemplo de su dominio.
</details>

### 3.2 Accuracy, Precision, Recall, F1

```python
import numpy as np

def accuracy(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """
    Accuracy = (TP + TN) / (TP + TN + FP + FN)

    Proporci√≥n de predicciones correctas.

    Problema: Puede ser enga√±oso con clases desbalanceadas.
    Si 99% son clase 0, predecir siempre 0 da 99% accuracy.
    """
    return np.mean(y_true == y_pred)

def precision(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """
    Precision = TP / (TP + FP)

    De todos los que predije como positivos, ¬øcu√°ntos realmente lo son?

    Alta precisi√≥n = pocos falsos positivos.
    Importante cuando el costo de FP es alto (ej: spam ‚Üí inbox).
    """
    tp, tn, fp, fn = extract_tp_tn_fp_fn(y_true, y_pred)
    if tp + fp == 0:
        return 0.0
    return tp / (tp + fp)

def recall(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """
    Recall (Sensitivity, True Positive Rate) = TP / (TP + FN)

    De todos los positivos reales, ¬øcu√°ntos captur√©?

    Alto recall = pocos falsos negativos.
    Importante cuando el costo de FN es alto (ej: detecci√≥n de c√°ncer).
    """
    tp, tn, fp, fn = extract_tp_tn_fp_fn(y_true, y_pred)
    if tp + fn == 0:
        return 0.0
    return tp / (tp + fn)

def f1_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """
    F1 = 2 * (precision * recall) / (precision + recall)

    Media arm√≥nica de precision y recall.

    √ötil cuando quieres un balance entre ambas m√©tricas.
    F1 alto solo si AMBAS precision y recall son altas.
    """
    p = precision(y_true, y_pred)
    r = recall(y_true, y_pred)
    if p + r == 0:
        return 0.0
    return 2 * (p * r) / (p + r)

def specificity(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """
    Specificity (True Negative Rate) = TN / (TN + FP)

    De todos los negativos reales, ¬øcu√°ntos identifiqu√©?
    """
    tp, tn, fp, fn = extract_tp_tn_fp_fn(y_true, y_pred)
    if tn + fp == 0:
        return 0.0
    return tn / (tn + fp)
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 3.2: Accuracy/Precision/Recall/F1 (cu√°ndo usar cada una)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Elegir m√©trica = declarar costo (y reportar threshold)
- **ID (opcional):** `M05-T03_2`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 3.1

#### 2) Objetivos
- Identificar cu√°ndo accuracy es enga√±osa (desbalance).
- Elegir precision vs recall seg√∫n el costo de FP vs FN.
- Entender F1 como balance: cae si una de las dos es baja.

#### 3) Relevancia
- Aqu√≠ defines ‚Äúqu√© significa que el modelo sea bueno‚Äù.

#### 4) Mapa conceptual m√≠nimo
- accuracy: desempe√±o global.
- precision: control de FP.
- recall: control de FN.
- F1: balance precision/recall.

#### 5) Definiciones esenciales
- **Precision** responde: ‚Äúsi dije 1, ¬øcu√°ntas veces acert√©?‚Äù
- **Recall** responde: ‚Äúde los 1 reales, ¬øcu√°ntos encontr√©?‚Äù

#### 6) Explicaci√≥n did√°ctica
- Al subir threshold, normalmente sube precision y baja recall.

#### 7) Ejemplo modelado
- Modelo conservador: predice pocos 1 ‚Üí precision alta, recall baja.

#### 8) Pr√°ctica guiada
- Con el mismo conjunto, eval√∫a `threshold` en 0.3/0.5/0.7 y compara.

#### 9) Pr√°ctica independiente
- Busca un threshold que maximice F1 en validaci√≥n y reporta (F1, threshold).

#### 10) Autoevaluaci√≥n
- ¬øQu√© te falta para reproducir el mismo reporte ma√±ana?

#### 11) Errores comunes
- Reportar m√©tricas sin decir threshold.
- Optimizar F1 sin justificar el costo del error.

#### 12) Retenci√≥n
- Regla: costo ‚Üí m√©trica ‚Üí threshold.

#### 13) Diferenciaci√≥n
- Multiclase: macro vs micro (cuando las clases est√°n desbalanceadas).

#### 14) Recursos
- Glosario: Precision/Recall/F1.

#### 15) Nota docente
- Obliga a que el alumno elija una m√©trica y la defienda con una frase de costo.
</details>

### 3.3 Clase Metrics Completa

```python
import numpy as np
from dataclasses import dataclass

@dataclass
class ClassificationReport:
    """Reporte de m√©tricas de clasificaci√≥n."""
    accuracy: float
    precision: float
    recall: float
    f1: float
    specificity: float
    confusion_matrix: np.ndarray

    def __str__(self) -> str:
        cm = self.confusion_matrix
        return f"""
Classification Report
=====================
Accuracy:    {self.accuracy:.4f}
Precision:   {self.precision:.4f}
Recall:      {self.recall:.4f}
F1 Score:    {self.f1:.4f}
Specificity: {self.specificity:.4f}

Confusion Matrix:
           Pred 0  Pred 1
Actual 0   {cm[0,0]:5d}   {cm[0,1]:5d}
Actual 1   {cm[1,0]:5d}   {cm[1,1]:5d}
"""

def classification_report(y_true: np.ndarray, y_pred: np.ndarray) -> ClassificationReport:
    """Genera reporte completo de m√©tricas."""
    return ClassificationReport(
        accuracy=accuracy(y_true, y_pred),
        precision=precision(y_true, y_pred),
        recall=recall(y_true, y_pred),
        f1=f1_score(y_true, y_pred),
        specificity=specificity(y_true, y_pred),
        confusion_matrix=confusion_matrix(y_true, y_pred)
    )

# Demo
y_true = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])
y_pred = np.array([0, 0, 1, 0, 1, 1, 0, 1, 1, 1])

report = classification_report(y_true, y_pred)
print(report)
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 3.3: Reporte de m√©tricas (de n√∫meros a diagn√≥stico)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Del reporte a la acci√≥n: qu√© cambiar si precision/recall no cumplen
- **ID (opcional):** `M05-T03_3`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 3.1‚Äì3.2

#### 2) Objetivos
- Empaquetar m√©tricas para comparar experimentos sin confusi√≥n.
- Interpretar el reporte como diagn√≥stico: qu√© tipo de error domina.
- Mantener reproducibilidad: mismo split/seed/threshold.

#### 3) Relevancia
- En un proyecto, el reporte es lo que justifica decisiones (no solo el c√≥digo).

#### 4) Mapa conceptual m√≠nimo
- confusion matrix ‚Üí m√©tricas ‚Üí reporte ‚Üí decisi√≥n (threshold/feature/modelo).

#### 5) Definiciones esenciales
- ‚ÄúReporte‚Äù no es solo n√∫meros: requiere contexto (dataset/split/threshold).

#### 6) Explicaci√≥n did√°ctica
- Si el reporte no incluye contexto, es f√°cil autoenga√±arse con comparaciones inv√°lidas.

#### 7) Ejemplo modelado
- Recall bajo: baja threshold o mejora features; Precision baja: sube threshold o reduce ruido.

#### 8) Pr√°ctica guiada
- Cambia 2 predicciones del demo y observa c√≥mo cambian todas las m√©tricas.

#### 9) Pr√°ctica independiente
- Extiende a macro-F1 en multiclase (one-vs-rest).

#### 10) Autoevaluaci√≥n
- ¬øQu√© te falta para reproducir el mismo reporte ma√±ana?

#### 11) Errores comunes
- Comparar reportes de datasets distintos.

#### 12) Retenci√≥n
- ‚ÄúM√©trica sin contexto = n√∫mero sin significado‚Äù.

#### 13) Diferenciaci√≥n
- Avanzado: incluir `mean¬±std` v√≠a cross-validation.

#### 14) Recursos
- Plan v5: disciplina de validaci√≥n y registro de resultados.

#### 15) Nota docente
- Pide una recomendaci√≥n concreta basada en el reporte (threshold/features/datos).
</details>

---

## üíª Parte 4: Validaci√≥n y Regularizaci√≥n

### 4.0 Validaci√≥n y regularizaci√≥n ‚Äî Nivel: intermedio/avanzado

**Prop√≥sito:** aprender el ‚Äúworkflow real‚Äù que evita autoenga√±o:

- dividir datos correctamente
- validar de forma robusta
- controlar overfitting (regularizaci√≥n)

#### Objetivos de aprendizaje (medibles)

Al terminar esta parte podr√°s:

- **Explicar** la diferencia entre train/val/test y por qu√© el test no se toca.
- **Aplicar** K-fold cross validation y reportar media ¬± desviaci√≥n.
- **Diagnosticar** sesgo-varianza en t√©rminos pr√°cticos (qu√© cambia si aumentas `Œª` o si cambias el tama√±o del modelo).
- **Implementar** regularizaci√≥n L2 y justificar por qu√© se excluye el bias.

#### Resumen ejecutivo (big idea)

- **Validaci√≥n** te dice si generalizas.
- **Regularizaci√≥n** controla complejidad efectiva.

Conectar esto con el Pathway:

- En el curso, se eval√∫a tanto la *matem√°tica* como tu capacidad de **evitar leakage** y reportar resultados correctamente.

#### Actividades activas (obligatorias)

- Ejecuta `train_test_split` con al menos 2 semillas distintas y compara varianza en accuracy.
- Haz K-fold (k=5) y reporta `mean ¬± std`.
- Prueba `lambda_` en `{0, 0.01, 0.1, 1.0}` y describe el efecto.

#### Errores comunes

- **Data leakage** por normalizar antes del split.
- **Elegir hiperpar√°metros mirando el test** (invalidas el test).
- **Regularizar el bias** sin querer.

#### Integraci√≥n con Plan v4/v5

- v4.0: usa simulacros para preguntas tipo examen (`study_tools/SIMULACRO_EXAMEN_TEORICO.md`).
- v5.0: valida tu implementaci√≥n con Shadow Mode (sklearn) antes de cerrar el m√≥dulo.

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 4.0: Validaci√≥n + Regularizaci√≥n (workflow anti-autoenga√±o)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** C√≥mo saber si generalizas: split correcto, validaci√≥n y control de overfitting
- **ID (opcional):** `M05-T04_0`
- **Duraci√≥n estimada:** 90‚Äì150 min
- **Nivel:** Intermedio/Avanzado
- **Dependencias:** M√©tricas (Parte 3), LogReg (Parte 2)

#### 2) Objetivos
- Explicar la diferencia entre train/val/test y por qu√© el test no se toca.
- Entender qu√© pregunta responde K-fold (variancia de performance).
- Entender regularizaci√≥n como control de complejidad efectiva (bias-varianza).

#### 3) Relevancia
- Sin validaci√≥n, puedes ‚Äúganar‚Äù en train y fallar en producci√≥n.
- Regularizaci√≥n es una herramienta central para modelos lineales y redes.

#### 4) Mapa conceptual m√≠nimo
- Entrenar en train.
- Elegir hiperpar√°metros con val (o CV).
- Reportar final en test una sola vez.

#### 5) Definiciones esenciales
- **Leakage:** usar info del test/val al entrenar.
- **Overfitting:** buen train, mal test.

#### 6) Explicaci√≥n did√°ctica
- Si miras el test repetidamente, el test se convierte en ‚Äúval‚Äù sin querer.

#### 7) Ejemplo modelado
- Dos seeds distintas ‚Üí dos splits distintos ‚Üí accuracy distinta: eso es varianza.

#### 8) Pr√°ctica guiada
- Ejecuta 2 splits con semillas diferentes y reporta ambas m√©tricas.

#### 9) Pr√°ctica independiente
- Haz K-fold y reporta `mean ¬± std`.

#### 10) Autoevaluaci√≥n
- ¬øCu√°l conjunto se usa para elegir `lambda_`?

#### 11) Errores comunes
- Normalizar usando todo el dataset antes del split.
- Elegir hiperpar√°metros ‚Äúviendo‚Äù el test.

#### 12) Retenci√≥n
- Regla: test se usa una vez, al final.

#### 13) Diferenciaci√≥n
- Avanzado: nested CV (conceptual) para selecci√≥n + evaluaci√≥n robusta.

#### 14) Recursos
- Plan v5: Shadow Mode para validar implementaciones.

#### 15) Nota docente
- Exigir que el alumno declare expl√≠citamente qu√© datos us√≥ para cada decisi√≥n.
</details>

### 4.1 Train/Test Split

```python
import numpy as np

def train_test_split(
    X: np.ndarray,
    y: np.ndarray,
    test_size: float = 0.2,
    random_state: int = None
) -> tuple:
    """
    Divide datos en conjuntos de entrenamiento y prueba.

    Args:
        X: features
        y: targets
        test_size: proporci√≥n para test (0-1)
        random_state: semilla para reproducibilidad
    """
    if random_state is not None:
        np.random.seed(random_state)

    n = len(y)
    indices = np.random.permutation(n)

    test_size_n = int(n * test_size)
    test_indices = indices[:test_size_n]
    train_indices = indices[test_size_n:]

    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 4.1: Train/Test Split (contratos y fugas)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Split reproducible: qu√© debe ser aleatorio y qu√© debe ser determinista
- **ID (opcional):** `M05-T04_1`
- **Duraci√≥n estimada:** 45‚Äì90 min
- **Nivel:** Intermedio
- **Dependencias:** 4.0

#### 2) Objetivos
- Verificar invariantes: tama√±os de split, alineaci√≥n X/y, sin duplicados.
- Entender el rol de `random_state`.

#### 3) Relevancia
- Si tu split est√° mal, todo el benchmark se vuelve irrelevante.

#### 4) Mapa conceptual m√≠nimo
- Permutar √≠ndices ‚Üí cortar ‚Üí indexar X/y.

#### 5) Definiciones esenciales
- **Reproducibilidad:** misma semilla ‚Üí mismo split.

#### 6) Explicaci√≥n did√°ctica
- Split debe hacerse antes de normalizar/seleccionar features (evita leakage).

#### 7) Ejemplo modelado
- Verifica que `len(train)+len(test)=n`.

#### 8) Pr√°ctica guiada
- Imprime tama√±os y distribuciones de clase por split.

#### 9) Pr√°ctica independiente
- Implementa split estratificado (conceptual) para clasificaci√≥n desbalanceada.

#### 10) Autoevaluaci√≥n
- ¬øQu√© se rompe si `X` y `y` se permutan con √≠ndices distintos?

#### 11) Errores comunes
- Reusar el test para ‚Äúajustar‚Äù el modelo.

#### 12) Retenci√≥n
- Regla: split primero; transformaciones despu√©s (fit en train).

#### 13) Diferenciaci√≥n
- Avanzado: train/val/test + pipelines.

#### 14) Recursos
- Plan v4/v5: disciplina de evaluaci√≥n.

#### 15) Nota docente
- Pide que el alumno identifique 2 formas de leakage y c√≥mo evitarlas.
</details>

### 4.2 K-Fold Cross Validation

```python
import numpy as np
from typing import List, Tuple

def k_fold_split(n: int, k: int) -> List[Tuple[np.ndarray, np.ndarray]]:
    """
    Genera √≠ndices para K-Fold Cross Validation.

    Returns:
        Lista de (train_indices, val_indices) para cada fold
    """
    indices = np.arange(n)
    np.random.shuffle(indices)

    fold_size = n // k
    folds = []

    for i in range(k):
        start = i * fold_size
        end = start + fold_size if i < k - 1 else n

        val_indices = indices[start:end]
        train_indices = np.concatenate([indices[:start], indices[end:]])

        folds.append((train_indices, val_indices))

    return folds

def cross_validate(
    model_class,
    X: np.ndarray,
    y: np.ndarray,
    k: int = 5,
    **model_params
) -> dict:
    """
    Realiza K-Fold Cross Validation.

    Returns:
        Dict con scores de cada fold y promedio
    """
    folds = k_fold_split(len(y), k)
    scores = []

    for i, (train_idx, val_idx) in enumerate(folds):
        # Split
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]

        # Train
        model = model_class()
        model.fit(X_train, y_train, **model_params)

        # Evaluate
        score = model.score(X_val, y_val)
        scores.append(score)

    return {
        'scores': scores,
        'mean': np.mean(scores),
        'std': np.std(scores)
    }

# Demo
# cv_results = cross_validate(LogisticRegression, X, y, k=5, learning_rate=0.1, n_iterations=500)
# print(f"CV Accuracy: {cv_results['mean']:.4f} ¬± {cv_results['std']:.4f}")
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 4.2: K-Fold (qu√© estima y qu√© no)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** K-fold como estimador de varianza y robustez (no como ‚Äúmejorar accuracy‚Äù)
- **ID (opcional):** `M05-T04_2`
- **Duraci√≥n estimada:** 60‚Äì120 min
- **Nivel:** Intermedio
- **Dependencias:** 4.1

#### 2) Objetivos
- Entender que K-fold produce una distribuci√≥n de scores.
- Reportar `mean ¬± std`.
- Evitar errores de leakage en CV (fit transforms dentro de cada fold).

#### 3) Relevancia
- Te da confianza en la estabilidad del modelo.

#### 4) Mapa conceptual m√≠nimo
- Repartir √≠ndices en folds ‚Üí entrenar k veces ‚Üí evaluar k veces.

#### 5) Definiciones esenciales
- **Fold:** partici√≥n usada como validaci√≥n.

#### 6) Explicaci√≥n did√°ctica
- Si la std es alta, tu rendimiento depende demasiado del split.

#### 7) Ejemplo modelado
- `k=5` ‚Üí 5 scores; promedia y reporta dispersi√≥n.

#### 8) Pr√°ctica guiada
- Ejecuta CV con 2 seeds y compara la std.

#### 9) Pr√°ctica independiente
- Implementa un ‚Äúgrid‚Äù peque√±o sobre `learning_rate` y compara medias.

#### 10) Autoevaluaci√≥n
- ¬øPor qu√© CV no reemplaza el test final?

#### 11) Errores comunes
- Elegir hiperpar√°metros y evaluar todo en el mismo CV sin un test final (sobreajuste de selecci√≥n).

#### 12) Retenci√≥n
- Regla: CV para selecci√≥n/estimaci√≥n; test para cierre.

#### 13) Diferenciaci√≥n
- Avanzado: nested CV (conceptual).

#### 14) Recursos
- Notas de validaci√≥n y bias-varianza.

#### 15) Nota docente
- Pide que el alumno explique qu√© significa ‚Äústd alta‚Äù con una analog√≠a.
</details>

### 4.3 Regularizaci√≥n

```python
import numpy as np

class LogisticRegressionRegularized:
    """Logistic Regression con regularizaci√≥n L1/L2."""

    def __init__(self, regularization: str = 'l2', lambda_: float = 0.01):
        """
        Args:
            regularization: 'l1', 'l2', o None
            lambda_: fuerza de regularizaci√≥n
        """
        self.regularization = regularization
        self.lambda_ = lambda_
        self.theta = None
        self.cost_history = []

    def _cost(self, X: np.ndarray, y: np.ndarray) -> float:
        """Costo con regularizaci√≥n."""
        m = len(y)
        h = sigmoid(X @ self.theta)
        h = np.clip(h, 1e-15, 1 - 1e-15)

        # Cross-entropy base
        bce = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))

        # Regularizaci√≥n (excluir bias theta[0])
        if self.regularization == 'l2':
            # Ridge: Œª/2m * Œ£Œ∏‚±º¬≤
            reg = (self.lambda_ / (2 * m)) * np.sum(self.theta[1:] ** 2)
        elif self.regularization == 'l1':
            # Lasso: Œª/m * Œ£|Œ∏‚±º|
            reg = (self.lambda_ / m) * np.sum(np.abs(self.theta[1:]))
        else:
            reg = 0

        return bce + reg

    def _gradient(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:
        """Gradiente con regularizaci√≥n."""
        m = len(y)
        h = sigmoid(X @ self.theta)

        # Gradiente base
        grad = (1/m) * X.T @ (h - y)

        # Regularizaci√≥n (excluir bias)
        if self.regularization == 'l2':
            reg_grad = np.concatenate([[0], (self.lambda_ / m) * self.theta[1:]])
        elif self.regularization == 'l1':
            reg_grad = np.concatenate([[0], (self.lambda_ / m) * np.sign(self.theta[1:])])
        else:
            reg_grad = 0

        return grad + reg_grad

    def fit(self, X: np.ndarray, y: np.ndarray,
            learning_rate: float = 0.1, n_iterations: int = 1000):
        X_b = np.column_stack([np.ones(len(X)), X])
        self.theta = np.zeros(X_b.shape[1])

        for _ in range(n_iterations):
            gradient = self._gradient(X_b, y)
            self.theta -= learning_rate * gradient
            self.cost_history.append(self._cost(X_b, y))

        return self

    def predict(self, X: np.ndarray) -> np.ndarray:
        X_b = np.column_stack([np.ones(len(X)), X])
        return (sigmoid(X_b @ self.theta) >= 0.5).astype(int)

    def score(self, X: np.ndarray, y: np.ndarray) -> float:
        return np.mean(self.predict(X) == y)
```

<details open>
<summary><strong>üìå Complemento pedag√≥gico ‚Äî Secci√≥n 4.3: Regularizaci√≥n (L1/L2 y por qu√© se excluye el bias)</strong></summary>

#### 1) Metadatos
- **T√≠tulo:** Regularizaci√≥n como control de complejidad: L2 (suaviza) vs L1 (sparse)
- **ID (opcional):** `M05-T04_3`
- **Duraci√≥n estimada:** 90‚Äì150 min
- **Nivel:** Intermedio
- **Dependencias:** 2.3 (BCE/gradiente), 4.0

#### 2) Objetivos
- Entender qu√© t√©rmino se agrega al costo y c√≥mo afecta el gradiente.
- Justificar por qu√© el bias no se regulariza.
- Relacionar `lambda_` con bias-varianza.

#### 3) Relevancia
- Regularizaci√≥n suele ser la diferencia entre generalizar o sobreajustar en modelos lineales.

#### 4) Mapa conceptual m√≠nimo
- Loss base + penalizaci√≥n a pesos ‚Üí update m√°s ‚Äúconservador‚Äù.

#### 5) Definiciones esenciales
- **L2:** penaliza cuadrados (shrink continuo).
- **L1:** penaliza valores absolutos (promueve sparsity).

#### 6) Explicaci√≥n did√°ctica
- Regularizar el bias puede desplazar la frontera innecesariamente.

#### 7) Ejemplo modelado
- Si `lambda_` sube, t√≠picamente bajan magnitudes de `theta[1:]`.

#### 8) Pr√°ctica guiada
- Prueba `lambda_` en `{0,0.01,0.1,1.0}` y observa train/test.

#### 9) Pr√°ctica independiente
- Grafica norma de `theta` vs `lambda_`.

#### 10) Autoevaluaci√≥n
- ¬øQu√© efecto esperas en el gap train-test cuando aumenta `lambda_`?

#### 11) Errores comunes
- Regularizar tambi√©n `theta[0]`.
- Olvidar ajustar el gradiente con el t√©rmino de regularizaci√≥n.

#### 12) Retenci√≥n
- Regla: penaliza pesos, no el bias.

#### 13) Diferenciaci√≥n
- Avanzado: conexi√≥n con MAP (prior gaussiano / laplaciano).

#### 14) Recursos
- Notas de Ridge/Lasso y sesgo-varianza.

#### 15) Nota docente
- Pide que el alumno explique por qu√© L1 puede hacer pesos exactamente 0.
</details>

---

### ‚ö†Ô∏è Aviso cr√≠tico antes de √Årboles: Recursividad (Semana 12)

La implementaci√≥n de √°rboles se basa en **recursi√≥n**. Si no defines y pruebas condiciones de parada, vas a generar √°rboles infinitos o muy profundos.

- Condiciones de parada m√≠nimas: `max_depth`, pureza (todas las etiquetas iguales), `min_samples_split`, ‚Äúno split improves‚Äù.
- Recurso recomendado: https://realpython.com/python-recursion/
- Debug m√≠nimo: imprime `depth`, `n_samples` y el criterio elegido por nodo durante desarrollo.

### Micro-sprint (15 minutos): recursividad m√≠nima para √°rboles

Dos reglas que debes internalizar:

- **Caso base:** el caso m√°s peque√±o que puedes responder inmediatamente (aqu√≠ se detiene la recursi√≥n).
- **Paso recursivo:** reduces el problema a una versi√≥n m√°s peque√±a de s√≠ mismo.

Si no puedes decir el caso base en 1 l√≠nea, tu implementaci√≥n del √°rbol probablemente recursar√° para siempre.

#### Ejemplo: suma recursiva (practica el modelo mental)

```python
from typing import Sequence

def sum_recursive(xs: Sequence[float]) -> float:
    # Caso base: la suma de una lista vac√≠a es 0
    if len(xs) == 0:
        return 0.0

    # Paso recursivo: reduces el problema quitando el primer elemento
    return float(xs[0]) + sum_recursive(xs[1:])


assert sum_recursive([]) == 0.0
assert sum_recursive([3.0]) == 3.0
assert sum_recursive([3.0, 2.0, 5.0]) == 10.0
```

#### Pila de llamadas (lo que Python est√° haciendo)

```text
sum_recursive([3, 2, 5])
= 3 + sum_recursive([2, 5])
    = 2 + sum_recursive([5])
        = 5 + sum_recursive([])
            = 0
```

#### Conexi√≥n con Decision Trees: condiciones de parada = casos base

Al construir un nodo, tu caso base deber√≠a dispararse cuando:

- `depth >= max_depth`
- el nodo es **puro** (todas las etiquetas son iguales)
- `n_samples < min_samples_split`
- ning√∫n split mejora impureza (information gain <= 0)

## üå≥ Parte 5: Tree-Based Models (Semana 12)

Esta semana cubre modelos supervisados **no diferenciables** (no entrenan con Gradient Descent). La l√≥gica de entrenamiento es:

- elegir un *split* (feature + threshold)
- medir qu√© tan ‚Äúpuro‚Äù queda cada lado (Entrop√≠a o Gini)
- repetir recursivamente

### 5.1 Entrop√≠a, Gini e Information Gain

Definiciones base (para clasificaci√≥n):

- **Entrop√≠a:** `H(y) = - Œ£ p(c) log2 p(c)`
- **Gini:** `G(y) = 1 - Œ£ p(c)^2`

Un split `(j, t)` divide el dataset en:

- izquierda: `x_j ‚â§ t`
- derecha: `x_j > t`

La idea es maximizar la mejora en pureza:

- **Information Gain:** `IG = impurity(parent) - weighted_impurity(children)`

### 5.2 Entrenable desde cero (entregable)

Entregable runnable:

- `scripts/decision_tree_from_scratch.py`

Ejecuta:

```bash
python3 scripts/decision_tree_from_scratch.py --criterion gini --max-depth 5
```

Objetivo m√≠nimo:

- que el script entrene un √°rbol y reporte accuracy train/test en un dataset toy
- que puedas explicar (en 5 l√≠neas) c√≥mo el √°rbol decide el mejor split

### 5.3 Ensembles (intro): Bagging vs Boosting

Conceptos clave:

- **Bagging (Random Forest):** muchos √°rboles entrenados en *bootstrap samples*; reduce varianza.
- **Boosting (Gradient Boosting/XGBoost):** √°rboles entrenados secuencialmente corrigiendo errores; reduce bias (pero puede sobreajustar).

---

## üéØ Ejercicios por tema (progresivos) + Soluciones

Reglas:

- **Intenta primero** sin mirar la soluci√≥n.
- **Timebox sugerido:** 20‚Äì45 min por ejercicio.
- **√âxito m√≠nimo:** tu soluci√≥n debe pasar los `assert`.

---

### Ejercicio 5.1: Regresi√≥n lineal (Normal Equation) + recuperaci√≥n de pesos

#### Enunciado

1) **B√°sico**

- Genera un dataset sint√©tico: `y = Xw + noise`.

2) **Intermedio**

- Estima `w_hat` usando la ecuaci√≥n normal con `np.linalg.solve`.

3) **Avanzado**

- Verifica que `w_hat` se aproxima a `w_true` y que el MSE es peque√±o.

#### Soluci√≥n

```python
import numpy as np

np.random.seed(0)
n, d = 500, 3
X = np.random.randn(n, d)
w_true = np.array([0.7, -1.5, 2.0])
noise = 0.05 * np.random.randn(n)
y = X @ w_true + noise

# Normal equation: (X^T X) w = X^T y
XtX = X.T @ X
Xty = X.T @ y
w_hat = np.linalg.solve(XtX, Xty)

mse = np.mean((X @ w_hat - y) ** 2)

assert w_hat.shape == (d,)
assert np.linalg.norm(w_hat - w_true) < 0.15
assert mse < 0.01
```

---

### Ejercicio 5.2: Regresi√≥n lineal (Gradient Descent) + comparaci√≥n con Normal Equation

#### Enunciado

1) **B√°sico**

- Implementa GD para minimizar MSE: `w <- w - Œ± (1/n) X^T (Xw - y)`.

2) **Intermedio**

- Compara `w_gd` contra `w_ne` (normal equation).

3) **Avanzado**

- Verifica que el loss disminuye (al menos al final es menor que al inicio).

#### Soluci√≥n

```python
import numpy as np

np.random.seed(1)
n, d = 400, 4
X = np.random.randn(n, d)
w_true = np.array([1.0, -2.0, 0.5, 3.0])
y = X @ w_true + 0.1 * np.random.randn(n)

XtX = X.T @ X
Xty = X.T @ y
w_ne = np.linalg.solve(XtX, Xty)

w = np.zeros(d)
alpha = 0.05
losses = []
for _ in range(3000):
    r = X @ w - y
    grad = (X.T @ r) / n
    w = w - alpha * grad
    losses.append(float(np.mean(r**2)))

w_gd = w

assert losses[-1] <= losses[0]
assert np.linalg.norm(w_gd - w_ne) < 0.2
```

---

### Ejercicio 5.3: M√©tricas desde una matriz de confusi√≥n (TP/TN/FP/FN)

#### Enunciado

1) **B√°sico**

- Implementa una funci√≥n que compute TP/TN/FP/FN para un problema binario.

2) **Intermedio**

- Implementa accuracy, precision, recall, F1.

3) **Avanzado**

- Valida con un caso conocido y `assert`.

#### Soluci√≥n

```python
import numpy as np

def confusion_counts(y_true: np.ndarray, y_pred: np.ndarray):
    y_true = np.asarray(y_true).astype(int)
    y_pred = np.asarray(y_pred).astype(int)
    tp = int(np.sum((y_true == 1) & (y_pred == 1)))
    tn = int(np.sum((y_true == 0) & (y_pred == 0)))
    fp = int(np.sum((y_true == 0) & (y_pred == 1)))
    fn = int(np.sum((y_true == 1) & (y_pred == 0)))
    return tp, tn, fp, fn


def precision_recall_f1(y_true: np.ndarray, y_pred: np.ndarray):
    tp, tn, fp, fn = confusion_counts(y_true, y_pred)
    eps = 1e-12
    acc = (tp + tn) / (tp + tn + fp + fn + eps)
    prec = tp / (tp + fp + eps)
    rec = tp / (tp + fn + eps)
    f1 = 2 * prec * rec / (prec + rec + eps)
    return float(acc), float(prec), float(rec), float(f1)


y_true = np.array([1, 1, 1, 0, 0, 0])
y_pred = np.array([1, 0, 1, 0, 1, 0])
tp, tn, fp, fn = confusion_counts(y_true, y_pred)

assert (tp, tn, fp, fn) == (2, 2, 1, 1)

acc, prec, rec, f1 = precision_recall_f1(y_true, y_pred)
assert np.isclose(acc, 4/6)
assert np.isclose(prec, 2/3)
assert np.isclose(rec, 2/3)
assert np.isclose(f1, 2/3)
```

---

### Ejercicio 5.4: Logistic Regression - sigmoid + BCE estable

#### Enunciado

1) **B√°sico**

- Implementa `sigmoid(z)` con `np.clip` para evitar overflow.

2) **Intermedio**

- Implementa Binary Cross-Entropy estable (con `clip`).

3) **Avanzado**

- Verifica:
  - BCE cerca de 0 para predicciones casi perfectas.
  - BCE ‚âà `-log(0.9)` cuando `y=1` y `p=0.9`.

#### Soluci√≥n

```python
import numpy as np

def sigmoid(z: np.ndarray) -> np.ndarray:
    z = np.asarray(z, dtype=float)
    z = np.clip(z, -500, 500)
    return 1.0 / (1.0 + np.exp(-z))


def bce(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-15) -> float:
    y_true = np.asarray(y_true, dtype=float)
    y_pred = np.asarray(y_pred, dtype=float)
    y_pred = np.clip(y_pred, eps, 1.0 - eps)
    return float(-np.mean(y_true * np.log(y_pred) + (1.0 - y_true) * np.log(1.0 - y_pred)))


y_true = np.array([1.0, 0.0, 1.0, 0.0])
y_pred_good = np.array([0.999, 0.001, 0.999, 0.001])
assert bce(y_true, y_pred_good) < 0.01
assert np.isclose(bce(np.array([1.0]), np.array([0.9])), -np.log(0.9), atol=1e-12)
```

---

### Ejercicio 5.5: Gradiente de Logistic Regression (verificaci√≥n num√©rica)

#### Enunciado

1) **B√°sico**

- Implementa el gradiente de BCE para Logistic Regression:
  - `≈∑ = sigmoid(Xw)`
  - `‚àáw = (1/n) X^T (≈∑ - y)`

2) **Intermedio**

- Implementa una funci√≥n de p√©rdida `L(w)`.

3) **Avanzado**

- Verifica 1 coordenada del gradiente con diferencias centrales.

#### Soluci√≥n

```python
import numpy as np

def sigmoid(z: np.ndarray) -> np.ndarray:
    z = np.asarray(z, dtype=float)
    z = np.clip(z, -500, 500)
    return 1.0 / (1.0 + np.exp(-z))


def bce_from_logits(X: np.ndarray, y: np.ndarray, w: np.ndarray, eps: float = 1e-15) -> float:
    logits = X @ w
    y_hat = sigmoid(logits)
    y_hat = np.clip(y_hat, eps, 1.0 - eps)
    return float(-np.mean(y * np.log(y_hat) + (1.0 - y) * np.log(1.0 - y_hat)))


def grad_bce(X: np.ndarray, y: np.ndarray, w: np.ndarray) -> np.ndarray:
    y_hat = sigmoid(X @ w)
    return (X.T @ (y_hat - y)) / X.shape[0]


np.random.seed(2)
n, d = 200, 3
X = np.random.randn(n, d)
w0 = np.array([0.3, -0.7, 1.2])
probs = sigmoid(X @ w0)
y = (np.random.rand(n) < probs).astype(float)

w = np.random.randn(d)
g = grad_bce(X, y, w)

idx = 1
h = 1e-6
e = np.zeros(d)
e[idx] = 1.0
L_plus = bce_from_logits(X, y, w + h * e)
L_minus = bce_from_logits(X, y, w - h * e)
g_num = (L_plus - L_minus) / (2.0 * h)

assert np.isclose(g[idx], g_num, rtol=1e-4, atol=1e-6)
```

---

### Ejercicio 5.6: Umbral (threshold) y trade-off precision/recall

#### Enunciado

1) **B√°sico**

- Dadas probabilidades `p` y etiquetas `y`, construye predicciones con umbral `t`.

2) **Intermedio**

- Calcula precision/recall para `t=0.5` y `t=0.3`.

3) **Avanzado**

- Verifica que al bajar el umbral t√≠picamente sube el recall (en el mismo dataset).

#### Soluci√≥n

```python
import numpy as np

def predict_threshold(p: np.ndarray, t: float) -> np.ndarray:
    return (np.asarray(p) >= t).astype(int)


def precision_recall(y_true: np.ndarray, y_pred: np.ndarray):
    y_true = np.asarray(y_true).astype(int)
    y_pred = np.asarray(y_pred).astype(int)
    tp = np.sum((y_true == 1) & (y_pred == 1))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == 0))
    eps = 1e-12
    prec = tp / (tp + fp + eps)
    rec = tp / (tp + fn + eps)
    return float(prec), float(rec)


np.random.seed(3)
y_true = np.array([1, 0, 1, 0, 1, 0, 1, 0])
p = np.array([0.9, 0.6, 0.55, 0.52, 0.4, 0.35, 0.2, 0.1])

pred_05 = predict_threshold(p, 0.5)
pred_03 = predict_threshold(p, 0.3)

prec05, rec05 = precision_recall(y_true, pred_05)
prec03, rec03 = precision_recall(y_true, pred_03)

assert rec03 >= rec05
```

---

### Ejercicio 5.7: Regularizaci√≥n L2 (Ridge) y norma de pesos

#### Enunciado

1) **B√°sico**

- Implementa Ridge Regression: `(X^T X + ŒªI) w = X^T y`.

2) **Intermedio**

- Compara `||w_ridge||` contra `||w_ols||`.

3) **Avanzado**

- Verifica que para `Œª>0`, t√≠picamente `||w_ridge|| <= ||w_ols||`.

#### Soluci√≥n

```python
import numpy as np

np.random.seed(4)
n, d = 300, 5
X = np.random.randn(n, d)
w_true = np.array([2.0, -1.0, 0.5, 0.0, 3.0])
y = X @ w_true + 0.2 * np.random.randn(n)

XtX = X.T @ X
Xty = X.T @ y
w_ols = np.linalg.solve(XtX, Xty)

lam = 10.0
w_ridge = np.linalg.solve(XtX + lam * np.eye(d), Xty)

assert np.linalg.norm(w_ridge) <= np.linalg.norm(w_ols) + 1e-8
```

---

### Ejercicio 5.8: Train/Test split reproducible (semilla)

#### Enunciado

1) **B√°sico**

- Implementa `train_test_split(X,y,test_size,seed)`.

2) **Intermedio**

- Verifica que con la misma semilla el split es id√©ntico.

3) **Avanzado**

- Verifica que no se pierden muestras y que shapes son correctos.

#### Soluci√≥n

```python
import numpy as np

def train_test_split(X: np.ndarray, y: np.ndarray, test_size: float = 0.2, seed: int = 0):
    X = np.asarray(X)
    y = np.asarray(y)
    n = X.shape[0]
    rng = np.random.default_rng(seed)
    idx = np.arange(n)
    rng.shuffle(idx)
    n_test = int(round(n * test_size))
    test_idx = idx[:n_test]
    train_idx = idx[n_test:]
    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]


np.random.seed(0)
X = np.random.randn(100, 2)
y = (np.random.rand(100) < 0.5).astype(int)

Xtr1, Xte1, ytr1, yte1 = train_test_split(X, y, test_size=0.25, seed=42)
Xtr2, Xte2, ytr2, yte2 = train_test_split(X, y, test_size=0.25, seed=42)

assert np.allclose(Xtr1, Xtr2)
assert np.allclose(Xte1, Xte2)
assert np.all(ytr1 == ytr2)
assert np.all(yte1 == yte2)
assert Xtr1.shape[0] + Xte1.shape[0] == 100
```

---

### Ejercicio 5.9: K-Fold cross-validation (partici√≥n correcta)

#### Enunciado

1) **B√°sico**

- Implementa un generador de folds (√≠ndices train/val).

2) **Intermedio**

- Verifica que cada √≠ndice aparece exactamente una vez en validaci√≥n.

3) **Avanzado**

- Verifica que train/val no se solapan.

#### Soluci√≥n

```python
import numpy as np

def kfold_indices(n: int, k: int, seed: int = 0):
    rng = np.random.default_rng(seed)
    idx = np.arange(n)
    rng.shuffle(idx)
    folds = np.array_split(idx, k)
    for i in range(k):
        val_idx = folds[i]
        train_idx = np.concatenate([folds[j] for j in range(k) if j != i])
        yield train_idx, val_idx


n = 23
k = 5
seen = np.zeros(n, dtype=int)
for tr, va in kfold_indices(n, k, seed=123):
    assert len(np.intersect1d(tr, va)) == 0
    seen[va] += 1
assert np.all(seen == 1)
```

---

### Ejercicio 5.10: √Årboles - Gini e Information Gain (split 1D)

#### Enunciado

1) **B√°sico**

- Implementa impurity Gini para etiquetas binarias.

2) **Intermedio**

- Para un feature 1D y un umbral `t`, computa el Information Gain.

3) **Avanzado**

- Encuentra el mejor umbral entre varios candidatos y verifica el resultado.

#### Soluci√≥n

```python
import numpy as np

def gini(y: np.ndarray) -> float:
    y = np.asarray(y).astype(int)
    if y.size == 0:
        return 0.0
    p1 = np.mean(y == 1)
    p0 = 1.0 - p1
    return float(1.0 - (p0**2 + p1**2))


def info_gain_gini(x: np.ndarray, y: np.ndarray, t: float) -> float:
    x = np.asarray(x, dtype=float)
    y = np.asarray(y, dtype=int)
    parent = gini(y)
    left = y[x <= t]
    right = y[x > t]
    w_left = left.size / y.size
    w_right = right.size / y.size
    child = w_left * gini(left) + w_right * gini(right)
    return float(parent - child)


x = np.array([0.1, 0.2, 0.25, 0.8, 0.85, 0.9])
y = np.array([0, 0, 0, 1, 1, 1])

candidates = [0.2, 0.25, 0.8]
gains = [info_gain_gini(x, y, t) for t in candidates]
best_t = candidates[int(np.argmax(gains))]

assert best_t in [0.25, 0.8]
assert max(gains) > 0.0
```

---

### (Bonus) Ejercicio 5.11: Shadow Mode - comparar contra soluci√≥n cerrada en mini-dataset

#### Enunciado

- Entrena regresi√≥n lineal por GD y compara predicci√≥n con soluci√≥n cerrada en un conjunto peque√±o.

#### Soluci√≥n

```python
import numpy as np

np.random.seed(5)
n, d = 30, 2
X = np.random.randn(n, d)
w_true = np.array([1.2, -0.4])
y = X @ w_true + 0.01 * np.random.randn(n)

w_ne = np.linalg.solve(X.T @ X, X.T @ y)

w = np.zeros(d)
alpha = 0.1
for _ in range(2000):
    grad = (X.T @ (X @ w - y)) / n
    w = w - alpha * grad

y_ne = X @ w_ne
y_gd = X @ w

assert np.mean((y_ne - y_gd) ** 2) < 1e-4
```


## üì¶ Entregable del M√≥dulo

- `supervised_learning.py` (regresi√≥n lineal + log√≠stica + m√©tricas + validaci√≥n).
- `scripts/decision_tree_from_scratch.py` (√°rbol de decisi√≥n simple desde cero, sin gradientes).

### `supervised_learning.py`

```python
"""
Supervised Learning Module

Implementaci√≥n desde cero de:
- Linear Regression (con Normal Equation y Gradient Descent)
- Logistic Regression (con regularizaci√≥n L1/L2)
- M√©tricas de evaluaci√≥n
- Cross Validation

Autor: [Tu nombre]
M√≥dulo: 05 - Supervised Learning
"""

import numpy as np
from typing import Tuple, List, Optional
from dataclasses import dataclass


# ============================================================
# FUNCIONES AUXILIARES
# ============================================================

def sigmoid(z: np.ndarray) -> np.ndarray:
    z = np.clip(z, -500, 500)
    return 1 / (1 + np.exp(-z))

def add_bias(X: np.ndarray) -> np.ndarray:
    return np.column_stack([np.ones(len(X)), X])


# ============================================================
# REGRESI√ìN LINEAL
# ============================================================

class LinearRegression:
    def __init__(self):
        self.theta = None
        self.cost_history = []

    def fit(self, X: np.ndarray, y: np.ndarray,
            method: str = 'normal', lr: float = 0.01, n_iter: int = 1000):
        X_b = add_bias(X)

        if method == 'normal':
            self.theta = np.linalg.solve(X_b.T @ X_b, X_b.T @ y)
        else:
            m, n = X_b.shape
            self.theta = np.zeros(n)
            for _ in range(n_iter):
                grad = (1/m) * X_b.T @ (X_b @ self.theta - y)
                self.theta -= lr * grad
                self.cost_history.append(np.mean((X_b @ self.theta - y)**2))
        return self

    def predict(self, X: np.ndarray) -> np.ndarray:
        return add_bias(X) @ self.theta

    def score(self, X: np.ndarray, y: np.ndarray) -> float:
        y_pred = self.predict(X)
        ss_res = np.sum((y - y_pred)**2)
        ss_tot = np.sum((y - np.mean(y))**2)
        return 1 - ss_res / ss_tot


# ============================================================
# REGRESI√ìN LOG√çSTICA
# ============================================================

class LogisticRegression:
    def __init__(self, reg: str = None, lambda_: float = 0.01):
        self.reg = reg
        self.lambda_ = lambda_
        self.theta = None
        self.cost_history = []

    def fit(self, X: np.ndarray, y: np.ndarray,
            lr: float = 0.1, n_iter: int = 1000):
        X_b = add_bias(X)
        m, n = X_b.shape
        self.theta = np.zeros(n)

        for _ in range(n_iter):
            h = sigmoid(X_b @ self.theta)
            grad = (1/m) * X_b.T @ (h - y)

            if self.reg == 'l2':
                grad[1:] += (self.lambda_/m) * self.theta[1:]
            elif self.reg == 'l1':
                grad[1:] += (self.lambda_/m) * np.sign(self.theta[1:])

            self.theta -= lr * grad
        return self

    def predict_proba(self, X: np.ndarray) -> np.ndarray:
        return sigmoid(add_bias(X) @ self.theta)

    def predict(self, X: np.ndarray) -> np.ndarray:
        return (self.predict_proba(X) >= 0.5).astype(int)

    def score(self, X: np.ndarray, y: np.ndarray) -> float:
        return np.mean(self.predict(X) == y)


# ============================================================
# M√âTRICAS
# ============================================================

def accuracy(y_true, y_pred):
    return np.mean(y_true == y_pred)

def precision(y_true, y_pred):
    tp = np.sum((y_true == 1) & (y_pred == 1))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    return tp / (tp + fp) if (tp + fp) > 0 else 0

def recall(y_true, y_pred):
    tp = np.sum((y_true == 1) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == 0))
    return tp / (tp + fn) if (tp + fn) > 0 else 0

def f1_score(y_true, y_pred):
    p, r = precision(y_true, y_pred), recall(y_true, y_pred)
    return 2*p*r/(p+r) if (p+r) > 0 else 0

def confusion_matrix(y_true, y_pred):
    cm = np.zeros((2, 2), dtype=int)
    cm[0, 0] = np.sum((y_true == 0) & (y_pred == 0))
    cm[0, 1] = np.sum((y_true == 0) & (y_pred == 1))
    cm[1, 0] = np.sum((y_true == 1) & (y_pred == 0))
    cm[1, 1] = np.sum((y_true == 1) & (y_pred == 1))
    return cm


# ============================================================
# VALIDACI√ìN
# ============================================================

def train_test_split(X, y, test_size=0.2, seed=None):
    if seed: np.random.seed(seed)
    n = len(y)
    idx = np.random.permutation(n)
    split = int(n * test_size)
    return X[idx[split:]], X[idx[:split]], y[idx[split:]], y[idx[:split]]

def cross_validate(model_class, X, y, k=5, **params):
    n = len(y)
    idx = np.random.permutation(n)
    fold_size = n // k
    scores = []

    for i in range(k):
        val_idx = idx[i*fold_size:(i+1)*fold_size]
        train_idx = np.concatenate([idx[:i*fold_size], idx[(i+1)*fold_size:]])

        model = model_class()
        model.fit(X[train_idx], y[train_idx], **params)
        scores.append(model.score(X[val_idx], y[val_idx]))

    return {'scores': scores, 'mean': np.mean(scores), 'std': np.std(scores)}


# ============================================================
# TESTS
# ============================================================

if __name__ == "__main__":
    np.random.seed(42)

    # Test Linear Regression
    X = 2 * np.random.rand(100, 1)
    y = 4 + 3 * X.flatten() + np.random.randn(100) * 0.5

    lr = LinearRegression()
    lr.fit(X, y)
    print(f"Linear Regression R¬≤: {lr.score(X, y):.4f}")

    # Test Logistic Regression
    X_c0 = np.random.randn(50, 2) + [-2, -2]
    X_c1 = np.random.randn(50, 2) + [2, 2]
    X_clf = np.vstack([X_c0, X_c1])
    y_clf = np.array([0]*50 + [1]*50)

    log_reg = LogisticRegression()
    log_reg.fit(X_clf, y_clf)
    print(f"Logistic Regression Accuracy: {log_reg.score(X_clf, y_clf):.4f}")

    # Test metrics
    y_true = np.array([0,0,0,1,1,1,1,1])
    y_pred = np.array([0,0,1,1,1,0,1,1])
    print(f"Precision: {precision(y_true, y_pred):.4f}")
    print(f"Recall: {recall(y_true, y_pred):.4f}")
    print(f"F1: {f1_score(y_true, y_pred):.4f}")

    # Test CV
    cv = cross_validate(LogisticRegression, X_clf, y_clf, k=5, lr=0.1, n_iter=500)
    print(f"CV Score: {cv['mean']:.4f} ¬± {cv['std']:.4f}")

    print("\n‚úì Todos los tests pasaron!")
```

---

## üìù Derivaci√≥n Anal√≠tica: El Entregable de L√°piz y Papel (v3.3)

> üéì **Simulaci√≥n de Examen:** En la maestr√≠a te pedir√°n: *"Derive la regla de actualizaci√≥n de pesos para Logistic Regression"*. Debes poder hacerlo a mano.

### Derivaci√≥n del Gradiente de Logistic Regression

**Objetivo:** Derivar `‚àÇL/‚àÇw` para la funci√≥n de costo Cross-Entropy.

#### Paso 1: Definir la Funci√≥n de Costo

```
L(w) = -(1/n) Œ£_{i=1..n} [ y_i log(≈∑_i) + (1 - y_i) log(1 - ≈∑_i) ]
```

Donde:
- `≈∑_i = œÉ(w·µÄ x_i) = 1 / (1 + e^{-w·µÄ x_i})`
- `œÉ(z)` es la funci√≥n sigmoid

#### Paso 2: Derivar la Sigmoid

```
dœÉ/dz = œÉ(z)(1 - œÉ(z))
```

**Demostraci√≥n:**
```
œÉ(z) = 1 / (1 + e^{-z})

dœÉ/dz = e^{-z} / (1 + e^{-z})^2
      = (1 / (1 + e^{-z})) ¬∑ (e^{-z} / (1 + e^{-z}))
      = œÉ(z)(1 - œÉ(z))
```

#### Paso 3: Aplicar la Regla de la Cadena

Para un solo ejemplo `(x_i, y_i)`:

```
‚àÇL_i/‚àÇw = (‚àÇL_i/‚àÇ≈∑_i) ¬∑ (‚àÇ≈∑_i/‚àÇz_i) ¬∑ (‚àÇz_i/‚àÇw)
```

Donde `z_i = w·µÄ x_i`

**Calcular cada t√©rmino:**

1. `‚àÇL_i/‚àÇ≈∑_i = -y_i/≈∑_i + (1 - y_i)/(1 - ≈∑_i)`

2. `‚àÇ≈∑_i/‚àÇz_i = ≈∑_i(1 - ≈∑_i)`

3. `‚àÇz_i/‚àÇw = x_i`

#### Paso 4: Simplificar

```
‚àÇL_i/‚àÇw = ( -y_i/≈∑_i + (1 - y_i)/(1 - ≈∑_i) ) ¬∑ ≈∑_i(1 - ≈∑_i) ¬∑ x_i
```

Simplificando el t√©rmino entre par√©ntesis:
```
= ( (-y_i(1 - ≈∑_i) + (1 - y_i)≈∑_i) / (≈∑_i(1 - ≈∑_i)) ) ¬∑ ≈∑_i(1 - ≈∑_i) ¬∑ x_i
= (-y_i + y_i≈∑_i + ≈∑_i - y_i≈∑_i) ¬∑ x_i
= (≈∑_i - y_i) ¬∑ x_i
```

#### Resultado Final

```
‚àÇL/‚àÇw = (1/n) Œ£_{i=1..n} (≈∑_i - y_i) x_i
      = (1/n) X·µÄ (≈∑ - y)
```

**Forma vectorizada (para c√≥digo):**
```python
gradient = (1/n) * X.T @ (y_pred - y_true)
```

### Tu Entregable

Escribe en un documento (Markdown o LaTeX):
1. La derivaci√≥n completa del gradiente de Cross-Entropy
2. La derivaci√≥n de la regla de actualizaci√≥n: `w <- w - Œ± ‚àáL`
3. Por qu√© el gradiente tiene la forma `(≈∑ - y)` (interpretaci√≥n geom√©trica)

---

## üéØ El Reto del Tablero Blanco (Metodolog√≠a Feynman)

Explica en **m√°ximo 5 l√≠neas** sin jerga t√©cnica:

1. **¬øPor qu√© usamos sigmoid en clasificaci√≥n?**
   > Pista: Piensa en probabilidades entre 0 y 1.

2. **¬øPor qu√© Cross-Entropy y no MSE para clasificaci√≥n?**
   > Pista: Piensa en qu√© pasa cuando `≈∑ ‚âà 0` pero `y = 1`.

3. **¬øQu√© significa "One-vs-All"?**
   > Pista: Piensa en c√≥mo clasificar 10 d√≠gitos con clasificadores binarios.

---

## üîç Shadow Mode: Validaci√≥n con sklearn (v3.3)

> ‚ö†Ô∏è **Regla:** sklearn est√° **prohibido para aprender**, pero es **necesario para validar**. Si tu implementaci√≥n difiere significativamente de sklearn, tienes un bug.

### Protocolo de Validaci√≥n (Viernes de Fase 2)

```python
"""
Shadow Mode - Validaci√≥n de Implementaciones
Compara tu c√≥digo desde cero vs sklearn para detectar bugs.

Regla: Si la diferencia de accuracy es >5%, revisar matem√°ticas.
"""
import numpy as np
from sklearn.linear_model import LogisticRegression as SklearnLR
from sklearn.linear_model import LinearRegression as SklearnLinReg
from sklearn.metrics import accuracy_score, mean_squared_error

# Importar tu implementaci√≥n
# from src.logistic_regression import LogisticRegression as MyLR
# from src.linear_regression import LinearRegression as MyLinReg


def shadow_mode_logistic_regression(X_train, y_train, X_test, y_test):
    """
    Compara tu Logistic Regression vs sklearn.

    Los coeficientes y accuracy deben ser casi id√©nticos.
    """
    print("=" * 60)
    print("SHADOW MODE: Logistic Regression")
    print("=" * 60)

    # ========== TU IMPLEMENTACI√ìN ==========
    # my_model = MyLR()
    # my_model.fit(X_train, y_train, lr=0.1, n_iter=1000)
    # my_pred = my_model.predict(X_test)
    # my_acc = accuracy_score(y_test, my_pred)
    # my_weights = my_model.weights

    # Placeholder (reemplazar con tu c√≥digo)
    my_acc = 0.85
    my_weights = np.zeros(X_train.shape[1])

    # ========== SKLEARN (GROUND TRUTH) ==========
    sklearn_model = SklearnLR(max_iter=1000, solver='lbfgs')
    sklearn_model.fit(X_train, y_train)
    sklearn_pred = sklearn_model.predict(X_test)
    sklearn_acc = accuracy_score(y_test, sklearn_pred)
    sklearn_weights = sklearn_model.coef_.flatten()

    # ========== COMPARACI√ìN ==========
    acc_diff = abs(my_acc - sklearn_acc)
    weight_diff = np.linalg.norm(my_weights - sklearn_weights[:len(my_weights)])

    print(f"\nüìä RESULTADOS:")
    print(f"  Tu Accuracy:     {my_acc:.4f}")
    print(f"  sklearn Accuracy: {sklearn_acc:.4f}")
    print(f"  Diferencia:       {acc_diff:.4f}")

    print(f"\nüìê PESOS:")
    print(f"  Diferencia L2 de pesos: {weight_diff:.4f}")

    # Veredicto
    print("\n" + "-" * 60)
    if acc_diff < 0.05:
        print("‚úì PASSED: Tu implementaci√≥n es correcta")
        return True
    else:
        print("‚úó FAILED: Diferencia significativa - revisa tu matem√°tica")
        print("  Posibles causas:")
        print("  - Gradiente mal calculado")
        print("  - Learning rate muy alto/bajo")
        print("  - Falta de normalizaci√≥n de datos")
        return False


def shadow_mode_linear_regression(X_train, y_train, X_test, y_test):
    """
    Compara tu Linear Regression vs sklearn.
    """
    print("=" * 60)
    print("SHADOW MODE: Linear Regression")
    print("=" * 60)

    # ========== TU IMPLEMENTACI√ìN ==========
    # my_model = MyLinReg()
    # my_model.fit(X_train, y_train)
    # my_pred = my_model.predict(X_test)
    # my_mse = mean_squared_error(y_test, my_pred)

    # Placeholder
    my_mse = 0.5

    # ========== SKLEARN ==========
    sklearn_model = SklearnLinReg()
    sklearn_model.fit(X_train, y_train)
    sklearn_pred = sklearn_model.predict(X_test)
    sklearn_mse = mean_squared_error(y_test, sklearn_pred)

    # ========== COMPARACI√ìN ==========
    mse_ratio = my_mse / sklearn_mse if sklearn_mse > 0 else float('inf')

    print(f"\nüìä RESULTADOS:")
    print(f"  Tu MSE:     {my_mse:.4f}")
    print(f"  sklearn MSE: {sklearn_mse:.4f}")
    print(f"  Ratio:       {mse_ratio:.2f}x")

    print("\n" + "-" * 60)
    if mse_ratio < 1.1:  # Dentro del 10%
        print("‚úì PASSED: Tu implementaci√≥n es correcta")
        return True
    else:
        print("‚úó FAILED: Tu MSE es significativamente mayor")
        return False


# ============================================================
# EJEMPLO DE USO
# ============================================================

if __name__ == "__main__":
    from sklearn.datasets import make_classification, make_regression
    from sklearn.model_selection import train_test_split

    # Dataset de clasificaci√≥n
    X_clf, y_clf = make_classification(
        n_samples=1000, n_features=10, n_classes=2, random_state=42
    )
    X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(
        X_clf, y_clf, test_size=0.2, random_state=42
    )

    # Dataset de regresi√≥n
    X_reg, y_reg = make_regression(
        n_samples=1000, n_features=10, noise=10, random_state=42
    )
    X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(
        X_reg, y_reg, test_size=0.2, random_state=42
    )

    # Ejecutar Shadow Mode
    shadow_mode_logistic_regression(X_train_c, y_train_c, X_test_c, y_test_c)
    print("\n")
    shadow_mode_linear_regression(X_train_r, y_train_r, X_test_r, y_test_r)
```

### Checklist Shadow Mode

| D√≠a | Algoritmo | Validar |
|-----|-----------|---------|
| Viernes Sem 10 | Linear Regression | MSE ‚âà sklearn |
| Viernes Sem 11 | Logistic Regression | Accuracy ‚âà sklearn |
| Viernes Sem 12 | M√©tricas | Precision/Recall = sklearn |

---

## ‚úÖ Checklist de Finalizaci√≥n (v3.3)

### Conocimiento
- [ ] Implement√© regresi√≥n lineal con Normal Equation y GD
- [ ] Entiendo MSE y su gradiente
- [ ] Implement√© regresi√≥n log√≠stica desde cero
- [ ] Entiendo sigmoid y binary cross-entropy
- [ ] Puedo calcular TP, TN, FP, FN de una matriz de confusi√≥n
- [ ] Implement√© accuracy, precision, recall, F1
- [ ] Implement√© train/test split
- [ ] Implement√© K-fold cross validation
- [ ] Entiendo regularizaci√≥n L1 vs L2

### Shadow Mode (v3.3 - Obligatorio)
- [ ] **Linear Regression**: Mi MSE ‚âà sklearn (ratio < 1.1)
- [ ] **Logistic Regression**: Mi Accuracy ‚âà sklearn (diff < 5%)

### Entregables de C√≥digo
- [ ] `logistic_regression.py` con tests pasando
- [ ] `artifacts/m05_logreg_weights.png` + 5‚Äì10 l√≠neas de interpretaci√≥n (pesos 28x28)
- [ ] `mypy src/` pasa sin errores
- [ ] `pytest tests/` pasa sin errores

### Derivaci√≥n Anal√≠tica (Obligatorio)
- [ ] Deriv√© el gradiente de Cross-Entropy a mano
- [ ] Documento con derivaci√≥n completa (Markdown o LaTeX)
- [ ] Puedo explicar por qu√© `‚àáL = X·µÄ(≈∑ - y)`

### Metodolog√≠a Feynman
- [ ] Puedo explicar sigmoid en 5 l√≠neas sin jerga
- [ ] Puedo explicar Cross-Entropy vs MSE en 5 l√≠neas
- [ ] Puedo explicar One-vs-All en 5 l√≠neas

---

## üîó Navegaci√≥n

| Anterior | √çndice | Siguiente |
|----------|--------|-----------|
| [04_PROBABILIDAD_ML](04_PROBABILIDAD_ML.md) | [00_INDICE](00_INDICE.md) | [06_UNSUPERVISED_LEARNING](06_UNSUPERVISED_LEARNING.md) |
