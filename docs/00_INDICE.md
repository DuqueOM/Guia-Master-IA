# ğŸ“š GUÃA MAESTRA: MS AI PATHWAY - ML SPECIALIST (v3.1)

> **De Python BÃ¡sico a Candidato del MS in AI de CU Boulder**  
> **24 Semanas (6 Meses Exactos) | Enfoque: LÃ­nea 1 - Machine Learning**  
> **FilosofÃ­a: "MatemÃ¡ticas Aplicadas a CÃ³digo"**

---

## ğŸ¯ Objetivo de Esta GuÃ­a

**Dominio absoluto de las 3 materias de la LÃ­nea de Machine Learning** del Performance-Based Admission Pathway:

### â­ LÃNEA 1: Machine Learning (3 crÃ©ditos) - FOCO PRINCIPAL

| Curso del Pathway | MÃ³dulo de Esta GuÃ­a |
|-------------------|---------------------|
| Introduction to Machine Learning: Supervised Learning | **MÃ³dulo 05** |
| Unsupervised Algorithms in Machine Learning | **MÃ³dulo 06** |
| Introduction to Deep Learning | **MÃ³dulo 07** |

### ğŸ“– LÃNEA 2: Probabilidad y EstadÃ­stica (Lectura Opcional)

| Curso del Pathway | Estado |
|-------------------|--------|
| Probability Foundations for Data Science and AI | Lectura opcional |
| Discrete-Time Markov Chains and Monte Carlo Methods | Lectura opcional |
| Statistical Estimation for Data Science and AI | Lectura opcional |

> **Nota:** La LÃ­nea 2 pertenece a la especializaciÃ³n de EstadÃ­stica. Esta guÃ­a incluye solo la probabilidad esencial para ML (MÃ³dulo 04).

---

## ğŸ—ºï¸ El Mapa de Ruta: 3 Fases CrÃ­ticas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 1: FUNDAMENTOS (Semanas 1-8)                                          â”‚
â”‚  Objetivo: Python cientÃ­fico + matemÃ¡ticas para leer papers de ML           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MÃ³dulo 01  Python + Pandas + NumPy   Carga de datos, vectorizaciÃ³n [2 sem] â”‚
â”‚  MÃ³dulo 02  Ãlgebra Lineal para ML    Matrices, normas, SVD, eigen  [3 sem] â”‚
â”‚  MÃ³dulo 03  CÃ¡lculo Multivariante     Gradientes, Chain Rule        [2 sem] â”‚
â”‚  MÃ³dulo 04  Probabilidad para ML      Bayes, Gaussiana, MLE         [1 sem] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 2: NÃšCLEO DE MACHINE LEARNING (Semanas 9-20)                          â”‚
â”‚  â­ SIMULACIÃ“N DEL PATHWAY - LÃNEA 1                                        â”‚
â”‚  Objetivo: Implementar desde cero los algoritmos de los 3 cursos            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MÃ³dulo 05  Supervised Learning       RegresiÃ³n, LogÃ­stica, CV      [4 sem] â”‚
â”‚  MÃ³dulo 06  Unsupervised Learning     K-Means, PCA, GMM             [4 sem] â”‚
â”‚  MÃ³dulo 07  Deep Learning             MLP, Backprop, CNNs           [4 sem] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 3: PROYECTO INTEGRADOR "MNIST ANALYST" (Semanas 21-24)                â”‚
â”‚  Objetivo: Un proyecto que demuestra competencia en las 3 Ã¡reas             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MÃ³dulo 08  MNIST End-to-End Pipeline                               [4 sem] â”‚
â”‚             PCA + K-Means + Logistic Regression + MLP desde cero            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Total: 8 mÃ³dulos obligatorios | 24 semanas | ~864 horas**

---

## ğŸ‘¤ Perfil de Entrada

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PERFIL IDEAL DE ENTRADA                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… Python bÃ¡sico (variables, funciones, listas, diccionarios) â”‚
â”‚  âœ… LÃ³gica de programaciÃ³n (if/else, loops)                    â”‚
â”‚  âœ… MatemÃ¡ticas de bachillerato (Ã¡lgebra bÃ¡sica)               â”‚
â”‚  âœ… Ganas de entender "cÃ³mo funciona por dentro"               â”‚
â”‚  âš ï¸  NO se requiere: numpy, pandas, sklearn, ML previo         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“– MÃ³dulos Obligatorios

### FASE 1: Fundamentos (Semanas 1-8)

*Python cientÃ­fico con Pandas, matemÃ¡ticas esenciales y probabilidad bÃ¡sica para ML.*

| # | MÃ³dulo | DescripciÃ³n | Tiempo | Archivo |
|---|--------|-------------|--------|---------|
| 01 | **Python + Pandas + NumPy** | Carga de datos, limpieza, vectorizaciÃ³n | 2 sem | [01_PYTHON_CIENTIFICO.md](01_PYTHON_CIENTIFICO.md) |
| 02 | **Ãlgebra Lineal para ML** | Vectores, matrices, normas, SVD, eigenvalues | 3 sem | [02_ALGEBRA_LINEAL_ML.md](02_ALGEBRA_LINEAL_ML.md) |
| 03 | **CÃ¡lculo Multivariante** | Derivadas parciales, gradiente, Chain Rule | 2 sem | [03_CALCULO_MULTIVARIANTE.md](03_CALCULO_MULTIVARIANTE.md) |
| 04 | **Probabilidad para ML** | Teorema de Bayes, Gaussiana, MLE | 1 sem | [04_PROBABILIDAD_ML.md](04_PROBABILIDAD_ML.md) |

**Entregables Fase 1:**
- Script de carga y limpieza de CSV con Pandas
- LibrerÃ­a `linear_algebra.py` con proyecciones y distancias
- Gradient Descent manual para minimizar funciones
- ImplementaciÃ³n de MLE para estimar parÃ¡metros de Gaussiana

---

### FASE 2: NÃºcleo de Machine Learning (Semanas 9-20) â­ PATHWAY LÃNEA 1

*Los 3 cursos del Pathway implementados desde cero.*

| # | MÃ³dulo | Curso del Pathway | Tiempo | Archivo |
|---|--------|-------------------|--------|---------|
| 05 | **Supervised Learning** | Introduction to ML: Supervised Learning | 4 sem | [05_SUPERVISED_LEARNING.md](05_SUPERVISED_LEARNING.md) |
| 06 | **Unsupervised Learning** | Unsupervised Algorithms in ML | 4 sem | [06_UNSUPERVISED_LEARNING.md](06_UNSUPERVISED_LEARNING.md) |
| 07 | **Deep Learning** | Introduction to Deep Learning | 4 sem | [07_DEEP_LEARNING.md](07_DEEP_LEARNING.md) |

**Entregables Fase 2:**
- `logistic_regression.py` con regularizaciÃ³n L2
- `kmeans.py` y `pca.py` funcionales
- `neural_network.py` con backprop manual (MLP)
- TeorÃ­a de CNNs (convoluciÃ³n, pooling, stride)

---

### FASE 3: Proyecto Final MNIST Analyst (Semanas 21-24)

*Pipeline completo en 4 semanas. MNIST es simple, no necesita mÃ¡s.*

| # | MÃ³dulo | DescripciÃ³n | Tiempo | Archivo |
|---|--------|-------------|--------|---------|
| 08 | **MNIST Analyst** | Pipeline end-to-end de clasificaciÃ³n de dÃ­gitos | 4 sem | [08_PROYECTO_MNIST.md](08_PROYECTO_MNIST.md) |

**Proyecto: "End-to-End Handwritten Digit Analysis Pipeline"**

| Semana | Componente | Materia Demostrada |
|--------|------------|-------------------|
| 21 | EDA + PCA + K-Means | Unsupervised Algorithms |
| 22 | RegresiÃ³n LogÃ­stica One-vs-All | Supervised Learning |
| 23 | MLP con Backprop desde cero | Deep Learning |
| 24 | Informe + ComparaciÃ³n de Modelos | IntegraciÃ³n |

---

## ğŸ”¨ Estructura del Proyecto Final

```
mnist-analyst/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ # FASE 1: FUNDAMENTOS
â”‚   â”œâ”€â”€ data_loader.py         # Carga con Pandas, limpieza (MÃ³dulo 01)
â”‚   â”œâ”€â”€ linear_algebra.py      # Vectores, matrices, normas (MÃ³dulo 02)
â”‚   â”œâ”€â”€ calculus.py            # Gradientes, derivadas (MÃ³dulo 03)
â”‚   â”œâ”€â”€ probability.py         # Bayes, Gaussiana, MLE (MÃ³dulo 04)
â”‚   â”‚
â”‚   â”œâ”€â”€ # FASE 2: ML CORE
â”‚   â”œâ”€â”€ logistic_regression.py # ClasificaciÃ³n binaria/multiclase (MÃ³dulo 05)
â”‚   â”œâ”€â”€ metrics.py             # Accuracy, Precision, Recall, F1 (MÃ³dulo 05)
â”‚   â”œâ”€â”€ kmeans.py              # Clustering K-Means++ (MÃ³dulo 06)
â”‚   â”œâ”€â”€ pca.py                 # ReducciÃ³n dimensional SVD (MÃ³dulo 06)
â”‚   â”œâ”€â”€ neural_network.py      # MLP con backprop (MÃ³dulo 07)
â”‚   â”œâ”€â”€ activations.py         # Sigmoid, ReLU, Softmax (MÃ³dulo 07)
â”‚   â”œâ”€â”€ optimizers.py          # SGD, Adam (MÃ³dulo 07)
â”‚   â”‚
â”‚   â””â”€â”€ # INTEGRACIÃ“N
â”‚   â””â”€â”€ mnist_pipeline.py      # Pipeline completo (MÃ³dulo 08)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_linear_algebra.py
â”‚   â”œâ”€â”€ test_logistic_regression.py
â”‚   â”œâ”€â”€ test_kmeans.py
â”‚   â”œâ”€â”€ test_pca.py
â”‚   â”œâ”€â”€ test_neural_network.py
â”‚   â””â”€â”€ test_pipeline.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ mnist/                 # Dataset MNIST (28x28 imÃ¡genes)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda_visualization.ipynb
â”‚   â”œâ”€â”€ 02_pca_kmeans.ipynb
â”‚   â”œâ”€â”€ 03_logistic_ova.ipynb
â”‚   â””â”€â”€ 04_mlp_benchmark.ipynb
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ MATHEMATICAL_FOUNDATIONS.md
â”‚   â””â”€â”€ MODEL_COMPARISON.md
â”‚
â”œâ”€â”€ README.md                  # DocumentaciÃ³n (inglÃ©s)
â”œâ”€â”€ pyproject.toml
â””â”€â”€ requirements.txt           # numpy, pandas, matplotlib, pytest
```

---

## â±ï¸ Tiempo Total

| Fase | Semanas | Horas (~36h/sem) | Enfoque |
|------|---------|------------------|---------|
| Fundamentos (01-04) | 8 | ~288h | Python + MatemÃ¡ticas + Probabilidad |
| ML Core (05-07) | 12 | ~432h | Algoritmos del Pathway |
| Proyecto MNIST (08) | 4 | ~144h | IntegraciÃ³n y demo |
| **TOTAL** | **24** | **~864h** | |

**DuraciÃ³n:** 6 meses exactos con 6h/dÃ­a (L-S)

---

## âŒ QuÃ© Se EliminÃ³ del Plan Original

Para que esto quepa en 6 meses y sea efectivo para la **LÃ­nea 1 de ML**:

| Eliminado | RazÃ³n |
|-----------|-------|
| Linked Lists, Stacks, Queues | Irrelevante para matemÃ¡ticas del Pathway |
| Binary Trees, BST | No se usa en los 3 cursos de ML |
| Grafos (BFS/DFS) | No es parte del currÃ­culo |
| QuickSort, MergeSort | En ML usas `numpy.sort()` |
| Inverted Index, TF-IDF | Proyecto de IR, no de CV/ML |
| Cadenas de Markov | Pertenece a LÃ­nea 2 (EstadÃ­stica) |
| Motor de BÃºsqueda | Reemplazado por MNIST Pipeline |

---

## ğŸ“¦ Material de Referencia

| Documento | DescripciÃ³n | Uso |
|-----------|-------------|-----|
| [GLOSARIO.md](GLOSARIO.md) | Definiciones tÃ©cnicas de ML | Consulta |
| [RECURSOS.md](RECURSOS.md) | Cursos y libros externos | Profundizar |
| [CHECKLIST.md](CHECKLIST.md) | VerificaciÃ³n de entregables | Seguimiento |

---

## ğŸš€ Comenzar

**[â†’ MÃ³dulo 01: Python + Pandas + NumPy](01_PYTHON_CIENTIFICO.md)**

---

## ğŸ“Œ Restricciones del Proyecto

- âœ… **NumPy + Pandas permitidos** - Herramientas reales de ML
- âŒ **Sin sklearn/tensorflow/pytorch** - Algoritmos desde cero
- âœ… **100% local** - Todo se ejecuta en tu mÃ¡quina
- âœ… **MatemÃ¡ticas primero** - Entender antes de implementar
- âœ… **MNIST como benchmark** - Dataset estÃ¡ndar de la industria

---

## ğŸ¯ VerificaciÃ³n de Competencias del Pathway

| Curso del Pathway | Â¿Cubierto? | Evidencia en el Proyecto |
|-------------------|------------|--------------------------|
| **ML: Supervised Learning** | âœ… | Logistic Regression OvA, mÃ©tricas, CV |
| **ML: Unsupervised Algorithms** | âœ… | K-Means++, PCA con SVD desde cero |
| **ML: Deep Learning** | âœ… | MLP con Backprop + teorÃ­a CNNs |

---

## âœ¨ Cambios en v3.1 (vs v3.0)

| Cambio | RazÃ³n |
|--------|-------|
| **24 semanas** (antes 26) | Proyecto MNIST reducido a 4 sem (es dataset simple) |
| **Pandas en MÃ³dulo 01** | Necesario para cargar y limpiar datos reales |
| **Probabilidad para ML (MÃ³dulo 04)** | Bayes y MLE son esenciales para entender loss functions |
| **CNNs en MÃ³dulo 07** | El curso de Deep Learning de CU Boulder las cubre |

---

## âœ¨ Cambios en v3.2 (vs v3.1)

| Cambio | RazÃ³n |
|--------|-------|
| **Debugging NumPy (M01)** | 5 errores comunes que causan horas de frustraciÃ³n |
| **EstÃ¡ndares Profesionales** | `mypy`, `ruff`, `pytest` obligatorios desde Semana 2 |
| **MetodologÃ­a Feynman** | "Reto del Tablero Blanco" en cada mÃ³dulo |
| **DerivaciÃ³n AnalÃ­tica (M05, M07)** | Simula exÃ¡menes de posgrado: derivar gradientes a mano |
| **AnÃ¡lisis Bias-Variance (M08)** | Concepto central de ML para diseÃ±o de modelos |
| **Formato Paper (M08)** | Notebook final con estructura acadÃ©mica |

---

## âœ¨ Cambios en v3.3 (vs v3.2)

| Cambio | RazÃ³n |
|--------|-------|
| **Gradient Checking (M03)** | ValidaciÃ³n matemÃ¡tica de derivadas (tÃ©cnica CS231n Stanford) |
| **Log-Sum-Exp Trick (M04)** | Softmax numÃ©ricamente estable (evita NaN) |
| **Shadow Mode (M05)** | Validar implementaciones vs sklearn |
| **Overfit Test (M07)** | Si no hace overfit en 10 ejemplos, tiene bug |
| **AnÃ¡lisis de Errores (M08)** | Visualizar y explicar fallos (nivel senior) |
| **Curvas de Aprendizaje (M08)** | DiagnÃ³stico grÃ¡fico de Bias-Variance |

### Nuevos Entregables v3.3

| MÃ³dulo | Nuevo Entregable |
|--------|------------------|
| 03 | `grad_check.py` - validaciÃ³n numÃ©rica de derivadas |
| 04 | `softmax` con log-sum-exp trick |
| 05 | Comparativa Shadow Mode vs sklearn |
| 07 | `overfit_test.py` - debugging de redes |
| 08 | SecciÃ³n "Error Analysis" + Learning Curves |

---

> ğŸ’¡ **FilosofÃ­a v3.3:** Esta guÃ­a incluye **validaciÃ³n matemÃ¡tica rigurosa** en cada paso. No confÃ­es en que tu cÃ³digo "parece funcionar"â€”valÃ­dalo con gradient checking, shadow mode y overfit tests. Si completas v3.3, tu cÃ³digo es **matemÃ¡ticamente correcto y profesionalmente validado**.
