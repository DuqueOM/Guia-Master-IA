# ğŸ§¹ Dirty Data Check â€“ v5.0

> *"El modelo es tan bueno como el dato que le das."*

Este documento te guÃ­a para documentar rigurosamente los problemas de tus datasets y las decisiones de limpieza que tomas.

Usa una copia de esta plantilla para cada dataset importante (MÃ³dulo 01, MÃ³dulo 05, proyecto MNIST si lo deseas).

---

## ğŸ“Œ Resumen del Dataset

- **Nombre del dataset:**
- **Fuente (URL / archivo local):**
- **TamaÃ±o (filas, columnas):**
- **Objetivo del modelo (regresiÃ³n / clasificaciÃ³n / otro):**

---

## ğŸ” Perfilado Inicial

Completa esta secciÃ³n con Pandas (MÃ³dulo 01) antes de empezar a limpiar.

- `df.info()` â€“ tipos de datos, nulos.
- `df.describe()` â€“ estadÃ­sticas bÃ¡sicas.
- Conteo de valores Ãºnicos por columna clave.

**Notas rÃ¡pidas:**
- Columnas con muchos nulos:
- Columnas con valores raros (e.g., "?", "N/A", "-999"):
- Sospechas de outliers:

---

## ğŸ§¯ Problemas Detectados y Decisiones

### Estructura para cada problema

```markdown
### Problema #N â€“ [TÃ­tulo breve]

**Columna(s) afectada(s):**
**Tipo de problema:** [nulos | outliers | tipo incorrecto | codificaciÃ³n | duplicados | otro]

**Evidencia:**
- [Ejemplo de salida de Pandas que muestra el problema]

**Opciones consideradas:**
- [OpciÃ³n A] (pros / contras)
- [OpciÃ³n B] (pros / contras)

**DecisiÃ³n final:**
- [QuÃ© hiciste y por quÃ©]

**Impacto esperado en el modelo:**
- [CÃ³mo crees que afecta a bias/variance, estabilidad, etc.]
```

---

## ğŸ§ª Caso 1 â€“ MÃ³dulo 01 (CSV Inicial)

> **Objetivo:** Mostrar que puedes hacer un anÃ¡lisis serio de calidad de datos con Pandas.

- Dataset utilizado (nombre / descripciÃ³n):
- MÃ­nimo **5 problemas documentados** usando la estructura anterior.

Checklist:
- [ ] IdentifiquÃ© y documentÃ© â‰¥ 5 problemas.
- [ ] JustifiquÃ© cada decisiÃ³n de limpieza.
- [ ] Puedo explicar a otra persona por quÃ© estas decisiones son razonables.

---

## ğŸ§ª Caso 2 â€“ MÃ³dulo 05 (Dataset Supervisado Real)

> **Objetivo:** Practicar un pipeline de preprocesamiento realista antes de RegresiÃ³n LogÃ­stica.

Requisitos del dataset:
- Al menos **1â€“2 columnas categÃ³ricas** â†’ requiere **One-Hot Encoding**.
- Al menos **2â€“3 columnas numÃ©ricas** â†’ requiere **escalado** (MinMax / StandardScaler manual).

Elementos obligatorios:
- [ ] Limpieza de nulos y valores raros.
- [ ] DiseÃ±o de features (crear, combinar o transformar columnas si es Ãºtil).
- [ ] One-Hot Encoding implementado a mano (sin sklearn).
- [ ] Escalado manual de features numÃ©ricos.
- [ ] DivisiÃ³n train/test definida despuÃ©s del preprocesamiento.

Documenta **al menos 5 decisiones clave** usando la estructura de problemas anterior.

---

## ğŸ“Š Resumen de Decisiones Clave

| # | Columna / Problema | DecisiÃ³n | JustificaciÃ³n corta |
|---|--------------------|----------|---------------------|
| 1 | | | |
| 2 | | | |
| 3 | | | |
| 4 | | | |
| 5 | | | |

---

## ğŸ§  ReflexiÃ³n

- Â¿QuÃ© aprendiste sobre la **realidad de los datos** respecto a los ejemplos sintÃ©ticos?
- Â¿QuÃ© habrÃ­as hecho distinto si tuvieras mÃ¡s tiempo o recursos?
- Â¿CÃ³mo impacta la calidad del dato en la interpretaciÃ³n de tus resultados de ML?
