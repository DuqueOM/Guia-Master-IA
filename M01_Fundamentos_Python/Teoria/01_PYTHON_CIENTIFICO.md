# M√≥dulo 01 ‚Äî Computaci√≥n Cient√≠fica con Python: NumPy y Pandas

> **Nivel:** Preparaci√≥n MS-AI (University of Colorado Boulder Pathway)
> **Duraci√≥n:** Semanas 1-2 | **Cr√©ditos Equivalentes:** 2 unidades
> **Prerrequisitos:** Python b√°sico (variables, funciones, estructuras de control)

---

## √çndice del M√≥dulo

1. [Fundamentos de Computaci√≥n Num√©rica](#1-fundamentos-de-computaci√≥n-num√©rica)
2. [NumPy: El Coraz√≥n del Stack Cient√≠fico](#2-numpy-el-coraz√≥n-del-stack-cient√≠fico)
3. [Pandas: Manipulaci√≥n de Datos Tabulares](#3-pandas-manipulaci√≥n-de-datos-tabulares)
4. [Broadcasting: Aritm√©tica de Tensores](#4-broadcasting-aritm√©tica-de-tensores)
5. [Vectorizaci√≥n y Rendimiento](#5-vectorizaci√≥n-y-rendimiento)
6. [Laboratorios Visuales Interactivos](#6-laboratorios-visuales-interactivos)

---

# 1. Fundamentos de Computaci√≥n Num√©rica

## 1.1 Contexto Hist√≥rico y Motivaci√≥n

### El Problema Computacional del Siglo XX

En 1945, John von Neumann public√≥ el *First Draft of a Report on the EDVAC*, estableciendo la arquitectura de memoria compartida que domina la computaci√≥n moderna. Sin embargo, esta arquitectura presenta un **cuello de botella cr√≠tico**: la velocidad del procesador supera exponencialmente la velocidad de acceso a memoria (el llamado *memory wall*).

**Implicaci√≥n para Machine Learning:** Los algoritmos de ML son *memory-bound*, no *compute-bound*. El costo dominante no es la operaci√≥n aritm√©tica, sino mover datos entre niveles de cach√© y memoria principal.

### Por Qu√© Python Puro es Inaceptable

Python es un lenguaje interpretado con tipado din√°mico. Cada operaci√≥n elemental incurre en:

1. **Dispatch din√°mico:** Resoluci√≥n de tipos en tiempo de ejecuci√≥n
2. **Boxing/Unboxing:** Cada n√∫mero es un objeto completo con metadatos
3. **Reference counting:** Gesti√≥n autom√°tica de memoria con overhead por operaci√≥n

**Consecuencia cuantificable:**

$$
T_{\text{Python}} \approx 100 \cdot T_{\text{C/Fortran}}
$$

Para $n = 10^6$ operaciones, esto significa la diferencia entre 2ms y 200ms‚Äîinaceptable en pipelines de ML donde estas operaciones se ejecutan millones de veces durante el entrenamiento.

### La Soluci√≥n: Bibliotecas Compiladas con Interfaz Python

NumPy (Numerical Python) fue desarrollado por Travis Oliphant en 2005, consolidando los proyectos *Numeric* (1995) y *Numarray* (2001). Su arquitectura sigue un principio elegante:

> **Principio de NumPy:** Exponer una API de alto nivel en Python que delegue el c√≥mputo intensivo a rutinas compiladas en C/Fortran optimizadas para la arquitectura del hardware.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        PYTHON (Alto nivel)                          ‚îÇ
‚îÇ   - Sintaxis legible                                                ‚îÇ
‚îÇ   - Gesti√≥n autom√°tica de memoria                                   ‚îÇ
‚îÇ   - Prototipado r√°pido                                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                     NUMPY C-API (Puente)                            ‚îÇ
‚îÇ   - Traducci√≥n de objetos Python a buffers de memoria               ‚îÇ
‚îÇ   - Dispatch de operaciones a rutinas optimizadas                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                    BLAS/LAPACK (Bajo nivel)                         ‚îÇ
‚îÇ   - Operaciones vectorizadas en C/Fortran                           ‚îÇ
‚îÇ   - Optimizaciones espec√≠ficas de arquitectura (SIMD, AVX)          ‚îÇ
‚îÇ   - Paralelizaci√≥n autom√°tica en m√∫ltiples cores                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 1.2 Analog√≠a de Alto Impacto: La F√°brica de Chocolates

Imagina que tienes que producir 1 mill√≥n de chocolates:

**M√©todo Python Puro (Artesanal):**
- Un maestro chocolatero hace cada chocolate individualmente
- Examina cada ingrediente, decide c√≥mo mezclarlo, lo moldea a mano
- Tiempo: 1 chocolate por segundo = 11.5 d√≠as

**M√©todo NumPy (Industrial):**
- Una l√≠nea de producci√≥n automatizada procesa lotes de 1000 chocolates
- Los ingredientes fluyen en bloques homog√©neos por cintas transportadoras optimizadas
- Tiempo: 1000 chocolates por segundo = 16 minutos

La clave no es que la f√°brica sea "m√°s r√°pida"‚Äîes que **procesa en bloque** y **elimina la toma de decisiones por unidad**.

---

## 1.3 Rigor Matem√°tico: El Modelo de Memoria

### Definici√≥n Formal: ndarray

Un `ndarray` de NumPy es una tupla $(B, S, D, T)$ donde:

- $B$ : **Buffer** ‚Äî Bloque contiguo de memoria de $N$ bytes
- $S$ : **Shape** ‚Äî Tupla $(d_1, d_2, \ldots, d_k)$ con $\prod_{i=1}^{k} d_i = N / \text{sizeof}(T)$
- $D$ : **Strides** ‚Äî Tupla $(s_1, s_2, \ldots, s_k)$ donde $s_i$ indica bytes entre elementos consecutivos en dimensi√≥n $i$
- $T$ : **Dtype** ‚Äî Tipo de dato homog√©neo (e.g., `float64`, `int32`)

### F√≥rmula de Acceso a Elemento

Para un array $A$ con shape $(d_1, \ldots, d_k)$ y strides $(s_1, \ldots, s_k)$, el elemento $A[i_1, \ldots, i_k]$ se ubica en:

$$
\text{offset} = \sum_{j=1}^{k} i_j \cdot s_j
$$

**Implicaci√≥n cr√≠tica:** La operaci√≥n de *reshape* no copia datos‚Äîsolo reinterpreta los strides.

### Ejemplo Concreto

```python
import numpy as np

# Crear array con datos en memoria contigua
a = np.array([[1, 2, 3],
              [4, 5, 6]], dtype=np.float64)

print(f"Shape: {a.shape}")       # (2, 3)
print(f"Strides: {a.strides}")   # (24, 8) ‚Äî 24 bytes por fila, 8 bytes por elemento
print(f"Dtype: {a.dtype}")       # float64 (8 bytes por n√∫mero)

# Verificaci√≥n: 24 = 3 elementos √ó 8 bytes/elemento
assert a.strides[0] == a.shape[1] * a.itemsize
```

---

## 1.4 Asunciones del Modelo

Para que NumPy funcione eficientemente, el dataset debe cumplir:

| Asunci√≥n | Descripci√≥n | Violaci√≥n Com√∫n |
|----------|-------------|-----------------|
| **Homogeneidad** | Todos los elementos del mismo tipo | Mezclar strings con n√∫meros |
| **Tama√±o conocido** | Dimensiones fijas tras creaci√≥n | Append din√°mico en loops |
| **Memoria suficiente** | El array completo cabe en RAM | Datasets > memoria disponible |
| **Alineaci√≥n** | Datos contiguos en memoria | Slices discontinuos (views) |

**Cuando las asunciones fallan:**

- **Datos heterog√©neos:** Usar Pandas (maneja columnas de tipos mixtos)
- **Datos que no caben en memoria:** Usar Dask, Vaex, o streaming
- **Append din√°mico:** Pre-alocar con `np.empty()` o usar listas y convertir al final

---

## 1.5 Pensamiento Cr√≠tico: Escenarios de Fallo

### Escenario 1: El Dtype Silencioso

```python
import numpy as np

# PELIGRO: El dtype se infiere autom√°ticamente
a = np.array([1, 2, 3])           # dtype=int64
b = np.array([1.0, 2.0, 3.0])     # dtype=float64

# Operaci√≥n entre tipos: promoci√≥n silenciosa
c = a + b  # dtype=float64 (correcto)

# PERO: asignaci√≥n in-place NO promociona
a += 0.5   # ¬°Se trunca a int! a = [1, 2, 3], no [1.5, 2.5, 3.5]
```

**Regla de oro:** Siempre declarar `dtype=np.float64` expl√≠citamente para datos de ML.

### Escenario 2: La Vista Fantasma

```python
import numpy as np

X = np.array([[1, 2, 3],
              [4, 5, 6]])

# Esto es una VISTA, no una copia
fila = X[0]
fila[0] = 999  # ¬°Modifica X original!

print(X[0, 0])  # 999

# Soluci√≥n: copia expl√≠cita
fila_segura = X[0].copy()
```

**Diagn√≥stico:** `np.shares_memory(X, fila)` retorna `True` si comparten buffer.

---

## 1.6 Comparativa: NumPy vs Alternativas

| Criterio | NumPy | PyTorch Tensors | JAX Arrays | CuPy |
|----------|-------|-----------------|------------|------|
| **Backend** | CPU (BLAS) | CPU/GPU | XLA (CPU/GPU/TPU) | GPU (CUDA) |
| **Autograd** | ‚ùå No | ‚úÖ S√≠ | ‚úÖ S√≠ (funcional) | ‚ùå No |
| **API** | Est√°ndar de facto | Similar a NumPy | Similar a NumPy | Id√©ntica a NumPy |
| **Uso principal** | Prototipado, preproceso | Deep Learning | Investigaci√≥n | GPU computing |

**Recomendaci√≥n para el Pathway:** Dominar NumPy primero‚Äîtodos los dem√°s frameworks imitan su API.

---

# 2. NumPy: El Coraz√≥n del Stack Cient√≠fico

## 2.1 Creaci√≥n de Arrays

### Contexto Hist√≥rico

El dise√±o de constructores de NumPy refleja patrones de MATLAB (1984) y APL (1966), lenguajes pioneros en computaci√≥n matricial. La filosof√≠a es: **hacer lo com√∫n f√°cil y lo complejo posible**.

### Constructores Fundamentales

```python
import numpy as np

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# DESDE DATOS EXISTENTES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Conversi√≥n expl√≠cita con control de tipo
data = [1, 2, 3, 4, 5]
arr = np.array(data, dtype=np.float64)
assert arr.dtype == np.float64

# Desde nested lists (matriz)
matrix = np.array([[1, 2, 3],
                   [4, 5, 6]], dtype=np.float64)
assert matrix.shape == (2, 3)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ARRAYS INICIALIZADOS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Ceros: √∫til para acumuladores
zeros = np.zeros((100, 50), dtype=np.float64)  # Shape (100, 50)

# Unos: √∫til para inicializaci√≥n de pesos
ones = np.ones((64, 128), dtype=np.float64)

# Identidad: matriz cuadrada con 1s en diagonal
I = np.eye(4, dtype=np.float64)  # I @ x = x para todo x

# Sin inicializar: M√ÅS R√ÅPIDO pero contiene basura
buffer = np.empty((1000, 1000), dtype=np.float64)  # ¬°No asumir valores!

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# SECUENCIAS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# arange: como range() pero retorna array
# CUIDADO: con floats puede dar longitud inesperada
indices = np.arange(0, 10, 1)  # [0, 1, 2, ..., 9]

# linspace: PREFERIDO para floats ‚Äî garantiza N puntos exactos
x = np.linspace(0, 2*np.pi, 100)  # 100 puntos entre 0 y 2œÄ (inclusive)
assert len(x) == 100
assert x[0] == 0
assert np.isclose(x[-1], 2*np.pi)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ALEATORIOS (Generador moderno)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

rng = np.random.default_rng(seed=42)  # Reproducibilidad

# Normal est√°ndar: Œº=0, œÉ=1
normal = rng.standard_normal((100, 10))

# Uniforme en [0, 1)
uniform = rng.random((100, 10))

# Enteros uniformes en [low, high)
integers = rng.integers(low=0, high=10, size=(5, 5))
```

### Rigor Matem√°tico: ¬øPor qu√© `linspace` sobre `arange` para floats?

El problema con `arange` y floats:

$$
\texttt{arange}(0, 1, 0.1) \rightarrow [0.0, 0.1, 0.2, \ldots, 0.9] \quad \text{(10 elementos)}
$$

Pero debido a errores de punto flotante:

$$
0.1 + 0.1 + \ldots + 0.1 \neq 1.0
$$

En algunos sistemas, `arange(0, 1, 0.1)` puede retornar 10 u 11 elementos dependiendo del redondeo.

**`linspace` garantiza:**

$$
x_i = a + i \cdot \frac{b - a}{n - 1}, \quad i \in \{0, 1, \ldots, n-1\}
$$

---

## 2.2 Indexaci√≥n y Slicing

### El Contrato de Indexaci√≥n NumPy

NumPy extiende la indexaci√≥n de Python con sem√°ntica multidimensional:

```python
import numpy as np

# Crear matriz de ejemplo
A = np.arange(20).reshape(4, 5)
# [[ 0,  1,  2,  3,  4],
#  [ 5,  6,  7,  8,  9],
#  [10, 11, 12, 13, 14],
#  [15, 16, 17, 18, 19]]

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# INDEXACI√ìN B√ÅSICA (retorna VISTAS)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Elemento escalar
elem = A[1, 2]  # 7 (fila 1, columna 2)

# Fila completa
row = A[1]      # [5, 6, 7, 8, 9] ‚Äî shape (5,), ES UNA VISTA
row = A[1, :]   # Equivalente expl√≠cito

# Columna completa
col = A[:, 2]   # [2, 7, 12, 17] ‚Äî shape (4,), ES UNA VISTA

# Submatriz (slice 2D)
sub = A[1:3, 2:4]  # [[7, 8], [12, 13]] ‚Äî shape (2, 2), VISTA

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# FANCY INDEXING (retorna COPIAS)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Selecci√≥n con lista de √≠ndices
rows = A[[0, 2, 3]]           # Filas 0, 2, 3 ‚Äî shape (3, 5), ES COPIA
elems = A[[0, 1, 2], [4, 3, 2]]  # A[0,4], A[1,3], A[2,2] = [4, 8, 12]

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# INDEXACI√ìN BOOLEANA (retorna COPIAS, siempre 1D)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

mask = A > 10
filtered = A[mask]  # [11, 12, 13, 14, 15, 16, 17, 18, 19] ‚Äî shape (9,)

# Combinaci√≥n de condiciones: usar & (and), | (or), ~ (not)
# IMPORTANTE: par√©ntesis obligatorios por precedencia de operadores
mask2 = (A > 5) & (A < 15)
filtered2 = A[mask2]  # [6, 7, 8, 9, 10, 11, 12, 13, 14]
```

### Teorema Fundamental: Vista vs Copia

| Operaci√≥n | Resultado | Modifica Original |
|-----------|-----------|-------------------|
| `A[i]`, `A[i:j]`, `A[:, k]` | Vista | ‚úÖ S√≠ |
| `A[[i, j, k]]` | Copia | ‚ùå No |
| `A[mask]` | Copia | ‚ùå No |
| `A.copy()` | Copia | ‚ùå No |

**Verificaci√≥n program√°tica:**

```python
import numpy as np

A = np.arange(10)
view = A[2:5]
copy = A[[2, 3, 4]]

print(np.shares_memory(A, view))   # True
print(np.shares_memory(A, copy))   # False
```

---

## 2.3 Operaciones Matriciales

### Contexto: BLAS y el Legado de Fortran

Las operaciones matriciales de NumPy delegan a **BLAS** (Basic Linear Algebra Subprograms), una especificaci√≥n de 1979 implementada en Fortran. Las implementaciones modernas (OpenBLAS, Intel MKL, Apple Accelerate) incluyen:

- **Paralelizaci√≥n autom√°tica** en m√∫ltiples cores
- **Vectorizaci√≥n SIMD** (Single Instruction, Multiple Data)
- **Optimizaci√≥n de cach√©** mediante *blocking*

Por esto, `A @ B` no es "una multiplicaci√≥n"‚Äîes **miles de l√≠neas de c√≥digo optimizado** ejecut√°ndose bajo el cap√≥.

### El Operador `@` vs `*`

```python
import numpy as np

A = np.array([[1, 2],
              [3, 4]], dtype=np.float64)

B = np.array([[5, 6],
              [7, 8]], dtype=np.float64)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# MULTIPLICACI√ìN ELEMENTO A ELEMENTO (Hadamard)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

C_hadamard = A * B
# [[ 5, 12],
#  [21, 32]]
# C[i,j] = A[i,j] * B[i,j]

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PRODUCTO MATRICIAL (matmul)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

C_matmul = A @ B
# [[19, 22],
#  [43, 50]]
# C[i,j] = Œ£‚Çñ A[i,k] * B[k,j]
```

### Formalizaci√≥n del Producto Matricial

Para $A \in \mathbb{R}^{m \times n}$ y $B \in \mathbb{R}^{n \times p}$:

$$
C = AB \in \mathbb{R}^{m \times p}, \quad C_{ij} = \sum_{k=1}^{n} A_{ik} B_{kj}
$$

**Regla de compatibilidad dimensional:**

$$
(m \times \underbrace{n}_{\text{deben coincidir}}) \times (\underbrace{n}_{\text{deben coincidir}} \times p) \rightarrow (m \times p)
$$

### Casos Especiales en ML

```python
import numpy as np

# Datos t√≠picos de ML
N, D, K = 100, 784, 10  # 100 muestras, 784 features, 10 clases
X = np.random.randn(N, D)  # Batch de inputs
W = np.random.randn(D, K)  # Pesos de capa densa
b = np.random.randn(K)     # Bias

# Forward pass de capa lineal
Z = X @ W + b  # (N, D) @ (D, K) + (K,) ‚Üí (N, K)
assert Z.shape == (N, K)

# Vector de pesos para regresi√≥n
w = np.random.randn(D)     # (D,)
y_pred = X @ w             # (N, D) @ (D,) ‚Üí (N,)
assert y_pred.shape == (N,)
```

---

## 2.4 Reshape: Reinterpretaci√≥n de Memoria

### Principio Fundamental

`reshape` **no mueve datos**‚Äîsolo cambia la interpretaci√≥n de los strides:

```python
import numpy as np

a = np.arange(12)  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

# Todos estos comparten el MISMO buffer de memoria
b = a.reshape(3, 4)   # (3, 4)
c = a.reshape(4, 3)   # (4, 3)
d = a.reshape(2, 2, 3)  # (2, 2, 3)

assert np.shares_memory(a, b)
assert np.shares_memory(a, c)
assert np.shares_memory(a, d)

# El invariante es el tama√±o total
assert a.size == b.size == c.size == d.size == 12
```

### El Par√°metro `-1`: Inferencia Autom√°tica

NumPy puede calcular **una** dimensi√≥n autom√°ticamente:

```python
import numpy as np

X = np.random.randn(100, 784)  # 100 im√°genes de 28√ó28 aplanadas

# Reshape a formato de imagen (inferir primera dimensi√≥n)
X_img = X.reshape(-1, 28, 28)
assert X_img.shape == (100, 28, 28)

# Aplanar de vuelta
X_flat = X_img.reshape(X_img.shape[0], -1)
assert X_flat.shape == (100, 784)
```

### Error Com√∫n: `(n,)` vs `(n, 1)`

```python
import numpy as np

v = np.array([1, 2, 3])  # Shape (3,) ‚Äî vector 1D

# NO es lo mismo que:
v_col = v.reshape(-1, 1)  # Shape (3, 1) ‚Äî matriz columna
v_row = v.reshape(1, -1)  # Shape (1, 3) ‚Äî matriz fila

# Diferencias en operaciones
print(v @ v)          # Producto punto: escalar = 14
print(v_col @ v_row)  # Outer product: matriz (3, 3)
# [[1, 2, 3],
#  [2, 4, 6],
#  [3, 6, 9]]
```

---

# 3. Pandas: Manipulaci√≥n de Datos Tabulares

## 3.1 Contexto y Motivaci√≥n

### El Problema de los Datos Reales

NumPy asume datos homog√©neos. Pero los datasets reales contienen:

- **Columnas de tipos mixtos:** num√©ricos, categ√≥ricos, fechas, texto
- **Valores faltantes:** representados como `NaN`, `None`, o c√≥digos especiales
- **Metadatos:** nombres de columnas, √≠ndices con significado

**Pandas** (Panel Data, desarrollado por Wes McKinney en 2008 para an√°lisis financiero) resuelve esto con estructuras que combinan la eficiencia de NumPy con la flexibilidad de etiquetas.

### Arquitectura DataFrame

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         DataFrame                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Index     ‚îÇ   Col_A     ‚îÇ   Col_B     ‚îÇ   Col_C     ‚îÇ   Col_D    ‚îÇ
‚îÇ  (object)   ‚îÇ  (float64)  ‚îÇ  (int64)    ‚îÇ  (object)   ‚îÇ (datetime) ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  "row_0"    ‚îÇ    1.5      ‚îÇ     10      ‚îÇ   "cat"     ‚îÇ 2024-01-01 ‚îÇ
‚îÇ  "row_1"    ‚îÇ    2.3      ‚îÇ     20      ‚îÇ   "dog"     ‚îÇ 2024-01-02 ‚îÇ
‚îÇ  "row_2"    ‚îÇ    NaN      ‚îÇ     30      ‚îÇ   "cat"     ‚îÇ 2024-01-03 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì               ‚Üì            ‚Üì            ‚Üì
               np.ndarray      np.ndarray   np.ndarray   np.ndarray
               (float64)       (int64)      (object)     (datetime64)
```

**Cada columna es un `np.ndarray` independiente** con su propio dtype.

## 3.2 Pipeline Can√≥nico: CSV ‚Üí Modelo

```python
import pandas as pd
import numpy as np

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CAPA 1: CARGA DE DATOS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

df = pd.read_csv(
    'data/dataset.csv',
    dtype={'id': str, 'category': 'category'},  # Tipos expl√≠citos
    parse_dates=['timestamp'],                   # Parsear fechas
    na_values=['', 'NA', 'null', '-999']         # Valores a tratar como NaN
)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CAPA 2: INSPECCI√ìN (EDA M√≠nimo)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

print(df.shape)           # (n_rows, n_cols)
print(df.dtypes)          # Tipos de cada columna
print(df.info())          # Resumen con memoria y nulos
print(df.describe())      # Estad√≠sticas de columnas num√©ricas

# Conteo de nulos
null_counts = df.isnull().sum()
null_pct = df.isnull().mean() * 100
print(null_pct.sort_values(ascending=False))

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CAPA 3: LIMPIEZA
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Estrategia de imputaci√≥n por tipo de variable
df_clean = df.copy()

# Num√©ricas: mediana (robusta a outliers)
numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
for col in numeric_cols:
    median_val = df_clean[col].median()
    df_clean[col] = df_clean[col].fillna(median_val)

# Categ√≥ricas: moda o categor√≠a "Unknown"
categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns
for col in categorical_cols:
    df_clean[col] = df_clean[col].fillna('Unknown')

# Verificar que no quedan nulos
assert df_clean.isnull().sum().sum() == 0, "A√∫n hay valores nulos"

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CAPA 4: PREPARACI√ìN PARA ML
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Seleccionar features y target
feature_cols = ['feat_1', 'feat_2', 'feat_3', 'feat_4']
target_col = 'target'

X = df_clean[feature_cols].to_numpy(dtype=np.float64)
y = df_clean[target_col].to_numpy(dtype=np.float64)

# Validaciones cr√≠ticas
assert X.ndim == 2, f"X debe ser 2D, got {X.ndim}D"
assert y.ndim == 1, f"y debe ser 1D, got {y.ndim}D"
assert X.shape[0] == y.shape[0], "X e y deben tener mismo n√∫mero de muestras"
assert not np.any(np.isnan(X)), "X contiene NaN"
assert not np.any(np.isnan(y)), "y contiene NaN"

print(f"X: {X.shape}, dtype={X.dtype}")
print(f"y: {y.shape}, dtype={y.dtype}")
```

## 3.3 Operaciones Avanzadas

### GroupBy: Split-Apply-Combine

El patr√≥n **Split-Apply-Combine** (Wickham, 2011) es fundamental para agregaciones:

```python
import pandas as pd
import numpy as np

# Datos de ejemplo
df = pd.DataFrame({
    'category': ['A', 'A', 'B', 'B', 'B'],
    'value': [10, 20, 30, 40, 50]
})

# Split-Apply-Combine
result = df.groupby('category')['value'].agg(['mean', 'std', 'count'])
#          mean       std  count
# A        15.0  7.071068      2
# B        40.0 10.000000      3
```

### Merge: Combinaci√≥n de DataFrames

```python
import pandas as pd

# Dos tablas relacionadas
users = pd.DataFrame({
    'user_id': [1, 2, 3],
    'name': ['Alice', 'Bob', 'Charlie']
})

transactions = pd.DataFrame({
    'user_id': [1, 1, 2, 4],
    'amount': [100, 200, 150, 300]
})

# Inner join (solo matches)
merged_inner = pd.merge(users, transactions, on='user_id', how='inner')

# Left join (todos los users, NaN si no hay transacci√≥n)
merged_left = pd.merge(users, transactions, on='user_id', how='left')
```

---

# 4. Broadcasting: Aritm√©tica de Tensores

## 4.1 Contexto Hist√≥rico

El broadcasting fue introducido en APL (1966) y refinado en NumPy siguiendo la "regla de compatibilidad dimensional". Es la caracter√≠stica m√°s poderosa y m√°s peligrosa de NumPy.

## 4.2 La Regla de Broadcasting

**Definici√≥n formal:** Dos arrays son compatibles para broadcasting si, para cada dimensi√≥n (alineando desde la derecha), los tama√±os son iguales o uno de ellos es 1.

### Algoritmo de Broadcasting

1. **Padding:** Si los arrays tienen diferente n√∫mero de dimensiones, agregar 1s al principio del shape m√°s corto
2. **Verificaci√≥n:** Para cada par de dimensiones, verificar compatibilidad
3. **Expansi√≥n:** Las dimensiones de tama√±o 1 se "estiran" para coincidir

### Ejemplo Detallado

```python
import numpy as np

A = np.ones((3, 4))      # Shape: (3, 4)
b = np.array([1, 2, 3, 4])  # Shape: (4,)

# Paso 1: Padding
# A: (3, 4)
# b: (1, 4)  ‚Üê se agrega 1 al principio

# Paso 2: Verificaci√≥n
# Dimensi√≥n 0: 3 vs 1 ‚Üí compatible (1 se estira)
# Dimensi√≥n 1: 4 vs 4 ‚Üí compatible (iguales)

# Paso 3: Resultado
C = A + b  # Shape: (3, 4)
# Cada fila de A se suma con b
```

### Visualizaci√≥n de Broadcasting

```
A (3, 4):                  b (4,) ‚Üí (1, 4):
‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1 ‚îÇ 1 ‚îÇ 1 ‚îÇ 1 ‚îÇ         ‚îÇ 1 ‚îÇ 2 ‚îÇ 3 ‚îÇ 4 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚î§         ‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îò
‚îÇ 1 ‚îÇ 1 ‚îÇ 1 ‚îÇ 1 ‚îÇ              ‚Üì broadcast
‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚î§         ‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1 ‚îÇ 1 ‚îÇ 1 ‚îÇ 1 ‚îÇ         ‚îÇ 1 ‚îÇ 2 ‚îÇ 3 ‚îÇ 4 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îò         ‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚î§
                          ‚îÇ 1 ‚îÇ 2 ‚îÇ 3 ‚îÇ 4 ‚îÇ
A + b:                    ‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚î§
‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ 1 ‚îÇ 2 ‚îÇ 3 ‚îÇ 4 ‚îÇ
‚îÇ 2 ‚îÇ 3 ‚îÇ 4 ‚îÇ 5 ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îò
‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 2 ‚îÇ 3 ‚îÇ 4 ‚îÇ 5 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 2 ‚îÇ 3 ‚îÇ 4 ‚îÇ 5 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îò
```

## 4.3 Aplicaci√≥n Cr√≠tica: Normalizaci√≥n de Features

```python
import numpy as np

# Dataset: N muestras, D features
N, D = 1000, 50
X = np.random.randn(N, D) * 10 + 5  # Media ‚âà 5, std ‚âà 10

# Normalizaci√≥n Z-score por columna (feature-wise)
# Œº y œÉ deben tener shape (D,) o (1, D) para broadcast correcto

mu = X.mean(axis=0)           # Shape: (D,)
sigma = X.std(axis=0) + 1e-8  # Shape: (D,), +eps para evitar divisi√≥n por cero

X_normalized = (X - mu) / sigma  # Broadcasting: (N, D) - (D,) / (D,) ‚Üí (N, D)

# Verificaci√≥n
assert X_normalized.shape == X.shape
assert np.allclose(X_normalized.mean(axis=0), 0, atol=1e-10)
assert np.allclose(X_normalized.std(axis=0), 1, atol=1e-10)
```

## 4.4 El Error Silencioso: Broadcasting Incorrecto

```python
import numpy as np

X = np.random.randn(100, 50)  # (N, D)

# ‚ùå INCORRECTO: media global (escalar)
mu_wrong = X.mean()  # Shape: () ‚Äî escalar
X_wrong = X - mu_wrong  # Resta el mismo valor a TODO

# ‚úÖ CORRECTO: media por columna
mu_correct = X.mean(axis=0)  # Shape: (D,)
X_correct = X - mu_correct   # Resta media de cada feature

# El c√≥digo "funciona" en ambos casos, pero sem√°nticamente son MUY diferentes
```

**Regla de seguridad:** Siempre usar `keepdims=True` cuando no est√©s seguro:

```python
import numpy as np

X = np.random.randn(100, 50)

mu = X.mean(axis=0, keepdims=True)  # Shape: (1, 50)
sigma = X.std(axis=0, keepdims=True)  # Shape: (1, 50)

X_norm = (X - mu) / sigma  # Broadcasting expl√≠cito y seguro
```

---

# 5. Vectorizaci√≥n y Rendimiento

## 5.1 Por Qu√© Vectorizar

### Benchmark Comparativo

```python
import numpy as np
import time

def benchmark(func, *args, n_runs=100):
    """Mide tiempo promedio de ejecuci√≥n."""
    times = []
    for _ in range(n_runs):
        start = time.perf_counter()
        func(*args)
        times.append(time.perf_counter() - start)
    return np.mean(times) * 1000  # ms

# Datos de prueba
N = 100_000
a = np.random.randn(N)
b = np.random.randn(N)

# Versi√≥n con loop
def dot_loop(a, b):
    result = 0.0
    for i in range(len(a)):
        result += a[i] * b[i]
    return result

# Versi√≥n vectorizada
def dot_vectorized(a, b):
    return np.dot(a, b)

# Benchmark
t_loop = benchmark(dot_loop, a, b, n_runs=10)
t_vec = benchmark(dot_vectorized, a, b, n_runs=100)

print(f"Loop:       {t_loop:.2f} ms")
print(f"Vectorized: {t_vec:.4f} ms")
print(f"Speedup:    {t_loop/t_vec:.0f}x")
# T√≠picamente: 50-200x m√°s r√°pido
```

### An√°lisis del Speedup

El speedup no es lineal y depende de:

1. **Overhead de interpretaci√≥n:** Cada iteraci√≥n en Python tiene costo fijo
2. **Cache locality:** Accesos contiguos en memoria son m√°s r√°pidos
3. **SIMD:** Operaciones vectoriales procesan m√∫ltiples datos por instrucci√≥n
4. **Optimizaciones del compilador:** NumPy est√° compilado con `-O3`

## 5.2 Patrones de Vectorizaci√≥n

### Patr√≥n 1: Eliminaci√≥n de Loops Expl√≠citos

```python
import numpy as np

X = np.random.randn(1000, 100)  # Datos
y = np.random.randn(1000)       # Target

# ‚ùå CON LOOP
def mse_loop(X, y, w):
    n = len(y)
    total = 0.0
    for i in range(n):
        pred = 0.0
        for j in range(len(w)):
            pred += X[i, j] * w[j]
        total += (pred - y[i]) ** 2
    return total / n

# ‚úÖ VECTORIZADO
def mse_vectorized(X, y, w):
    pred = X @ w  # Predicciones vectorizadas
    return np.mean((pred - y) ** 2)
```

### Patr√≥n 2: Uso de `np.where` en lugar de condicionales

```python
import numpy as np

x = np.random.randn(10000)

# ‚ùå CON LOOP
def relu_loop(x):
    result = np.zeros_like(x)
    for i in range(len(x)):
        if x[i] > 0:
            result[i] = x[i]
    return result

# ‚úÖ VECTORIZADO con np.where
def relu_where(x):
    return np.where(x > 0, x, 0)

# ‚úÖ VECTORIZADO con np.maximum (a√∫n m√°s r√°pido)
def relu_maximum(x):
    return np.maximum(x, 0)
```

### Patr√≥n 3: Distancias Euclidianas en Batch

Problema: Calcular distancia entre cada par de puntos en dos conjuntos.

```python
import numpy as np

# X: (N, D), Y: (M, D)
# Resultado: (N, M) donde D[i,j] = ||X[i] - Y[j]||¬≤

def pairwise_distances_loop(X, Y):
    N, D = X.shape
    M = Y.shape[0]
    distances = np.zeros((N, M))
    for i in range(N):
        for j in range(M):
            diff = X[i] - Y[j]
            distances[i, j] = np.sum(diff ** 2)
    return distances

def pairwise_distances_vectorized(X, Y):
    # ||x - y||¬≤ = ||x||¬≤ + ||y||¬≤ - 2¬∑x¬∑y
    X_sqnorm = np.sum(X ** 2, axis=1, keepdims=True)  # (N, 1)
    Y_sqnorm = np.sum(Y ** 2, axis=1, keepdims=True)  # (M, 1)
    cross = X @ Y.T  # (N, M)
    return X_sqnorm + Y_sqnorm.T - 2 * cross  # Broadcasting: (N, 1) + (1, M) - (N, M)

# Verificaci√≥n
np.random.seed(42)
X = np.random.randn(100, 50)
Y = np.random.randn(80, 50)

D_loop = pairwise_distances_loop(X, Y)
D_vec = pairwise_distances_vectorized(X, Y)

assert np.allclose(D_loop, D_vec)
```

---

# 6. Laboratorios Visuales Interactivos

## 6.1 Lab 1: Explorador de Broadcasting (Streamlit)

```python
"""
Archivo: visual_labs/m01_broadcasting_explorer.py
Ejecutar: streamlit run visual_labs/m01_broadcasting_explorer.py
"""
import streamlit as st
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots

st.set_page_config(page_title="Broadcasting Explorer", layout="wide")
st.title("üî¨ Explorador de Broadcasting NumPy")

st.markdown("""
### Regla de Broadcasting
Dos arrays son compatibles si, para cada dimensi√≥n (de derecha a izquierda):
1. Las dimensiones son iguales, O
2. Una de ellas es 1
""")

col1, col2 = st.columns(2)

with col1:
    st.subheader("Array A")
    a_rows = st.slider("Filas de A", 1, 5, 3, key="a_rows")
    a_cols = st.slider("Columnas de A", 1, 5, 4, key="a_cols")
    A = np.arange(a_rows * a_cols).reshape(a_rows, a_cols)
    st.write(f"Shape: {A.shape}")
    st.dataframe(A)

with col2:
    st.subheader("Array B")
    b_shape_type = st.selectbox(
        "Tipo de B",
        ["Vector fila (1, n)", "Vector columna (m, 1)", "Escalar ()", "Matriz (m, n)"]
    )

    if b_shape_type == "Vector fila (1, n)":
        B = np.arange(a_cols).reshape(1, a_cols) * 10
    elif b_shape_type == "Vector columna (m, 1)":
        B = np.arange(a_rows).reshape(a_rows, 1) * 10
    elif b_shape_type == "Escalar ()":
        B = np.array(100)
    else:
        B = np.arange(a_rows * a_cols).reshape(a_rows, a_cols) * 10

    st.write(f"Shape: {B.shape}")
    if B.ndim == 0:
        st.write(f"Valor: {B}")
    else:
        st.dataframe(B)

st.subheader("Resultado: A + B")

try:
    C = A + B
    st.success(f"‚úÖ Broadcasting exitoso! Shape resultado: {C.shape}")
    st.dataframe(C)

    # Visualizaci√≥n
    fig = make_subplots(
        rows=1, cols=3,
        subplot_titles=["Array A", "Array B (broadcast)", "A + B"]
    )

    fig.add_trace(go.Heatmap(z=A, colorscale='Blues', showscale=False), row=1, col=1)

    B_broadcast = np.broadcast_to(B, C.shape) if B.ndim > 0 else np.full_like(C, B)
    fig.add_trace(go.Heatmap(z=B_broadcast, colorscale='Reds', showscale=False), row=1, col=2)

    fig.add_trace(go.Heatmap(z=C, colorscale='Viridis', showscale=False), row=1, col=3)

    fig.update_layout(height=300)
    st.plotly_chart(fig, use_container_width=True)

except ValueError as e:
    st.error(f"‚ùå Broadcasting fall√≥: {e}")
    st.markdown("""
    **Diagn√≥stico:** Las shapes no son compatibles.
    Revisa que cada dimensi√≥n cumpla la regla.
    """)
```

## 6.2 Lab 2: Comparador de Rendimiento (Streamlit)

```python
"""
Archivo: visual_labs/m01_performance_benchmark.py
Ejecutar: streamlit run visual_labs/m01_performance_benchmark.py
"""
import streamlit as st
import numpy as np
import time
import plotly.graph_objects as go

st.set_page_config(page_title="NumPy Performance Lab", layout="wide")
st.title("‚ö° Laboratorio de Rendimiento: Loop vs Vectorizado")

operation = st.selectbox(
    "Selecciona operaci√≥n",
    ["Producto punto", "Suma de elementos", "Distancia Euclidiana", "Normalizaci√≥n Z-score"]
)

sizes = st.multiselect(
    "Tama√±os a probar (N)",
    [100, 1000, 10000, 100000, 1000000],
    default=[1000, 10000, 100000]
)

if st.button("üöÄ Ejecutar Benchmark"):
    results = {"N": [], "Loop (ms)": [], "Vectorizado (ms)": [], "Speedup": []}

    progress = st.progress(0)

    for idx, N in enumerate(sizes):
        a = np.random.randn(N)
        b = np.random.randn(N)

        # Loop version
        if operation == "Producto punto":
            def loop_func():
                result = 0.0
                for i in range(N):
                    result += a[i] * b[i]
                return result
            vec_func = lambda: np.dot(a, b)
        elif operation == "Suma de elementos":
            def loop_func():
                result = 0.0
                for i in range(N):
                    result += a[i]
                return result
            vec_func = lambda: np.sum(a)
        elif operation == "Distancia Euclidiana":
            def loop_func():
                result = 0.0
                for i in range(N):
                    result += (a[i] - b[i]) ** 2
                return np.sqrt(result)
            vec_func = lambda: np.linalg.norm(a - b)
        else:  # Normalizaci√≥n
            def loop_func():
                mean = sum(a) / N
                std = np.sqrt(sum((x - mean)**2 for x in a) / N)
                return [(x - mean) / std for x in a]
            vec_func = lambda: (a - np.mean(a)) / np.std(a)

        # Benchmark
        n_runs = max(1, 100000 // N)

        start = time.perf_counter()
        for _ in range(n_runs):
            loop_func()
        t_loop = (time.perf_counter() - start) / n_runs * 1000

        start = time.perf_counter()
        for _ in range(n_runs):
            vec_func()
        t_vec = (time.perf_counter() - start) / n_runs * 1000

        results["N"].append(N)
        results["Loop (ms)"].append(t_loop)
        results["Vectorizado (ms)"].append(t_vec)
        results["Speedup"].append(t_loop / t_vec)

        progress.progress((idx + 1) / len(sizes))

    # Mostrar resultados
    st.subheader("Resultados")
    st.dataframe(results)

    # Gr√°fico
    fig = go.Figure()
    fig.add_trace(go.Bar(name="Loop", x=[str(n) for n in results["N"]], y=results["Loop (ms)"]))
    fig.add_trace(go.Bar(name="Vectorizado", x=[str(n) for n in results["N"]], y=results["Vectorizado (ms)"]))
    fig.update_layout(
        barmode='group',
        xaxis_title="N (elementos)",
        yaxis_title="Tiempo (ms)",
        yaxis_type="log"
    )
    st.plotly_chart(fig, use_container_width=True)

    st.metric("Speedup promedio", f"{np.mean(results['Speedup']):.0f}x")
```

## 6.3 Animaci√≥n Manim: Memoria Contigua vs Dispersa

```python
"""
Archivo: visual_labs/m01_memory_animation.py
Ejecutar: manim -pql visual_labs/m01_memory_animation.py MemoryLayoutAnimation
"""
from manim import *

class MemoryLayoutAnimation(Scene):
    def construct(self):
        # T√≠tulo
        title = Text("Memoria: Lista Python vs NumPy Array", font_size=36)
        title.to_edge(UP)
        self.play(Write(title))
        self.wait()

        # Lista Python (referencias dispersas)
        list_title = Text("Lista Python", font_size=24, color=RED)
        list_title.move_to(LEFT * 4 + UP * 2)

        # Crear cajas de referencia
        ref_boxes = VGroup()
        obj_boxes = VGroup()
        arrows = VGroup()

        for i in range(5):
            ref = Square(side_length=0.5, color=RED)
            ref.move_to(LEFT * 4 + DOWN * i * 0.7)
            ref_boxes.add(ref)

            obj = Square(side_length=0.5, color=YELLOW)
            obj.move_to(LEFT * (2 - i * 0.3) + DOWN * (i * 0.5 - 1) + RIGHT * np.random.uniform(-0.5, 0.5))
            obj_boxes.add(obj)

            arrow = Arrow(ref.get_right(), obj.get_left(), buff=0.1, color=GRAY)
            arrows.add(arrow)

        # NumPy Array (contiguo)
        np_title = Text("NumPy Array", font_size=24, color=GREEN)
        np_title.move_to(RIGHT * 3 + UP * 2)

        np_boxes = VGroup()
        for i in range(5):
            box = Square(side_length=0.5, color=GREEN)
            box.move_to(RIGHT * 3 + DOWN * i * 0.6)
            num = Text(str(i+1), font_size=20)
            num.move_to(box)
            np_boxes.add(VGroup(box, num))

        # Animaciones
        self.play(Write(list_title), Write(np_title))
        self.play(
            LaggedStart(*[Create(box) for box in ref_boxes], lag_ratio=0.1),
            LaggedStart(*[Create(box) for box in np_boxes], lag_ratio=0.1),
        )
        self.play(
            LaggedStart(*[Create(obj) for obj in obj_boxes], lag_ratio=0.1),
            LaggedStart(*[Create(arrow) for arrow in arrows], lag_ratio=0.1),
        )
        self.wait()

        # Explicaci√≥n
        exp1 = Text("Disperso en memoria", font_size=18, color=RED)
        exp1.next_to(ref_boxes, DOWN)

        exp2 = Text("Contiguo en memoria", font_size=18, color=GREEN)
        exp2.next_to(np_boxes, DOWN)

        self.play(Write(exp1), Write(exp2))
        self.wait()

        # Conclusi√≥n
        conclusion = Text(
            "Acceso contiguo = mejor uso de cach√© = m√°s velocidad",
            font_size=24,
            color=BLUE
        )
        conclusion.to_edge(DOWN)
        self.play(Write(conclusion))
        self.wait(2)
```

---

# 7. Pensamiento Cr√≠tico y Edge Cases

## 7.1 Escenario de Fallo 1: Overflow Silencioso

```python
import numpy as np

# Arrays de enteros tienen l√≠mites
a = np.array([2**62, 2**62], dtype=np.int64)
b = a + a  # ¬°OVERFLOW! Sin error ni warning

print(b)  # N√∫meros negativos o basura

# Soluci√≥n: usar float64 o verificar l√≠mites
a_safe = np.array([2**62, 2**62], dtype=np.float64)
b_safe = a_safe + a_safe  # Funciona correctamente
```

## 7.2 Escenario de Fallo 2: Broadcasting Sem√°ntico Incorrecto

```python
import numpy as np

# Supongamos que queremos sumar bias a cada muestra
X = np.random.randn(100, 10)  # 100 muestras, 10 features
b = np.random.randn(100)       # ¬øBias? NO - esto es por muestra, no por feature

# El broadcasting "funciona" pero est√° MAL sem√°nticamente
# X: (100, 10)
# b: (100,) ‚Üí se convierte en (100, 1) o (1, 100)?

# NumPy hace: (100, 10) + (100,) ‚Üí error porque 10 ‚â† 100

# Si b fuera (10,):
b_correct = np.random.randn(10)  # Bias por feature
Z = X + b_correct  # (100, 10) + (10,) ‚Üí (100, 10) ‚úÖ
```

## 7.3 Comparativa: NumPy vs Alternativas

| Escenario | Usar NumPy | Usar Alternativa |
|-----------|------------|------------------|
| Prototipado r√°pido | ‚úÖ | |
| Datos < 1GB en RAM | ‚úÖ | |
| Necesitas autograd | | PyTorch/JAX |
| GPU computing | | CuPy/JAX |
| Datos > RAM | | Dask/Vaex |
| Streaming data | | Generadores Python |

---

# 8. Evaluaci√≥n y Autoevaluaci√≥n

## 8.1 Checklist de Competencias

Antes de avanzar al M√≥dulo 02, verifica que puedes:

- [ ] Crear arrays con `np.zeros`, `np.ones`, `np.eye`, `np.random.default_rng`
- [ ] Predecir shapes resultantes de operaciones matriciales
- [ ] Identificar cu√°ndo una operaci√≥n produce vista vs copia
- [ ] Implementar normalizaci√≥n Z-score vectorizada
- [ ] Explicar por qu√© NumPy es m√°s r√°pido que Python puro
- [ ] Usar `axis` y `keepdims` correctamente en agregaciones
- [ ] Convertir un DataFrame de Pandas a arrays NumPy listos para ML

## 8.2 Ejercicio Integrador

```python
"""
Ejercicio: Implementar un pipeline completo de preprocesamiento

Dado un dataset CSV con:
- Columnas num√©ricas con algunos NaN
- Una columna categ√≥rica 'target'

Producir:
- X: np.ndarray de shape (n_samples, n_features), dtype=float64, sin NaN
- y: np.ndarray de shape (n_samples,), dtype=int64, con target codificado

Restricciones:
- No usar sklearn
- Imputar con mediana
- Verificar todas las shapes con assert
"""

import pandas as pd
import numpy as np

def prepare_ml_data(csv_path: str, target_col: str) -> tuple[np.ndarray, np.ndarray]:
    """Pipeline de preparaci√≥n de datos para ML."""
    # Tu implementaci√≥n aqu√≠
    pass

# Tests (deben pasar)
# X, y = prepare_ml_data('data/test.csv', 'target')
# assert X.ndim == 2
# assert y.ndim == 1
# assert X.shape[0] == y.shape[0]
# assert X.dtype == np.float64
# assert not np.any(np.isnan(X))
```

---

## Referencias y Lecturas Adicionales

1. **Harris, C.R., et al. (2020).** "Array programming with NumPy." *Nature*, 585, 357-362.
2. **McKinney, W. (2017).** *Python for Data Analysis*, 2nd ed. O'Reilly Media.
3. **Van Der Walt, S., Colbert, S.C., & Varoquaux, G. (2011).** "The NumPy Array: A Structure for Efficient Numerical Computation." *Computing in Science & Engineering*, 13(2), 22-30.
4. **3Blue1Brown - Linear Algebra Series:** [youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)

---

*M√≥dulo desarrollado siguiendo el curriculum del MS-AI Pathway de la University of Colorado Boulder.*
