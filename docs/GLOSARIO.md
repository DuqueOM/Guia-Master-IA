# üìñ Glosario T√©cnico - ML Specialist v3.3

> Definiciones A-Z de t√©rminos de Machine Learning usados en la gu√≠a.

---

## A

### Activation Function
**Definici√≥n:** Funci√≥n no lineal aplicada a la salida de una neurona.
**Ejemplos:** ReLU, Sigmoid, Tanh, Softmax.
**Por qu√©:** Sin activaciones, una red ser√≠a solo transformaciones lineales.

### Adam
**Definici√≥n:** Adaptive Moment Estimation - optimizador que combina Momentum y RMSprop.
**Par√°metros:** lr=0.001, Œ≤‚ÇÅ=0.9, Œ≤‚ÇÇ=0.999, Œµ=1e-8
**Uso:** Default moderno para entrenar redes neuronales.

### Accuracy
**Definici√≥n:** Proporci√≥n de predicciones correctas.
**F√≥rmula:** (TP + TN) / (TP + TN + FP + FN)
**Limitaci√≥n:** Enga√±oso con clases desbalanceadas.

---

## B

### Backpropagation
**Definici√≥n:** Algoritmo para calcular gradientes en redes neuronales usando la Chain Rule.
**Proceso:** Forward pass ‚Üí calcular loss ‚Üí backward pass ‚Üí actualizar pesos.
**Base matem√°tica:** ‚àÇL/‚àÇw = ‚àÇL/‚àÇa ¬∑ ‚àÇa/‚àÇz ¬∑ ‚àÇz/‚àÇw

### Batch Size
**Definici√≥n:** N√∫mero de muestras procesadas antes de actualizar pesos.
**Trade-off:** Grande = estable pero lento; peque√±o = ruidoso pero r√°pido.
**Com√∫n:** 32, 64, 128, 256.

### Bias (par√°metro)
**Definici√≥n:** T√©rmino constante en z = Wx + b que permite desplazar la funci√≥n.
**Analog√≠a:** El intercepto en una recta y = mx + b.

### Binary Cross-Entropy
**Definici√≥n:** Funci√≥n de p√©rdida para clasificaci√≥n binaria.
**F√≥rmula:** L = -[y¬∑log(≈∑) + (1-y)¬∑log(1-≈∑)]
**Uso:** Salida sigmoid, predicci√≥n de probabilidad.

### Broadcasting
**Definici√≥n:** Expansi√≥n autom√°tica de arrays para operaciones elemento a elemento.
**Ejemplo:** array(3,1) + array(1,4) ‚Üí array(3,4)
**Regla:** Dimensiones deben ser iguales o una debe ser 1.

---

## C

### Centroid
**Definici√≥n:** Punto central de un cluster (promedio de sus puntos).
**En K-Means:** Se actualiza iterativamente hasta convergencia.

### Chain Rule
**Definici√≥n:** Regla para derivar funciones compuestas.
**F√≥rmula:** d/dx f(g(x)) = f'(g(x)) ¬∑ g'(x)
**Importancia:** Base matem√°tica de Backpropagation.

### Classification
**Definici√≥n:** Tarea de predecir una categor√≠a discreta.
**Binaria:** 2 clases (spam/no spam).
**Multiclase:** >2 clases (d√≠gitos 0-9).

### Clustering
**Definici√≥n:** Agrupar puntos similares sin etiquetas supervisadas.
**Algoritmos:** K-Means, DBSCAN, Hierarchical.

### Confusion Matrix
**Definici√≥n:** Tabla que muestra predicciones vs valores reales.
**Componentes:** TP, TN, FP, FN.

### Convergence
**Definici√≥n:** Cuando el algoritmo deja de mejorar significativamente.
**Criterio:** Cambio en loss < tolerancia, o gradiente ‚âà 0.

### Cosine Similarity
**Definici√≥n:** Similitud basada en el √°ngulo entre vectores.
**F√≥rmula:** cos(Œ∏) = (a¬∑b) / (||a|| ||b||)
**Rango:** [-1, 1], donde 1 = id√©nticos.

### Cross-Validation
**Definici√≥n:** T√©cnica para evaluar modelo dividiendo datos en K folds.
**K-Fold:** Entrenar K veces, cada vez con diferente fold como validaci√≥n.
**Uso:** Estimar rendimiento real, evitar overfitting.

---

## D

### Deep Learning
**Definici√≥n:** ML con redes neuronales de m√∫ltiples capas ocultas.
**Ventaja:** Aprende features autom√°ticamente.
**Requisito:** Muchos datos y compute.

### Derivative
**Definici√≥n:** Tasa de cambio instant√°nea de una funci√≥n.
**Notaci√≥n:** f'(x), df/dx, ‚àÇf/‚àÇx (parcial).

### Dimensionality Reduction
**Definici√≥n:** Reducir n√∫mero de features preservando informaci√≥n.
**M√©todos:** PCA, t-SNE, UMAP.
**Uso:** Visualizaci√≥n, eliminar ruido, acelerar entrenamiento.

### Dot Product
**Definici√≥n:** Suma de productos elemento a elemento.
**F√≥rmula:** a¬∑b = Œ£ a·µ¢b·µ¢
**Uso:** Similitud, proyecciones, capas de red neuronal.

---

## E

### Eigenvalue / Eigenvector
**Definici√≥n:** Para matriz A, Av = Œªv donde v es eigenvector y Œª es eigenvalue.
**Interpretaci√≥n:** Direcciones principales de la transformaci√≥n.
**Uso en ML:** PCA usa eigenvectors de la matriz de covarianza.

### Epoch
**Definici√≥n:** Una pasada completa por todo el dataset de entrenamiento.
**T√≠pico:** 10-100 epochs dependiendo del problema.

### Euclidean Distance
**Definici√≥n:** Distancia en l√≠nea recta entre dos puntos.
**F√≥rmula:** d(a,b) = ‚àöŒ£(a·µ¢ - b·µ¢)¬≤
**Uso:** K-Means, KNN.

---

## F

### F1 Score
**Definici√≥n:** Media arm√≥nica de Precision y Recall.
**F√≥rmula:** F1 = 2 ¬∑ (P ¬∑ R) / (P + R)
**Uso:** Balance entre precision y recall.

### Feature
**Definici√≥n:** Variable de entrada (columna) en un dataset.
**Ejemplo:** En MNIST, cada p√≠xel es un feature (784 total).

### Forward Pass
**Definici√≥n:** Propagaci√≥n de input a trav√©s de la red para obtener output.
**C√°lculo:** z = Wx + b, a = activation(z), repetir por capa.

---

## G

### Gradient
**Definici√≥n:** Vector de derivadas parciales.
**Notaci√≥n:** ‚àáf = [‚àÇf/‚àÇx‚ÇÅ, ‚àÇf/‚àÇx‚ÇÇ, ...]
**Propiedad:** Apunta en direcci√≥n de m√°ximo ascenso.

### Gradient Descent
**Definici√≥n:** Algoritmo de optimizaci√≥n que sigue el gradiente negativo.
**Update:** Œ∏ = Œ∏ - Œ± ¬∑ ‚àáL(Œ∏)
**Variantes:** Batch, Mini-batch, Stochastic (SGD).

---

## H

### Hidden Layer
**Definici√≥n:** Capa entre input y output en una red neuronal.
**Funci√≥n:** Aprende representaciones intermedias.

### Hyperparameter
**Definici√≥n:** Par√°metro configurado antes del entrenamiento (no aprendido).
**Ejemplos:** Learning rate, n√∫mero de capas, batch size.

---

## I

### Inertia
**Definici√≥n:** Suma de distancias cuadradas de puntos a sus centroides.
**En K-Means:** M√©trica a minimizar.
**Uso:** M√©todo del codo para elegir K.

---

## K

### K-Means
**Definici√≥n:** Algoritmo de clustering que particiona en K grupos.
**Pasos:** 1) Inicializar centroides 2) Asignar puntos 3) Actualizar centroides 4) Repetir.
**Complejidad:** O(n ¬∑ k ¬∑ i ¬∑ d) donde i=iteraciones, d=dimensiones.

### K-Means++
**Definici√≥n:** Inicializaci√≥n inteligente para K-Means.
**M√©todo:** Elegir centroides iniciales lejos entre s√≠.
**Ventaja:** Mejor convergencia, evita m√≠nimos locales.

---

## L

### L1 Norm (Manhattan)
**Definici√≥n:** Suma de valores absolutos.
**F√≥rmula:** ||x||‚ÇÅ = Œ£|x·µ¢|
**Uso:** Regularizaci√≥n Lasso, promueve sparsity.

### L2 Norm (Euclidean)
**Definici√≥n:** Ra√≠z de suma de cuadrados (longitud del vector).
**F√≥rmula:** ||x||‚ÇÇ = ‚àöŒ£x·µ¢¬≤
**Uso:** Regularizaci√≥n Ridge, normalizaci√≥n.

### Learning Rate
**Definici√≥n:** Tama√±o del paso en Gradient Descent.
**S√≠mbolo:** Œ± (alpha) o lr.
**Trade-off:** Grande = r√°pido pero inestable; peque√±o = estable pero lento.

### Linear Regression
**Definici√≥n:** Modelo que predice valor continuo con combinaci√≥n lineal.
**F√≥rmula:** ≈∑ = XŒ∏
**Loss:** MSE (Mean Squared Error).

### Logistic Regression
**Definici√≥n:** Modelo de clasificaci√≥n binaria usando sigmoid.
**F√≥rmula:** P(y=1) = œÉ(XŒ∏)
**Loss:** Binary Cross-Entropy.

### Loss Function
**Definici√≥n:** Funci√≥n que mide error entre predicci√≥n y valor real.
**Ejemplos:** MSE (regresi√≥n), Cross-Entropy (clasificaci√≥n).
**Objetivo:** Minimizar durante entrenamiento.

---

## M

### Matrix Multiplication
**Definici√≥n:** Operaci√≥n (m√ón) @ (n√óp) ‚Üí (m√óp).
**Elemento:** C[i,j] = Œ£‚Çñ A[i,k] ¬∑ B[k,j]
**Uso:** Transformaciones lineales, capas de red.

### Mini-batch
**Definici√≥n:** Subconjunto de datos usado en una iteraci√≥n de SGD.
**Ventaja:** Balance entre eficiencia y estabilidad.

### MLP (Multilayer Perceptron)
**Definici√≥n:** Red neuronal fully-connected con capas ocultas.
**Arquitectura:** Input ‚Üí Hidden(s) ‚Üí Output.

### MNIST
**Definici√≥n:** Dataset de d√≠gitos escritos a mano (28√ó28 p√≠xeles).
**Tama√±o:** 60k train, 10k test.
**Uso:** Benchmark cl√°sico de clasificaci√≥n de im√°genes.

### MSE (Mean Squared Error)
**Definici√≥n:** Promedio de errores al cuadrado.
**F√≥rmula:** MSE = (1/n) Œ£(y - ≈∑)¬≤
**Uso:** Loss para regresi√≥n.

### Momentum
**Definici√≥n:** T√©cnica que acelera SGD acumulando gradientes pasados.
**F√≥rmula:** v = Œ≤¬∑v + (1-Œ≤)¬∑‚àáL; Œ∏ = Œ∏ - Œ±¬∑v
**Ventaja:** Escapa m√≠nimos locales, reduce oscilaciones.

---

## N

### Normalization
**Definici√≥n:** Escalar datos a un rango est√°ndar.
**Min-Max:** x' = (x - min) / (max - min) ‚Üí [0, 1]
**Z-score:** x' = (x - Œº) / œÉ ‚Üí media 0, std 1.

### NumPy
**Definici√≥n:** Librer√≠a de Python para computaci√≥n num√©rica eficiente.
**Ventaja:** Operaciones vectorizadas (evita loops).
**Objeto principal:** ndarray (n-dimensional array).

---

## O

### One-Hot Encoding
**Definici√≥n:** Representar categor√≠a como vector binario.
**Ejemplo:** clase 3 de 5 ‚Üí [0, 0, 0, 1, 0]
**Uso:** Labels para clasificaci√≥n multiclase.

### Overfitting
**Definici√≥n:** Modelo que memoriza training data pero no generaliza.
**S√≠ntoma:** Train loss bajo, test loss alto.
**Soluciones:** M√°s datos, regularizaci√≥n, dropout, early stopping.

---

## P

### Partial Derivative
**Definici√≥n:** Derivada respecto a una variable, tratando otras como constantes.
**Notaci√≥n:** ‚àÇf/‚àÇx
**Uso:** Calcular gradientes en funciones multivariable.

### PCA (Principal Component Analysis)
**Definici√≥n:** Reducci√≥n dimensional que preserva m√°xima varianza.
**M√©todo:** Proyectar datos en eigenvectors principales.
**Output:** Componentes principales ordenados por varianza explicada.

### Precision
**Definici√≥n:** De los predichos positivos, ¬øcu√°ntos son correctos?
**F√≥rmula:** TP / (TP + FP)
**Importancia:** Cuando FP es costoso.

### Projection
**Definici√≥n:** Mapear un punto a un subespacio (l√≠nea, plano).
**En PCA:** Proyectar datos al espacio de componentes principales.

---

## R

### Recall
**Definici√≥n:** De los positivos reales, ¬øcu√°ntos captur√©?
**F√≥rmula:** TP / (TP + FN)
**Importancia:** Cuando FN es costoso.

### Regression
**Definici√≥n:** Predecir un valor continuo.
**Ejemplos:** Precio de casa, temperatura.

### Regularization
**Definici√≥n:** T√©cnica para prevenir overfitting penalizando complejidad.
**L1 (Lasso):** A√±ade Œª¬∑||Œ∏||‚ÇÅ al loss.
**L2 (Ridge):** A√±ade Œª¬∑||Œ∏||‚ÇÇ¬≤ al loss.

### ReLU (Rectified Linear Unit)
**Definici√≥n:** f(x) = max(0, x)
**Derivada:** 1 si x > 0, 0 si x ‚â§ 0.
**Ventaja:** Simple, evita vanishing gradient.

---

## S

### SGD (Stochastic Gradient Descent)
**Definici√≥n:** Gradient descent con una muestra (o mini-batch) por update.
**Ventaja:** M√°s r√°pido, escapa m√≠nimos locales.
**Desventaja:** Updates ruidosos.

### Sigmoid
**Definici√≥n:** œÉ(x) = 1 / (1 + e‚ÅªÀ£)
**Rango:** (0, 1)
**Uso:** Clasificaci√≥n binaria, probabilidades.
**Derivada:** œÉ(x) ¬∑ (1 - œÉ(x))

### Silhouette Score
**Definici√≥n:** M√©trica de calidad de clustering.
**Rango:** [-1, 1], mayor es mejor.
**C√°lculo:** Basado en cohesi√≥n intra-cluster y separaci√≥n inter-cluster.

### Softmax
**Definici√≥n:** Convierte vector a distribuci√≥n de probabilidad.
**F√≥rmula:** softmax(z)·µ¢ = e·∂ª‚Å± / Œ£‚±º e·∂ª ≤
**Uso:** Capa de salida para clasificaci√≥n multiclase.

### Supervised Learning
**Definici√≥n:** Aprender de datos con etiquetas (X, y).
**Tareas:** Clasificaci√≥n, Regresi√≥n.

### SVD (Singular Value Decomposition)
**Definici√≥n:** Factorizaci√≥n A = UŒ£V·µÄ.
**Uso:** PCA (m√°s estable), compresi√≥n, sistemas de recomendaci√≥n.

---

## T

### Tanh
**Definici√≥n:** Tangente hiperb√≥lica, similar a sigmoid pero centrada en 0.
**Rango:** (-1, 1)
**Derivada:** 1 - tanh¬≤(x)

### Test Set
**Definici√≥n:** Datos reservados para evaluaci√≥n final del modelo.
**Regla:** NUNCA usar para entrenar o seleccionar hiperpar√°metros.

### Training Set
**Definici√≥n:** Datos usados para entrenar el modelo.
**T√≠pico:** 70-80% del dataset total.

### Transpose
**Definici√≥n:** Intercambiar filas y columnas de una matriz.
**Notaci√≥n:** A·µÄ
**Propiedad:** (AB)·µÄ = B·µÄA·µÄ

---

## U

### Underfitting
**Definici√≥n:** Modelo demasiado simple que no captura patrones.
**S√≠ntoma:** Train loss alto, test loss alto.
**Soluciones:** Modelo m√°s complejo, m√°s features, m√°s entrenamiento.

### Unsupervised Learning
**Definici√≥n:** Aprender de datos sin etiquetas.
**Tareas:** Clustering, reducci√≥n dimensional, detecci√≥n de anomal√≠as.

---

## V

### Validation Set
**Definici√≥n:** Datos para ajustar hiperpar√°metros y detectar overfitting.
**T√≠pico:** 10-20% del training data.

### Variance (estad√≠stica)
**Definici√≥n:** Medida de dispersi√≥n de los datos.
**F√≥rmula:** Var(X) = E[(X - Œº)¬≤]

### Variance (ML)
**Definici√≥n:** Error por sensibilidad a fluctuaciones en training data.
**Alta varianza:** Overfitting.

### Vectorization
**Definici√≥n:** Reemplazar loops por operaciones de arrays.
**Ventaja:** 10-100x m√°s r√°pido con NumPy.
**Ejemplo:** `np.dot(a, b)` en lugar de `sum(a[i]*b[i] for i in range(n))`

---

## W

### Weight
**Definici√≥n:** Par√°metro aprendido que determina importancia de input.
**En redes:** Matriz W en z = Wx + b.

---

## X

### Xavier Initialization
**Definici√≥n:** Inicializar pesos con varianza 1/n_inputs.
**F√≥rmula:** W ~ N(0, 1/n_in) o U(-‚àö(1/n_in), ‚àö(1/n_in))
**Uso:** Capas con tanh/sigmoid.

### XOR Problem
**Definici√≥n:** Problema no linealmente separable cl√°sico.
**Importancia:** Demuestra necesidad de capas ocultas en redes neuronales.
**Soluci√≥n:** MLP con al menos una capa oculta.
