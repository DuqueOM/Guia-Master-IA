# üìö Referencias Bibliogr√°ficas - Gu√≠a Master IA

> **Programa de Preparaci√≥n para MS in AI - CU Boulder**
> Bibliograf√≠a obligatoria y recomendada organizada por √°rea tem√°tica

---

## üìñ C√≥mo Usar Este Documento

- **‚≠ê‚≠ê‚≠ê** = Lectura obligatoria (core del programa)
- **‚≠ê‚≠ê** = Altamente recomendada
- **‚≠ê** = Referencia complementaria
- üìò = Libro completo disponible online
- üîó = Enlace directo al recurso

---

## 1. Matem√°ticas Fundamentales (M01-M04)

### 1.1 √Ålgebra Lineal (M02)

| Recurso | Autor(es) | Cap√≠tulos Clave | Prioridad |
|---------|-----------|-----------------|-----------|
| **Introduction to Linear Algebra** | Gilbert Strang | Cap. 1-6 | ‚≠ê‚≠ê‚≠ê |
| [MIT 18.06 Lectures](https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/) | Gilbert Strang | Videos 1-24 | ‚≠ê‚≠ê‚≠ê üìò |
| **Linear Algebra Done Right** | Sheldon Axler | Cap. 1-5, 7 | ‚≠ê‚≠ê |
| [3Blue1Brown: Essence of Linear Algebra](https://www.3blue1brown.com/topics/linear-algebra) | Grant Sanderson | Serie completa | ‚≠ê‚≠ê üîó |

**Temas cubiertos:** Vectores, matrices, eigenvalues/eigenvectors, SVD, proyecciones, espacios vectoriales.

### 1.2 C√°lculo y Optimizaci√≥n (M03)

| Recurso | Autor(es) | Cap√≠tulos Clave | Prioridad |
|---------|-----------|-----------------|-----------|
| **Calculus** | James Stewart | Cap. 11-16 (Multivar) | ‚≠ê‚≠ê |
| [Convex Optimization](https://web.stanford.edu/~boyd/cvxbook/) | Boyd & Vandenberghe | Cap. 1-5, 9 | ‚≠ê‚≠ê‚≠ê üìò |
| **Numerical Optimization** | Nocedal & Wright | Cap. 1-3 | ‚≠ê‚≠ê |

**Temas cubiertos:** Derivadas parciales, gradientes, Hessiano, regla de la cadena, optimizaci√≥n convexa, gradient descent.

### 1.3 Probabilidad y Estad√≠stica (M04)

| Recurso | Autor(es) | Cap√≠tulos Clave | Prioridad |
|---------|-----------|-----------------|-----------|
| **[Machine Learning: A Probabilistic Perspective](https://probml.github.io/pml-book/)** | Kevin P. Murphy | Cap. 2, 3, 5, 17, 24 | ‚≠ê‚≠ê‚≠ê üìò |
| **[Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning/)** | Christopher Bishop | Cap. 1.2, 2, 8, 11 | ‚≠ê‚≠ê‚≠ê üìò |
| **[Markov Chains and Mixing Times](https://pages.uoregon.edu/dlevin/MARKOV/markovmixing.pdf)** | Levin, Peres, Wilmer | Cap. 1-4, 12 | ‚≠ê‚≠ê üìò |
| **Introduction to Probability** | Blitzstein & Hwang | Cap. 1-9 | ‚≠ê‚≠ê |

**Temas cubiertos:** Bayes, distribuciones, MLE/MAP, cadenas de Markov, Monte Carlo, MCMC.

---

## 2. Machine Learning Cl√°sico (M05-M06)

### 2.1 Aprendizaje Supervisado (M05) ‚Äî CSCA 5622

| Recurso | Autor(es) | Cap√≠tulos Clave | Prioridad |
|---------|-----------|-----------------|-----------|
| **[Machine Learning: A Probabilistic Perspective](https://probml.github.io/pml-book/)** | Kevin P. Murphy | Cap. 7-9, 14, 16 | ‚≠ê‚≠ê‚≠ê üìò |
| **[The Elements of Statistical Learning](https://hastie.su.domains/ElemStatLearn/)** | Hastie, Tibshirani, Friedman | Cap. 2-4, 7, 9, 15 | ‚≠ê‚≠ê‚≠ê üìò |
| **[An Introduction to Statistical Learning](https://www.statlearning.com/)** | James, Witten, Hastie, Tibshirani | Cap. 2-6, 8-9 | ‚≠ê‚≠ê üìò |
| **[Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)** | Christoph Molnar | Cap. 5-9 (SHAP, LIME) | ‚≠ê‚≠ê üìò |

**Temas cubiertos:** Regresi√≥n lineal/log√≠stica, √°rboles de decisi√≥n, SVM, ensemble methods, interpretabilidad.

### 2.2 Aprendizaje No Supervisado (M06) ‚Äî CSCA 5632

| Recurso | Autor(es) | Cap√≠tulos Clave | Prioridad |
|---------|-----------|-----------------|-----------|
| **[Machine Learning: A Probabilistic Perspective](https://probml.github.io/pml-book/)** | Kevin P. Murphy | Cap. 11, 12, 25, 27 | ‚≠ê‚≠ê‚≠ê üìò |
| **Pattern Recognition and Machine Learning** | Christopher Bishop | Cap. 9, 12 | ‚≠ê‚≠ê‚≠ê |
| **Mining of Massive Datasets** | Leskovec, Rajaraman, Ullman | Cap. 9, 11 | ‚≠ê‚≠ê |
| [Recommender Systems Handbook](https://link.springer.com/book/10.1007/978-1-0716-2197-4) | Ricci et al. | Cap. 1-5 | ‚≠ê‚≠ê |

**Temas cubiertos:** K-Means, PCA, GMM/EM, sistemas de recomendaci√≥n, matrix factorization.

---

## 3. Deep Learning (M07-M08)

### 3.1 Fundamentos Deep Learning (M07) ‚Äî CSCA 5642

| Recurso | Autor(es) | Cap√≠tulos Clave | Prioridad |
|---------|-----------|-----------------|-----------|
| **[Deep Learning](https://www.deeplearningbook.org/)** | Goodfellow, Bengio, Courville | Cap. 6-12 | ‚≠ê‚≠ê‚≠ê üìò |
| **[Dive into Deep Learning](https://d2l.ai/)** | Zhang, Lipton, Li, Smola | Cap. 3-10, 14-16 | ‚≠ê‚≠ê‚≠ê üìò |
| [Stanford CS231n: CNNs](http://cs231n.stanford.edu/) | Fei-Fei Li et al. | Lectures 1-15 | ‚≠ê‚≠ê üîó |
| [Stanford CS224n: NLP with DL](http://web.stanford.edu/class/cs224n/) | Christopher Manning | Lectures 1-12 | ‚≠ê‚≠ê üîó |

**Temas cubiertos:** MLPs, backpropagation, CNNs, RNNs/LSTMs, regularizaci√≥n, transfer learning.

### 3.2 NLP y Transformers (M08)

| Recurso | Autor(es) | Cap√≠tulos Clave | Prioridad |
|---------|-----------|-----------------|-----------|
| **[Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/)** | Jurafsky & Martin | Cap. 3-7, 9-11 | ‚≠ê‚≠ê‚≠ê üìò |
| [HuggingFace Course](https://huggingface.co/learn/nlp-course/) | HuggingFace Team | M√≥dulos 1-8 | ‚≠ê‚≠ê‚≠ê üîó |
| **[Attention Is All You Need](https://arxiv.org/abs/1706.03762)** | Vaswani et al. | Paper completo | ‚≠ê‚≠ê |
| **[BERT Paper](https://arxiv.org/abs/1810.04805)** | Devlin et al. | Paper completo | ‚≠ê‚≠ê |

**Temas cubiertos:** Word embeddings, RNNs para NLP, attention, transformers, BERT, fine-tuning.

---

## 4. Frameworks y Herramientas

### 4.1 Keras/TensorFlow (Framework Principal)

| Recurso | Tipo | Enlace |
|---------|------|--------|
| **Keras Documentation** | Oficial | [keras.io](https://keras.io/) |
| **TensorFlow Tutorials** | Oficial | [tensorflow.org/tutorials](https://www.tensorflow.org/tutorials) |
| **Deep Learning with Python, 2nd Ed** | Libro (Chollet) | [manning.com](https://www.manning.com/books/deep-learning-with-python-second-edition) |

### 4.2 Scikit-Learn

| Recurso | Tipo | Enlace |
|---------|------|--------|
| **Scikit-Learn User Guide** | Oficial | [scikit-learn.org](https://scikit-learn.org/stable/user_guide.html) |
| **Hands-On ML with Scikit-Learn, Keras & TF** | Libro (G√©ron) | [oreilly.com](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) |

### 4.3 PyTorch (Track Opcional)

| Recurso | Tipo | Enlace |
|---------|------|--------|
| **PyTorch Tutorials** | Oficial | [pytorch.org/tutorials](https://pytorch.org/tutorials/) |
| **Deep Learning with PyTorch** | Libro | [pytorch.org/deep-learning-with-pytorch](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf) |

---

## 5. Papers Fundamentales

### Machine Learning Cl√°sico

| Paper | Autores | A√±o | Relevancia |
|-------|---------|-----|------------|
| Random Forests | Leo Breiman | 2001 | M05: Ensemble Methods |
| XGBoost | Chen & Guestrin | 2016 | M05: Gradient Boosting |
| A Few Useful Things to Know About ML | Pedro Domingos | 2012 | Perspectiva general |

### Deep Learning

| Paper | Autores | A√±o | Relevancia |
|-------|---------|-----|------------|
| **ImageNet Classification with Deep CNNs (AlexNet)** | Krizhevsky et al. | 2012 | M07: CNNs |
| **Dropout** | Srivastava et al. | 2014 | M07: Regularizaci√≥n |
| **Batch Normalization** | Ioffe & Szegedy | 2015 | M07: T√©cnicas de entrenamiento |
| **Adam Optimizer** | Kingma & Ba | 2015 | M07: Optimizaci√≥n |
| **ResNet** | He et al. | 2015 | M07: Arquitecturas profundas |

### NLP

| Paper | Autores | A√±o | Relevancia |
|-------|---------|-----|------------|
| **Word2Vec** | Mikolov et al. | 2013 | M08: Word Embeddings |
| **GloVe** | Pennington et al. | 2014 | M08: Word Embeddings |
| **Attention Is All You Need** | Vaswani et al. | 2017 | M08: Transformers |
| **BERT** | Devlin et al. | 2018 | M08: Transfer Learning NLP |

---

## 6. Cursos Online Complementarios

### MOOCs Gratuitos

| Curso | Plataforma | Instructor | M√≥dulos Relacionados |
|-------|------------|------------|---------------------|
| [Machine Learning](https://www.coursera.org/learn/machine-learning) | Coursera | Andrew Ng | M05-M06 |
| [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) | Coursera | Andrew Ng | M07-M08 |
| [CS229: Machine Learning](https://cs229.stanford.edu/) | Stanford | Andrew Ng | M05-M07 |
| [Fast.ai Practical Deep Learning](https://course.fast.ai/) | fast.ai | Jeremy Howard | M07-M08 |

---

## 7. Recursos por M√≥dulo (Resumen R√°pido)

| M√≥dulo | Recurso Principal | Recurso Secundario |
|--------|-------------------|-------------------|
| **M01** | Python Data Science Handbook | NumPy/Pandas Docs |
| **M02** | Strang - Linear Algebra | 3Blue1Brown Videos |
| **M03** | Boyd - Convex Optimization | Stewart Calculus |
| **M04** | Murphy - ML Probabilistic | Levin - Markov Chains |
| **M05** | ESL (Hastie) | ISL + Molnar (XAI) |
| **M06** | Murphy Cap. 11-12, 25 | Bishop Cap. 9, 12 |
| **M07** | Goodfellow - Deep Learning | d2l.ai |
| **M08** | Jurafsky - SLP3 | HuggingFace Course |

---

## 8. Citas Formales (BibTeX)

```bibtex
@book{goodfellow2016deep,
  title={Deep Learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT Press},
  url={https://www.deeplearningbook.org/}
}

@book{murphy2012machine,
  title={Machine Learning: A Probabilistic Perspective},
  author={Murphy, Kevin P.},
  year={2012},
  publisher={MIT Press}
}

@book{bishop2006pattern,
  title={Pattern Recognition and Machine Learning},
  author={Bishop, Christopher M.},
  year={2006},
  publisher={Springer}
}

@book{levin2017markov,
  title={Markov Chains and Mixing Times},
  author={Levin, David A. and Peres, Yuval and Wilmer, Elizabeth L.},
  year={2017},
  edition={2nd},
  publisher={American Mathematical Society}
}

@book{hastie2009elements,
  title={The Elements of Statistical Learning},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year={2009},
  edition={2nd},
  publisher={Springer}
}

@article{vaswani2017attention,
  title={Attention Is All You Need},
  author={Vaswani, Ashish and others},
  journal={NeurIPS},
  year={2017}
}

@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers},
  author={Devlin, Jacob and others},
  journal={NAACL},
  year={2019}
}
```

---

## üìã Checklist de Lecturas por Pathway Course

### CSCA 5622 - Supervised Learning
- [ ] ESL Cap. 2-4 (Fundamentos)
- [ ] Murphy Cap. 7-9 (Clasificaci√≥n)
- [ ] Molnar Cap. 5-9 (Interpretabilidad)

### CSCA 5632 - Unsupervised Learning
- [ ] Murphy Cap. 11-12 (Clustering)
- [ ] Bishop Cap. 9 (EM Algorithm)
- [ ] Murphy Cap. 25, 27 (Recommenders)

### CSCA 5642 - Deep Learning
- [ ] Goodfellow Cap. 6-12 (Core DL)
- [ ] CS231n Lectures (CNNs)
- [ ] HuggingFace Course (Transformers)

---

*√öltima actualizaci√≥n: Diciembre 2024*
*Programa alineado con MS in AI - CU Boulder*
