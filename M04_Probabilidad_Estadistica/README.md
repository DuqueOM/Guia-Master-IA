# MÃ³dulo 04: Probabilidad y EstadÃ­stica para Machine Learning

> **Semana:** 8 | **Fase:** Fundamentos MatemÃ¡ticos
> **Curso Alineado:** PreparaciÃ³n para CSCA 5622, 5632, 5642
> **Carga Estimada:** 10-12 horas

---

## ğŸ¯ Objetivos de Aprendizaje

Al completar este mÃ³dulo, el estudiante serÃ¡ capaz de:

1. **Fundamentos ProbabilÃ­sticos**
   - Aplicar regla de Bayes en problemas de clasificaciÃ³n
   - Distinguir entre probabilidad frecuentista y bayesiana
   - Calcular probabilidades condicionales e independencia

2. **EstimaciÃ³n EstadÃ­stica**
   - Derivar estimadores MLE (Maximum Likelihood Estimation)
   - Derivar estimadores MAP (Maximum A Posteriori)
   - Comparar sesgo, varianza y MSE de estimadores

3. **Cadenas de Markov**
   - Construir matrices de transiciÃ³n
   - Calcular distribuciones estacionarias
   - Analizar propiedades de ergodicidad y mixing time

4. **MÃ©todos de Monte Carlo**
   - Implementar Monte Carlo simple para integraciÃ³n
   - Implementar Metropolis-Hastings y Gibbs Sampling
   - Diagnosticar convergencia (R-hat, ESS, trace plots)

---

## ğŸ“… Syllabus Detallado (Semana 8)

### DÃ­a 1-2: Fundamentos de Probabilidad y Bayes

| Tema | Contenido | Ejercicio |
|------|-----------|-----------|
| Axiomas de probabilidad | Espacios muestrales, eventos, sigma-Ã¡lgebras | Ejercicio 1.1 |
| Probabilidad condicional | P(A\|B), independencia, Bayes | Ejercicio 1.2 |
| Regla de Bayes | Prior, likelihood, posterior, evidencia | Ejercicio 1.3 |
| Variables aleatorias | Discretas vs continuas, PMF/PDF, CDF | Ejercicio 1.4 |

**Lectura obligatoria:** Murphy Cap. 2.1-2.4, Bishop Cap. 1.2

### DÃ­a 3-4: Distribuciones y EstimaciÃ³n (MLE/MAP)

| Tema | Contenido | Ejercicio |
|------|-----------|-----------|
| Distribuciones comunes | Bernoulli, Binomial, Gaussiana, Poisson | Ejercicio 2.1 |
| Esperanza y varianza | E[X], Var(X), propiedades | Ejercicio 2.2 |
| **MLE** | DerivaciÃ³n log-likelihood, ejemplos analÃ­ticos | **Lab 1** |
| **MAP** | Priors conjugados, regularizaciÃ³n bayesiana | **Lab 1** |
| Sesgo-Varianza | Trade-off, MSE = BiasÂ² + Variance | Ejercicio 2.3 |

**Lectura obligatoria:** Murphy Cap. 3.1-3.5, Bishop Cap. 2.1-2.3

### DÃ­a 5: Cadenas de Markov (Discrete-Time)

| Tema | Contenido | Ejercicio |
|------|-----------|-----------|
| DefiniciÃ³n DTMC | Estados, transiciones, matriz P | Ejercicio 3.1 |
| Propiedades | Irreducibilidad, aperiodicidad, recurrencia | Ejercicio 3.2 |
| DistribuciÃ³n estacionaria | Ï€ = Ï€P, existencia y unicidad | **Lab 3** |
| Teorema ergÃ³dico | Convergencia, mixing time | **Lab 3** |
| Aplicaciones ML | PageRank, HMM preview | Ejercicio 3.3 |

**Lectura obligatoria:** Levin & Peres Cap. 1-2, Murphy Cap. 17.2

### DÃ­a 6-7: Monte Carlo y MCMC

| Tema | Contenido | Ejercicio |
|------|-----------|-----------|
| Monte Carlo simple | IntegraciÃ³n, estimaciÃ³n de Ï€ | Ejercicio 4.1 |
| Importance Sampling | ReducciÃ³n de varianza | Ejercicio 4.2 |
| **Metropolis-Hastings** | Algoritmo, acceptance ratio, proposal | **Lab 2** |
| **Gibbs Sampling** | Caso especial, conditional sampling | **Lab 2** |
| DiagnÃ³sticos | Burn-in, thinning, R-hat, ESS, trace plots | **Lab 2** |

**Lectura obligatoria:** Murphy Cap. 24.1-24.3, Bishop Cap. 11.2-11.3

---

## ğŸ§ª Laboratorios Obligatorios

### Lab 1: MLE/MAP y Estimadores (`Notebooks/Lab1_MLE_MAP.py`)

**Objetivos:**
- Derivar MLE para Bernoulli, Gaussiana, Poisson
- Implementar MLE numÃ©ricamente con scipy.optimize
- Comparar MLE vs MAP con diferentes priors
- Visualizar efecto del tamaÃ±o de muestra

**Entregables:**
- [ ] DerivaciÃ³n analÃ­tica de MLE para Gaussiana (Î¼, ÏƒÂ²)
- [ ] ImplementaciÃ³n de MLE numÃ©rico
- [ ] ComparaciÃ³n MLE vs MAP con prior Beta-Binomial
- [ ] GrÃ¡fico: sesgo vs varianza vs n

### Lab 2: Monte Carlo y MCMC (`Notebooks/Lab2_MonteCarlo_MCMC.py`)

**Objetivos:**
- Estimar Ï€ usando Monte Carlo
- Implementar Metropolis-Hastings desde cero
- Implementar Gibbs Sampling para Gaussiana bivariada
- Diagnosticar convergencia con trace plots y R-hat

**Entregables:**
- [ ] EstimaciÃ³n de Ï€ con intervalos de confianza
- [ ] Muestreo de distribuciÃ³n objetivo con M-H
- [ ] Gibbs Sampler para mixture de Gaussianas
- [ ] AnÃ¡lisis de convergencia (burn-in, ESS)

### Lab 3: Cadenas de Markov (`Notebooks/Lab3_MarkovChains.py`)

**Objetivos:**
- Construir matriz de transiciÃ³n desde datos
- Calcular distribuciÃ³n estacionaria analÃ­tica y numÃ©ricamente
- Simular random walks y verificar convergencia
- Estimar mixing time empÃ­ricamente

**Entregables:**
- [ ] Matriz de transiciÃ³n para problema de clima
- [ ] CÃ¡lculo de eigenvector para Ï€
- [ ] SimulaciÃ³n de 10,000 pasos y histograma
- [ ] ComparaciÃ³n: teÃ³rico vs empÃ­rico

---

## ğŸ“Š Datasets Recomendados

| Dataset | Uso | Fuente |
|---------|-----|--------|
| Iris | EstimaciÃ³n de parÃ¡metros Gaussianos | sklearn.datasets |
| Weather transitions | Cadenas de Markov | SintÃ©tico |
| Beta-Binomial | MLE vs MAP | SintÃ©tico |
| 2D Gaussian Mixture | MCMC sampling | SintÃ©tico |

---

## âœ… Checklist de AutoevaluaciÃ³n

### TeorÃ­a (antes de avanzar a M05)

- [ ] Puedo derivar la regla de Bayes y explicar cada tÃ©rmino
- [ ] Puedo derivar MLE para distribuciÃ³n Gaussiana
- [ ] Entiendo la diferencia entre MLE y MAP
- [ ] Puedo construir una matriz de transiciÃ³n de Markov
- [ ] Entiendo quÃ© significa "estacionaria" y "ergÃ³dica"
- [ ] Puedo explicar por quÃ© funciona Metropolis-Hastings

### PrÃ¡ctica (Labs completados)

- [ ] Lab 1: MLE/MAP implementado y validado
- [ ] Lab 2: MCMC funcionando con diagnÃ³sticos
- [ ] Lab 3: Cadena de Markov simulada correctamente

### Ejercicios Tipo Examen

- [ ] Ejercicio 1.1-1.4 completados
- [ ] Ejercicio 2.1-2.3 completados
- [ ] Ejercicio 3.1-3.3 completados
- [ ] Ejercicio 4.1-4.2 completados

---

## ğŸ“ Estructura del MÃ³dulo

```
M04_Probabilidad_Estadistica/
â”œâ”€â”€ README.md                          # Este archivo (syllabus)
â”œâ”€â”€ Teoria/
â”‚   â”œâ”€â”€ 04_PROBABILIDAD_ML.md          # Fundamentos teÃ³ricos
â”‚   â””â”€â”€ markov_montecarlo.md           # DTMC + MCMC detallado
â”œâ”€â”€ Notebooks/
â”‚   â”œâ”€â”€ 01_distribuciones_mle.py       # IntroducciÃ³n
â”‚   â”œâ”€â”€ Lab1_MLE_MAP.py                # Lab obligatorio 1
â”‚   â”œâ”€â”€ Lab2_MonteCarlo_MCMC.py        # Lab obligatorio 2
â”‚   â””â”€â”€ Lab3_MarkovChains.py           # Lab obligatorio 3
â”œâ”€â”€ Laboratorios_Interactivos/
â”‚   â””â”€â”€ gmm_3_gaussians_contours.py    # VisualizaciÃ³n GMM
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_m04_labs.py               # Tests automÃ¡ticos
â””â”€â”€ assets/
```

---

## ğŸ“š Referencias Obligatorias

| Recurso | CapÃ­tulos | Prioridad |
|---------|-----------|-----------|
| **Murphy - ML: A Probabilistic Perspective** | Cap. 2, 3, 17, 24 | â­â­â­ |
| **Bishop - Pattern Recognition and ML** | Cap. 1.2, 2, 11 | â­â­â­ |
| **Levin & Peres - Markov Chains and Mixing Times** | Cap. 1-4 | â­â­ |
| **Goodfellow - Deep Learning** | Cap. 3 (Probability) | â­â­ |

Ver [REFERENCES.md](../REFERENCES.md) para lista completa con enlaces.

---

## ğŸ”— Conexiones con Otros MÃ³dulos

| MÃ³dulo | Concepto de M04 | AplicaciÃ³n |
|--------|-----------------|------------|
| **M05** | MLE/MAP | RegresiÃ³n logÃ­stica, regularizaciÃ³n |
| **M06** | EM Algorithm | GMM, clustering probabilÃ­stico |
| **M06** | Markov Chains | Sistemas de recomendaciÃ³n |
| **M07** | Bayes | Dropout como aproximaciÃ³n bayesiana |
| **M07** | Monte Carlo | Dropout, variational inference |
| **M08** | Probabilidad | Naive Bayes, language models |

---

## ğŸ”— NavegaciÃ³n

| Anterior | Ãndice | Siguiente |
|----------|--------|-----------|
| [â† M03: CÃ¡lculo](../M03_Calculo_Optimizacion/) | [README Principal](../README.md) | [M05: Supervisado â†’](../M05_Aprendizaje_Supervisado/) |
